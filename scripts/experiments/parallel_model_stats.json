{
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=8_scaler_type=identity_seed=789": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 789,
        "scores": {
            "smape": 0.09199618548154831,
            "mse": 490537696.0,
            "mae": 2097.20947265625,
            "r2_score": 0.894037127494812,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06464005261659622,
                "median": 0.03982824459671974,
                "std": 0.18293237686157227,
                "max": 0.41004979610443115,
                "min": -0.23985207080841064,
                "frobenius_norm": 1.900970458984375,
                "spectral_norm": 1.0516374111175537,
                "alpha": 1.4393005454584067,
                "alpha_hat": 2.335707895455146
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.11470700800418854,
                "median": 0.15999168157577515,
                "std": 0.22117236256599426,
                "max": 0.455912321805954,
                "min": -0.33733049035072327,
                "frobenius_norm": 1.9931869506835938,
                "spectral_norm": 1.4532947540283203,
                "alpha": 1.1556881033503619,
                "alpha_hat": 2.8974282454246985
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.038249608129262924,
                "median": 0.046950969845056534,
                "std": 0.2332790642976761,
                "max": 0.4613490104675293,
                "min": -0.39498400688171387,
                "frobenius_norm": 1.8911525011062622,
                "spectral_norm": 1.3486237525939941,
                "alpha": 1.1903256492222951,
                "alpha_hat": 2.0131528299969244
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04433397203683853,
                "median": 0.020143423229455948,
                "std": 0.22196604311466217,
                "max": 0.3826211988925934,
                "min": -0.342570036649704,
                "frobenius_norm": 1.8108017444610596,
                "spectral_norm": 1.1260747909545898,
                "alpha": 1.2220027782970186,
                "alpha_hat": 2.145135509257053
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=8_scaler_type=identity_seed=42": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 42,
        "scores": {
            "smape": 0.08539404720067978,
            "mse": 495138720.0,
            "mae": 2036.4228515625,
            "r2_score": 0.8930432200431824,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06464005261659622,
                "median": 0.03982824459671974,
                "std": 0.18293237686157227,
                "max": 0.41004979610443115,
                "min": -0.23985207080841064,
                "frobenius_norm": 1.900970458984375,
                "spectral_norm": 1.0516374111175537,
                "alpha": 1.4393005454584067,
                "alpha_hat": 2.335707895455146
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.11470700800418854,
                "median": 0.15999168157577515,
                "std": 0.22117236256599426,
                "max": 0.455912321805954,
                "min": -0.33733049035072327,
                "frobenius_norm": 1.9931869506835938,
                "spectral_norm": 1.4532947540283203,
                "alpha": 1.1556881033503619,
                "alpha_hat": 2.8974282454246985
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.038249608129262924,
                "median": 0.046950969845056534,
                "std": 0.2332790642976761,
                "max": 0.4613490104675293,
                "min": -0.39498400688171387,
                "frobenius_norm": 1.8911525011062622,
                "spectral_norm": 1.3486237525939941,
                "alpha": 1.1903256492222951,
                "alpha_hat": 2.0131528299969244
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04433397203683853,
                "median": 0.020143423229455948,
                "std": 0.22196604311466217,
                "max": 0.3826211988925934,
                "min": -0.342570036649704,
                "frobenius_norm": 1.8108017444610596,
                "spectral_norm": 1.1260747909545898,
                "alpha": 1.2220027782970186,
                "alpha_hat": 2.145135509257053
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=8_scaler_type=identity_seed=123": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 123,
        "scores": {
            "smape": 0.08470618724822998,
            "mse": 489893376.0,
            "mae": 1985.4432373046875,
            "r2_score": 0.8941762447357178,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06464005261659622,
                "median": 0.03982824459671974,
                "std": 0.18293237686157227,
                "max": 0.41004979610443115,
                "min": -0.23985207080841064,
                "frobenius_norm": 1.900970458984375,
                "spectral_norm": 1.0516374111175537,
                "alpha": 1.4393005454584067,
                "alpha_hat": 2.335707895455146
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.11470700800418854,
                "median": 0.15999168157577515,
                "std": 0.22117236256599426,
                "max": 0.455912321805954,
                "min": -0.33733049035072327,
                "frobenius_norm": 1.9931869506835938,
                "spectral_norm": 1.4532947540283203,
                "alpha": 1.1556881033503619,
                "alpha_hat": 2.8974282454246985
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.038249608129262924,
                "median": 0.046950969845056534,
                "std": 0.2332790642976761,
                "max": 0.4613490104675293,
                "min": -0.39498400688171387,
                "frobenius_norm": 1.8911525011062622,
                "spectral_norm": 1.3486237525939941,
                "alpha": 1.1903256492222951,
                "alpha_hat": 2.0131528299969244
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04433397203683853,
                "median": 0.020143423229455948,
                "std": 0.22196604311466217,
                "max": 0.3826211988925934,
                "min": -0.342570036649704,
                "frobenius_norm": 1.8108017444610596,
                "spectral_norm": 1.1260747909545898,
                "alpha": 1.2220027782970186,
                "alpha_hat": 2.145135509257053
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=8_scaler_type=identity_seed=456": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 456,
        "scores": {
            "smape": 0.0876530110836029,
            "mse": 474609920.0,
            "mae": 2080.901123046875,
            "r2_score": 0.8974777460098267,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06464005261659622,
                "median": 0.03982824459671974,
                "std": 0.18293237686157227,
                "max": 0.41004979610443115,
                "min": -0.23985207080841064,
                "frobenius_norm": 1.900970458984375,
                "spectral_norm": 1.0516374111175537,
                "alpha": 1.4393005454584067,
                "alpha_hat": 2.335707895455146
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.11470700800418854,
                "median": 0.15999168157577515,
                "std": 0.22117236256599426,
                "max": 0.455912321805954,
                "min": -0.33733049035072327,
                "frobenius_norm": 1.9931869506835938,
                "spectral_norm": 1.4532947540283203,
                "alpha": 1.1556881033503619,
                "alpha_hat": 2.8974282454246985
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.038249608129262924,
                "median": 0.046950969845056534,
                "std": 0.2332790642976761,
                "max": 0.4613490104675293,
                "min": -0.39498400688171387,
                "frobenius_norm": 1.8911525011062622,
                "spectral_norm": 1.3486237525939941,
                "alpha": 1.1903256492222951,
                "alpha_hat": 2.0131528299969244
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04433397203683853,
                "median": 0.020143423229455948,
                "std": 0.22196604311466217,
                "max": 0.3826211988925934,
                "min": -0.342570036649704,
                "frobenius_norm": 1.8108017444610596,
                "spectral_norm": 1.1260747909545898,
                "alpha": 1.2220027782970186,
                "alpha_hat": 2.145135509257053
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=8_scaler_type=identity_seed=1415": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1415,
        "scores": {
            "smape": 0.09656679630279541,
            "mse": 532536448.0,
            "mae": 2185.41259765625,
            "r2_score": 0.8849647641181946,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06915420293807983,
                "median": 0.07056509703397751,
                "std": 0.16325755417346954,
                "max": 0.3643658757209778,
                "min": -0.30343106389045715,
                "frobenius_norm": 1.7371792793273926,
                "spectral_norm": 0.955101728439331,
                "alpha": 1.5903129735765968,
                "alpha_hat": 2.20095060001035
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06027775630354881,
                "median": 0.08537417650222778,
                "std": 0.23239147663116455,
                "max": 0.4666557013988495,
                "min": -0.347915381193161,
                "frobenius_norm": 1.9206534624099731,
                "spectral_norm": 1.272744059562683,
                "alpha": 1.233321456048024,
                "alpha_hat": 2.0684017265802757
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.09219028800725937,
                "median": 0.04507412761449814,
                "std": 0.24254053831100464,
                "max": 0.609021008014679,
                "min": -0.30721262097358704,
                "frobenius_norm": 2.0757644176483154,
                "spectral_norm": 1.4190889596939087,
                "alpha": 1.1276333242729257,
                "alpha_hat": 3.250890135846739
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.1058669239282608,
                "median": 0.12373964488506317,
                "std": 0.18926997482776642,
                "max": 0.47327977418899536,
                "min": -0.27788156270980835,
                "frobenius_norm": 1.7349292039871216,
                "spectral_norm": 1.090621829032898,
                "alpha": 1.154111275027156,
                "alpha_hat": 1.4974131687136158
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=8_scaler_type=identity_seed=1213": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1213,
        "scores": {
            "smape": 0.0871180072426796,
            "mse": 489901504.0,
            "mae": 2044.5255126953125,
            "r2_score": 0.8941745162010193,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06915420293807983,
                "median": 0.07056509703397751,
                "std": 0.16325755417346954,
                "max": 0.3643658757209778,
                "min": -0.30343106389045715,
                "frobenius_norm": 1.7371792793273926,
                "spectral_norm": 0.955101728439331,
                "alpha": 1.5903129735765968,
                "alpha_hat": 2.20095060001035
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06027775630354881,
                "median": 0.08537417650222778,
                "std": 0.23239147663116455,
                "max": 0.4666557013988495,
                "min": -0.347915381193161,
                "frobenius_norm": 1.9206534624099731,
                "spectral_norm": 1.272744059562683,
                "alpha": 1.233321456048024,
                "alpha_hat": 2.0684017265802757
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.09219028800725937,
                "median": 0.04507412761449814,
                "std": 0.24254053831100464,
                "max": 0.609021008014679,
                "min": -0.30721262097358704,
                "frobenius_norm": 2.0757644176483154,
                "spectral_norm": 1.4190889596939087,
                "alpha": 1.1276333242729257,
                "alpha_hat": 3.250890135846739
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.1058669239282608,
                "median": 0.12373964488506317,
                "std": 0.18926997482776642,
                "max": 0.47327977418899536,
                "min": -0.27788156270980835,
                "frobenius_norm": 1.7349292039871216,
                "spectral_norm": 1.090621829032898,
                "alpha": 1.154111275027156,
                "alpha_hat": 1.4974131687136158
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=8_scaler_type=identity_seed=1617": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1617,
        "scores": {
            "smape": 0.0844448059797287,
            "mse": 497058752.0,
            "mae": 2001.8243408203125,
            "r2_score": 0.8926284313201904,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06915420293807983,
                "median": 0.07056509703397751,
                "std": 0.16325755417346954,
                "max": 0.3643658757209778,
                "min": -0.30343106389045715,
                "frobenius_norm": 1.7371792793273926,
                "spectral_norm": 0.955101728439331,
                "alpha": 1.5903129735765968,
                "alpha_hat": 2.20095060001035
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06027775630354881,
                "median": 0.08537417650222778,
                "std": 0.23239147663116455,
                "max": 0.4666557013988495,
                "min": -0.347915381193161,
                "frobenius_norm": 1.9206534624099731,
                "spectral_norm": 1.272744059562683,
                "alpha": 1.233321456048024,
                "alpha_hat": 2.0684017265802757
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.09219028800725937,
                "median": 0.04507412761449814,
                "std": 0.24254053831100464,
                "max": 0.609021008014679,
                "min": -0.30721262097358704,
                "frobenius_norm": 2.0757644176483154,
                "spectral_norm": 1.4190889596939087,
                "alpha": 1.1276333242729257,
                "alpha_hat": 3.250890135846739
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.1058669239282608,
                "median": 0.12373964488506317,
                "std": 0.18926997482776642,
                "max": 0.47327977418899536,
                "min": -0.27788156270980835,
                "frobenius_norm": 1.7349292039871216,
                "spectral_norm": 1.090621829032898,
                "alpha": 1.154111275027156,
                "alpha_hat": 1.4974131687136158
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=8_scaler_type=identity_seed=1011": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1011,
        "scores": {
            "smape": 0.08564665168523788,
            "mse": 476451616.0,
            "mae": 1988.677734375,
            "r2_score": 0.8970798850059509,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06915420293807983,
                "median": 0.07056509703397751,
                "std": 0.16325755417346954,
                "max": 0.3643658757209778,
                "min": -0.30343106389045715,
                "frobenius_norm": 1.7371792793273926,
                "spectral_norm": 0.955101728439331,
                "alpha": 1.5903129735765968,
                "alpha_hat": 2.20095060001035
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06027775630354881,
                "median": 0.08537417650222778,
                "std": 0.23239147663116455,
                "max": 0.4666557013988495,
                "min": -0.347915381193161,
                "frobenius_norm": 1.9206534624099731,
                "spectral_norm": 1.272744059562683,
                "alpha": 1.233321456048024,
                "alpha_hat": 2.0684017265802757
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.09219028800725937,
                "median": 0.04507412761449814,
                "std": 0.24254053831100464,
                "max": 0.609021008014679,
                "min": -0.30721262097358704,
                "frobenius_norm": 2.0757644176483154,
                "spectral_norm": 1.4190889596939087,
                "alpha": 1.1276333242729257,
                "alpha_hat": 3.250890135846739
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.1058669239282608,
                "median": 0.12373964488506317,
                "std": 0.18926997482776642,
                "max": 0.47327977418899536,
                "min": -0.27788156270980835,
                "frobenius_norm": 1.7349292039871216,
                "spectral_norm": 1.090621829032898,
                "alpha": 1.154111275027156,
                "alpha_hat": 1.4974131687136158
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=8_scaler_type=identity_seed=2021": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 2021,
        "scores": {
            "smape": 0.08711054921150208,
            "mse": 515887168.0,
            "mae": 2026.3277587890625,
            "r2_score": 0.8885612487792969,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.043843794614076614,
                "median": 0.03251907229423523,
                "std": 0.22750438749790192,
                "max": 0.595206081867218,
                "min": -0.6154820322990417,
                "frobenius_norm": 2.270094633102417,
                "spectral_norm": 1.4875121116638184,
                "alpha": 1.5165878408451383,
                "alpha_hat": 2.598183174625705
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.040674056857824326,
                "median": 0.06284704059362411,
                "std": 0.26729798316955566,
                "max": 0.589946985244751,
                "min": -0.6533570289611816,
                "frobenius_norm": 2.162999391555786,
                "spectral_norm": 1.4788559675216675,
                "alpha": 1.2062863127646914,
                "alpha_hat": 2.697167975439639
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.009580506943166256,
                "median": -0.0003565163351595402,
                "std": 0.24509526789188385,
                "max": 0.4417218863964081,
                "min": -0.4736759662628174,
                "frobenius_norm": 1.9622596502304077,
                "spectral_norm": 1.1950496435165405,
                "alpha": 1.298946403914483,
                "alpha_hat": 2.115316391609419
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.042544107884168625,
                "median": 0.05114039033651352,
                "std": 0.19781464338302612,
                "max": 0.4392780065536499,
                "min": -0.30448585748672485,
                "frobenius_norm": 1.6187034845352173,
                "spectral_norm": 0.9232165217399597,
                "alpha": 1.3607256054461696,
                "alpha_hat": 1.3739604117630642
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=8_scaler_type=identity_seed=1819": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1819,
        "scores": {
            "smape": 0.08661650121212006,
            "mse": 507499328.0,
            "mae": 1987.771728515625,
            "r2_score": 0.890373170375824,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.043843794614076614,
                "median": 0.03251907229423523,
                "std": 0.22750438749790192,
                "max": 0.595206081867218,
                "min": -0.6154820322990417,
                "frobenius_norm": 2.270094633102417,
                "spectral_norm": 1.4875121116638184,
                "alpha": 1.5165878408451383,
                "alpha_hat": 2.598183174625705
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.040674056857824326,
                "median": 0.06284704059362411,
                "std": 0.26729798316955566,
                "max": 0.589946985244751,
                "min": -0.6533570289611816,
                "frobenius_norm": 2.162999391555786,
                "spectral_norm": 1.4788559675216675,
                "alpha": 1.2062863127646914,
                "alpha_hat": 2.697167975439639
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.009580506943166256,
                "median": -0.0003565163351595402,
                "std": 0.24509526789188385,
                "max": 0.4417218863964081,
                "min": -0.4736759662628174,
                "frobenius_norm": 1.9622596502304077,
                "spectral_norm": 1.1950496435165405,
                "alpha": 1.298946403914483,
                "alpha_hat": 2.115316391609419
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.042544107884168625,
                "median": 0.05114039033651352,
                "std": 0.19781464338302612,
                "max": 0.4392780065536499,
                "min": -0.30448585748672485,
                "frobenius_norm": 1.6187034845352173,
                "spectral_norm": 0.9232165217399597,
                "alpha": 1.3607256054461696,
                "alpha_hat": 1.3739604117630642
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=8_scaler_type=standard_seed=123": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 123,
        "scores": {
            "smape": 0.07625913619995117,
            "mse": 482725792.0,
            "mae": 2073.77099609375,
            "r2_score": 0.8957245945930481,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.043843794614076614,
                "median": 0.03251907229423523,
                "std": 0.22750438749790192,
                "max": 0.595206081867218,
                "min": -0.6154820322990417,
                "frobenius_norm": 2.270094633102417,
                "spectral_norm": 1.4875121116638184,
                "alpha": 1.5165878408451383,
                "alpha_hat": 2.598183174625705
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.040674056857824326,
                "median": 0.06284704059362411,
                "std": 0.26729798316955566,
                "max": 0.589946985244751,
                "min": -0.6533570289611816,
                "frobenius_norm": 2.162999391555786,
                "spectral_norm": 1.4788559675216675,
                "alpha": 1.2062863127646914,
                "alpha_hat": 2.697167975439639
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.009580506943166256,
                "median": -0.0003565163351595402,
                "std": 0.24509526789188385,
                "max": 0.4417218863964081,
                "min": -0.4736759662628174,
                "frobenius_norm": 1.9622596502304077,
                "spectral_norm": 1.1950496435165405,
                "alpha": 1.298946403914483,
                "alpha_hat": 2.115316391609419
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.042544107884168625,
                "median": 0.05114039033651352,
                "std": 0.19781464338302612,
                "max": 0.4392780065536499,
                "min": -0.30448585748672485,
                "frobenius_norm": 1.6187034845352173,
                "spectral_norm": 0.9232165217399597,
                "alpha": 1.3607256054461696,
                "alpha_hat": 1.3739604117630642
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=8_scaler_type=standard_seed=42": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 42,
        "scores": {
            "smape": 0.07525523751974106,
            "mse": 505596800.0,
            "mae": 2040.0718994140625,
            "r2_score": 0.8907841444015503,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.043843794614076614,
                "median": 0.03251907229423523,
                "std": 0.22750438749790192,
                "max": 0.595206081867218,
                "min": -0.6154820322990417,
                "frobenius_norm": 2.270094633102417,
                "spectral_norm": 1.4875121116638184,
                "alpha": 1.5165878408451383,
                "alpha_hat": 2.598183174625705
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.040674056857824326,
                "median": 0.06284704059362411,
                "std": 0.26729798316955566,
                "max": 0.589946985244751,
                "min": -0.6533570289611816,
                "frobenius_norm": 2.162999391555786,
                "spectral_norm": 1.4788559675216675,
                "alpha": 1.2062863127646914,
                "alpha_hat": 2.697167975439639
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.009580506943166256,
                "median": -0.0003565163351595402,
                "std": 0.24509526789188385,
                "max": 0.4417218863964081,
                "min": -0.4736759662628174,
                "frobenius_norm": 1.9622596502304077,
                "spectral_norm": 1.1950496435165405,
                "alpha": 1.298946403914483,
                "alpha_hat": 2.115316391609419
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.042544107884168625,
                "median": 0.05114039033651352,
                "std": 0.19781464338302612,
                "max": 0.4392780065536499,
                "min": -0.30448585748672485,
                "frobenius_norm": 1.6187034845352173,
                "spectral_norm": 0.9232165217399597,
                "alpha": 1.3607256054461696,
                "alpha_hat": 1.3739604117630642
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=8_scaler_type=standard_seed=789": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 789,
        "scores": {
            "smape": 0.0747818648815155,
            "mse": 489605376.0,
            "mae": 2022.929443359375,
            "r2_score": 0.8942384719848633,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.03873974457383156,
                "median": 0.03912046551704407,
                "std": 0.22069275379180908,
                "max": 0.5618289113044739,
                "min": -0.563112199306488,
                "frobenius_norm": 2.1954002380371094,
                "spectral_norm": 1.5294615030288696,
                "alpha": 1.5790223204124398,
                "alpha_hat": 2.7312388120449946
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022713612765073776,
                "median": 0.04843361675739288,
                "std": 0.271024227142334,
                "max": 0.5069514513015747,
                "min": -0.611933708190918,
                "frobenius_norm": 2.1757946014404297,
                "spectral_norm": 1.4072128534317017,
                "alpha": 1.2061594801227398,
                "alpha_hat": 1.7488437383745798
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.021582651883363724,
                "median": -0.02278102934360504,
                "std": 0.24410755932331085,
                "max": 0.7747266292572021,
                "min": -0.3317151963710785,
                "frobenius_norm": 1.9604785442352295,
                "spectral_norm": 1.1748735904693604,
                "alpha": 1.1637445819178593,
                "alpha_hat": 2.2681603879341137
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.052389685064554214,
                "median": 0.037525251507759094,
                "std": 0.19685207307338715,
                "max": 0.5095969438552856,
                "min": -0.2514117360115051,
                "frobenius_norm": 1.6296337842941284,
                "spectral_norm": 0.9613553881645203,
                "alpha": 1.2775914728090672,
                "alpha_hat": 1.248807388440892
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=8_scaler_type=standard_seed=1011": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1011,
        "scores": {
            "smape": 0.07525801658630371,
            "mse": 492225504.0,
            "mae": 2024.6864013671875,
            "r2_score": 0.893672525882721,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.03873974457383156,
                "median": 0.03912046551704407,
                "std": 0.22069275379180908,
                "max": 0.5618289113044739,
                "min": -0.563112199306488,
                "frobenius_norm": 2.1954002380371094,
                "spectral_norm": 1.5294615030288696,
                "alpha": 1.5790223204124398,
                "alpha_hat": 2.7312388120449946
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022713612765073776,
                "median": 0.04843361675739288,
                "std": 0.271024227142334,
                "max": 0.5069514513015747,
                "min": -0.611933708190918,
                "frobenius_norm": 2.1757946014404297,
                "spectral_norm": 1.4072128534317017,
                "alpha": 1.2061594801227398,
                "alpha_hat": 1.7488437383745798
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.021582651883363724,
                "median": -0.02278102934360504,
                "std": 0.24410755932331085,
                "max": 0.7747266292572021,
                "min": -0.3317151963710785,
                "frobenius_norm": 1.9604785442352295,
                "spectral_norm": 1.1748735904693604,
                "alpha": 1.1637445819178593,
                "alpha_hat": 2.2681603879341137
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.052389685064554214,
                "median": 0.037525251507759094,
                "std": 0.19685207307338715,
                "max": 0.5095969438552856,
                "min": -0.2514117360115051,
                "frobenius_norm": 1.6296337842941284,
                "spectral_norm": 0.9613553881645203,
                "alpha": 1.2775914728090672,
                "alpha_hat": 1.248807388440892
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=8_scaler_type=standard_seed=456": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 456,
        "scores": {
            "smape": 0.0749703049659729,
            "mse": 499808992.0,
            "mae": 2048.8076171875,
            "r2_score": 0.8920343518257141,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.03873974457383156,
                "median": 0.03912046551704407,
                "std": 0.22069275379180908,
                "max": 0.5618289113044739,
                "min": -0.563112199306488,
                "frobenius_norm": 2.1954002380371094,
                "spectral_norm": 1.5294615030288696,
                "alpha": 1.5790223204124398,
                "alpha_hat": 2.7312388120449946
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022713612765073776,
                "median": 0.04843361675739288,
                "std": 0.271024227142334,
                "max": 0.5069514513015747,
                "min": -0.611933708190918,
                "frobenius_norm": 2.1757946014404297,
                "spectral_norm": 1.4072128534317017,
                "alpha": 1.2061594801227398,
                "alpha_hat": 1.7488437383745798
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.021582651883363724,
                "median": -0.02278102934360504,
                "std": 0.24410755932331085,
                "max": 0.7747266292572021,
                "min": -0.3317151963710785,
                "frobenius_norm": 1.9604785442352295,
                "spectral_norm": 1.1748735904693604,
                "alpha": 1.1637445819178593,
                "alpha_hat": 2.2681603879341137
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.052389685064554214,
                "median": 0.037525251507759094,
                "std": 0.19685207307338715,
                "max": 0.5095969438552856,
                "min": -0.2514117360115051,
                "frobenius_norm": 1.6296337842941284,
                "spectral_norm": 0.9613553881645203,
                "alpha": 1.2775914728090672,
                "alpha_hat": 1.248807388440892
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=8_scaler_type=standard_seed=1213": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1213,
        "scores": {
            "smape": 0.07538110762834549,
            "mse": 503369056.0,
            "mae": 2042.7545166015625,
            "r2_score": 0.891265332698822,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.03873974457383156,
                "median": 0.03912046551704407,
                "std": 0.22069275379180908,
                "max": 0.5618289113044739,
                "min": -0.563112199306488,
                "frobenius_norm": 2.1954002380371094,
                "spectral_norm": 1.5294615030288696,
                "alpha": 1.5790223204124398,
                "alpha_hat": 2.7312388120449946
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022713612765073776,
                "median": 0.04843361675739288,
                "std": 0.271024227142334,
                "max": 0.5069514513015747,
                "min": -0.611933708190918,
                "frobenius_norm": 2.1757946014404297,
                "spectral_norm": 1.4072128534317017,
                "alpha": 1.2061594801227398,
                "alpha_hat": 1.7488437383745798
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.021582651883363724,
                "median": -0.02278102934360504,
                "std": 0.24410755932331085,
                "max": 0.7747266292572021,
                "min": -0.3317151963710785,
                "frobenius_norm": 1.9604785442352295,
                "spectral_norm": 1.1748735904693604,
                "alpha": 1.1637445819178593,
                "alpha_hat": 2.2681603879341137
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.052389685064554214,
                "median": 0.037525251507759094,
                "std": 0.19685207307338715,
                "max": 0.5095969438552856,
                "min": -0.2514117360115051,
                "frobenius_norm": 1.6296337842941284,
                "spectral_norm": 0.9613553881645203,
                "alpha": 1.2775914728090672,
                "alpha_hat": 1.248807388440892
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=8_scaler_type=standard_seed=1819": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1819,
        "scores": {
            "smape": 0.07554197311401367,
            "mse": 504806592.0,
            "mae": 2049.552978515625,
            "r2_score": 0.8909547924995422,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.04216332733631134,
                "median": 0.02862975373864174,
                "std": 0.22515931725502014,
                "max": 0.5309051275253296,
                "min": -0.5388734936714172,
                "frobenius_norm": 2.24444842338562,
                "spectral_norm": 1.4710451364517212,
                "alpha": 1.4749215781565126,
                "alpha_hat": 2.4860186876699197
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.023066356778144836,
                "median": 0.0489942692220211,
                "std": 0.2641698718070984,
                "max": 0.616060733795166,
                "min": -0.6672312021255493,
                "frobenius_norm": 2.1213996410369873,
                "spectral_norm": 1.4744378328323364,
                "alpha": 1.2498209642335956,
                "alpha_hat": 2.1963801319705163
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.021503742784261703,
                "median": 0.004818175919353962,
                "std": 0.2540973126888275,
                "max": 0.8090000152587891,
                "min": -0.4235084056854248,
                "frobenius_norm": 2.0400450229644775,
                "spectral_norm": 1.3543027639389038,
                "alpha": 1.241910783710575,
                "alpha_hat": 2.9498250269843016
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06405185908079147,
                "median": 0.0570199191570282,
                "std": 0.19217969477176666,
                "max": 0.4886458218097687,
                "min": -0.23485167324543,
                "frobenius_norm": 1.6205811500549316,
                "spectral_norm": 0.9386008977890015,
                "alpha": 1.218311655722967,
                "alpha_hat": 1.1938495913617844
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=8_scaler_type=standard_seed=1617": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1617,
        "scores": {
            "smape": 0.07497566938400269,
            "mse": 501337376.0,
            "mae": 2045.2767333984375,
            "r2_score": 0.8917042016983032,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.04216332733631134,
                "median": 0.02862975373864174,
                "std": 0.22515931725502014,
                "max": 0.5309051275253296,
                "min": -0.5388734936714172,
                "frobenius_norm": 2.24444842338562,
                "spectral_norm": 1.4710451364517212,
                "alpha": 1.4749215781565126,
                "alpha_hat": 2.4860186876699197
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.023066356778144836,
                "median": 0.0489942692220211,
                "std": 0.2641698718070984,
                "max": 0.616060733795166,
                "min": -0.6672312021255493,
                "frobenius_norm": 2.1213996410369873,
                "spectral_norm": 1.4744378328323364,
                "alpha": 1.2498209642335956,
                "alpha_hat": 2.1963801319705163
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.021503742784261703,
                "median": 0.004818175919353962,
                "std": 0.2540973126888275,
                "max": 0.8090000152587891,
                "min": -0.4235084056854248,
                "frobenius_norm": 2.0400450229644775,
                "spectral_norm": 1.3543027639389038,
                "alpha": 1.241910783710575,
                "alpha_hat": 2.9498250269843016
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06405185908079147,
                "median": 0.0570199191570282,
                "std": 0.19217969477176666,
                "max": 0.4886458218097687,
                "min": -0.23485167324543,
                "frobenius_norm": 1.6205811500549316,
                "spectral_norm": 0.9386008977890015,
                "alpha": 1.218311655722967,
                "alpha_hat": 1.1938495913617844
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=8_scaler_type=standard_seed=1415": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1415,
        "scores": {
            "smape": 0.07489559054374695,
            "mse": 492957664.0,
            "mae": 2026.46337890625,
            "r2_score": 0.8935143351554871,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.04216332733631134,
                "median": 0.02862975373864174,
                "std": 0.22515931725502014,
                "max": 0.5309051275253296,
                "min": -0.5388734936714172,
                "frobenius_norm": 2.24444842338562,
                "spectral_norm": 1.4710451364517212,
                "alpha": 1.4749215781565126,
                "alpha_hat": 2.4860186876699197
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.023066356778144836,
                "median": 0.0489942692220211,
                "std": 0.2641698718070984,
                "max": 0.616060733795166,
                "min": -0.6672312021255493,
                "frobenius_norm": 2.1213996410369873,
                "spectral_norm": 1.4744378328323364,
                "alpha": 1.2498209642335956,
                "alpha_hat": 2.1963801319705163
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.021503742784261703,
                "median": 0.004818175919353962,
                "std": 0.2540973126888275,
                "max": 0.8090000152587891,
                "min": -0.4235084056854248,
                "frobenius_norm": 2.0400450229644775,
                "spectral_norm": 1.3543027639389038,
                "alpha": 1.241910783710575,
                "alpha_hat": 2.9498250269843016
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06405185908079147,
                "median": 0.0570199191570282,
                "std": 0.19217969477176666,
                "max": 0.4886458218097687,
                "min": -0.23485167324543,
                "frobenius_norm": 1.6205811500549316,
                "spectral_norm": 0.9386008977890015,
                "alpha": 1.218311655722967,
                "alpha_hat": 1.1938495913617844
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=8_scaler_type=standard_seed=2021": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 2021,
        "scores": {
            "smape": 0.07505179941654205,
            "mse": 498538784.0,
            "mae": 2034.9635009765625,
            "r2_score": 0.89230877161026,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.04216332733631134,
                "median": 0.02862975373864174,
                "std": 0.22515931725502014,
                "max": 0.5309051275253296,
                "min": -0.5388734936714172,
                "frobenius_norm": 2.24444842338562,
                "spectral_norm": 1.4710451364517212,
                "alpha": 1.4749215781565126,
                "alpha_hat": 2.4860186876699197
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.023066356778144836,
                "median": 0.0489942692220211,
                "std": 0.2641698718070984,
                "max": 0.616060733795166,
                "min": -0.6672312021255493,
                "frobenius_norm": 2.1213996410369873,
                "spectral_norm": 1.4744378328323364,
                "alpha": 1.2498209642335956,
                "alpha_hat": 2.1963801319705163
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.021503742784261703,
                "median": 0.004818175919353962,
                "std": 0.2540973126888275,
                "max": 0.8090000152587891,
                "min": -0.4235084056854248,
                "frobenius_norm": 2.0400450229644775,
                "spectral_norm": 1.3543027639389038,
                "alpha": 1.241910783710575,
                "alpha_hat": 2.9498250269843016
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06405185908079147,
                "median": 0.0570199191570282,
                "std": 0.19217969477176666,
                "max": 0.4886458218097687,
                "min": -0.23485167324543,
                "frobenius_norm": 1.6205811500549316,
                "spectral_norm": 0.9386008977890015,
                "alpha": 1.218311655722967,
                "alpha_hat": 1.1938495913617844
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=8_scaler_type=robust_seed=42": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 42,
        "scores": {
            "smape": 0.07474727183580399,
            "mse": 518273280.0,
            "mae": 2047.1138916015625,
            "r2_score": 0.8880458474159241,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.05419032275676727,
                "median": 0.043721139430999756,
                "std": 0.22177648544311523,
                "max": 0.5796747207641602,
                "min": -0.6177511811256409,
                "frobenius_norm": 2.2368850708007812,
                "spectral_norm": 1.5553195476531982,
                "alpha": 1.5097354654005741,
                "alpha_hat": 2.3071833632199277
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07121378183364868,
                "median": 0.1059282198548317,
                "std": 0.25867342948913574,
                "max": 0.5829203724861145,
                "min": -0.6702489256858826,
                "frobenius_norm": 2.146376848220825,
                "spectral_norm": 1.4638301134109497,
                "alpha": 1.2564979924463913,
                "alpha_hat": 2.5250417937507645
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.025268245488405228,
                "median": 0.014808999374508858,
                "std": 0.26086798310279846,
                "max": 0.8042773604393005,
                "min": -0.4812382459640503,
                "frobenius_norm": 2.0967111587524414,
                "spectral_norm": 1.3408653736114502,
                "alpha": 1.3064107790198234,
                "alpha_hat": 2.5813073831492077
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06431806087493896,
                "median": 0.05605830252170563,
                "std": 0.19387446343898773,
                "max": 0.5267611145973206,
                "min": -0.23729926347732544,
                "frobenius_norm": 1.6341185569763184,
                "spectral_norm": 0.9541508555412292,
                "alpha": 1.2425237220942889,
                "alpha_hat": 1.2388198241180466
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=8_scaler_type=robust_seed=123": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 123,
        "scores": {
            "smape": 0.0745679959654808,
            "mse": 517815232.0,
            "mae": 2051.061279296875,
            "r2_score": 0.8881447911262512,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.05419032275676727,
                "median": 0.043721139430999756,
                "std": 0.22177648544311523,
                "max": 0.5796747207641602,
                "min": -0.6177511811256409,
                "frobenius_norm": 2.2368850708007812,
                "spectral_norm": 1.5553195476531982,
                "alpha": 1.5097354654005741,
                "alpha_hat": 2.3071833632199277
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07121378183364868,
                "median": 0.1059282198548317,
                "std": 0.25867342948913574,
                "max": 0.5829203724861145,
                "min": -0.6702489256858826,
                "frobenius_norm": 2.146376848220825,
                "spectral_norm": 1.4638301134109497,
                "alpha": 1.2564979924463913,
                "alpha_hat": 2.5250417937507645
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.025268245488405228,
                "median": 0.014808999374508858,
                "std": 0.26086798310279846,
                "max": 0.8042773604393005,
                "min": -0.4812382459640503,
                "frobenius_norm": 2.0967111587524414,
                "spectral_norm": 1.3408653736114502,
                "alpha": 1.3064107790198234,
                "alpha_hat": 2.5813073831492077
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06431806087493896,
                "median": 0.05605830252170563,
                "std": 0.19387446343898773,
                "max": 0.5267611145973206,
                "min": -0.23729926347732544,
                "frobenius_norm": 1.6341185569763184,
                "spectral_norm": 0.9541508555412292,
                "alpha": 1.2425237220942889,
                "alpha_hat": 1.2388198241180466
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=8_scaler_type=robust_seed=456": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 456,
        "scores": {
            "smape": 0.07397644966840744,
            "mse": 509729088.0,
            "mae": 2059.48681640625,
            "r2_score": 0.889891505241394,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.05419032275676727,
                "median": 0.043721139430999756,
                "std": 0.22177648544311523,
                "max": 0.5796747207641602,
                "min": -0.6177511811256409,
                "frobenius_norm": 2.2368850708007812,
                "spectral_norm": 1.5553195476531982,
                "alpha": 1.5097354654005741,
                "alpha_hat": 2.3071833632199277
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07121378183364868,
                "median": 0.1059282198548317,
                "std": 0.25867342948913574,
                "max": 0.5829203724861145,
                "min": -0.6702489256858826,
                "frobenius_norm": 2.146376848220825,
                "spectral_norm": 1.4638301134109497,
                "alpha": 1.2564979924463913,
                "alpha_hat": 2.5250417937507645
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.025268245488405228,
                "median": 0.014808999374508858,
                "std": 0.26086798310279846,
                "max": 0.8042773604393005,
                "min": -0.4812382459640503,
                "frobenius_norm": 2.0967111587524414,
                "spectral_norm": 1.3408653736114502,
                "alpha": 1.3064107790198234,
                "alpha_hat": 2.5813073831492077
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06431806087493896,
                "median": 0.05605830252170563,
                "std": 0.19387446343898773,
                "max": 0.5267611145973206,
                "min": -0.23729926347732544,
                "frobenius_norm": 1.6341185569763184,
                "spectral_norm": 0.9541508555412292,
                "alpha": 1.2425237220942889,
                "alpha_hat": 1.2388198241180466
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=8_scaler_type=robust_seed=789": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 789,
        "scores": {
            "smape": 0.07437139749526978,
            "mse": 526745344.0,
            "mae": 2068.831787109375,
            "r2_score": 0.8862157464027405,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.05419032275676727,
                "median": 0.043721139430999756,
                "std": 0.22177648544311523,
                "max": 0.5796747207641602,
                "min": -0.6177511811256409,
                "frobenius_norm": 2.2368850708007812,
                "spectral_norm": 1.5553195476531982,
                "alpha": 1.5097354654005741,
                "alpha_hat": 2.3071833632199277
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07121378183364868,
                "median": 0.1059282198548317,
                "std": 0.25867342948913574,
                "max": 0.5829203724861145,
                "min": -0.6702489256858826,
                "frobenius_norm": 2.146376848220825,
                "spectral_norm": 1.4638301134109497,
                "alpha": 1.2564979924463913,
                "alpha_hat": 2.5250417937507645
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.025268245488405228,
                "median": 0.014808999374508858,
                "std": 0.26086798310279846,
                "max": 0.8042773604393005,
                "min": -0.4812382459640503,
                "frobenius_norm": 2.0967111587524414,
                "spectral_norm": 1.3408653736114502,
                "alpha": 1.3064107790198234,
                "alpha_hat": 2.5813073831492077
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06431806087493896,
                "median": 0.05605830252170563,
                "std": 0.19387446343898773,
                "max": 0.5267611145973206,
                "min": -0.23729926347732544,
                "frobenius_norm": 1.6341185569763184,
                "spectral_norm": 0.9541508555412292,
                "alpha": 1.2425237220942889,
                "alpha_hat": 1.2388198241180466
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=8_scaler_type=robust_seed=1213": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1213,
        "scores": {
            "smape": 0.07417015731334686,
            "mse": 522229472.0,
            "mae": 2040.31884765625,
            "r2_score": 0.8871912360191345,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.04477715864777565,
                "median": 0.04693308472633362,
                "std": 0.21814990043640137,
                "max": 0.5614593029022217,
                "min": -0.5851405262947083,
                "frobenius_norm": 2.181985378265381,
                "spectral_norm": 1.4987103939056396,
                "alpha": 1.5199800947210245,
                "alpha_hat": 2.3243850248365914
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07886648178100586,
                "median": 0.09421383589506149,
                "std": 0.25326013565063477,
                "max": 0.5003690123558044,
                "min": -0.6487371921539307,
                "frobenius_norm": 2.1220459938049316,
                "spectral_norm": 1.4689643383026123,
                "alpha": 1.1820943810864206,
                "alpha_hat": 2.702428134072698
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02718331106007099,
                "median": -0.007659954018890858,
                "std": 0.25486236810684204,
                "max": 0.8011415004730225,
                "min": -0.4246128499507904,
                "frobenius_norm": 2.0504634380340576,
                "spectral_norm": 1.2643934488296509,
                "alpha": 1.1907340012310628,
                "alpha_hat": 2.260874042459718
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05783193185925484,
                "median": 0.05240047723054886,
                "std": 0.19306699931621552,
                "max": 0.49444112181663513,
                "min": -0.2450386881828308,
                "frobenius_norm": 1.6123404502868652,
                "spectral_norm": 0.9272661805152893,
                "alpha": 1.2083965300617623,
                "alpha_hat": 1.2121302162302745
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=8_scaler_type=robust_seed=1011": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1011,
        "scores": {
            "smape": 0.07400984317064285,
            "mse": 509283392.0,
            "mae": 2101.681640625,
            "r2_score": 0.8899877667427063,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.04477715864777565,
                "median": 0.04693308472633362,
                "std": 0.21814990043640137,
                "max": 0.5614593029022217,
                "min": -0.5851405262947083,
                "frobenius_norm": 2.181985378265381,
                "spectral_norm": 1.4987103939056396,
                "alpha": 1.5199800947210245,
                "alpha_hat": 2.3243850248365914
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07886648178100586,
                "median": 0.09421383589506149,
                "std": 0.25326013565063477,
                "max": 0.5003690123558044,
                "min": -0.6487371921539307,
                "frobenius_norm": 2.1220459938049316,
                "spectral_norm": 1.4689643383026123,
                "alpha": 1.1820943810864206,
                "alpha_hat": 2.702428134072698
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02718331106007099,
                "median": -0.007659954018890858,
                "std": 0.25486236810684204,
                "max": 0.8011415004730225,
                "min": -0.4246128499507904,
                "frobenius_norm": 2.0504634380340576,
                "spectral_norm": 1.2643934488296509,
                "alpha": 1.1907340012310628,
                "alpha_hat": 2.260874042459718
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05783193185925484,
                "median": 0.05240047723054886,
                "std": 0.19306699931621552,
                "max": 0.49444112181663513,
                "min": -0.2450386881828308,
                "frobenius_norm": 1.6123404502868652,
                "spectral_norm": 0.9272661805152893,
                "alpha": 1.2083965300617623,
                "alpha_hat": 1.2121302162302745
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=8_scaler_type=robust_seed=1415": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1415,
        "scores": {
            "smape": 0.07397893071174622,
            "mse": 513894976.0,
            "mae": 2060.84619140625,
            "r2_score": 0.8889915943145752,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.04477715864777565,
                "median": 0.04693308472633362,
                "std": 0.21814990043640137,
                "max": 0.5614593029022217,
                "min": -0.5851405262947083,
                "frobenius_norm": 2.181985378265381,
                "spectral_norm": 1.4987103939056396,
                "alpha": 1.5199800947210245,
                "alpha_hat": 2.3243850248365914
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07886648178100586,
                "median": 0.09421383589506149,
                "std": 0.25326013565063477,
                "max": 0.5003690123558044,
                "min": -0.6487371921539307,
                "frobenius_norm": 2.1220459938049316,
                "spectral_norm": 1.4689643383026123,
                "alpha": 1.1820943810864206,
                "alpha_hat": 2.702428134072698
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02718331106007099,
                "median": -0.007659954018890858,
                "std": 0.25486236810684204,
                "max": 0.8011415004730225,
                "min": -0.4246128499507904,
                "frobenius_norm": 2.0504634380340576,
                "spectral_norm": 1.2643934488296509,
                "alpha": 1.1907340012310628,
                "alpha_hat": 2.260874042459718
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05783193185925484,
                "median": 0.05240047723054886,
                "std": 0.19306699931621552,
                "max": 0.49444112181663513,
                "min": -0.2450386881828308,
                "frobenius_norm": 1.6123404502868652,
                "spectral_norm": 0.9272661805152893,
                "alpha": 1.2083965300617623,
                "alpha_hat": 1.2121302162302745
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=8_scaler_type=robust_seed=1617": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1617,
        "scores": {
            "smape": 0.07459111511707306,
            "mse": 525466432.0,
            "mae": 2048.8017578125,
            "r2_score": 0.8864920139312744,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.04477715864777565,
                "median": 0.04693308472633362,
                "std": 0.21814990043640137,
                "max": 0.5614593029022217,
                "min": -0.5851405262947083,
                "frobenius_norm": 2.181985378265381,
                "spectral_norm": 1.4987103939056396,
                "alpha": 1.5199800947210245,
                "alpha_hat": 2.3243850248365914
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07886648178100586,
                "median": 0.09421383589506149,
                "std": 0.25326013565063477,
                "max": 0.5003690123558044,
                "min": -0.6487371921539307,
                "frobenius_norm": 2.1220459938049316,
                "spectral_norm": 1.4689643383026123,
                "alpha": 1.1820943810864206,
                "alpha_hat": 2.702428134072698
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02718331106007099,
                "median": -0.007659954018890858,
                "std": 0.25486236810684204,
                "max": 0.8011415004730225,
                "min": -0.4246128499507904,
                "frobenius_norm": 2.0504634380340576,
                "spectral_norm": 1.2643934488296509,
                "alpha": 1.1907340012310628,
                "alpha_hat": 2.260874042459718
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05783193185925484,
                "median": 0.05240047723054886,
                "std": 0.19306699931621552,
                "max": 0.49444112181663513,
                "min": -0.2450386881828308,
                "frobenius_norm": 1.6123404502868652,
                "spectral_norm": 0.9272661805152893,
                "alpha": 1.2083965300617623,
                "alpha_hat": 1.2121302162302745
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=8_scaler_type=minmax_seed=42": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 42,
        "scores": {
            "smape": 0.08343576639890671,
            "mse": 619537472.0,
            "mae": 2316.9267578125,
            "r2_score": 0.8661713600158691,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.05660364031791687,
                "median": 0.05073235183954239,
                "std": 0.21002371609210968,
                "max": 0.5497872233390808,
                "min": -0.5293592810630798,
                "frobenius_norm": 2.1312289237976074,
                "spectral_norm": 1.4661827087402344,
                "alpha": 1.4260767298303583,
                "alpha_hat": 2.1241682146147522
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0695466473698616,
                "median": 0.12392367422580719,
                "std": 0.25508418679237366,
                "max": 0.5591632723808289,
                "min": -0.6694671511650085,
                "frobenius_norm": 2.115159273147583,
                "spectral_norm": 1.4585291147232056,
                "alpha": 1.1864474440062907,
                "alpha_hat": 1.9648769261248642
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.017085719853639603,
                "median": -0.01959630288183689,
                "std": 0.2652426064014435,
                "max": 0.8331454396247864,
                "min": -0.4866134226322174,
                "frobenius_norm": 2.1263387203216553,
                "spectral_norm": 1.3936182260513306,
                "alpha": 1.1383444190058405,
                "alpha_hat": 2.390104125954728
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05772390216588974,
                "median": 0.04692419618368149,
                "std": 0.1897813081741333,
                "max": 0.4696246087551117,
                "min": -0.22852776944637299,
                "frobenius_norm": 1.5869265794754028,
                "spectral_norm": 0.8956881761550903,
                "alpha": 1.2038890306974956,
                "alpha_hat": 1.1912148120466792
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=8_scaler_type=robust_seed=1819": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1819,
        "scores": {
            "smape": 0.0745682567358017,
            "mse": 518047744.0,
            "mae": 2026.994140625,
            "r2_score": 0.8880945444107056,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.05660364031791687,
                "median": 0.05073235183954239,
                "std": 0.21002371609210968,
                "max": 0.5497872233390808,
                "min": -0.5293592810630798,
                "frobenius_norm": 2.1312289237976074,
                "spectral_norm": 1.4661827087402344,
                "alpha": 1.4260767298303583,
                "alpha_hat": 2.1241682146147522
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0695466473698616,
                "median": 0.12392367422580719,
                "std": 0.25508418679237366,
                "max": 0.5591632723808289,
                "min": -0.6694671511650085,
                "frobenius_norm": 2.115159273147583,
                "spectral_norm": 1.4585291147232056,
                "alpha": 1.1864474440062907,
                "alpha_hat": 1.9648769261248642
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.017085719853639603,
                "median": -0.01959630288183689,
                "std": 0.2652426064014435,
                "max": 0.8331454396247864,
                "min": -0.4866134226322174,
                "frobenius_norm": 2.1263387203216553,
                "spectral_norm": 1.3936182260513306,
                "alpha": 1.1383444190058405,
                "alpha_hat": 2.390104125954728
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05772390216588974,
                "median": 0.04692419618368149,
                "std": 0.1897813081741333,
                "max": 0.4696246087551117,
                "min": -0.22852776944637299,
                "frobenius_norm": 1.5869265794754028,
                "spectral_norm": 0.8956881761550903,
                "alpha": 1.2038890306974956,
                "alpha_hat": 1.1912148120466792
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=8_scaler_type=robust_seed=2021": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 2021,
        "scores": {
            "smape": 0.07402759045362473,
            "mse": 530686368.0,
            "mae": 2029.036865234375,
            "r2_score": 0.8853644132614136,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.05660364031791687,
                "median": 0.05073235183954239,
                "std": 0.21002371609210968,
                "max": 0.5497872233390808,
                "min": -0.5293592810630798,
                "frobenius_norm": 2.1312289237976074,
                "spectral_norm": 1.4661827087402344,
                "alpha": 1.4260767298303583,
                "alpha_hat": 2.1241682146147522
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0695466473698616,
                "median": 0.12392367422580719,
                "std": 0.25508418679237366,
                "max": 0.5591632723808289,
                "min": -0.6694671511650085,
                "frobenius_norm": 2.115159273147583,
                "spectral_norm": 1.4585291147232056,
                "alpha": 1.1864474440062907,
                "alpha_hat": 1.9648769261248642
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.017085719853639603,
                "median": -0.01959630288183689,
                "std": 0.2652426064014435,
                "max": 0.8331454396247864,
                "min": -0.4866134226322174,
                "frobenius_norm": 2.1263387203216553,
                "spectral_norm": 1.3936182260513306,
                "alpha": 1.1383444190058405,
                "alpha_hat": 2.390104125954728
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05772390216588974,
                "median": 0.04692419618368149,
                "std": 0.1897813081741333,
                "max": 0.4696246087551117,
                "min": -0.22852776944637299,
                "frobenius_norm": 1.5869265794754028,
                "spectral_norm": 0.8956881761550903,
                "alpha": 1.2038890306974956,
                "alpha_hat": 1.1912148120466792
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=8_scaler_type=minmax_seed=123": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 123,
        "scores": {
            "smape": 0.08630189299583435,
            "mse": 693798016.0,
            "mae": 2402.495849609375,
            "r2_score": 0.8501300811767578,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.05660364031791687,
                "median": 0.05073235183954239,
                "std": 0.21002371609210968,
                "max": 0.5497872233390808,
                "min": -0.5293592810630798,
                "frobenius_norm": 2.1312289237976074,
                "spectral_norm": 1.4661827087402344,
                "alpha": 1.4260767298303583,
                "alpha_hat": 2.1241682146147522
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0695466473698616,
                "median": 0.12392367422580719,
                "std": 0.25508418679237366,
                "max": 0.5591632723808289,
                "min": -0.6694671511650085,
                "frobenius_norm": 2.115159273147583,
                "spectral_norm": 1.4585291147232056,
                "alpha": 1.1864474440062907,
                "alpha_hat": 1.9648769261248642
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.017085719853639603,
                "median": -0.01959630288183689,
                "std": 0.2652426064014435,
                "max": 0.8331454396247864,
                "min": -0.4866134226322174,
                "frobenius_norm": 2.1263387203216553,
                "spectral_norm": 1.3936182260513306,
                "alpha": 1.1383444190058405,
                "alpha_hat": 2.390104125954728
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05772390216588974,
                "median": 0.04692419618368149,
                "std": 0.1897813081741333,
                "max": 0.4696246087551117,
                "min": -0.22852776944637299,
                "frobenius_norm": 1.5869265794754028,
                "spectral_norm": 0.8956881761550903,
                "alpha": 1.2038890306974956,
                "alpha_hat": 1.1912148120466792
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=8_scaler_type=minmax_seed=1011": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1011,
        "scores": {
            "smape": 0.08772429078817368,
            "mse": 729636928.0,
            "mae": 2473.558349609375,
            "r2_score": 0.842388391494751,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06576906889677048,
                "median": 0.05733764171600342,
                "std": 0.18900026381015778,
                "max": 0.5004959106445312,
                "min": -0.3263893723487854,
                "frobenius_norm": 1.9607346057891846,
                "spectral_norm": 1.3522875308990479,
                "alpha": 1.42137676109075,
                "alpha_hat": 2.1655957137972615
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0256710946559906,
                "median": 0.05904855579137802,
                "std": 0.24487623572349548,
                "max": 0.44891247153282166,
                "min": -0.6999765634536743,
                "frobenius_norm": 1.96974515914917,
                "spectral_norm": 1.2560566663742065,
                "alpha": 1.3824214652490396,
                "alpha_hat": 2.078636108578509
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0105301383882761,
                "median": 0.0027199527248740196,
                "std": 0.23635317385196686,
                "max": 0.6855414509773254,
                "min": -0.501273512840271,
                "frobenius_norm": 1.8927010297775269,
                "spectral_norm": 1.176173448562622,
                "alpha": 1.2507448543553779,
                "alpha_hat": 2.1089706650066526
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04814973846077919,
                "median": 0.03520173579454422,
                "std": 0.1906031221151352,
                "max": 0.42768988013267517,
                "min": -0.2650204598903656,
                "frobenius_norm": 1.5727263689041138,
                "spectral_norm": 0.8529982566833496,
                "alpha": 1.2752372083504913,
                "alpha_hat": 1.1841063141257242
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=8_scaler_type=minmax_seed=456": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 456,
        "scores": {
            "smape": 0.08739717304706573,
            "mse": 729232768.0,
            "mae": 2474.346923828125,
            "r2_score": 0.8424756526947021,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06576906889677048,
                "median": 0.05733764171600342,
                "std": 0.18900026381015778,
                "max": 0.5004959106445312,
                "min": -0.3263893723487854,
                "frobenius_norm": 1.9607346057891846,
                "spectral_norm": 1.3522875308990479,
                "alpha": 1.42137676109075,
                "alpha_hat": 2.1655957137972615
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0256710946559906,
                "median": 0.05904855579137802,
                "std": 0.24487623572349548,
                "max": 0.44891247153282166,
                "min": -0.6999765634536743,
                "frobenius_norm": 1.96974515914917,
                "spectral_norm": 1.2560566663742065,
                "alpha": 1.3824214652490396,
                "alpha_hat": 2.078636108578509
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0105301383882761,
                "median": 0.0027199527248740196,
                "std": 0.23635317385196686,
                "max": 0.6855414509773254,
                "min": -0.501273512840271,
                "frobenius_norm": 1.8927010297775269,
                "spectral_norm": 1.176173448562622,
                "alpha": 1.2507448543553779,
                "alpha_hat": 2.1089706650066526
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04814973846077919,
                "median": 0.03520173579454422,
                "std": 0.1906031221151352,
                "max": 0.42768988013267517,
                "min": -0.2650204598903656,
                "frobenius_norm": 1.5727263689041138,
                "spectral_norm": 0.8529982566833496,
                "alpha": 1.2752372083504913,
                "alpha_hat": 1.1841063141257242
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=8_scaler_type=minmax_seed=789": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 789,
        "scores": {
            "smape": 0.08801796287298203,
            "mse": 729932224.0,
            "mae": 2438.930908203125,
            "r2_score": 0.8423246145248413,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06576906889677048,
                "median": 0.05733764171600342,
                "std": 0.18900026381015778,
                "max": 0.5004959106445312,
                "min": -0.3263893723487854,
                "frobenius_norm": 1.9607346057891846,
                "spectral_norm": 1.3522875308990479,
                "alpha": 1.42137676109075,
                "alpha_hat": 2.1655957137972615
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0256710946559906,
                "median": 0.05904855579137802,
                "std": 0.24487623572349548,
                "max": 0.44891247153282166,
                "min": -0.6999765634536743,
                "frobenius_norm": 1.96974515914917,
                "spectral_norm": 1.2560566663742065,
                "alpha": 1.3824214652490396,
                "alpha_hat": 2.078636108578509
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0105301383882761,
                "median": 0.0027199527248740196,
                "std": 0.23635317385196686,
                "max": 0.6855414509773254,
                "min": -0.501273512840271,
                "frobenius_norm": 1.8927010297775269,
                "spectral_norm": 1.176173448562622,
                "alpha": 1.2507448543553779,
                "alpha_hat": 2.1089706650066526
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04814973846077919,
                "median": 0.03520173579454422,
                "std": 0.1906031221151352,
                "max": 0.42768988013267517,
                "min": -0.2650204598903656,
                "frobenius_norm": 1.5727263689041138,
                "spectral_norm": 0.8529982566833496,
                "alpha": 1.2752372083504913,
                "alpha_hat": 1.1841063141257242
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=8_scaler_type=minmax_seed=1213": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1213,
        "scores": {
            "smape": 0.0877964124083519,
            "mse": 718894144.0,
            "mae": 2432.294677734375,
            "r2_score": 0.8447089791297913,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06576906889677048,
                "median": 0.05733764171600342,
                "std": 0.18900026381015778,
                "max": 0.5004959106445312,
                "min": -0.3263893723487854,
                "frobenius_norm": 1.9607346057891846,
                "spectral_norm": 1.3522875308990479,
                "alpha": 1.42137676109075,
                "alpha_hat": 2.1655957137972615
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0256710946559906,
                "median": 0.05904855579137802,
                "std": 0.24487623572349548,
                "max": 0.44891247153282166,
                "min": -0.6999765634536743,
                "frobenius_norm": 1.96974515914917,
                "spectral_norm": 1.2560566663742065,
                "alpha": 1.3824214652490396,
                "alpha_hat": 2.078636108578509
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0105301383882761,
                "median": 0.0027199527248740196,
                "std": 0.23635317385196686,
                "max": 0.6855414509773254,
                "min": -0.501273512840271,
                "frobenius_norm": 1.8927010297775269,
                "spectral_norm": 1.176173448562622,
                "alpha": 1.2507448543553779,
                "alpha_hat": 2.1089706650066526
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04814973846077919,
                "median": 0.03520173579454422,
                "std": 0.1906031221151352,
                "max": 0.42768988013267517,
                "min": -0.2650204598903656,
                "frobenius_norm": 1.5727263689041138,
                "spectral_norm": 0.8529982566833496,
                "alpha": 1.2752372083504913,
                "alpha_hat": 1.1841063141257242
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=8_scaler_type=minmax_seed=1617": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1617,
        "scores": {
            "smape": 0.0821838229894638,
            "mse": 599206720.0,
            "mae": 2306.4951171875,
            "r2_score": 0.8705630898475647,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06063244864344597,
                "median": 0.052353598177433014,
                "std": 0.1943373680114746,
                "max": 0.4899812638759613,
                "min": -0.3260669708251953,
                "frobenius_norm": 1.9946321249008179,
                "spectral_norm": 1.3590197563171387,
                "alpha": 1.6403735201118563,
                "alpha_hat": 2.4288031280825177
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02133413776755333,
                "median": 0.04359698295593262,
                "std": 0.24619615077972412,
                "max": 0.439890593290329,
                "min": -0.612537145614624,
                "frobenius_norm": 1.9769502878189087,
                "spectral_norm": 1.13743257522583,
                "alpha": 1.3350902688155748,
                "alpha_hat": 1.8940996993582497
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02318725734949112,
                "median": -0.0005643805488944054,
                "std": 0.23696790635585785,
                "max": 0.6790247559547424,
                "min": -0.5063823461532593,
                "frobenius_norm": 1.904797077178955,
                "spectral_norm": 1.1935299634933472,
                "alpha": 1.2687935911333215,
                "alpha_hat": 2.0609347093860735
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.055124200880527496,
                "median": 0.0446358323097229,
                "std": 0.19095659255981445,
                "max": 0.4387265145778656,
                "min": -0.2639046311378479,
                "frobenius_norm": 1.5900309085845947,
                "spectral_norm": 0.8803536891937256,
                "alpha": 1.2603231375133377,
                "alpha_hat": 1.226222734638411
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=8_scaler_type=minmax_seed=1415": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1415,
        "scores": {
            "smape": 0.08899851143360138,
            "mse": 749962944.0,
            "mae": 2490.0849609375,
            "r2_score": 0.8379976749420166,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06063244864344597,
                "median": 0.052353598177433014,
                "std": 0.1943373680114746,
                "max": 0.4899812638759613,
                "min": -0.3260669708251953,
                "frobenius_norm": 1.9946321249008179,
                "spectral_norm": 1.3590197563171387,
                "alpha": 1.6403735201118563,
                "alpha_hat": 2.4288031280825177
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02133413776755333,
                "median": 0.04359698295593262,
                "std": 0.24619615077972412,
                "max": 0.439890593290329,
                "min": -0.612537145614624,
                "frobenius_norm": 1.9769502878189087,
                "spectral_norm": 1.13743257522583,
                "alpha": 1.3350902688155748,
                "alpha_hat": 1.8940996993582497
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02318725734949112,
                "median": -0.0005643805488944054,
                "std": 0.23696790635585785,
                "max": 0.6790247559547424,
                "min": -0.5063823461532593,
                "frobenius_norm": 1.904797077178955,
                "spectral_norm": 1.1935299634933472,
                "alpha": 1.2687935911333215,
                "alpha_hat": 2.0609347093860735
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.055124200880527496,
                "median": 0.0446358323097229,
                "std": 0.19095659255981445,
                "max": 0.4387265145778656,
                "min": -0.2639046311378479,
                "frobenius_norm": 1.5900309085845947,
                "spectral_norm": 0.8803536891937256,
                "alpha": 1.2603231375133377,
                "alpha_hat": 1.226222734638411
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=8_scaler_type=minmax_seed=1819": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1819,
        "scores": {
            "smape": 0.08451280742883682,
            "mse": 686709440.0,
            "mae": 2384.664794921875,
            "r2_score": 0.8516613245010376,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06063244864344597,
                "median": 0.052353598177433014,
                "std": 0.1943373680114746,
                "max": 0.4899812638759613,
                "min": -0.3260669708251953,
                "frobenius_norm": 1.9946321249008179,
                "spectral_norm": 1.3590197563171387,
                "alpha": 1.6403735201118563,
                "alpha_hat": 2.4288031280825177
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02133413776755333,
                "median": 0.04359698295593262,
                "std": 0.24619615077972412,
                "max": 0.439890593290329,
                "min": -0.612537145614624,
                "frobenius_norm": 1.9769502878189087,
                "spectral_norm": 1.13743257522583,
                "alpha": 1.3350902688155748,
                "alpha_hat": 1.8940996993582497
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02318725734949112,
                "median": -0.0005643805488944054,
                "std": 0.23696790635585785,
                "max": 0.6790247559547424,
                "min": -0.5063823461532593,
                "frobenius_norm": 1.904797077178955,
                "spectral_norm": 1.1935299634933472,
                "alpha": 1.2687935911333215,
                "alpha_hat": 2.0609347093860735
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.055124200880527496,
                "median": 0.0446358323097229,
                "std": 0.19095659255981445,
                "max": 0.4387265145778656,
                "min": -0.2639046311378479,
                "frobenius_norm": 1.5900309085845947,
                "spectral_norm": 0.8803536891937256,
                "alpha": 1.2603231375133377,
                "alpha_hat": 1.226222734638411
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=8_scaler_type=minmax_seed=2021": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 2021,
        "scores": {
            "smape": 0.08636011183261871,
            "mse": 658092544.0,
            "mae": 2348.6376953125,
            "r2_score": 0.8578429222106934,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06063244864344597,
                "median": 0.052353598177433014,
                "std": 0.1943373680114746,
                "max": 0.4899812638759613,
                "min": -0.3260669708251953,
                "frobenius_norm": 1.9946321249008179,
                "spectral_norm": 1.3590197563171387,
                "alpha": 1.6403735201118563,
                "alpha_hat": 2.4288031280825177
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02133413776755333,
                "median": 0.04359698295593262,
                "std": 0.24619615077972412,
                "max": 0.439890593290329,
                "min": -0.612537145614624,
                "frobenius_norm": 1.9769502878189087,
                "spectral_norm": 1.13743257522583,
                "alpha": 1.3350902688155748,
                "alpha_hat": 1.8940996993582497
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02318725734949112,
                "median": -0.0005643805488944054,
                "std": 0.23696790635585785,
                "max": 0.6790247559547424,
                "min": -0.5063823461532593,
                "frobenius_norm": 1.904797077178955,
                "spectral_norm": 1.1935299634933472,
                "alpha": 1.2687935911333215,
                "alpha_hat": 2.0609347093860735
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.055124200880527496,
                "median": 0.0446358323097229,
                "std": 0.19095659255981445,
                "max": 0.4387265145778656,
                "min": -0.2639046311378479,
                "frobenius_norm": 1.5900309085845947,
                "spectral_norm": 0.8803536891937256,
                "alpha": 1.2603231375133377,
                "alpha_hat": 1.226222734638411
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=16_scaler_type=identity_seed=42": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 42,
        "scores": {
            "smape": 0.08416789025068283,
            "mse": 506591680.0,
            "mae": 2014.8212890625,
            "r2_score": 0.8905692100524902,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.07177899032831192,
                "median": 0.07177664339542389,
                "std": 0.1656152606010437,
                "max": 0.37465742230415344,
                "min": -0.30424270033836365,
                "frobenius_norm": 1.7685420513153076,
                "spectral_norm": 0.9866408109664917,
                "alpha": 1.5445432682355396,
                "alpha_hat": 2.045815261874589
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.054401081055402756,
                "median": 0.08804962784051895,
                "std": 0.23639144003391266,
                "max": 0.447878360748291,
                "min": -0.39796411991119385,
                "frobenius_norm": 1.9405629634857178,
                "spectral_norm": 1.3203132152557373,
                "alpha": 1.2078054087516479,
                "alpha_hat": 2.1188453954735715
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.09245192259550095,
                "median": 0.05752827227115631,
                "std": 0.24971722066402435,
                "max": 0.6659411787986755,
                "min": -0.310713529586792,
                "frobenius_norm": 2.1302552223205566,
                "spectral_norm": 1.514011263847351,
                "alpha": 1.1960051637758302,
                "alpha_hat": 3.096597076474588
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.11498633027076721,
                "median": 0.12387265264987946,
                "std": 0.19194810092449188,
                "max": 0.5023963451385498,
                "min": -0.26572975516319275,
                "frobenius_norm": 1.7900333404541016,
                "spectral_norm": 1.145759105682373,
                "alpha": 1.1505090553779889,
                "alpha_hat": 1.4026564949125664
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=16_scaler_type=identity_seed=123": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 123,
        "scores": {
            "smape": 0.0848264992237091,
            "mse": 504850944.0,
            "mae": 2017.347900390625,
            "r2_score": 0.8909452557563782,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.07177899032831192,
                "median": 0.07177664339542389,
                "std": 0.1656152606010437,
                "max": 0.37465742230415344,
                "min": -0.30424270033836365,
                "frobenius_norm": 1.7685420513153076,
                "spectral_norm": 0.9866408109664917,
                "alpha": 1.5445432682355396,
                "alpha_hat": 2.045815261874589
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.054401081055402756,
                "median": 0.08804962784051895,
                "std": 0.23639144003391266,
                "max": 0.447878360748291,
                "min": -0.39796411991119385,
                "frobenius_norm": 1.9405629634857178,
                "spectral_norm": 1.3203132152557373,
                "alpha": 1.2078054087516479,
                "alpha_hat": 2.1188453954735715
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.09245192259550095,
                "median": 0.05752827227115631,
                "std": 0.24971722066402435,
                "max": 0.6659411787986755,
                "min": -0.310713529586792,
                "frobenius_norm": 2.1302552223205566,
                "spectral_norm": 1.514011263847351,
                "alpha": 1.1960051637758302,
                "alpha_hat": 3.096597076474588
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.11498633027076721,
                "median": 0.12387265264987946,
                "std": 0.19194810092449188,
                "max": 0.5023963451385498,
                "min": -0.26572975516319275,
                "frobenius_norm": 1.7900333404541016,
                "spectral_norm": 1.145759105682373,
                "alpha": 1.1505090553779889,
                "alpha_hat": 1.4026564949125664
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=16_scaler_type=identity_seed=456": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 456,
        "scores": {
            "smape": 0.08379282057285309,
            "mse": 497150880.0,
            "mae": 2005.53369140625,
            "r2_score": 0.8926085829734802,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.07177899032831192,
                "median": 0.07177664339542389,
                "std": 0.1656152606010437,
                "max": 0.37465742230415344,
                "min": -0.30424270033836365,
                "frobenius_norm": 1.7685420513153076,
                "spectral_norm": 0.9866408109664917,
                "alpha": 1.5445432682355396,
                "alpha_hat": 2.045815261874589
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.054401081055402756,
                "median": 0.08804962784051895,
                "std": 0.23639144003391266,
                "max": 0.447878360748291,
                "min": -0.39796411991119385,
                "frobenius_norm": 1.9405629634857178,
                "spectral_norm": 1.3203132152557373,
                "alpha": 1.2078054087516479,
                "alpha_hat": 2.1188453954735715
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.09245192259550095,
                "median": 0.05752827227115631,
                "std": 0.24971722066402435,
                "max": 0.6659411787986755,
                "min": -0.310713529586792,
                "frobenius_norm": 2.1302552223205566,
                "spectral_norm": 1.514011263847351,
                "alpha": 1.1960051637758302,
                "alpha_hat": 3.096597076474588
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.11498633027076721,
                "median": 0.12387265264987946,
                "std": 0.19194810092449188,
                "max": 0.5023963451385498,
                "min": -0.26572975516319275,
                "frobenius_norm": 1.7900333404541016,
                "spectral_norm": 1.145759105682373,
                "alpha": 1.1505090553779889,
                "alpha_hat": 1.4026564949125664
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=16_scaler_type=identity_seed=789": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 789,
        "scores": {
            "smape": 0.0866946280002594,
            "mse": 502684960.0,
            "mae": 2052.75244140625,
            "r2_score": 0.8914130926132202,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.07177899032831192,
                "median": 0.07177664339542389,
                "std": 0.1656152606010437,
                "max": 0.37465742230415344,
                "min": -0.30424270033836365,
                "frobenius_norm": 1.7685420513153076,
                "spectral_norm": 0.9866408109664917,
                "alpha": 1.5445432682355396,
                "alpha_hat": 2.045815261874589
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.054401081055402756,
                "median": 0.08804962784051895,
                "std": 0.23639144003391266,
                "max": 0.447878360748291,
                "min": -0.39796411991119385,
                "frobenius_norm": 1.9405629634857178,
                "spectral_norm": 1.3203132152557373,
                "alpha": 1.2078054087516479,
                "alpha_hat": 2.1188453954735715
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.09245192259550095,
                "median": 0.05752827227115631,
                "std": 0.24971722066402435,
                "max": 0.6659411787986755,
                "min": -0.310713529586792,
                "frobenius_norm": 2.1302552223205566,
                "spectral_norm": 1.514011263847351,
                "alpha": 1.1960051637758302,
                "alpha_hat": 3.096597076474588
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.11498633027076721,
                "median": 0.12387265264987946,
                "std": 0.19194810092449188,
                "max": 0.5023963451385498,
                "min": -0.26572975516319275,
                "frobenius_norm": 1.7900333404541016,
                "spectral_norm": 1.145759105682373,
                "alpha": 1.1505090553779889,
                "alpha_hat": 1.4026564949125664
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=16_scaler_type=identity_seed=1415": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1415,
        "scores": {
            "smape": 0.08277484029531479,
            "mse": 469556736.0,
            "mae": 1983.813232421875,
            "r2_score": 0.8985692858695984,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.07244644314050674,
                "median": 0.07633168995380402,
                "std": 0.1639581322669983,
                "max": 0.3700883686542511,
                "min": -0.28589197993278503,
                "frobenius_norm": 1.7562896013259888,
                "spectral_norm": 0.9649801850318909,
                "alpha": 1.5563966589647245,
                "alpha_hat": 1.9758374216476782
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0580843910574913,
                "median": 0.07930928468704224,
                "std": 0.23470358550548553,
                "max": 0.4471449553966522,
                "min": -0.3813815116882324,
                "frobenius_norm": 1.9342732429504395,
                "spectral_norm": 1.300881266593933,
                "alpha": 1.183464250163254,
                "alpha_hat": 2.0743164464281314
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.09467148035764694,
                "median": 0.06411925703287125,
                "std": 0.2521704137325287,
                "max": 0.6811526417732239,
                "min": -0.30982375144958496,
                "frobenius_norm": 2.1548473834991455,
                "spectral_norm": 1.540543556213379,
                "alpha": 1.1783582766041365,
                "alpha_hat": 3.0202263359726444
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.11447637528181076,
                "median": 0.12193342298269272,
                "std": 0.1916784793138504,
                "max": 0.5021336078643799,
                "min": -0.2639472782611847,
                "frobenius_norm": 1.7860881090164185,
                "spectral_norm": 1.1408520936965942,
                "alpha": 1.1530251268091534,
                "alpha_hat": 1.3964369577041833
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=16_scaler_type=identity_seed=1213": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1213,
        "scores": {
            "smape": 0.08468213677406311,
            "mse": 500113184.0,
            "mae": 2007.5205078125,
            "r2_score": 0.8919686675071716,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.07244644314050674,
                "median": 0.07633168995380402,
                "std": 0.1639581322669983,
                "max": 0.3700883686542511,
                "min": -0.28589197993278503,
                "frobenius_norm": 1.7562896013259888,
                "spectral_norm": 0.9649801850318909,
                "alpha": 1.5563966589647245,
                "alpha_hat": 1.9758374216476782
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0580843910574913,
                "median": 0.07930928468704224,
                "std": 0.23470358550548553,
                "max": 0.4471449553966522,
                "min": -0.3813815116882324,
                "frobenius_norm": 1.9342732429504395,
                "spectral_norm": 1.300881266593933,
                "alpha": 1.183464250163254,
                "alpha_hat": 2.0743164464281314
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.09467148035764694,
                "median": 0.06411925703287125,
                "std": 0.2521704137325287,
                "max": 0.6811526417732239,
                "min": -0.30982375144958496,
                "frobenius_norm": 2.1548473834991455,
                "spectral_norm": 1.540543556213379,
                "alpha": 1.1783582766041365,
                "alpha_hat": 3.0202263359726444
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.11447637528181076,
                "median": 0.12193342298269272,
                "std": 0.1916784793138504,
                "max": 0.5021336078643799,
                "min": -0.2639472782611847,
                "frobenius_norm": 1.7860881090164185,
                "spectral_norm": 1.1408520936965942,
                "alpha": 1.1530251268091534,
                "alpha_hat": 1.3964369577041833
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=16_scaler_type=identity_seed=1011": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1011,
        "scores": {
            "smape": 0.086209736764431,
            "mse": 504180032.0,
            "mae": 2018.7872314453125,
            "r2_score": 0.8910901546478271,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.07244644314050674,
                "median": 0.07633168995380402,
                "std": 0.1639581322669983,
                "max": 0.3700883686542511,
                "min": -0.28589197993278503,
                "frobenius_norm": 1.7562896013259888,
                "spectral_norm": 0.9649801850318909,
                "alpha": 1.5563966589647245,
                "alpha_hat": 1.9758374216476782
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0580843910574913,
                "median": 0.07930928468704224,
                "std": 0.23470358550548553,
                "max": 0.4471449553966522,
                "min": -0.3813815116882324,
                "frobenius_norm": 1.9342732429504395,
                "spectral_norm": 1.300881266593933,
                "alpha": 1.183464250163254,
                "alpha_hat": 2.0743164464281314
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.09467148035764694,
                "median": 0.06411925703287125,
                "std": 0.2521704137325287,
                "max": 0.6811526417732239,
                "min": -0.30982375144958496,
                "frobenius_norm": 2.1548473834991455,
                "spectral_norm": 1.540543556213379,
                "alpha": 1.1783582766041365,
                "alpha_hat": 3.0202263359726444
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.11447637528181076,
                "median": 0.12193342298269272,
                "std": 0.1916784793138504,
                "max": 0.5021336078643799,
                "min": -0.2639472782611847,
                "frobenius_norm": 1.7860881090164185,
                "spectral_norm": 1.1408520936965942,
                "alpha": 1.1530251268091534,
                "alpha_hat": 1.3964369577041833
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=16_scaler_type=identity_seed=1617": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1617,
        "scores": {
            "smape": 0.08669362962245941,
            "mse": 497114720.0,
            "mae": 2034.478515625,
            "r2_score": 0.8926163911819458,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.07244644314050674,
                "median": 0.07633168995380402,
                "std": 0.1639581322669983,
                "max": 0.3700883686542511,
                "min": -0.28589197993278503,
                "frobenius_norm": 1.7562896013259888,
                "spectral_norm": 0.9649801850318909,
                "alpha": 1.5563966589647245,
                "alpha_hat": 1.9758374216476782
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0580843910574913,
                "median": 0.07930928468704224,
                "std": 0.23470358550548553,
                "max": 0.4471449553966522,
                "min": -0.3813815116882324,
                "frobenius_norm": 1.9342732429504395,
                "spectral_norm": 1.300881266593933,
                "alpha": 1.183464250163254,
                "alpha_hat": 2.0743164464281314
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.09467148035764694,
                "median": 0.06411925703287125,
                "std": 0.2521704137325287,
                "max": 0.6811526417732239,
                "min": -0.30982375144958496,
                "frobenius_norm": 2.1548473834991455,
                "spectral_norm": 1.540543556213379,
                "alpha": 1.1783582766041365,
                "alpha_hat": 3.0202263359726444
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.11447637528181076,
                "median": 0.12193342298269272,
                "std": 0.1916784793138504,
                "max": 0.5021336078643799,
                "min": -0.2639472782611847,
                "frobenius_norm": 1.7860881090164185,
                "spectral_norm": 1.1408520936965942,
                "alpha": 1.1530251268091534,
                "alpha_hat": 1.3964369577041833
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=16_scaler_type=identity_seed=2021": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 2021,
        "scores": {
            "smape": 0.08938463032245636,
            "mse": 516665696.0,
            "mae": 2118.379638671875,
            "r2_score": 0.8883931040763855,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.05604124441742897,
                "median": 0.03709644824266434,
                "std": 0.23461389541625977,
                "max": 0.5386717319488525,
                "min": -0.5569496154785156,
                "frobenius_norm": 2.3634071350097656,
                "spectral_norm": 1.4830646514892578,
                "alpha": 1.4465809051468255,
                "alpha_hat": 2.4397258828253077
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.040799446403980255,
                "median": 0.09198752045631409,
                "std": 0.29232653975486755,
                "max": 0.6497326493263245,
                "min": -0.7708374261856079,
                "frobenius_norm": 2.3612794876098633,
                "spectral_norm": 1.5868116617202759,
                "alpha": 1.2594685068863956,
                "alpha_hat": 2.032126160099541
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01932571828365326,
                "median": 0.0198698490858078,
                "std": 0.26503339409828186,
                "max": 0.8489891290664673,
                "min": -0.48046931624412537,
                "frobenius_norm": 2.125896453857422,
                "spectral_norm": 1.3979206085205078,
                "alpha": 1.1700817897431397,
                "alpha_hat": 2.7929685921597818
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.059881698340177536,
                "median": 0.03212137520313263,
                "std": 0.19044624269008636,
                "max": 0.44813868403434753,
                "min": -0.23497503995895386,
                "frobenius_norm": 1.5971091985702515,
                "spectral_norm": 0.8855050802230835,
                "alpha": 1.216933411374999,
                "alpha_hat": 1.1521224773003993
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=16_scaler_type=identity_seed=1819": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1819,
        "scores": {
            "smape": 0.08318846672773361,
            "mse": 502923104.0,
            "mae": 2000.610595703125,
            "r2_score": 0.891361653804779,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.05604124441742897,
                "median": 0.03709644824266434,
                "std": 0.23461389541625977,
                "max": 0.5386717319488525,
                "min": -0.5569496154785156,
                "frobenius_norm": 2.3634071350097656,
                "spectral_norm": 1.4830646514892578,
                "alpha": 1.4465809051468255,
                "alpha_hat": 2.4397258828253077
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.040799446403980255,
                "median": 0.09198752045631409,
                "std": 0.29232653975486755,
                "max": 0.6497326493263245,
                "min": -0.7708374261856079,
                "frobenius_norm": 2.3612794876098633,
                "spectral_norm": 1.5868116617202759,
                "alpha": 1.2594685068863956,
                "alpha_hat": 2.032126160099541
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01932571828365326,
                "median": 0.0198698490858078,
                "std": 0.26503339409828186,
                "max": 0.8489891290664673,
                "min": -0.48046931624412537,
                "frobenius_norm": 2.125896453857422,
                "spectral_norm": 1.3979206085205078,
                "alpha": 1.1700817897431397,
                "alpha_hat": 2.7929685921597818
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.059881698340177536,
                "median": 0.03212137520313263,
                "std": 0.19044624269008636,
                "max": 0.44813868403434753,
                "min": -0.23497503995895386,
                "frobenius_norm": 1.5971091985702515,
                "spectral_norm": 0.8855050802230835,
                "alpha": 1.216933411374999,
                "alpha_hat": 1.1521224773003993
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=16_scaler_type=standard_seed=42": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 42,
        "scores": {
            "smape": 0.07479127496480942,
            "mse": 492118848.0,
            "mae": 2027.8604736328125,
            "r2_score": 0.8936955332756042,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.05604124441742897,
                "median": 0.03709644824266434,
                "std": 0.23461389541625977,
                "max": 0.5386717319488525,
                "min": -0.5569496154785156,
                "frobenius_norm": 2.3634071350097656,
                "spectral_norm": 1.4830646514892578,
                "alpha": 1.4465809051468255,
                "alpha_hat": 2.4397258828253077
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.040799446403980255,
                "median": 0.09198752045631409,
                "std": 0.29232653975486755,
                "max": 0.6497326493263245,
                "min": -0.7708374261856079,
                "frobenius_norm": 2.3612794876098633,
                "spectral_norm": 1.5868116617202759,
                "alpha": 1.2594685068863956,
                "alpha_hat": 2.032126160099541
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01932571828365326,
                "median": 0.0198698490858078,
                "std": 0.26503339409828186,
                "max": 0.8489891290664673,
                "min": -0.48046931624412537,
                "frobenius_norm": 2.125896453857422,
                "spectral_norm": 1.3979206085205078,
                "alpha": 1.1700817897431397,
                "alpha_hat": 2.7929685921597818
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.059881698340177536,
                "median": 0.03212137520313263,
                "std": 0.19044624269008636,
                "max": 0.44813868403434753,
                "min": -0.23497503995895386,
                "frobenius_norm": 1.5971091985702515,
                "spectral_norm": 0.8855050802230835,
                "alpha": 1.216933411374999,
                "alpha_hat": 1.1521224773003993
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=16_scaler_type=standard_seed=123": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 123,
        "scores": {
            "smape": 0.07480330765247345,
            "mse": 487944096.0,
            "mae": 2022.8553466796875,
            "r2_score": 0.8945973515510559,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.05604124441742897,
                "median": 0.03709644824266434,
                "std": 0.23461389541625977,
                "max": 0.5386717319488525,
                "min": -0.5569496154785156,
                "frobenius_norm": 2.3634071350097656,
                "spectral_norm": 1.4830646514892578,
                "alpha": 1.4465809051468255,
                "alpha_hat": 2.4397258828253077
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.040799446403980255,
                "median": 0.09198752045631409,
                "std": 0.29232653975486755,
                "max": 0.6497326493263245,
                "min": -0.7708374261856079,
                "frobenius_norm": 2.3612794876098633,
                "spectral_norm": 1.5868116617202759,
                "alpha": 1.2594685068863956,
                "alpha_hat": 2.032126160099541
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01932571828365326,
                "median": 0.0198698490858078,
                "std": 0.26503339409828186,
                "max": 0.8489891290664673,
                "min": -0.48046931624412537,
                "frobenius_norm": 2.125896453857422,
                "spectral_norm": 1.3979206085205078,
                "alpha": 1.1700817897431397,
                "alpha_hat": 2.7929685921597818
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.059881698340177536,
                "median": 0.03212137520313263,
                "std": 0.19044624269008636,
                "max": 0.44813868403434753,
                "min": -0.23497503995895386,
                "frobenius_norm": 1.5971091985702515,
                "spectral_norm": 0.8855050802230835,
                "alpha": 1.216933411374999,
                "alpha_hat": 1.1521224773003993
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=16_scaler_type=standard_seed=789": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 789,
        "scores": {
            "smape": 0.07459759712219238,
            "mse": 461844032.0,
            "mae": 1993.3658447265625,
            "r2_score": 0.9002352952957153,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.05079786852002144,
                "median": 0.03754556179046631,
                "std": 0.23348568379878998,
                "max": 0.5742321610450745,
                "min": -0.5453168153762817,
                "frobenius_norm": 2.3411996364593506,
                "spectral_norm": 1.4740864038467407,
                "alpha": 1.4631743142959643,
                "alpha_hat": 2.5358410920623053
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.017083194106817245,
                "median": 0.029648296535015106,
                "std": 0.27951493859291077,
                "max": 0.6597614288330078,
                "min": -0.7471596002578735,
                "frobenius_norm": 2.2402920722961426,
                "spectral_norm": 1.4744319915771484,
                "alpha": 1.2117116990820054,
                "alpha_hat": 2.7269646461311976
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01780342310667038,
                "median": 0.002386166714131832,
                "std": 0.26294073462486267,
                "max": 0.891014814376831,
                "min": -0.455803781747818,
                "frobenius_norm": 2.108341932296753,
                "spectral_norm": 1.422608494758606,
                "alpha": 1.2620754617180485,
                "alpha_hat": 3.6812232391741233
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0528264045715332,
                "median": 0.026773355901241302,
                "std": 0.19184499979019165,
                "max": 0.4496281147003174,
                "min": -0.23792769014835358,
                "frobenius_norm": 1.5918821096420288,
                "spectral_norm": 0.8724684715270996,
                "alpha": 1.223174805117691,
                "alpha_hat": 1.1335066820131519
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=16_scaler_type=standard_seed=456": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 456,
        "scores": {
            "smape": 0.07502507418394089,
            "mse": 491690784.0,
            "mae": 2044.0281982421875,
            "r2_score": 0.8937879800796509,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.05079786852002144,
                "median": 0.03754556179046631,
                "std": 0.23348568379878998,
                "max": 0.5742321610450745,
                "min": -0.5453168153762817,
                "frobenius_norm": 2.3411996364593506,
                "spectral_norm": 1.4740864038467407,
                "alpha": 1.4631743142959643,
                "alpha_hat": 2.5358410920623053
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.017083194106817245,
                "median": 0.029648296535015106,
                "std": 0.27951493859291077,
                "max": 0.6597614288330078,
                "min": -0.7471596002578735,
                "frobenius_norm": 2.2402920722961426,
                "spectral_norm": 1.4744319915771484,
                "alpha": 1.2117116990820054,
                "alpha_hat": 2.7269646461311976
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01780342310667038,
                "median": 0.002386166714131832,
                "std": 0.26294073462486267,
                "max": 0.891014814376831,
                "min": -0.455803781747818,
                "frobenius_norm": 2.108341932296753,
                "spectral_norm": 1.422608494758606,
                "alpha": 1.2620754617180485,
                "alpha_hat": 3.6812232391741233
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0528264045715332,
                "median": 0.026773355901241302,
                "std": 0.19184499979019165,
                "max": 0.4496281147003174,
                "min": -0.23792769014835358,
                "frobenius_norm": 1.5918821096420288,
                "spectral_norm": 0.8724684715270996,
                "alpha": 1.223174805117691,
                "alpha_hat": 1.1335066820131519
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=16_scaler_type=standard_seed=1011": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1011,
        "scores": {
            "smape": 0.0746108889579773,
            "mse": 493089952.0,
            "mae": 2029.75146484375,
            "r2_score": 0.8934857845306396,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.05079786852002144,
                "median": 0.03754556179046631,
                "std": 0.23348568379878998,
                "max": 0.5742321610450745,
                "min": -0.5453168153762817,
                "frobenius_norm": 2.3411996364593506,
                "spectral_norm": 1.4740864038467407,
                "alpha": 1.4631743142959643,
                "alpha_hat": 2.5358410920623053
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.017083194106817245,
                "median": 0.029648296535015106,
                "std": 0.27951493859291077,
                "max": 0.6597614288330078,
                "min": -0.7471596002578735,
                "frobenius_norm": 2.2402920722961426,
                "spectral_norm": 1.4744319915771484,
                "alpha": 1.2117116990820054,
                "alpha_hat": 2.7269646461311976
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01780342310667038,
                "median": 0.002386166714131832,
                "std": 0.26294073462486267,
                "max": 0.891014814376831,
                "min": -0.455803781747818,
                "frobenius_norm": 2.108341932296753,
                "spectral_norm": 1.422608494758606,
                "alpha": 1.2620754617180485,
                "alpha_hat": 3.6812232391741233
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0528264045715332,
                "median": 0.026773355901241302,
                "std": 0.19184499979019165,
                "max": 0.4496281147003174,
                "min": -0.23792769014835358,
                "frobenius_norm": 1.5918821096420288,
                "spectral_norm": 0.8724684715270996,
                "alpha": 1.223174805117691,
                "alpha_hat": 1.1335066820131519
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=16_scaler_type=standard_seed=1213": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1213,
        "scores": {
            "smape": 0.07501015067100525,
            "mse": 501819200.0,
            "mae": 2033.540283203125,
            "r2_score": 0.8916001319885254,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.05079786852002144,
                "median": 0.03754556179046631,
                "std": 0.23348568379878998,
                "max": 0.5742321610450745,
                "min": -0.5453168153762817,
                "frobenius_norm": 2.3411996364593506,
                "spectral_norm": 1.4740864038467407,
                "alpha": 1.4631743142959643,
                "alpha_hat": 2.5358410920623053
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.017083194106817245,
                "median": 0.029648296535015106,
                "std": 0.27951493859291077,
                "max": 0.6597614288330078,
                "min": -0.7471596002578735,
                "frobenius_norm": 2.2402920722961426,
                "spectral_norm": 1.4744319915771484,
                "alpha": 1.2117116990820054,
                "alpha_hat": 2.7269646461311976
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01780342310667038,
                "median": 0.002386166714131832,
                "std": 0.26294073462486267,
                "max": 0.891014814376831,
                "min": -0.455803781747818,
                "frobenius_norm": 2.108341932296753,
                "spectral_norm": 1.422608494758606,
                "alpha": 1.2620754617180485,
                "alpha_hat": 3.6812232391741233
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0528264045715332,
                "median": 0.026773355901241302,
                "std": 0.19184499979019165,
                "max": 0.4496281147003174,
                "min": -0.23792769014835358,
                "frobenius_norm": 1.5918821096420288,
                "spectral_norm": 0.8724684715270996,
                "alpha": 1.223174805117691,
                "alpha_hat": 1.1335066820131519
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=16_scaler_type=standard_seed=1415": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1415,
        "scores": {
            "smape": 0.07486704736948013,
            "mse": 497144416.0,
            "mae": 2036.8670654296875,
            "r2_score": 0.8926099538803101,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.040282588452100754,
                "median": 0.029558543115854263,
                "std": 0.23765692114830017,
                "max": 0.5960391163825989,
                "min": -0.6256370544433594,
                "frobenius_norm": 2.3617653846740723,
                "spectral_norm": 1.5802818536758423,
                "alpha": 1.5149045643277812,
                "alpha_hat": 2.749914316467037
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.017068475484848022,
                "median": 0.06770429760217667,
                "std": 0.2831774353981018,
                "max": 0.6623959541320801,
                "min": -0.7480639815330505,
                "frobenius_norm": 2.269531011581421,
                "spectral_norm": 1.6141529083251953,
                "alpha": 1.1765684044485267,
                "alpha_hat": 2.1834376734636765
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.014468112960457802,
                "median": 0.002409588545560837,
                "std": 0.2630443871021271,
                "max": 0.8555805087089539,
                "min": -0.4130134582519531,
                "frobenius_norm": 2.1075358390808105,
                "spectral_norm": 1.4579343795776367,
                "alpha": 1.2054285087635601,
                "alpha_hat": 2.8245157844994626
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.046424500644207,
                "median": 0.038637977093458176,
                "std": 0.19148463010787964,
                "max": 0.4736712872982025,
                "min": -0.2641944885253906,
                "frobenius_norm": 1.5762557983398438,
                "spectral_norm": 0.8923837542533875,
                "alpha": 1.3321284417259538,
                "alpha_hat": 1.317422257028455
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=16_scaler_type=standard_seed=1819": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1819,
        "scores": {
            "smape": 0.07486391067504883,
            "mse": 499678848.0,
            "mae": 2029.885498046875,
            "r2_score": 0.8920624852180481,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.040282588452100754,
                "median": 0.029558543115854263,
                "std": 0.23765692114830017,
                "max": 0.5960391163825989,
                "min": -0.6256370544433594,
                "frobenius_norm": 2.3617653846740723,
                "spectral_norm": 1.5802818536758423,
                "alpha": 1.5149045643277812,
                "alpha_hat": 2.749914316467037
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.017068475484848022,
                "median": 0.06770429760217667,
                "std": 0.2831774353981018,
                "max": 0.6623959541320801,
                "min": -0.7480639815330505,
                "frobenius_norm": 2.269531011581421,
                "spectral_norm": 1.6141529083251953,
                "alpha": 1.1765684044485267,
                "alpha_hat": 2.1834376734636765
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.014468112960457802,
                "median": 0.002409588545560837,
                "std": 0.2630443871021271,
                "max": 0.8555805087089539,
                "min": -0.4130134582519531,
                "frobenius_norm": 2.1075358390808105,
                "spectral_norm": 1.4579343795776367,
                "alpha": 1.2054285087635601,
                "alpha_hat": 2.8245157844994626
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.046424500644207,
                "median": 0.038637977093458176,
                "std": 0.19148463010787964,
                "max": 0.4736712872982025,
                "min": -0.2641944885253906,
                "frobenius_norm": 1.5762557983398438,
                "spectral_norm": 0.8923837542533875,
                "alpha": 1.3321284417259538,
                "alpha_hat": 1.317422257028455
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=16_scaler_type=standard_seed=1617": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1617,
        "scores": {
            "smape": 0.07490652054548264,
            "mse": 504027232.0,
            "mae": 2047.4449462890625,
            "r2_score": 0.8911231756210327,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.040282588452100754,
                "median": 0.029558543115854263,
                "std": 0.23765692114830017,
                "max": 0.5960391163825989,
                "min": -0.6256370544433594,
                "frobenius_norm": 2.3617653846740723,
                "spectral_norm": 1.5802818536758423,
                "alpha": 1.5149045643277812,
                "alpha_hat": 2.749914316467037
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.017068475484848022,
                "median": 0.06770429760217667,
                "std": 0.2831774353981018,
                "max": 0.6623959541320801,
                "min": -0.7480639815330505,
                "frobenius_norm": 2.269531011581421,
                "spectral_norm": 1.6141529083251953,
                "alpha": 1.1765684044485267,
                "alpha_hat": 2.1834376734636765
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.014468112960457802,
                "median": 0.002409588545560837,
                "std": 0.2630443871021271,
                "max": 0.8555805087089539,
                "min": -0.4130134582519531,
                "frobenius_norm": 2.1075358390808105,
                "spectral_norm": 1.4579343795776367,
                "alpha": 1.2054285087635601,
                "alpha_hat": 2.8245157844994626
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.046424500644207,
                "median": 0.038637977093458176,
                "std": 0.19148463010787964,
                "max": 0.4736712872982025,
                "min": -0.2641944885253906,
                "frobenius_norm": 1.5762557983398438,
                "spectral_norm": 0.8923837542533875,
                "alpha": 1.3321284417259538,
                "alpha_hat": 1.317422257028455
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=16_scaler_type=standard_seed=2021": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 2021,
        "scores": {
            "smape": 0.07495846599340439,
            "mse": 505627872.0,
            "mae": 2036.2005615234375,
            "r2_score": 0.8907774090766907,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.040282588452100754,
                "median": 0.029558543115854263,
                "std": 0.23765692114830017,
                "max": 0.5960391163825989,
                "min": -0.6256370544433594,
                "frobenius_norm": 2.3617653846740723,
                "spectral_norm": 1.5802818536758423,
                "alpha": 1.5149045643277812,
                "alpha_hat": 2.749914316467037
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.017068475484848022,
                "median": 0.06770429760217667,
                "std": 0.2831774353981018,
                "max": 0.6623959541320801,
                "min": -0.7480639815330505,
                "frobenius_norm": 2.269531011581421,
                "spectral_norm": 1.6141529083251953,
                "alpha": 1.1765684044485267,
                "alpha_hat": 2.1834376734636765
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.014468112960457802,
                "median": 0.002409588545560837,
                "std": 0.2630443871021271,
                "max": 0.8555805087089539,
                "min": -0.4130134582519531,
                "frobenius_norm": 2.1075358390808105,
                "spectral_norm": 1.4579343795776367,
                "alpha": 1.2054285087635601,
                "alpha_hat": 2.8245157844994626
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.046424500644207,
                "median": 0.038637977093458176,
                "std": 0.19148463010787964,
                "max": 0.4736712872982025,
                "min": -0.2641944885253906,
                "frobenius_norm": 1.5762557983398438,
                "spectral_norm": 0.8923837542533875,
                "alpha": 1.3321284417259538,
                "alpha_hat": 1.317422257028455
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=16_scaler_type=robust_seed=456": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 456,
        "scores": {
            "smape": 0.07371322810649872,
            "mse": 505243008.0,
            "mae": 2023.150146484375,
            "r2_score": 0.8908605575561523,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.05036015436053276,
                "median": 0.04270514100790024,
                "std": 0.22273942828178406,
                "max": 0.6754158139228821,
                "min": -0.5886420011520386,
                "frobenius_norm": 2.2374770641326904,
                "spectral_norm": 1.568111777305603,
                "alpha": 1.4950853588515567,
                "alpha_hat": 2.2683238910966663
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.10459385812282562,
                "median": 0.13318757712841034,
                "std": 0.27993667125701904,
                "max": 0.6413317322731018,
                "min": -0.7537670731544495,
                "frobenius_norm": 2.390707492828369,
                "spectral_norm": 1.7305233478546143,
                "alpha": 1.2564109331105564,
                "alpha_hat": 3.507039980886287
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.00043848250061273575,
                "median": 0.00011196499690413475,
                "std": 0.2535436451435089,
                "max": 0.48146963119506836,
                "min": -0.5960509181022644,
                "frobenius_norm": 2.0283522605895996,
                "spectral_norm": 1.201357364654541,
                "alpha": 1.2101317305158423,
                "alpha_hat": 2.207250848790421
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04749135673046112,
                "median": 0.04725123941898346,
                "std": 0.19060103595256805,
                "max": 0.44886255264282227,
                "min": -0.2789026200771332,
                "frobenius_norm": 1.571428656578064,
                "spectral_norm": 0.8759722113609314,
                "alpha": 1.3172823372329936,
                "alpha_hat": 1.2960748907094677
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=16_scaler_type=robust_seed=42": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 42,
        "scores": {
            "smape": 0.07429876923561096,
            "mse": 517248576.0,
            "mae": 2059.278076171875,
            "r2_score": 0.8882671594619751,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.05036015436053276,
                "median": 0.04270514100790024,
                "std": 0.22273942828178406,
                "max": 0.6754158139228821,
                "min": -0.5886420011520386,
                "frobenius_norm": 2.2374770641326904,
                "spectral_norm": 1.568111777305603,
                "alpha": 1.4950853588515567,
                "alpha_hat": 2.2683238910966663
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.10459385812282562,
                "median": 0.13318757712841034,
                "std": 0.27993667125701904,
                "max": 0.6413317322731018,
                "min": -0.7537670731544495,
                "frobenius_norm": 2.390707492828369,
                "spectral_norm": 1.7305233478546143,
                "alpha": 1.2564109331105564,
                "alpha_hat": 3.507039980886287
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.00043848250061273575,
                "median": 0.00011196499690413475,
                "std": 0.2535436451435089,
                "max": 0.48146963119506836,
                "min": -0.5960509181022644,
                "frobenius_norm": 2.0283522605895996,
                "spectral_norm": 1.201357364654541,
                "alpha": 1.2101317305158423,
                "alpha_hat": 2.207250848790421
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04749135673046112,
                "median": 0.04725123941898346,
                "std": 0.19060103595256805,
                "max": 0.44886255264282227,
                "min": -0.2789026200771332,
                "frobenius_norm": 1.571428656578064,
                "spectral_norm": 0.8759722113609314,
                "alpha": 1.3172823372329936,
                "alpha_hat": 1.2960748907094677
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=16_scaler_type=robust_seed=789": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 789,
        "scores": {
            "smape": 0.07479545474052429,
            "mse": 523592928.0,
            "mae": 2068.332763671875,
            "r2_score": 0.8868967294692993,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.05036015436053276,
                "median": 0.04270514100790024,
                "std": 0.22273942828178406,
                "max": 0.6754158139228821,
                "min": -0.5886420011520386,
                "frobenius_norm": 2.2374770641326904,
                "spectral_norm": 1.568111777305603,
                "alpha": 1.4950853588515567,
                "alpha_hat": 2.2683238910966663
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.10459385812282562,
                "median": 0.13318757712841034,
                "std": 0.27993667125701904,
                "max": 0.6413317322731018,
                "min": -0.7537670731544495,
                "frobenius_norm": 2.390707492828369,
                "spectral_norm": 1.7305233478546143,
                "alpha": 1.2564109331105564,
                "alpha_hat": 3.507039980886287
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.00043848250061273575,
                "median": 0.00011196499690413475,
                "std": 0.2535436451435089,
                "max": 0.48146963119506836,
                "min": -0.5960509181022644,
                "frobenius_norm": 2.0283522605895996,
                "spectral_norm": 1.201357364654541,
                "alpha": 1.2101317305158423,
                "alpha_hat": 2.207250848790421
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04749135673046112,
                "median": 0.04725123941898346,
                "std": 0.19060103595256805,
                "max": 0.44886255264282227,
                "min": -0.2789026200771332,
                "frobenius_norm": 1.571428656578064,
                "spectral_norm": 0.8759722113609314,
                "alpha": 1.3172823372329936,
                "alpha_hat": 1.2960748907094677
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=16_scaler_type=robust_seed=123": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 123,
        "scores": {
            "smape": 0.07351898401975632,
            "mse": 501865504.0,
            "mae": 2019.8590087890625,
            "r2_score": 0.8915901184082031,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.05036015436053276,
                "median": 0.04270514100790024,
                "std": 0.22273942828178406,
                "max": 0.6754158139228821,
                "min": -0.5886420011520386,
                "frobenius_norm": 2.2374770641326904,
                "spectral_norm": 1.568111777305603,
                "alpha": 1.4950853588515567,
                "alpha_hat": 2.2683238910966663
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.10459385812282562,
                "median": 0.13318757712841034,
                "std": 0.27993667125701904,
                "max": 0.6413317322731018,
                "min": -0.7537670731544495,
                "frobenius_norm": 2.390707492828369,
                "spectral_norm": 1.7305233478546143,
                "alpha": 1.2564109331105564,
                "alpha_hat": 3.507039980886287
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.00043848250061273575,
                "median": 0.00011196499690413475,
                "std": 0.2535436451435089,
                "max": 0.48146963119506836,
                "min": -0.5960509181022644,
                "frobenius_norm": 2.0283522605895996,
                "spectral_norm": 1.201357364654541,
                "alpha": 1.2101317305158423,
                "alpha_hat": 2.207250848790421
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04749135673046112,
                "median": 0.04725123941898346,
                "std": 0.19060103595256805,
                "max": 0.44886255264282227,
                "min": -0.2789026200771332,
                "frobenius_norm": 1.571428656578064,
                "spectral_norm": 0.8759722113609314,
                "alpha": 1.3172823372329936,
                "alpha_hat": 1.2960748907094677
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=16_scaler_type=robust_seed=1213": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1213,
        "scores": {
            "smape": 0.0739375427365303,
            "mse": 509480992.0,
            "mae": 2028.4388427734375,
            "r2_score": 0.8899450898170471,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.05303850397467613,
                "median": 0.05805327743291855,
                "std": 0.2286398559808731,
                "max": 0.6207082271575928,
                "min": -0.5923538208007812,
                "frobenius_norm": 2.2996890544891357,
                "spectral_norm": 1.5913857221603394,
                "alpha": 1.490849852962892,
                "alpha_hat": 2.4256469729507217
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08101114630699158,
                "median": 0.15054787695407867,
                "std": 0.27755481004714966,
                "max": 0.5536568760871887,
                "min": -0.7740583419799805,
                "frobenius_norm": 2.3130860328674316,
                "spectral_norm": 1.6650794744491577,
                "alpha": 1.2494776634792162,
                "alpha_hat": 2.7787641182059053
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.018563104793429375,
                "median": -0.005901333875954151,
                "std": 0.2610553503036499,
                "max": 0.8516896367073059,
                "min": -0.4182380437850952,
                "frobenius_norm": 2.0937161445617676,
                "spectral_norm": 1.3514519929885864,
                "alpha": 1.2259032693227687,
                "alpha_hat": 2.4746182610109413
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06607072055339813,
                "median": 0.052628591656684875,
                "std": 0.19253599643707275,
                "max": 0.5168519020080566,
                "min": -0.27962762117385864,
                "frobenius_norm": 1.6284559965133667,
                "spectral_norm": 0.9694679975509644,
                "alpha": 1.2462065518976067,
                "alpha_hat": 1.329465626414517
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=16_scaler_type=robust_seed=1011": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1011,
        "scores": {
            "smape": 0.07434861361980438,
            "mse": 526211264.0,
            "mae": 2065.558349609375,
            "r2_score": 0.8863310813903809,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.05303850397467613,
                "median": 0.05805327743291855,
                "std": 0.2286398559808731,
                "max": 0.6207082271575928,
                "min": -0.5923538208007812,
                "frobenius_norm": 2.2996890544891357,
                "spectral_norm": 1.5913857221603394,
                "alpha": 1.490849852962892,
                "alpha_hat": 2.4256469729507217
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08101114630699158,
                "median": 0.15054787695407867,
                "std": 0.27755481004714966,
                "max": 0.5536568760871887,
                "min": -0.7740583419799805,
                "frobenius_norm": 2.3130860328674316,
                "spectral_norm": 1.6650794744491577,
                "alpha": 1.2494776634792162,
                "alpha_hat": 2.7787641182059053
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.018563104793429375,
                "median": -0.005901333875954151,
                "std": 0.2610553503036499,
                "max": 0.8516896367073059,
                "min": -0.4182380437850952,
                "frobenius_norm": 2.0937161445617676,
                "spectral_norm": 1.3514519929885864,
                "alpha": 1.2259032693227687,
                "alpha_hat": 2.4746182610109413
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06607072055339813,
                "median": 0.052628591656684875,
                "std": 0.19253599643707275,
                "max": 0.5168519020080566,
                "min": -0.27962762117385864,
                "frobenius_norm": 1.6284559965133667,
                "spectral_norm": 0.9694679975509644,
                "alpha": 1.2462065518976067,
                "alpha_hat": 1.329465626414517
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=16_scaler_type=robust_seed=1617": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1617,
        "scores": {
            "smape": 0.07394144684076309,
            "mse": 524200384.0,
            "mae": 2065.1474609375,
            "r2_score": 0.8867654800415039,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.05303850397467613,
                "median": 0.05805327743291855,
                "std": 0.2286398559808731,
                "max": 0.6207082271575928,
                "min": -0.5923538208007812,
                "frobenius_norm": 2.2996890544891357,
                "spectral_norm": 1.5913857221603394,
                "alpha": 1.490849852962892,
                "alpha_hat": 2.4256469729507217
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08101114630699158,
                "median": 0.15054787695407867,
                "std": 0.27755481004714966,
                "max": 0.5536568760871887,
                "min": -0.7740583419799805,
                "frobenius_norm": 2.3130860328674316,
                "spectral_norm": 1.6650794744491577,
                "alpha": 1.2494776634792162,
                "alpha_hat": 2.7787641182059053
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.018563104793429375,
                "median": -0.005901333875954151,
                "std": 0.2610553503036499,
                "max": 0.8516896367073059,
                "min": -0.4182380437850952,
                "frobenius_norm": 2.0937161445617676,
                "spectral_norm": 1.3514519929885864,
                "alpha": 1.2259032693227687,
                "alpha_hat": 2.4746182610109413
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06607072055339813,
                "median": 0.052628591656684875,
                "std": 0.19253599643707275,
                "max": 0.5168519020080566,
                "min": -0.27962762117385864,
                "frobenius_norm": 1.6284559965133667,
                "spectral_norm": 0.9694679975509644,
                "alpha": 1.2462065518976067,
                "alpha_hat": 1.329465626414517
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=16_scaler_type=robust_seed=1415": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1415,
        "scores": {
            "smape": 0.07367929816246033,
            "mse": 510597504.0,
            "mae": 2056.68603515625,
            "r2_score": 0.8897038698196411,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.05303850397467613,
                "median": 0.05805327743291855,
                "std": 0.2286398559808731,
                "max": 0.6207082271575928,
                "min": -0.5923538208007812,
                "frobenius_norm": 2.2996890544891357,
                "spectral_norm": 1.5913857221603394,
                "alpha": 1.490849852962892,
                "alpha_hat": 2.4256469729507217
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08101114630699158,
                "median": 0.15054787695407867,
                "std": 0.27755481004714966,
                "max": 0.5536568760871887,
                "min": -0.7740583419799805,
                "frobenius_norm": 2.3130860328674316,
                "spectral_norm": 1.6650794744491577,
                "alpha": 1.2494776634792162,
                "alpha_hat": 2.7787641182059053
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.018563104793429375,
                "median": -0.005901333875954151,
                "std": 0.2610553503036499,
                "max": 0.8516896367073059,
                "min": -0.4182380437850952,
                "frobenius_norm": 2.0937161445617676,
                "spectral_norm": 1.3514519929885864,
                "alpha": 1.2259032693227687,
                "alpha_hat": 2.4746182610109413
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06607072055339813,
                "median": 0.052628591656684875,
                "std": 0.19253599643707275,
                "max": 0.5168519020080566,
                "min": -0.27962762117385864,
                "frobenius_norm": 1.6284559965133667,
                "spectral_norm": 0.9694679975509644,
                "alpha": 1.2462065518976067,
                "alpha_hat": 1.329465626414517
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=16_scaler_type=minmax_seed=123": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 123,
        "scores": {
            "smape": 0.0833619087934494,
            "mse": 668053568.0,
            "mae": 2364.97900390625,
            "r2_score": 0.8556911945343018,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.05496320128440857,
                "median": 0.04489433020353317,
                "std": 0.22065898776054382,
                "max": 0.6053951382637024,
                "min": -0.5792112350463867,
                "frobenius_norm": 2.2280685901641846,
                "spectral_norm": 1.5098247528076172,
                "alpha": 1.506535389948598,
                "alpha_hat": 2.382217813576678
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06490819901227951,
                "median": 0.09444719552993774,
                "std": 0.2903444468975067,
                "max": 0.5747959017753601,
                "min": -0.7426148056983948,
                "frobenius_norm": 2.3800904750823975,
                "spectral_norm": 1.6486676931381226,
                "alpha": 1.1909623017452877,
                "alpha_hat": 2.5413520607364792
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.015406179241836071,
                "median": 0.037776242941617966,
                "std": 0.27038830518722534,
                "max": 0.8620643615722656,
                "min": -0.5580230355262756,
                "frobenius_norm": 2.1666147708892822,
                "spectral_norm": 1.4473249912261963,
                "alpha": 1.136943418422404,
                "alpha_hat": 2.4115332192547503
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0669412687420845,
                "median": 0.054260242730379105,
                "std": 0.1912485957145691,
                "max": 0.48622703552246094,
                "min": -0.2272392362356186,
                "frobenius_norm": 1.6210054159164429,
                "spectral_norm": 0.9242535829544067,
                "alpha": 1.238474698828057,
                "alpha_hat": 1.2233927707109273
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=16_scaler_type=minmax_seed=42": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 42,
        "scores": {
            "smape": 0.08335257321596146,
            "mse": 644565120.0,
            "mae": 2349.343505859375,
            "r2_score": 0.8607650399208069,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.05496320128440857,
                "median": 0.04489433020353317,
                "std": 0.22065898776054382,
                "max": 0.6053951382637024,
                "min": -0.5792112350463867,
                "frobenius_norm": 2.2280685901641846,
                "spectral_norm": 1.5098247528076172,
                "alpha": 1.506535389948598,
                "alpha_hat": 2.382217813576678
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06490819901227951,
                "median": 0.09444719552993774,
                "std": 0.2903444468975067,
                "max": 0.5747959017753601,
                "min": -0.7426148056983948,
                "frobenius_norm": 2.3800904750823975,
                "spectral_norm": 1.6486676931381226,
                "alpha": 1.1909623017452877,
                "alpha_hat": 2.5413520607364792
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.015406179241836071,
                "median": 0.037776242941617966,
                "std": 0.27038830518722534,
                "max": 0.8620643615722656,
                "min": -0.5580230355262756,
                "frobenius_norm": 2.1666147708892822,
                "spectral_norm": 1.4473249912261963,
                "alpha": 1.136943418422404,
                "alpha_hat": 2.4115332192547503
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0669412687420845,
                "median": 0.054260242730379105,
                "std": 0.1912485957145691,
                "max": 0.48622703552246094,
                "min": -0.2272392362356186,
                "frobenius_norm": 1.6210054159164429,
                "spectral_norm": 0.9242535829544067,
                "alpha": 1.238474698828057,
                "alpha_hat": 1.2233927707109273
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=16_scaler_type=robust_seed=1819": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1819,
        "scores": {
            "smape": 0.07408001273870468,
            "mse": 503510592.0,
            "mae": 2024.8062744140625,
            "r2_score": 0.8912347555160522,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.05496320128440857,
                "median": 0.04489433020353317,
                "std": 0.22065898776054382,
                "max": 0.6053951382637024,
                "min": -0.5792112350463867,
                "frobenius_norm": 2.2280685901641846,
                "spectral_norm": 1.5098247528076172,
                "alpha": 1.506535389948598,
                "alpha_hat": 2.382217813576678
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06490819901227951,
                "median": 0.09444719552993774,
                "std": 0.2903444468975067,
                "max": 0.5747959017753601,
                "min": -0.7426148056983948,
                "frobenius_norm": 2.3800904750823975,
                "spectral_norm": 1.6486676931381226,
                "alpha": 1.1909623017452877,
                "alpha_hat": 2.5413520607364792
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.015406179241836071,
                "median": 0.037776242941617966,
                "std": 0.27038830518722534,
                "max": 0.8620643615722656,
                "min": -0.5580230355262756,
                "frobenius_norm": 2.1666147708892822,
                "spectral_norm": 1.4473249912261963,
                "alpha": 1.136943418422404,
                "alpha_hat": 2.4115332192547503
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0669412687420845,
                "median": 0.054260242730379105,
                "std": 0.1912485957145691,
                "max": 0.48622703552246094,
                "min": -0.2272392362356186,
                "frobenius_norm": 1.6210054159164429,
                "spectral_norm": 0.9242535829544067,
                "alpha": 1.238474698828057,
                "alpha_hat": 1.2233927707109273
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=16_scaler_type=robust_seed=2021": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 2021,
        "scores": {
            "smape": 0.07497025281190872,
            "mse": 435250752.0,
            "mae": 2083.826904296875,
            "r2_score": 0.9059798717498779,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.05496320128440857,
                "median": 0.04489433020353317,
                "std": 0.22065898776054382,
                "max": 0.6053951382637024,
                "min": -0.5792112350463867,
                "frobenius_norm": 2.2280685901641846,
                "spectral_norm": 1.5098247528076172,
                "alpha": 1.506535389948598,
                "alpha_hat": 2.382217813576678
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06490819901227951,
                "median": 0.09444719552993774,
                "std": 0.2903444468975067,
                "max": 0.5747959017753601,
                "min": -0.7426148056983948,
                "frobenius_norm": 2.3800904750823975,
                "spectral_norm": 1.6486676931381226,
                "alpha": 1.1909623017452877,
                "alpha_hat": 2.5413520607364792
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.015406179241836071,
                "median": 0.037776242941617966,
                "std": 0.27038830518722534,
                "max": 0.8620643615722656,
                "min": -0.5580230355262756,
                "frobenius_norm": 2.1666147708892822,
                "spectral_norm": 1.4473249912261963,
                "alpha": 1.136943418422404,
                "alpha_hat": 2.4115332192547503
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0669412687420845,
                "median": 0.054260242730379105,
                "std": 0.1912485957145691,
                "max": 0.48622703552246094,
                "min": -0.2272392362356186,
                "frobenius_norm": 1.6210054159164429,
                "spectral_norm": 0.9242535829544067,
                "alpha": 1.238474698828057,
                "alpha_hat": 1.2233927707109273
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=16_scaler_type=minmax_seed=789": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 789,
        "scores": {
            "smape": 0.08451024442911148,
            "mse": 677939648.0,
            "mae": 2391.5048828125,
            "r2_score": 0.8535556793212891,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06023523584008217,
                "median": 0.05148541182279587,
                "std": 0.19732201099395752,
                "max": 0.5527331233024597,
                "min": -0.3271865248680115,
                "frobenius_norm": 2.0214273929595947,
                "spectral_norm": 1.4068714380264282,
                "alpha": 1.4779539053306434,
                "alpha_hat": 2.2797490365514674
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.036911044269800186,
                "median": 0.03486476093530655,
                "std": 0.26442354917526245,
                "max": 0.4379890263080597,
                "min": -0.7403846383094788,
                "frobenius_norm": 2.1358985900878906,
                "spectral_norm": 1.3723082542419434,
                "alpha": 1.282003775125176,
                "alpha_hat": 2.071211552029654
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.024040397256612778,
                "median": 0.017247550189495087,
                "std": 0.23967476189136505,
                "max": 0.6647711992263794,
                "min": -0.5117553472518921,
                "frobenius_norm": 1.9270193576812744,
                "spectral_norm": 1.2001644372940063,
                "alpha": 1.2277691519072627,
                "alpha_hat": 1.8837563663172323
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04748247563838959,
                "median": 0.038083985447883606,
                "std": 0.19220884144306183,
                "max": 0.4218962788581848,
                "min": -0.27369225025177,
                "frobenius_norm": 1.5838953256607056,
                "spectral_norm": 0.857269287109375,
                "alpha": 1.2753273144108959,
                "alpha_hat": 1.1856866488661566
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=16_scaler_type=minmax_seed=1213": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1213,
        "scores": {
            "smape": 0.07912209630012512,
            "mse": 537674240.0,
            "mae": 2267.903076171875,
            "r2_score": 0.8838549852371216,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06023523584008217,
                "median": 0.05148541182279587,
                "std": 0.19732201099395752,
                "max": 0.5527331233024597,
                "min": -0.3271865248680115,
                "frobenius_norm": 2.0214273929595947,
                "spectral_norm": 1.4068714380264282,
                "alpha": 1.4779539053306434,
                "alpha_hat": 2.2797490365514674
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.036911044269800186,
                "median": 0.03486476093530655,
                "std": 0.26442354917526245,
                "max": 0.4379890263080597,
                "min": -0.7403846383094788,
                "frobenius_norm": 2.1358985900878906,
                "spectral_norm": 1.3723082542419434,
                "alpha": 1.282003775125176,
                "alpha_hat": 2.071211552029654
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.024040397256612778,
                "median": 0.017247550189495087,
                "std": 0.23967476189136505,
                "max": 0.6647711992263794,
                "min": -0.5117553472518921,
                "frobenius_norm": 1.9270193576812744,
                "spectral_norm": 1.2001644372940063,
                "alpha": 1.2277691519072627,
                "alpha_hat": 1.8837563663172323
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04748247563838959,
                "median": 0.038083985447883606,
                "std": 0.19220884144306183,
                "max": 0.4218962788581848,
                "min": -0.27369225025177,
                "frobenius_norm": 1.5838953256607056,
                "spectral_norm": 0.857269287109375,
                "alpha": 1.2753273144108959,
                "alpha_hat": 1.1856866488661566
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=16_scaler_type=minmax_seed=1011": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1011,
        "scores": {
            "smape": 0.07892933487892151,
            "mse": 527862048.0,
            "mae": 2177.430419921875,
            "r2_score": 0.8859745264053345,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06023523584008217,
                "median": 0.05148541182279587,
                "std": 0.19732201099395752,
                "max": 0.5527331233024597,
                "min": -0.3271865248680115,
                "frobenius_norm": 2.0214273929595947,
                "spectral_norm": 1.4068714380264282,
                "alpha": 1.4779539053306434,
                "alpha_hat": 2.2797490365514674
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.036911044269800186,
                "median": 0.03486476093530655,
                "std": 0.26442354917526245,
                "max": 0.4379890263080597,
                "min": -0.7403846383094788,
                "frobenius_norm": 2.1358985900878906,
                "spectral_norm": 1.3723082542419434,
                "alpha": 1.282003775125176,
                "alpha_hat": 2.071211552029654
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.024040397256612778,
                "median": 0.017247550189495087,
                "std": 0.23967476189136505,
                "max": 0.6647711992263794,
                "min": -0.5117553472518921,
                "frobenius_norm": 1.9270193576812744,
                "spectral_norm": 1.2001644372940063,
                "alpha": 1.2277691519072627,
                "alpha_hat": 1.8837563663172323
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04748247563838959,
                "median": 0.038083985447883606,
                "std": 0.19220884144306183,
                "max": 0.4218962788581848,
                "min": -0.27369225025177,
                "frobenius_norm": 1.5838953256607056,
                "spectral_norm": 0.857269287109375,
                "alpha": 1.2753273144108959,
                "alpha_hat": 1.1856866488661566
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=16_scaler_type=minmax_seed=456": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 456,
        "scores": {
            "smape": 0.08673681318759918,
            "mse": 696165696.0,
            "mae": 2408.684814453125,
            "r2_score": 0.8496186137199402,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06023523584008217,
                "median": 0.05148541182279587,
                "std": 0.19732201099395752,
                "max": 0.5527331233024597,
                "min": -0.3271865248680115,
                "frobenius_norm": 2.0214273929595947,
                "spectral_norm": 1.4068714380264282,
                "alpha": 1.4779539053306434,
                "alpha_hat": 2.2797490365514674
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.036911044269800186,
                "median": 0.03486476093530655,
                "std": 0.26442354917526245,
                "max": 0.4379890263080597,
                "min": -0.7403846383094788,
                "frobenius_norm": 2.1358985900878906,
                "spectral_norm": 1.3723082542419434,
                "alpha": 1.282003775125176,
                "alpha_hat": 2.071211552029654
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.024040397256612778,
                "median": 0.017247550189495087,
                "std": 0.23967476189136505,
                "max": 0.6647711992263794,
                "min": -0.5117553472518921,
                "frobenius_norm": 1.9270193576812744,
                "spectral_norm": 1.2001644372940063,
                "alpha": 1.2277691519072627,
                "alpha_hat": 1.8837563663172323
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04748247563838959,
                "median": 0.038083985447883606,
                "std": 0.19220884144306183,
                "max": 0.4218962788581848,
                "min": -0.27369225025177,
                "frobenius_norm": 1.5838953256607056,
                "spectral_norm": 0.857269287109375,
                "alpha": 1.2753273144108959,
                "alpha_hat": 1.1856866488661566
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=16_scaler_type=minmax_seed=1617": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1617,
        "scores": {
            "smape": 0.08147284388542175,
            "mse": 543606144.0,
            "mae": 2258.27685546875,
            "r2_score": 0.8825736045837402,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06247194483876228,
                "median": 0.052881330251693726,
                "std": 0.1968381106853485,
                "max": 0.5402711033821106,
                "min": -0.3314647674560547,
                "frobenius_norm": 2.0234146118164062,
                "spectral_norm": 1.415022611618042,
                "alpha": 1.5729723435406935,
                "alpha_hat": 2.414739572972087
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.025076955556869507,
                "median": 0.06492795050144196,
                "std": 0.2528151571750641,
                "max": 0.4664793014526367,
                "min": -0.8124131560325623,
                "frobenius_norm": 2.0324463844299316,
                "spectral_norm": 1.3159712553024292,
                "alpha": 1.2915830908259216,
                "alpha_hat": 1.9747125085383817
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.015796158462762833,
                "median": 0.018233349546790123,
                "std": 0.2462841123342514,
                "max": 0.7066810727119446,
                "min": -0.7043029069900513,
                "frobenius_norm": 1.9743211269378662,
                "spectral_norm": 1.253862738609314,
                "alpha": 1.251142088678931,
                "alpha_hat": 2.233969147757202
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0551535040140152,
                "median": 0.04977857694029808,
                "std": 0.19038338959217072,
                "max": 0.416982501745224,
                "min": -0.27462589740753174,
                "frobenius_norm": 1.585690975189209,
                "spectral_norm": 0.8651964068412781,
                "alpha": 1.2549615561904737,
                "alpha_hat": 1.202371661852002
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=16_scaler_type=minmax_seed=1819": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1819,
        "scores": {
            "smape": 0.0802922397851944,
            "mse": 536711008.0,
            "mae": 2268.999267578125,
            "r2_score": 0.8840630054473877,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06247194483876228,
                "median": 0.052881330251693726,
                "std": 0.1968381106853485,
                "max": 0.5402711033821106,
                "min": -0.3314647674560547,
                "frobenius_norm": 2.0234146118164062,
                "spectral_norm": 1.415022611618042,
                "alpha": 1.5729723435406935,
                "alpha_hat": 2.414739572972087
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.025076955556869507,
                "median": 0.06492795050144196,
                "std": 0.2528151571750641,
                "max": 0.4664793014526367,
                "min": -0.8124131560325623,
                "frobenius_norm": 2.0324463844299316,
                "spectral_norm": 1.3159712553024292,
                "alpha": 1.2915830908259216,
                "alpha_hat": 1.9747125085383817
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.015796158462762833,
                "median": 0.018233349546790123,
                "std": 0.2462841123342514,
                "max": 0.7066810727119446,
                "min": -0.7043029069900513,
                "frobenius_norm": 1.9743211269378662,
                "spectral_norm": 1.253862738609314,
                "alpha": 1.251142088678931,
                "alpha_hat": 2.233969147757202
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0551535040140152,
                "median": 0.04977857694029808,
                "std": 0.19038338959217072,
                "max": 0.416982501745224,
                "min": -0.27462589740753174,
                "frobenius_norm": 1.585690975189209,
                "spectral_norm": 0.8651964068412781,
                "alpha": 1.2549615561904737,
                "alpha_hat": 1.202371661852002
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=16_scaler_type=minmax_seed=2021": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 2021,
        "scores": {
            "smape": 0.08521082252264023,
            "mse": 688221440.0,
            "mae": 2397.376708984375,
            "r2_score": 0.8513346910476685,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06247194483876228,
                "median": 0.052881330251693726,
                "std": 0.1968381106853485,
                "max": 0.5402711033821106,
                "min": -0.3314647674560547,
                "frobenius_norm": 2.0234146118164062,
                "spectral_norm": 1.415022611618042,
                "alpha": 1.5729723435406935,
                "alpha_hat": 2.414739572972087
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.025076955556869507,
                "median": 0.06492795050144196,
                "std": 0.2528151571750641,
                "max": 0.4664793014526367,
                "min": -0.8124131560325623,
                "frobenius_norm": 2.0324463844299316,
                "spectral_norm": 1.3159712553024292,
                "alpha": 1.2915830908259216,
                "alpha_hat": 1.9747125085383817
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.015796158462762833,
                "median": 0.018233349546790123,
                "std": 0.2462841123342514,
                "max": 0.7066810727119446,
                "min": -0.7043029069900513,
                "frobenius_norm": 1.9743211269378662,
                "spectral_norm": 1.253862738609314,
                "alpha": 1.251142088678931,
                "alpha_hat": 2.233969147757202
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0551535040140152,
                "median": 0.04977857694029808,
                "std": 0.19038338959217072,
                "max": 0.416982501745224,
                "min": -0.27462589740753174,
                "frobenius_norm": 1.585690975189209,
                "spectral_norm": 0.8651964068412781,
                "alpha": 1.2549615561904737,
                "alpha_hat": 1.202371661852002
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=16_scaler_type=minmax_seed=1415": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1415,
        "scores": {
            "smape": 0.08107583224773407,
            "mse": 559703616.0,
            "mae": 2330.57373046875,
            "r2_score": 0.8790963292121887,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06247194483876228,
                "median": 0.052881330251693726,
                "std": 0.1968381106853485,
                "max": 0.5402711033821106,
                "min": -0.3314647674560547,
                "frobenius_norm": 2.0234146118164062,
                "spectral_norm": 1.415022611618042,
                "alpha": 1.5729723435406935,
                "alpha_hat": 2.414739572972087
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.025076955556869507,
                "median": 0.06492795050144196,
                "std": 0.2528151571750641,
                "max": 0.4664793014526367,
                "min": -0.8124131560325623,
                "frobenius_norm": 2.0324463844299316,
                "spectral_norm": 1.3159712553024292,
                "alpha": 1.2915830908259216,
                "alpha_hat": 1.9747125085383817
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.015796158462762833,
                "median": 0.018233349546790123,
                "std": 0.2462841123342514,
                "max": 0.7066810727119446,
                "min": -0.7043029069900513,
                "frobenius_norm": 1.9743211269378662,
                "spectral_norm": 1.253862738609314,
                "alpha": 1.251142088678931,
                "alpha_hat": 2.233969147757202
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0551535040140152,
                "median": 0.04977857694029808,
                "std": 0.19038338959217072,
                "max": 0.416982501745224,
                "min": -0.27462589740753174,
                "frobenius_norm": 1.585690975189209,
                "spectral_norm": 0.8651964068412781,
                "alpha": 1.2549615561904737,
                "alpha_hat": 1.202371661852002
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=32_scaler_type=identity_seed=42": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 42,
        "scores": {
            "smape": 0.08524714410305023,
            "mse": 510303968.0,
            "mae": 2039.3658447265625,
            "r2_score": 0.8897672891616821,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.04759424924850464,
                "median": 0.04727557301521301,
                "std": 0.17339852452278137,
                "max": 0.39140403270721436,
                "min": -0.331039160490036,
                "frobenius_norm": 1.761788010597229,
                "spectral_norm": 0.9295071363449097,
                "alpha": 1.706912623130835,
                "alpha_hat": 2.05272498529031
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.061240971088409424,
                "median": 0.10130971670150757,
                "std": 0.25990942120552063,
                "max": 0.7509924173355103,
                "min": -0.3695742189884186,
                "frobenius_norm": 2.1362152099609375,
                "spectral_norm": 1.6247167587280273,
                "alpha": 1.1603040387059587,
                "alpha_hat": 2.568066613800146
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08337679505348206,
                "median": 0.13844965398311615,
                "std": 0.22370055317878723,
                "max": 0.4549884796142578,
                "min": -0.33371198177337646,
                "frobenius_norm": 1.9098670482635498,
                "spectral_norm": 1.3058675527572632,
                "alpha": 1.1203340125989651,
                "alpha_hat": 2.1862281191310786
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0985349714756012,
                "median": 0.1149555891752243,
                "std": 0.23176029324531555,
                "max": 0.5217996835708618,
                "min": -0.2805379629135132,
                "frobenius_norm": 2.014697313308716,
                "spectral_norm": 1.3678404092788696,
                "alpha": 1.3434140620413646,
                "alpha_hat": 2.3767019738562136
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=32_scaler_type=identity_seed=123": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 123,
        "scores": {
            "smape": 0.0837012454867363,
            "mse": 490652192.0,
            "mae": 2004.6873779296875,
            "r2_score": 0.8940123319625854,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.04759424924850464,
                "median": 0.04727557301521301,
                "std": 0.17339852452278137,
                "max": 0.39140403270721436,
                "min": -0.331039160490036,
                "frobenius_norm": 1.761788010597229,
                "spectral_norm": 0.9295071363449097,
                "alpha": 1.706912623130835,
                "alpha_hat": 2.05272498529031
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.061240971088409424,
                "median": 0.10130971670150757,
                "std": 0.25990942120552063,
                "max": 0.7509924173355103,
                "min": -0.3695742189884186,
                "frobenius_norm": 2.1362152099609375,
                "spectral_norm": 1.6247167587280273,
                "alpha": 1.1603040387059587,
                "alpha_hat": 2.568066613800146
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08337679505348206,
                "median": 0.13844965398311615,
                "std": 0.22370055317878723,
                "max": 0.4549884796142578,
                "min": -0.33371198177337646,
                "frobenius_norm": 1.9098670482635498,
                "spectral_norm": 1.3058675527572632,
                "alpha": 1.1203340125989651,
                "alpha_hat": 2.1862281191310786
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0985349714756012,
                "median": 0.1149555891752243,
                "std": 0.23176029324531555,
                "max": 0.5217996835708618,
                "min": -0.2805379629135132,
                "frobenius_norm": 2.014697313308716,
                "spectral_norm": 1.3678404092788696,
                "alpha": 1.3434140620413646,
                "alpha_hat": 2.3767019738562136
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=32_scaler_type=identity_seed=789": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 789,
        "scores": {
            "smape": 0.08614853769540787,
            "mse": 498325376.0,
            "mae": 2009.1397705078125,
            "r2_score": 0.8923548460006714,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.04759424924850464,
                "median": 0.04727557301521301,
                "std": 0.17339852452278137,
                "max": 0.39140403270721436,
                "min": -0.331039160490036,
                "frobenius_norm": 1.761788010597229,
                "spectral_norm": 0.9295071363449097,
                "alpha": 1.706912623130835,
                "alpha_hat": 2.05272498529031
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.061240971088409424,
                "median": 0.10130971670150757,
                "std": 0.25990942120552063,
                "max": 0.7509924173355103,
                "min": -0.3695742189884186,
                "frobenius_norm": 2.1362152099609375,
                "spectral_norm": 1.6247167587280273,
                "alpha": 1.1603040387059587,
                "alpha_hat": 2.568066613800146
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08337679505348206,
                "median": 0.13844965398311615,
                "std": 0.22370055317878723,
                "max": 0.4549884796142578,
                "min": -0.33371198177337646,
                "frobenius_norm": 1.9098670482635498,
                "spectral_norm": 1.3058675527572632,
                "alpha": 1.1203340125989651,
                "alpha_hat": 2.1862281191310786
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0985349714756012,
                "median": 0.1149555891752243,
                "std": 0.23176029324531555,
                "max": 0.5217996835708618,
                "min": -0.2805379629135132,
                "frobenius_norm": 2.014697313308716,
                "spectral_norm": 1.3678404092788696,
                "alpha": 1.3434140620413646,
                "alpha_hat": 2.3767019738562136
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=32_scaler_type=identity_seed=456": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 456,
        "scores": {
            "smape": 0.08516795188188553,
            "mse": 506529984.0,
            "mae": 2053.275146484375,
            "r2_score": 0.8905825614929199,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.04759424924850464,
                "median": 0.04727557301521301,
                "std": 0.17339852452278137,
                "max": 0.39140403270721436,
                "min": -0.331039160490036,
                "frobenius_norm": 1.761788010597229,
                "spectral_norm": 0.9295071363449097,
                "alpha": 1.706912623130835,
                "alpha_hat": 2.05272498529031
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.061240971088409424,
                "median": 0.10130971670150757,
                "std": 0.25990942120552063,
                "max": 0.7509924173355103,
                "min": -0.3695742189884186,
                "frobenius_norm": 2.1362152099609375,
                "spectral_norm": 1.6247167587280273,
                "alpha": 1.1603040387059587,
                "alpha_hat": 2.568066613800146
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08337679505348206,
                "median": 0.13844965398311615,
                "std": 0.22370055317878723,
                "max": 0.4549884796142578,
                "min": -0.33371198177337646,
                "frobenius_norm": 1.9098670482635498,
                "spectral_norm": 1.3058675527572632,
                "alpha": 1.1203340125989651,
                "alpha_hat": 2.1862281191310786
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0985349714756012,
                "median": 0.1149555891752243,
                "std": 0.23176029324531555,
                "max": 0.5217996835708618,
                "min": -0.2805379629135132,
                "frobenius_norm": 2.014697313308716,
                "spectral_norm": 1.3678404092788696,
                "alpha": 1.3434140620413646,
                "alpha_hat": 2.3767019738562136
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=32_scaler_type=identity_seed=1213": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1213,
        "scores": {
            "smape": 0.08621538430452347,
            "mse": 514022496.0,
            "mae": 2049.220947265625,
            "r2_score": 0.888964056968689,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.07725710421800613,
                "median": 0.08167919516563416,
                "std": 0.16506817936897278,
                "max": 0.37820932269096375,
                "min": -0.30185598134994507,
                "frobenius_norm": 1.7857075929641724,
                "spectral_norm": 0.9976959228515625,
                "alpha": 1.57059329875726,
                "alpha_hat": 1.9541286111767904
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05828721821308136,
                "median": 0.07441313564777374,
                "std": 0.2382698506116867,
                "max": 0.4551740884780884,
                "min": -0.390205979347229,
                "frobenius_norm": 1.962364673614502,
                "spectral_norm": 1.3329904079437256,
                "alpha": 1.1727309363894718,
                "alpha_hat": 2.116749780781819
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.09554237127304077,
                "median": 0.052576154470443726,
                "std": 0.2493285834789276,
                "max": 0.6697980761528015,
                "min": -0.30626922845840454,
                "frobenius_norm": 2.136061429977417,
                "spectral_norm": 1.5123040676116943,
                "alpha": 1.2213719829012333,
                "alpha_hat": 3.202753554322801
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.11558521538972855,
                "median": 0.12507162988185883,
                "std": 0.1913214474916458,
                "max": 0.4978945255279541,
                "min": -0.2601172626018524,
                "frobenius_norm": 1.7882074117660522,
                "spectral_norm": 1.1472469568252563,
                "alpha": 1.1356947660704704,
                "alpha_hat": 1.3986517320792746
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=32_scaler_type=identity_seed=1011": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1011,
        "scores": {
            "smape": 0.08546256273984909,
            "mse": 499860160.0,
            "mae": 2017.2066650390625,
            "r2_score": 0.8920233249664307,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.07725710421800613,
                "median": 0.08167919516563416,
                "std": 0.16506817936897278,
                "max": 0.37820932269096375,
                "min": -0.30185598134994507,
                "frobenius_norm": 1.7857075929641724,
                "spectral_norm": 0.9976959228515625,
                "alpha": 1.57059329875726,
                "alpha_hat": 1.9541286111767904
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05828721821308136,
                "median": 0.07441313564777374,
                "std": 0.2382698506116867,
                "max": 0.4551740884780884,
                "min": -0.390205979347229,
                "frobenius_norm": 1.962364673614502,
                "spectral_norm": 1.3329904079437256,
                "alpha": 1.1727309363894718,
                "alpha_hat": 2.116749780781819
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.09554237127304077,
                "median": 0.052576154470443726,
                "std": 0.2493285834789276,
                "max": 0.6697980761528015,
                "min": -0.30626922845840454,
                "frobenius_norm": 2.136061429977417,
                "spectral_norm": 1.5123040676116943,
                "alpha": 1.2213719829012333,
                "alpha_hat": 3.202753554322801
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.11558521538972855,
                "median": 0.12507162988185883,
                "std": 0.1913214474916458,
                "max": 0.4978945255279541,
                "min": -0.2601172626018524,
                "frobenius_norm": 1.7882074117660522,
                "spectral_norm": 1.1472469568252563,
                "alpha": 1.1356947660704704,
                "alpha_hat": 1.3986517320792746
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=32_scaler_type=identity_seed=1415": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1415,
        "scores": {
            "smape": 0.08458881825208664,
            "mse": 499214208.0,
            "mae": 2013.9801025390625,
            "r2_score": 0.8921628594398499,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.07725710421800613,
                "median": 0.08167919516563416,
                "std": 0.16506817936897278,
                "max": 0.37820932269096375,
                "min": -0.30185598134994507,
                "frobenius_norm": 1.7857075929641724,
                "spectral_norm": 0.9976959228515625,
                "alpha": 1.57059329875726,
                "alpha_hat": 1.9541286111767904
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05828721821308136,
                "median": 0.07441313564777374,
                "std": 0.2382698506116867,
                "max": 0.4551740884780884,
                "min": -0.390205979347229,
                "frobenius_norm": 1.962364673614502,
                "spectral_norm": 1.3329904079437256,
                "alpha": 1.1727309363894718,
                "alpha_hat": 2.116749780781819
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.09554237127304077,
                "median": 0.052576154470443726,
                "std": 0.2493285834789276,
                "max": 0.6697980761528015,
                "min": -0.30626922845840454,
                "frobenius_norm": 2.136061429977417,
                "spectral_norm": 1.5123040676116943,
                "alpha": 1.2213719829012333,
                "alpha_hat": 3.202753554322801
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.11558521538972855,
                "median": 0.12507162988185883,
                "std": 0.1913214474916458,
                "max": 0.4978945255279541,
                "min": -0.2601172626018524,
                "frobenius_norm": 1.7882074117660522,
                "spectral_norm": 1.1472469568252563,
                "alpha": 1.1356947660704704,
                "alpha_hat": 1.3986517320792746
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=32_scaler_type=identity_seed=1617": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1617,
        "scores": {
            "smape": 0.08381418138742447,
            "mse": 501045728.0,
            "mae": 2015.0372314453125,
            "r2_score": 0.8917672038078308,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.07725710421800613,
                "median": 0.08167919516563416,
                "std": 0.16506817936897278,
                "max": 0.37820932269096375,
                "min": -0.30185598134994507,
                "frobenius_norm": 1.7857075929641724,
                "spectral_norm": 0.9976959228515625,
                "alpha": 1.57059329875726,
                "alpha_hat": 1.9541286111767904
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05828721821308136,
                "median": 0.07441313564777374,
                "std": 0.2382698506116867,
                "max": 0.4551740884780884,
                "min": -0.390205979347229,
                "frobenius_norm": 1.962364673614502,
                "spectral_norm": 1.3329904079437256,
                "alpha": 1.1727309363894718,
                "alpha_hat": 2.116749780781819
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.09554237127304077,
                "median": 0.052576154470443726,
                "std": 0.2493285834789276,
                "max": 0.6697980761528015,
                "min": -0.30626922845840454,
                "frobenius_norm": 2.136061429977417,
                "spectral_norm": 1.5123040676116943,
                "alpha": 1.2213719829012333,
                "alpha_hat": 3.202753554322801
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.11558521538972855,
                "median": 0.12507162988185883,
                "std": 0.1913214474916458,
                "max": 0.4978945255279541,
                "min": -0.2601172626018524,
                "frobenius_norm": 1.7882074117660522,
                "spectral_norm": 1.1472469568252563,
                "alpha": 1.1356947660704704,
                "alpha_hat": 1.3986517320792746
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=32_scaler_type=identity_seed=2021": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 2021,
        "scores": {
            "smape": 0.09249702095985413,
            "mse": 531164928.0,
            "mae": 2171.062744140625,
            "r2_score": 0.885261058807373,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06654974818229675,
                "median": 0.04919186979532242,
                "std": 0.24160686135292053,
                "max": 0.6536399126052856,
                "min": -0.5152900815010071,
                "frobenius_norm": 2.4554150104522705,
                "spectral_norm": 1.697942852973938,
                "alpha": 1.4381148157997792,
                "alpha_hat": 2.9838668152132346
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.054443299770355225,
                "median": 0.0987003892660141,
                "std": 0.3014269173145294,
                "max": 0.6340587139129639,
                "min": -0.7941184043884277,
                "frobenius_norm": 2.4504334926605225,
                "spectral_norm": 1.6602708101272583,
                "alpha": 1.1562188479134126,
                "alpha_hat": 2.068436552148958
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.008935803547501564,
                "median": 0.005969320423901081,
                "std": 0.267793208360672,
                "max": 0.8429059386253357,
                "min": -0.5041216611862183,
                "frobenius_norm": 2.143538236618042,
                "spectral_norm": 1.5350459814071655,
                "alpha": 1.1801850270608825,
                "alpha_hat": 4.235047287866088
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06294819712638855,
                "median": 0.04404786601662636,
                "std": 0.1888131946325302,
                "max": 0.46325841546058655,
                "min": -0.23485167324543,
                "frobenius_norm": 1.5922391414642334,
                "spectral_norm": 0.88762366771698,
                "alpha": 1.2164811021555084,
                "alpha_hat": 1.172982655962921
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=32_scaler_type=identity_seed=1819": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1819,
        "scores": {
            "smape": 0.08517007529735565,
            "mse": 503051136.0,
            "mae": 2028.660400390625,
            "r2_score": 0.8913339972496033,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06654974818229675,
                "median": 0.04919186979532242,
                "std": 0.24160686135292053,
                "max": 0.6536399126052856,
                "min": -0.5152900815010071,
                "frobenius_norm": 2.4554150104522705,
                "spectral_norm": 1.697942852973938,
                "alpha": 1.4381148157997792,
                "alpha_hat": 2.9838668152132346
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.054443299770355225,
                "median": 0.0987003892660141,
                "std": 0.3014269173145294,
                "max": 0.6340587139129639,
                "min": -0.7941184043884277,
                "frobenius_norm": 2.4504334926605225,
                "spectral_norm": 1.6602708101272583,
                "alpha": 1.1562188479134126,
                "alpha_hat": 2.068436552148958
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.008935803547501564,
                "median": 0.005969320423901081,
                "std": 0.267793208360672,
                "max": 0.8429059386253357,
                "min": -0.5041216611862183,
                "frobenius_norm": 2.143538236618042,
                "spectral_norm": 1.5350459814071655,
                "alpha": 1.1801850270608825,
                "alpha_hat": 4.235047287866088
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06294819712638855,
                "median": 0.04404786601662636,
                "std": 0.1888131946325302,
                "max": 0.46325841546058655,
                "min": -0.23485167324543,
                "frobenius_norm": 1.5922391414642334,
                "spectral_norm": 0.88762366771698,
                "alpha": 1.2164811021555084,
                "alpha_hat": 1.172982655962921
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=32_scaler_type=standard_seed=42": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 42,
        "scores": {
            "smape": 0.07518751919269562,
            "mse": 443337376.0,
            "mae": 2003.8095703125,
            "r2_score": 0.9042330384254456,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06654974818229675,
                "median": 0.04919186979532242,
                "std": 0.24160686135292053,
                "max": 0.6536399126052856,
                "min": -0.5152900815010071,
                "frobenius_norm": 2.4554150104522705,
                "spectral_norm": 1.697942852973938,
                "alpha": 1.4381148157997792,
                "alpha_hat": 2.9838668152132346
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.054443299770355225,
                "median": 0.0987003892660141,
                "std": 0.3014269173145294,
                "max": 0.6340587139129639,
                "min": -0.7941184043884277,
                "frobenius_norm": 2.4504334926605225,
                "spectral_norm": 1.6602708101272583,
                "alpha": 1.1562188479134126,
                "alpha_hat": 2.068436552148958
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.008935803547501564,
                "median": 0.005969320423901081,
                "std": 0.267793208360672,
                "max": 0.8429059386253357,
                "min": -0.5041216611862183,
                "frobenius_norm": 2.143538236618042,
                "spectral_norm": 1.5350459814071655,
                "alpha": 1.1801850270608825,
                "alpha_hat": 4.235047287866088
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06294819712638855,
                "median": 0.04404786601662636,
                "std": 0.1888131946325302,
                "max": 0.46325841546058655,
                "min": -0.23485167324543,
                "frobenius_norm": 1.5922391414642334,
                "spectral_norm": 0.88762366771698,
                "alpha": 1.2164811021555084,
                "alpha_hat": 1.172982655962921
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=32_scaler_type=standard_seed=123": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 123,
        "scores": {
            "smape": 0.07463603466749191,
            "mse": 477807520.0,
            "mae": 2002.92529296875,
            "r2_score": 0.8967869877815247,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06654974818229675,
                "median": 0.04919186979532242,
                "std": 0.24160686135292053,
                "max": 0.6536399126052856,
                "min": -0.5152900815010071,
                "frobenius_norm": 2.4554150104522705,
                "spectral_norm": 1.697942852973938,
                "alpha": 1.4381148157997792,
                "alpha_hat": 2.9838668152132346
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.054443299770355225,
                "median": 0.0987003892660141,
                "std": 0.3014269173145294,
                "max": 0.6340587139129639,
                "min": -0.7941184043884277,
                "frobenius_norm": 2.4504334926605225,
                "spectral_norm": 1.6602708101272583,
                "alpha": 1.1562188479134126,
                "alpha_hat": 2.068436552148958
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.008935803547501564,
                "median": 0.005969320423901081,
                "std": 0.267793208360672,
                "max": 0.8429059386253357,
                "min": -0.5041216611862183,
                "frobenius_norm": 2.143538236618042,
                "spectral_norm": 1.5350459814071655,
                "alpha": 1.1801850270608825,
                "alpha_hat": 4.235047287866088
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06294819712638855,
                "median": 0.04404786601662636,
                "std": 0.1888131946325302,
                "max": 0.46325841546058655,
                "min": -0.23485167324543,
                "frobenius_norm": 1.5922391414642334,
                "spectral_norm": 0.88762366771698,
                "alpha": 1.2164811021555084,
                "alpha_hat": 1.172982655962921
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=32_scaler_type=standard_seed=456": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 456,
        "scores": {
            "smape": 0.07461206614971161,
            "mse": 494022432.0,
            "mae": 2035.19775390625,
            "r2_score": 0.8932843208312988,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.048812881112098694,
                "median": 0.03332531452178955,
                "std": 0.24071688950061798,
                "max": 0.5926357507705688,
                "min": -0.5824346542358398,
                "frobenius_norm": 2.4065375328063965,
                "spectral_norm": 1.562693476676941,
                "alpha": 1.4674868480848575,
                "alpha_hat": 2.7740348752647788
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02808169089257717,
                "median": 0.039301611483097076,
                "std": 0.30375009775161743,
                "max": 0.6634227633476257,
                "min": -0.795931875705719,
                "frobenius_norm": 2.4403631687164307,
                "spectral_norm": 1.648883581161499,
                "alpha": 1.1569495940712695,
                "alpha_hat": 1.8613031894139473
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.009072556160390377,
                "median": -0.00639227032661438,
                "std": 0.269683301448822,
                "max": 0.8904402256011963,
                "min": -0.4244001805782318,
                "frobenius_norm": 2.158686876296997,
                "spectral_norm": 1.4793990850448608,
                "alpha": 1.2262891531910018,
                "alpha_hat": 2.6898065425879913
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0493135005235672,
                "median": 0.041739679872989655,
                "std": 0.19334955513477325,
                "max": 0.4745347499847412,
                "min": -0.28288137912750244,
                "frobenius_norm": 1.5963131189346313,
                "spectral_norm": 0.9051700234413147,
                "alpha": 1.3267172098877476,
                "alpha_hat": 1.3225492189659191
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=32_scaler_type=standard_seed=1011": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1011,
        "scores": {
            "smape": 0.07469728589057922,
            "mse": 495078752.0,
            "mae": 2035.651123046875,
            "r2_score": 0.8930561542510986,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.048812881112098694,
                "median": 0.03332531452178955,
                "std": 0.24071688950061798,
                "max": 0.5926357507705688,
                "min": -0.5824346542358398,
                "frobenius_norm": 2.4065375328063965,
                "spectral_norm": 1.562693476676941,
                "alpha": 1.4674868480848575,
                "alpha_hat": 2.7740348752647788
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02808169089257717,
                "median": 0.039301611483097076,
                "std": 0.30375009775161743,
                "max": 0.6634227633476257,
                "min": -0.795931875705719,
                "frobenius_norm": 2.4403631687164307,
                "spectral_norm": 1.648883581161499,
                "alpha": 1.1569495940712695,
                "alpha_hat": 1.8613031894139473
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.009072556160390377,
                "median": -0.00639227032661438,
                "std": 0.269683301448822,
                "max": 0.8904402256011963,
                "min": -0.4244001805782318,
                "frobenius_norm": 2.158686876296997,
                "spectral_norm": 1.4793990850448608,
                "alpha": 1.2262891531910018,
                "alpha_hat": 2.6898065425879913
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0493135005235672,
                "median": 0.041739679872989655,
                "std": 0.19334955513477325,
                "max": 0.4745347499847412,
                "min": -0.28288137912750244,
                "frobenius_norm": 1.5963131189346313,
                "spectral_norm": 0.9051700234413147,
                "alpha": 1.3267172098877476,
                "alpha_hat": 1.3225492189659191
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=32_scaler_type=standard_seed=789": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 789,
        "scores": {
            "smape": 0.07388084381818771,
            "mse": 463434368.0,
            "mae": 2041.726318359375,
            "r2_score": 0.8998917937278748,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.048812881112098694,
                "median": 0.03332531452178955,
                "std": 0.24071688950061798,
                "max": 0.5926357507705688,
                "min": -0.5824346542358398,
                "frobenius_norm": 2.4065375328063965,
                "spectral_norm": 1.562693476676941,
                "alpha": 1.4674868480848575,
                "alpha_hat": 2.7740348752647788
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02808169089257717,
                "median": 0.039301611483097076,
                "std": 0.30375009775161743,
                "max": 0.6634227633476257,
                "min": -0.795931875705719,
                "frobenius_norm": 2.4403631687164307,
                "spectral_norm": 1.648883581161499,
                "alpha": 1.1569495940712695,
                "alpha_hat": 1.8613031894139473
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.009072556160390377,
                "median": -0.00639227032661438,
                "std": 0.269683301448822,
                "max": 0.8904402256011963,
                "min": -0.4244001805782318,
                "frobenius_norm": 2.158686876296997,
                "spectral_norm": 1.4793990850448608,
                "alpha": 1.2262891531910018,
                "alpha_hat": 2.6898065425879913
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0493135005235672,
                "median": 0.041739679872989655,
                "std": 0.19334955513477325,
                "max": 0.4745347499847412,
                "min": -0.28288137912750244,
                "frobenius_norm": 1.5963131189346313,
                "spectral_norm": 0.9051700234413147,
                "alpha": 1.3267172098877476,
                "alpha_hat": 1.3225492189659191
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=32_scaler_type=standard_seed=1213": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1213,
        "scores": {
            "smape": 0.07465079426765442,
            "mse": 502730528.0,
            "mae": 2050.03076171875,
            "r2_score": 0.8914032578468323,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.048812881112098694,
                "median": 0.03332531452178955,
                "std": 0.24071688950061798,
                "max": 0.5926357507705688,
                "min": -0.5824346542358398,
                "frobenius_norm": 2.4065375328063965,
                "spectral_norm": 1.562693476676941,
                "alpha": 1.4674868480848575,
                "alpha_hat": 2.7740348752647788
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02808169089257717,
                "median": 0.039301611483097076,
                "std": 0.30375009775161743,
                "max": 0.6634227633476257,
                "min": -0.795931875705719,
                "frobenius_norm": 2.4403631687164307,
                "spectral_norm": 1.648883581161499,
                "alpha": 1.1569495940712695,
                "alpha_hat": 1.8613031894139473
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.009072556160390377,
                "median": -0.00639227032661438,
                "std": 0.269683301448822,
                "max": 0.8904402256011963,
                "min": -0.4244001805782318,
                "frobenius_norm": 2.158686876296997,
                "spectral_norm": 1.4793990850448608,
                "alpha": 1.2262891531910018,
                "alpha_hat": 2.6898065425879913
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0493135005235672,
                "median": 0.041739679872989655,
                "std": 0.19334955513477325,
                "max": 0.4745347499847412,
                "min": -0.28288137912750244,
                "frobenius_norm": 1.5963131189346313,
                "spectral_norm": 0.9051700234413147,
                "alpha": 1.3267172098877476,
                "alpha_hat": 1.3225492189659191
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=32_scaler_type=standard_seed=1415": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1415,
        "scores": {
            "smape": 0.07394948601722717,
            "mse": 472467296.0,
            "mae": 2051.327880859375,
            "r2_score": 0.8979405760765076,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.05377189815044403,
                "median": 0.03221797198057175,
                "std": 0.2421337217092514,
                "max": 0.5960853695869446,
                "min": -0.5267396569252014,
                "frobenius_norm": 2.43021297454834,
                "spectral_norm": 1.5874848365783691,
                "alpha": 1.4506230316357813,
                "alpha_hat": 2.9732279271768163
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.023569835349917412,
                "median": 0.0360100083053112,
                "std": 0.28504088521003723,
                "max": 0.6748949885368347,
                "min": -0.8114977478981018,
                "frobenius_norm": 2.288109540939331,
                "spectral_norm": 1.603421926498413,
                "alpha": 1.0993538761283388,
                "alpha_hat": 2.1292664650135498
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02019675448536873,
                "median": -0.029490061104297638,
                "std": 0.2650034427642822,
                "max": 0.8915327787399292,
                "min": -0.43107736110687256,
                "frobenius_norm": 2.12617564201355,
                "spectral_norm": 1.469099760055542,
                "alpha": 1.2709044139311496,
                "alpha_hat": 4.09395363935452
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06079453229904175,
                "median": 0.04151717573404312,
                "std": 0.191529780626297,
                "max": 0.47145089507102966,
                "min": -0.23709449172019958,
                "frobenius_norm": 1.6075745820999146,
                "spectral_norm": 0.9002249836921692,
                "alpha": 1.228734589347311,
                "alpha_hat": 1.190592161819556
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=32_scaler_type=standard_seed=1617": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1617,
        "scores": {
            "smape": 0.07478722184896469,
            "mse": 500693440.0,
            "mae": 2037.741455078125,
            "r2_score": 0.891843318939209,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.05377189815044403,
                "median": 0.03221797198057175,
                "std": 0.2421337217092514,
                "max": 0.5960853695869446,
                "min": -0.5267396569252014,
                "frobenius_norm": 2.43021297454834,
                "spectral_norm": 1.5874848365783691,
                "alpha": 1.4506230316357813,
                "alpha_hat": 2.9732279271768163
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.023569835349917412,
                "median": 0.0360100083053112,
                "std": 0.28504088521003723,
                "max": 0.6748949885368347,
                "min": -0.8114977478981018,
                "frobenius_norm": 2.288109540939331,
                "spectral_norm": 1.603421926498413,
                "alpha": 1.0993538761283388,
                "alpha_hat": 2.1292664650135498
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02019675448536873,
                "median": -0.029490061104297638,
                "std": 0.2650034427642822,
                "max": 0.8915327787399292,
                "min": -0.43107736110687256,
                "frobenius_norm": 2.12617564201355,
                "spectral_norm": 1.469099760055542,
                "alpha": 1.2709044139311496,
                "alpha_hat": 4.09395363935452
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06079453229904175,
                "median": 0.04151717573404312,
                "std": 0.191529780626297,
                "max": 0.47145089507102966,
                "min": -0.23709449172019958,
                "frobenius_norm": 1.6075745820999146,
                "spectral_norm": 0.9002249836921692,
                "alpha": 1.228734589347311,
                "alpha_hat": 1.190592161819556
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=32_scaler_type=standard_seed=1819": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1819,
        "scores": {
            "smape": 0.07463144510984421,
            "mse": 488327680.0,
            "mae": 2026.26904296875,
            "r2_score": 0.8945145010948181,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.05377189815044403,
                "median": 0.03221797198057175,
                "std": 0.2421337217092514,
                "max": 0.5960853695869446,
                "min": -0.5267396569252014,
                "frobenius_norm": 2.43021297454834,
                "spectral_norm": 1.5874848365783691,
                "alpha": 1.4506230316357813,
                "alpha_hat": 2.9732279271768163
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.023569835349917412,
                "median": 0.0360100083053112,
                "std": 0.28504088521003723,
                "max": 0.6748949885368347,
                "min": -0.8114977478981018,
                "frobenius_norm": 2.288109540939331,
                "spectral_norm": 1.603421926498413,
                "alpha": 1.0993538761283388,
                "alpha_hat": 2.1292664650135498
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02019675448536873,
                "median": -0.029490061104297638,
                "std": 0.2650034427642822,
                "max": 0.8915327787399292,
                "min": -0.43107736110687256,
                "frobenius_norm": 2.12617564201355,
                "spectral_norm": 1.469099760055542,
                "alpha": 1.2709044139311496,
                "alpha_hat": 4.09395363935452
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06079453229904175,
                "median": 0.04151717573404312,
                "std": 0.191529780626297,
                "max": 0.47145089507102966,
                "min": -0.23709449172019958,
                "frobenius_norm": 1.6075745820999146,
                "spectral_norm": 0.9002249836921692,
                "alpha": 1.228734589347311,
                "alpha_hat": 1.190592161819556
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=32_scaler_type=standard_seed=2021": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 2021,
        "scores": {
            "smape": 0.07470463216304779,
            "mse": 501439936.0,
            "mae": 2032.37841796875,
            "r2_score": 0.8916820883750916,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.05377189815044403,
                "median": 0.03221797198057175,
                "std": 0.2421337217092514,
                "max": 0.5960853695869446,
                "min": -0.5267396569252014,
                "frobenius_norm": 2.43021297454834,
                "spectral_norm": 1.5874848365783691,
                "alpha": 1.4506230316357813,
                "alpha_hat": 2.9732279271768163
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.023569835349917412,
                "median": 0.0360100083053112,
                "std": 0.28504088521003723,
                "max": 0.6748949885368347,
                "min": -0.8114977478981018,
                "frobenius_norm": 2.288109540939331,
                "spectral_norm": 1.603421926498413,
                "alpha": 1.0993538761283388,
                "alpha_hat": 2.1292664650135498
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02019675448536873,
                "median": -0.029490061104297638,
                "std": 0.2650034427642822,
                "max": 0.8915327787399292,
                "min": -0.43107736110687256,
                "frobenius_norm": 2.12617564201355,
                "spectral_norm": 1.469099760055542,
                "alpha": 1.2709044139311496,
                "alpha_hat": 4.09395363935452
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06079453229904175,
                "median": 0.04151717573404312,
                "std": 0.191529780626297,
                "max": 0.47145089507102966,
                "min": -0.23709449172019958,
                "frobenius_norm": 1.6075745820999146,
                "spectral_norm": 0.9002249836921692,
                "alpha": 1.228734589347311,
                "alpha_hat": 1.190592161819556
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=32_scaler_type=robust_seed=42": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 42,
        "scores": {
            "smape": 0.07334897667169571,
            "mse": 480514048.0,
            "mae": 2010.2530517578125,
            "r2_score": 0.8962023258209229,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06304594874382019,
                "median": 0.05270710214972496,
                "std": 0.23203472793102264,
                "max": 0.6639083623886108,
                "min": -0.5796465277671814,
                "frobenius_norm": 2.3558926582336426,
                "spectral_norm": 1.6508769989013672,
                "alpha": 1.3946504861288744,
                "alpha_hat": 2.4108611963611692
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07909267395734787,
                "median": 0.11602651327848434,
                "std": 0.286481112241745,
                "max": 0.6138613820075989,
                "min": -0.8334023356437683,
                "frobenius_norm": 2.377589702606201,
                "spectral_norm": 1.673153281211853,
                "alpha": 1.174141806069655,
                "alpha_hat": 2.554745150918316
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.007167058065533638,
                "median": -0.018081488087773323,
                "std": 0.2686769962310791,
                "max": 0.903472900390625,
                "min": -0.563660740852356,
                "frobenius_norm": 2.1501805782318115,
                "spectral_norm": 1.3914343118667603,
                "alpha": 1.1433637217646218,
                "alpha_hat": 2.475566145834297
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06532458961009979,
                "median": 0.03978452458977699,
                "std": 0.1899985820055008,
                "max": 0.48575183749198914,
                "min": -0.23350068926811218,
                "frobenius_norm": 1.6073185205459595,
                "spectral_norm": 0.90079265832901,
                "alpha": 1.231111580127883,
                "alpha_hat": 1.217084632266012
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=32_scaler_type=robust_seed=123": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 123,
        "scores": {
            "smape": 0.07378602772951126,
            "mse": 498642816.0,
            "mae": 2011.6109619140625,
            "r2_score": 0.8922863006591797,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06304594874382019,
                "median": 0.05270710214972496,
                "std": 0.23203472793102264,
                "max": 0.6639083623886108,
                "min": -0.5796465277671814,
                "frobenius_norm": 2.3558926582336426,
                "spectral_norm": 1.6508769989013672,
                "alpha": 1.3946504861288744,
                "alpha_hat": 2.4108611963611692
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07909267395734787,
                "median": 0.11602651327848434,
                "std": 0.286481112241745,
                "max": 0.6138613820075989,
                "min": -0.8334023356437683,
                "frobenius_norm": 2.377589702606201,
                "spectral_norm": 1.673153281211853,
                "alpha": 1.174141806069655,
                "alpha_hat": 2.554745150918316
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.007167058065533638,
                "median": -0.018081488087773323,
                "std": 0.2686769962310791,
                "max": 0.903472900390625,
                "min": -0.563660740852356,
                "frobenius_norm": 2.1501805782318115,
                "spectral_norm": 1.3914343118667603,
                "alpha": 1.1433637217646218,
                "alpha_hat": 2.475566145834297
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06532458961009979,
                "median": 0.03978452458977699,
                "std": 0.1899985820055008,
                "max": 0.48575183749198914,
                "min": -0.23350068926811218,
                "frobenius_norm": 1.6073185205459595,
                "spectral_norm": 0.90079265832901,
                "alpha": 1.231111580127883,
                "alpha_hat": 1.217084632266012
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=32_scaler_type=robust_seed=456": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 456,
        "scores": {
            "smape": 0.07368405163288116,
            "mse": 513364800.0,
            "mae": 2037.2923583984375,
            "r2_score": 0.8891061544418335,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06304594874382019,
                "median": 0.05270710214972496,
                "std": 0.23203472793102264,
                "max": 0.6639083623886108,
                "min": -0.5796465277671814,
                "frobenius_norm": 2.3558926582336426,
                "spectral_norm": 1.6508769989013672,
                "alpha": 1.3946504861288744,
                "alpha_hat": 2.4108611963611692
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07909267395734787,
                "median": 0.11602651327848434,
                "std": 0.286481112241745,
                "max": 0.6138613820075989,
                "min": -0.8334023356437683,
                "frobenius_norm": 2.377589702606201,
                "spectral_norm": 1.673153281211853,
                "alpha": 1.174141806069655,
                "alpha_hat": 2.554745150918316
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.007167058065533638,
                "median": -0.018081488087773323,
                "std": 0.2686769962310791,
                "max": 0.903472900390625,
                "min": -0.563660740852356,
                "frobenius_norm": 2.1501805782318115,
                "spectral_norm": 1.3914343118667603,
                "alpha": 1.1433637217646218,
                "alpha_hat": 2.475566145834297
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06532458961009979,
                "median": 0.03978452458977699,
                "std": 0.1899985820055008,
                "max": 0.48575183749198914,
                "min": -0.23350068926811218,
                "frobenius_norm": 1.6073185205459595,
                "spectral_norm": 0.90079265832901,
                "alpha": 1.231111580127883,
                "alpha_hat": 1.217084632266012
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=32_scaler_type=robust_seed=789": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 789,
        "scores": {
            "smape": 0.0740942656993866,
            "mse": 512482240.0,
            "mae": 2046.871337890625,
            "r2_score": 0.8892967700958252,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06304594874382019,
                "median": 0.05270710214972496,
                "std": 0.23203472793102264,
                "max": 0.6639083623886108,
                "min": -0.5796465277671814,
                "frobenius_norm": 2.3558926582336426,
                "spectral_norm": 1.6508769989013672,
                "alpha": 1.3946504861288744,
                "alpha_hat": 2.4108611963611692
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07909267395734787,
                "median": 0.11602651327848434,
                "std": 0.286481112241745,
                "max": 0.6138613820075989,
                "min": -0.8334023356437683,
                "frobenius_norm": 2.377589702606201,
                "spectral_norm": 1.673153281211853,
                "alpha": 1.174141806069655,
                "alpha_hat": 2.554745150918316
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.007167058065533638,
                "median": -0.018081488087773323,
                "std": 0.2686769962310791,
                "max": 0.903472900390625,
                "min": -0.563660740852356,
                "frobenius_norm": 2.1501805782318115,
                "spectral_norm": 1.3914343118667603,
                "alpha": 1.1433637217646218,
                "alpha_hat": 2.475566145834297
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06532458961009979,
                "median": 0.03978452458977699,
                "std": 0.1899985820055008,
                "max": 0.48575183749198914,
                "min": -0.23350068926811218,
                "frobenius_norm": 1.6073185205459595,
                "spectral_norm": 0.90079265832901,
                "alpha": 1.231111580127883,
                "alpha_hat": 1.217084632266012
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=32_scaler_type=robust_seed=1011": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1011,
        "scores": {
            "smape": 0.07370676100254059,
            "mse": 500443520.0,
            "mae": 2021.3756103515625,
            "r2_score": 0.8918973207473755,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06679335236549377,
                "median": 0.05123196542263031,
                "std": 0.2288360297679901,
                "max": 0.6234695315361023,
                "min": -0.5447420477867126,
                "frobenius_norm": 2.335683822631836,
                "spectral_norm": 1.6082780361175537,
                "alpha": 1.499444846588359,
                "alpha_hat": 2.5530037761181346
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08467848598957062,
                "median": 0.10053632408380508,
                "std": 0.2853015661239624,
                "max": 0.6132697463035583,
                "min": -0.7999040484428406,
                "frobenius_norm": 2.3808224201202393,
                "spectral_norm": 1.7183246612548828,
                "alpha": 1.1968772766440265,
                "alpha_hat": 3.7577148024342844
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02810267172753811,
                "median": 0.033904559910297394,
                "std": 0.2614479660987854,
                "max": 0.7870427966117859,
                "min": -0.5651231408119202,
                "frobenius_norm": 2.1036317348480225,
                "spectral_norm": 1.4010597467422485,
                "alpha": 1.1659179182368353,
                "alpha_hat": 2.615560049843092
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06974752247333527,
                "median": 0.06134641915559769,
                "std": 0.18793760240077972,
                "max": 0.4801601767539978,
                "min": -0.2255781888961792,
                "frobenius_norm": 1.6037007570266724,
                "spectral_norm": 0.8931291103363037,
                "alpha": 1.2236864252940516,
                "alpha_hat": 1.2125078213707403
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=32_scaler_type=robust_seed=1213": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1213,
        "scores": {
            "smape": 0.07343035191297531,
            "mse": 500451648.0,
            "mae": 2025.298828125,
            "r2_score": 0.8918955326080322,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06679335236549377,
                "median": 0.05123196542263031,
                "std": 0.2288360297679901,
                "max": 0.6234695315361023,
                "min": -0.5447420477867126,
                "frobenius_norm": 2.335683822631836,
                "spectral_norm": 1.6082780361175537,
                "alpha": 1.499444846588359,
                "alpha_hat": 2.5530037761181346
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08467848598957062,
                "median": 0.10053632408380508,
                "std": 0.2853015661239624,
                "max": 0.6132697463035583,
                "min": -0.7999040484428406,
                "frobenius_norm": 2.3808224201202393,
                "spectral_norm": 1.7183246612548828,
                "alpha": 1.1968772766440265,
                "alpha_hat": 3.7577148024342844
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02810267172753811,
                "median": 0.033904559910297394,
                "std": 0.2614479660987854,
                "max": 0.7870427966117859,
                "min": -0.5651231408119202,
                "frobenius_norm": 2.1036317348480225,
                "spectral_norm": 1.4010597467422485,
                "alpha": 1.1659179182368353,
                "alpha_hat": 2.615560049843092
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06974752247333527,
                "median": 0.06134641915559769,
                "std": 0.18793760240077972,
                "max": 0.4801601767539978,
                "min": -0.2255781888961792,
                "frobenius_norm": 1.6037007570266724,
                "spectral_norm": 0.8931291103363037,
                "alpha": 1.2236864252940516,
                "alpha_hat": 1.2125078213707403
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=32_scaler_type=robust_seed=1415": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1415,
        "scores": {
            "smape": 0.07357339560985565,
            "mse": 505037728.0,
            "mae": 2024.203369140625,
            "r2_score": 0.8909049034118652,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06679335236549377,
                "median": 0.05123196542263031,
                "std": 0.2288360297679901,
                "max": 0.6234695315361023,
                "min": -0.5447420477867126,
                "frobenius_norm": 2.335683822631836,
                "spectral_norm": 1.6082780361175537,
                "alpha": 1.499444846588359,
                "alpha_hat": 2.5530037761181346
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08467848598957062,
                "median": 0.10053632408380508,
                "std": 0.2853015661239624,
                "max": 0.6132697463035583,
                "min": -0.7999040484428406,
                "frobenius_norm": 2.3808224201202393,
                "spectral_norm": 1.7183246612548828,
                "alpha": 1.1968772766440265,
                "alpha_hat": 3.7577148024342844
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02810267172753811,
                "median": 0.033904559910297394,
                "std": 0.2614479660987854,
                "max": 0.7870427966117859,
                "min": -0.5651231408119202,
                "frobenius_norm": 2.1036317348480225,
                "spectral_norm": 1.4010597467422485,
                "alpha": 1.1659179182368353,
                "alpha_hat": 2.615560049843092
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06974752247333527,
                "median": 0.06134641915559769,
                "std": 0.18793760240077972,
                "max": 0.4801601767539978,
                "min": -0.2255781888961792,
                "frobenius_norm": 1.6037007570266724,
                "spectral_norm": 0.8931291103363037,
                "alpha": 1.2236864252940516,
                "alpha_hat": 1.2125078213707403
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=32_scaler_type=robust_seed=1617": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1617,
        "scores": {
            "smape": 0.07342813909053802,
            "mse": 496652000.0,
            "mae": 2009.9140625,
            "r2_score": 0.8927163481712341,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06679335236549377,
                "median": 0.05123196542263031,
                "std": 0.2288360297679901,
                "max": 0.6234695315361023,
                "min": -0.5447420477867126,
                "frobenius_norm": 2.335683822631836,
                "spectral_norm": 1.6082780361175537,
                "alpha": 1.499444846588359,
                "alpha_hat": 2.5530037761181346
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08467848598957062,
                "median": 0.10053632408380508,
                "std": 0.2853015661239624,
                "max": 0.6132697463035583,
                "min": -0.7999040484428406,
                "frobenius_norm": 2.3808224201202393,
                "spectral_norm": 1.7183246612548828,
                "alpha": 1.1968772766440265,
                "alpha_hat": 3.7577148024342844
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02810267172753811,
                "median": 0.033904559910297394,
                "std": 0.2614479660987854,
                "max": 0.7870427966117859,
                "min": -0.5651231408119202,
                "frobenius_norm": 2.1036317348480225,
                "spectral_norm": 1.4010597467422485,
                "alpha": 1.1659179182368353,
                "alpha_hat": 2.615560049843092
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06974752247333527,
                "median": 0.06134641915559769,
                "std": 0.18793760240077972,
                "max": 0.4801601767539978,
                "min": -0.2255781888961792,
                "frobenius_norm": 1.6037007570266724,
                "spectral_norm": 0.8931291103363037,
                "alpha": 1.2236864252940516,
                "alpha_hat": 1.2125078213707403
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=32_scaler_type=minmax_seed=42": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 42,
        "scores": {
            "smape": 0.08458326756954193,
            "mse": 652677952.0,
            "mae": 2363.574462890625,
            "r2_score": 0.8590125441551208,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.03639834746718407,
                "median": 0.043467700481414795,
                "std": 0.20287548005580902,
                "max": 0.560364842414856,
                "min": -0.33632218837738037,
                "frobenius_norm": 2.0195040702819824,
                "spectral_norm": 1.2217844724655151,
                "alpha": 1.5648554017194232,
                "alpha_hat": 2.074431126164439
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022980911657214165,
                "median": 0.061155736446380615,
                "std": 0.27197667956352234,
                "max": 0.5856873989105225,
                "min": -0.7193127274513245,
                "frobenius_norm": 2.1835668087005615,
                "spectral_norm": 1.4990248680114746,
                "alpha": 1.3152953662847122,
                "alpha_hat": 2.36078202388422
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02166355587542057,
                "median": 0.04364466294646263,
                "std": 0.24290694296360016,
                "max": 0.5433268547058105,
                "min": -0.4617117941379547,
                "frobenius_norm": 1.9509683847427368,
                "spectral_norm": 1.2265958786010742,
                "alpha": 1.2631375008718073,
                "alpha_hat": 2.1848654600187927
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07136586308479309,
                "median": 0.0759425237774849,
                "std": 0.20491014420986176,
                "max": 0.5749915242195129,
                "min": -0.3455636203289032,
                "frobenius_norm": 1.7358571290969849,
                "spectral_norm": 1.2389107942581177,
                "alpha": 1.0935349046393248,
                "alpha_hat": 2.2790765149698915
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=32_scaler_type=robust_seed=1819": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1819,
        "scores": {
            "smape": 0.07365737855434418,
            "mse": 511845344.0,
            "mae": 2037.5439453125,
            "r2_score": 0.8894343376159668,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.03639834746718407,
                "median": 0.043467700481414795,
                "std": 0.20287548005580902,
                "max": 0.560364842414856,
                "min": -0.33632218837738037,
                "frobenius_norm": 2.0195040702819824,
                "spectral_norm": 1.2217844724655151,
                "alpha": 1.5648554017194232,
                "alpha_hat": 2.074431126164439
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022980911657214165,
                "median": 0.061155736446380615,
                "std": 0.27197667956352234,
                "max": 0.5856873989105225,
                "min": -0.7193127274513245,
                "frobenius_norm": 2.1835668087005615,
                "spectral_norm": 1.4990248680114746,
                "alpha": 1.3152953662847122,
                "alpha_hat": 2.36078202388422
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02166355587542057,
                "median": 0.04364466294646263,
                "std": 0.24290694296360016,
                "max": 0.5433268547058105,
                "min": -0.4617117941379547,
                "frobenius_norm": 1.9509683847427368,
                "spectral_norm": 1.2265958786010742,
                "alpha": 1.2631375008718073,
                "alpha_hat": 2.1848654600187927
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07136586308479309,
                "median": 0.0759425237774849,
                "std": 0.20491014420986176,
                "max": 0.5749915242195129,
                "min": -0.3455636203289032,
                "frobenius_norm": 1.7358571290969849,
                "spectral_norm": 1.2389107942581177,
                "alpha": 1.0935349046393248,
                "alpha_hat": 2.2790765149698915
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=32_scaler_type=minmax_seed=123": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 123,
        "scores": {
            "smape": 0.07982322573661804,
            "mse": 506769600.0,
            "mae": 2213.824462890625,
            "r2_score": 0.8905307650566101,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.03639834746718407,
                "median": 0.043467700481414795,
                "std": 0.20287548005580902,
                "max": 0.560364842414856,
                "min": -0.33632218837738037,
                "frobenius_norm": 2.0195040702819824,
                "spectral_norm": 1.2217844724655151,
                "alpha": 1.5648554017194232,
                "alpha_hat": 2.074431126164439
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022980911657214165,
                "median": 0.061155736446380615,
                "std": 0.27197667956352234,
                "max": 0.5856873989105225,
                "min": -0.7193127274513245,
                "frobenius_norm": 2.1835668087005615,
                "spectral_norm": 1.4990248680114746,
                "alpha": 1.3152953662847122,
                "alpha_hat": 2.36078202388422
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02166355587542057,
                "median": 0.04364466294646263,
                "std": 0.24290694296360016,
                "max": 0.5433268547058105,
                "min": -0.4617117941379547,
                "frobenius_norm": 1.9509683847427368,
                "spectral_norm": 1.2265958786010742,
                "alpha": 1.2631375008718073,
                "alpha_hat": 2.1848654600187927
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07136586308479309,
                "median": 0.0759425237774849,
                "std": 0.20491014420986176,
                "max": 0.5749915242195129,
                "min": -0.3455636203289032,
                "frobenius_norm": 1.7358571290969849,
                "spectral_norm": 1.2389107942581177,
                "alpha": 1.0935349046393248,
                "alpha_hat": 2.2790765149698915
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=32_scaler_type=robust_seed=2021": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 2021,
        "scores": {
            "smape": 0.07354036718606949,
            "mse": 498359424.0,
            "mae": 2020.86181640625,
            "r2_score": 0.892347514629364,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.03639834746718407,
                "median": 0.043467700481414795,
                "std": 0.20287548005580902,
                "max": 0.560364842414856,
                "min": -0.33632218837738037,
                "frobenius_norm": 2.0195040702819824,
                "spectral_norm": 1.2217844724655151,
                "alpha": 1.5648554017194232,
                "alpha_hat": 2.074431126164439
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022980911657214165,
                "median": 0.061155736446380615,
                "std": 0.27197667956352234,
                "max": 0.5856873989105225,
                "min": -0.7193127274513245,
                "frobenius_norm": 2.1835668087005615,
                "spectral_norm": 1.4990248680114746,
                "alpha": 1.3152953662847122,
                "alpha_hat": 2.36078202388422
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02166355587542057,
                "median": 0.04364466294646263,
                "std": 0.24290694296360016,
                "max": 0.5433268547058105,
                "min": -0.4617117941379547,
                "frobenius_norm": 1.9509683847427368,
                "spectral_norm": 1.2265958786010742,
                "alpha": 1.2631375008718073,
                "alpha_hat": 2.1848654600187927
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07136586308479309,
                "median": 0.0759425237774849,
                "std": 0.20491014420986176,
                "max": 0.5749915242195129,
                "min": -0.3455636203289032,
                "frobenius_norm": 1.7358571290969849,
                "spectral_norm": 1.2389107942581177,
                "alpha": 1.0935349046393248,
                "alpha_hat": 2.2790765149698915
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=32_scaler_type=minmax_seed=789": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 789,
        "scores": {
            "smape": 0.08504822850227356,
            "mse": 646392064.0,
            "mae": 2354.461669921875,
            "r2_score": 0.860370397567749,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06365596503019333,
                "median": 0.05006328225135803,
                "std": 0.20105880498886108,
                "max": 0.5575433373451233,
                "min": -0.3194192349910736,
                "frobenius_norm": 2.0663414001464844,
                "spectral_norm": 1.4597877264022827,
                "alpha": 1.5415353094232955,
                "alpha_hat": 2.296988145376929
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03807844966650009,
                "median": 0.07726827263832092,
                "std": 0.2549404501914978,
                "max": 0.48147955536842346,
                "min": -0.823212206363678,
                "frobenius_norm": 2.062147855758667,
                "spectral_norm": 1.3162401914596558,
                "alpha": 1.253839881289208,
                "alpha_hat": 2.1642196472483324
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02119799517095089,
                "median": 0.004776317160576582,
                "std": 0.24310831725597382,
                "max": 0.7063159942626953,
                "min": -0.6264904737472534,
                "frobenius_norm": 1.9522461891174316,
                "spectral_norm": 1.1918810606002808,
                "alpha": 1.3632181046996465,
                "alpha_hat": 2.568064432930227
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06623916327953339,
                "median": 0.045082710683345795,
                "std": 0.18748903274536133,
                "max": 0.4220511317253113,
                "min": -0.2373107224702835,
                "frobenius_norm": 1.590768575668335,
                "spectral_norm": 0.8713216781616211,
                "alpha": 1.2283141063910956,
                "alpha_hat": 1.1995875061249628
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=32_scaler_type=minmax_seed=456": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 456,
        "scores": {
            "smape": 0.08123140782117844,
            "mse": 607192320.0,
            "mae": 2278.012451171875,
            "r2_score": 0.8688380718231201,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06365596503019333,
                "median": 0.05006328225135803,
                "std": 0.20105880498886108,
                "max": 0.5575433373451233,
                "min": -0.3194192349910736,
                "frobenius_norm": 2.0663414001464844,
                "spectral_norm": 1.4597877264022827,
                "alpha": 1.5415353094232955,
                "alpha_hat": 2.296988145376929
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03807844966650009,
                "median": 0.07726827263832092,
                "std": 0.2549404501914978,
                "max": 0.48147955536842346,
                "min": -0.823212206363678,
                "frobenius_norm": 2.062147855758667,
                "spectral_norm": 1.3162401914596558,
                "alpha": 1.253839881289208,
                "alpha_hat": 2.1642196472483324
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02119799517095089,
                "median": 0.004776317160576582,
                "std": 0.24310831725597382,
                "max": 0.7063159942626953,
                "min": -0.6264904737472534,
                "frobenius_norm": 1.9522461891174316,
                "spectral_norm": 1.1918810606002808,
                "alpha": 1.3632181046996465,
                "alpha_hat": 2.568064432930227
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06623916327953339,
                "median": 0.045082710683345795,
                "std": 0.18748903274536133,
                "max": 0.4220511317253113,
                "min": -0.2373107224702835,
                "frobenius_norm": 1.590768575668335,
                "spectral_norm": 0.8713216781616211,
                "alpha": 1.2283141063910956,
                "alpha_hat": 1.1995875061249628
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=32_scaler_type=minmax_seed=1213": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1213,
        "scores": {
            "smape": 0.08219228684902191,
            "mse": 618940160.0,
            "mae": 2286.909912109375,
            "r2_score": 0.8663004040718079,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06365596503019333,
                "median": 0.05006328225135803,
                "std": 0.20105880498886108,
                "max": 0.5575433373451233,
                "min": -0.3194192349910736,
                "frobenius_norm": 2.0663414001464844,
                "spectral_norm": 1.4597877264022827,
                "alpha": 1.5415353094232955,
                "alpha_hat": 2.296988145376929
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03807844966650009,
                "median": 0.07726827263832092,
                "std": 0.2549404501914978,
                "max": 0.48147955536842346,
                "min": -0.823212206363678,
                "frobenius_norm": 2.062147855758667,
                "spectral_norm": 1.3162401914596558,
                "alpha": 1.253839881289208,
                "alpha_hat": 2.1642196472483324
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02119799517095089,
                "median": 0.004776317160576582,
                "std": 0.24310831725597382,
                "max": 0.7063159942626953,
                "min": -0.6264904737472534,
                "frobenius_norm": 1.9522461891174316,
                "spectral_norm": 1.1918810606002808,
                "alpha": 1.3632181046996465,
                "alpha_hat": 2.568064432930227
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06623916327953339,
                "median": 0.045082710683345795,
                "std": 0.18748903274536133,
                "max": 0.4220511317253113,
                "min": -0.2373107224702835,
                "frobenius_norm": 1.590768575668335,
                "spectral_norm": 0.8713216781616211,
                "alpha": 1.2283141063910956,
                "alpha_hat": 1.1995875061249628
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=32_scaler_type=minmax_seed=1011": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1011,
        "scores": {
            "smape": 0.08202026784420013,
            "mse": 612276224.0,
            "mae": 2275.14453125,
            "r2_score": 0.8677399158477783,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06365596503019333,
                "median": 0.05006328225135803,
                "std": 0.20105880498886108,
                "max": 0.5575433373451233,
                "min": -0.3194192349910736,
                "frobenius_norm": 2.0663414001464844,
                "spectral_norm": 1.4597877264022827,
                "alpha": 1.5415353094232955,
                "alpha_hat": 2.296988145376929
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03807844966650009,
                "median": 0.07726827263832092,
                "std": 0.2549404501914978,
                "max": 0.48147955536842346,
                "min": -0.823212206363678,
                "frobenius_norm": 2.062147855758667,
                "spectral_norm": 1.3162401914596558,
                "alpha": 1.253839881289208,
                "alpha_hat": 2.1642196472483324
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02119799517095089,
                "median": 0.004776317160576582,
                "std": 0.24310831725597382,
                "max": 0.7063159942626953,
                "min": -0.6264904737472534,
                "frobenius_norm": 1.9522461891174316,
                "spectral_norm": 1.1918810606002808,
                "alpha": 1.3632181046996465,
                "alpha_hat": 2.568064432930227
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06623916327953339,
                "median": 0.045082710683345795,
                "std": 0.18748903274536133,
                "max": 0.4220511317253113,
                "min": -0.2373107224702835,
                "frobenius_norm": 1.590768575668335,
                "spectral_norm": 0.8713216781616211,
                "alpha": 1.2283141063910956,
                "alpha_hat": 1.1995875061249628
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=32_scaler_type=minmax_seed=1819": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1819,
        "scores": {
            "smape": 0.08022104203701019,
            "mse": 477997184.0,
            "mae": 2162.88525390625,
            "r2_score": 0.896746039390564,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.03171679750084877,
                "median": 0.02514643222093582,
                "std": 0.20547156035900116,
                "max": 0.5098399519920349,
                "min": -0.5393314361572266,
                "frobenius_norm": 2.0370452404022217,
                "spectral_norm": 1.352288007736206,
                "alpha": 1.4961030938008022,
                "alpha_hat": 2.602676501947603
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.00920762401074171,
                "median": 0.035396479070186615,
                "std": 0.24935807287693024,
                "max": 0.5059114694595337,
                "min": -0.5424681305885315,
                "frobenius_norm": 1.996224045753479,
                "spectral_norm": 1.399903416633606,
                "alpha": 1.2186900294047331,
                "alpha_hat": 1.7258692093346886
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.032833799719810486,
                "median": 0.03441633656620979,
                "std": 0.2386079579591751,
                "max": 0.6042032837867737,
                "min": -0.39066529273986816,
                "frobenius_norm": 1.926851511001587,
                "spectral_norm": 1.41205894947052,
                "alpha": 1.1127097396972034,
                "alpha_hat": 1.9812865315138688
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03309471905231476,
                "median": 0.0658431351184845,
                "std": 0.22539426386356354,
                "max": 0.49533089995384216,
                "min": -0.36088740825653076,
                "frobenius_norm": 1.822487711906433,
                "spectral_norm": 1.0294219255447388,
                "alpha": 1.1341910823532408,
                "alpha_hat": 1.6066151679016067
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=32_scaler_type=minmax_seed=1415": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1415,
        "scores": {
            "smape": 0.08280719816684723,
            "mse": 646051840.0,
            "mae": 2333.046630859375,
            "r2_score": 0.8604438900947571,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.03171679750084877,
                "median": 0.02514643222093582,
                "std": 0.20547156035900116,
                "max": 0.5098399519920349,
                "min": -0.5393314361572266,
                "frobenius_norm": 2.0370452404022217,
                "spectral_norm": 1.352288007736206,
                "alpha": 1.4961030938008022,
                "alpha_hat": 2.602676501947603
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.00920762401074171,
                "median": 0.035396479070186615,
                "std": 0.24935807287693024,
                "max": 0.5059114694595337,
                "min": -0.5424681305885315,
                "frobenius_norm": 1.996224045753479,
                "spectral_norm": 1.399903416633606,
                "alpha": 1.2186900294047331,
                "alpha_hat": 1.7258692093346886
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.032833799719810486,
                "median": 0.03441633656620979,
                "std": 0.2386079579591751,
                "max": 0.6042032837867737,
                "min": -0.39066529273986816,
                "frobenius_norm": 1.926851511001587,
                "spectral_norm": 1.41205894947052,
                "alpha": 1.1127097396972034,
                "alpha_hat": 1.9812865315138688
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03309471905231476,
                "median": 0.0658431351184845,
                "std": 0.22539426386356354,
                "max": 0.49533089995384216,
                "min": -0.36088740825653076,
                "frobenius_norm": 1.822487711906433,
                "spectral_norm": 1.0294219255447388,
                "alpha": 1.1341910823532408,
                "alpha_hat": 1.6066151679016067
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=32_scaler_type=minmax_seed=1617": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1617,
        "scores": {
            "smape": 0.08246809244155884,
            "mse": 603908800.0,
            "mae": 2277.218017578125,
            "r2_score": 0.8695473670959473,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.03171679750084877,
                "median": 0.02514643222093582,
                "std": 0.20547156035900116,
                "max": 0.5098399519920349,
                "min": -0.5393314361572266,
                "frobenius_norm": 2.0370452404022217,
                "spectral_norm": 1.352288007736206,
                "alpha": 1.4961030938008022,
                "alpha_hat": 2.602676501947603
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.00920762401074171,
                "median": 0.035396479070186615,
                "std": 0.24935807287693024,
                "max": 0.5059114694595337,
                "min": -0.5424681305885315,
                "frobenius_norm": 1.996224045753479,
                "spectral_norm": 1.399903416633606,
                "alpha": 1.2186900294047331,
                "alpha_hat": 1.7258692093346886
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.032833799719810486,
                "median": 0.03441633656620979,
                "std": 0.2386079579591751,
                "max": 0.6042032837867737,
                "min": -0.39066529273986816,
                "frobenius_norm": 1.926851511001587,
                "spectral_norm": 1.41205894947052,
                "alpha": 1.1127097396972034,
                "alpha_hat": 1.9812865315138688
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03309471905231476,
                "median": 0.0658431351184845,
                "std": 0.22539426386356354,
                "max": 0.49533089995384216,
                "min": -0.36088740825653076,
                "frobenius_norm": 1.822487711906433,
                "spectral_norm": 1.0294219255447388,
                "alpha": 1.1341910823532408,
                "alpha_hat": 1.6066151679016067
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.001_batch_size=32_scaler_type=minmax_seed=2021": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 2021,
        "scores": {
            "smape": 0.08130791783332825,
            "mse": 495458208.0,
            "mae": 2207.590087890625,
            "r2_score": 0.8929741978645325,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.03171679750084877,
                "median": 0.02514643222093582,
                "std": 0.20547156035900116,
                "max": 0.5098399519920349,
                "min": -0.5393314361572266,
                "frobenius_norm": 2.0370452404022217,
                "spectral_norm": 1.352288007736206,
                "alpha": 1.4961030938008022,
                "alpha_hat": 2.602676501947603
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.00920762401074171,
                "median": 0.035396479070186615,
                "std": 0.24935807287693024,
                "max": 0.5059114694595337,
                "min": -0.5424681305885315,
                "frobenius_norm": 1.996224045753479,
                "spectral_norm": 1.399903416633606,
                "alpha": 1.2186900294047331,
                "alpha_hat": 1.7258692093346886
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.032833799719810486,
                "median": 0.03441633656620979,
                "std": 0.2386079579591751,
                "max": 0.6042032837867737,
                "min": -0.39066529273986816,
                "frobenius_norm": 1.926851511001587,
                "spectral_norm": 1.41205894947052,
                "alpha": 1.1127097396972034,
                "alpha_hat": 1.9812865315138688
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03309471905231476,
                "median": 0.0658431351184845,
                "std": 0.22539426386356354,
                "max": 0.49533089995384216,
                "min": -0.36088740825653076,
                "frobenius_norm": 1.822487711906433,
                "spectral_norm": 1.0294219255447388,
                "alpha": 1.1341910823532408,
                "alpha_hat": 1.6066151679016067
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=8_scaler_type=identity_seed=123": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 8,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 123,
        "scores": {
            "smape": 0.08694729208946228,
            "mse": 513025856.0,
            "mae": 2052.585693359375,
            "r2_score": 0.8891793489456177,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.0794723704457283,
                "median": 0.08016777783632278,
                "std": 0.157553032040596,
                "max": 0.37686780095100403,
                "min": -0.22410792112350464,
                "frobenius_norm": 1.7289668321609497,
                "spectral_norm": 0.9925488233566284,
                "alpha": 1.6537331380371723,
                "alpha_hat": 2.3879445299459303
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06253908574581146,
                "median": 0.08125533163547516,
                "std": 0.2302664816379547,
                "max": 0.4649101793766022,
                "min": -0.3396340012550354,
                "frobenius_norm": 1.9088642597198486,
                "spectral_norm": 1.228135108947754,
                "alpha": 1.1370596938862214,
                "alpha_hat": 1.8456933900254964
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07409924268722534,
                "median": 0.030582383275032043,
                "std": 0.23846246302127838,
                "max": 0.5447297096252441,
                "min": -0.297452449798584,
                "frobenius_norm": 1.9976792335510254,
                "spectral_norm": 1.369116187095642,
                "alpha": 1.232459470057894,
                "alpha_hat": 3.1917804880499836
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.10107950121164322,
                "median": 0.1116371750831604,
                "std": 0.1876341700553894,
                "max": 0.4832982122898102,
                "min": -0.26481229066848755,
                "frobenius_norm": 1.7050259113311768,
                "spectral_norm": 1.0380829572677612,
                "alpha": 1.2048273858471865,
                "alpha_hat": 1.4746364485124468
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=8_scaler_type=identity_seed=42": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 8,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 42,
        "scores": {
            "smape": 0.08541163802146912,
            "mse": 533879520.0,
            "mae": 2040.6815185546875,
            "r2_score": 0.8846746683120728,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.0794723704457283,
                "median": 0.08016777783632278,
                "std": 0.157553032040596,
                "max": 0.37686780095100403,
                "min": -0.22410792112350464,
                "frobenius_norm": 1.7289668321609497,
                "spectral_norm": 0.9925488233566284,
                "alpha": 1.6537331380371723,
                "alpha_hat": 2.3879445299459303
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06253908574581146,
                "median": 0.08125533163547516,
                "std": 0.2302664816379547,
                "max": 0.4649101793766022,
                "min": -0.3396340012550354,
                "frobenius_norm": 1.9088642597198486,
                "spectral_norm": 1.228135108947754,
                "alpha": 1.1370596938862214,
                "alpha_hat": 1.8456933900254964
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07409924268722534,
                "median": 0.030582383275032043,
                "std": 0.23846246302127838,
                "max": 0.5447297096252441,
                "min": -0.297452449798584,
                "frobenius_norm": 1.9976792335510254,
                "spectral_norm": 1.369116187095642,
                "alpha": 1.232459470057894,
                "alpha_hat": 3.1917804880499836
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.10107950121164322,
                "median": 0.1116371750831604,
                "std": 0.1876341700553894,
                "max": 0.4832982122898102,
                "min": -0.26481229066848755,
                "frobenius_norm": 1.7050259113311768,
                "spectral_norm": 1.0380829572677612,
                "alpha": 1.2048273858471865,
                "alpha_hat": 1.4746364485124468
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=8_scaler_type=identity_seed=789": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 8,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 789,
        "scores": {
            "smape": 0.0850491002202034,
            "mse": 500034144.0,
            "mae": 2014.097900390625,
            "r2_score": 0.8919857144355774,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.0794723704457283,
                "median": 0.08016777783632278,
                "std": 0.157553032040596,
                "max": 0.37686780095100403,
                "min": -0.22410792112350464,
                "frobenius_norm": 1.7289668321609497,
                "spectral_norm": 0.9925488233566284,
                "alpha": 1.6537331380371723,
                "alpha_hat": 2.3879445299459303
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06253908574581146,
                "median": 0.08125533163547516,
                "std": 0.2302664816379547,
                "max": 0.4649101793766022,
                "min": -0.3396340012550354,
                "frobenius_norm": 1.9088642597198486,
                "spectral_norm": 1.228135108947754,
                "alpha": 1.1370596938862214,
                "alpha_hat": 1.8456933900254964
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07409924268722534,
                "median": 0.030582383275032043,
                "std": 0.23846246302127838,
                "max": 0.5447297096252441,
                "min": -0.297452449798584,
                "frobenius_norm": 1.9976792335510254,
                "spectral_norm": 1.369116187095642,
                "alpha": 1.232459470057894,
                "alpha_hat": 3.1917804880499836
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.10107950121164322,
                "median": 0.1116371750831604,
                "std": 0.1876341700553894,
                "max": 0.4832982122898102,
                "min": -0.26481229066848755,
                "frobenius_norm": 1.7050259113311768,
                "spectral_norm": 1.0380829572677612,
                "alpha": 1.2048273858471865,
                "alpha_hat": 1.4746364485124468
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=8_scaler_type=identity_seed=456": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 8,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 456,
        "scores": {
            "smape": 0.08891062438488007,
            "mse": 512817504.0,
            "mae": 2079.37353515625,
            "r2_score": 0.8892243504524231,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.0794723704457283,
                "median": 0.08016777783632278,
                "std": 0.157553032040596,
                "max": 0.37686780095100403,
                "min": -0.22410792112350464,
                "frobenius_norm": 1.7289668321609497,
                "spectral_norm": 0.9925488233566284,
                "alpha": 1.6537331380371723,
                "alpha_hat": 2.3879445299459303
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06253908574581146,
                "median": 0.08125533163547516,
                "std": 0.2302664816379547,
                "max": 0.4649101793766022,
                "min": -0.3396340012550354,
                "frobenius_norm": 1.9088642597198486,
                "spectral_norm": 1.228135108947754,
                "alpha": 1.1370596938862214,
                "alpha_hat": 1.8456933900254964
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07409924268722534,
                "median": 0.030582383275032043,
                "std": 0.23846246302127838,
                "max": 0.5447297096252441,
                "min": -0.297452449798584,
                "frobenius_norm": 1.9976792335510254,
                "spectral_norm": 1.369116187095642,
                "alpha": 1.232459470057894,
                "alpha_hat": 3.1917804880499836
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.10107950121164322,
                "median": 0.1116371750831604,
                "std": 0.1876341700553894,
                "max": 0.4832982122898102,
                "min": -0.26481229066848755,
                "frobenius_norm": 1.7050259113311768,
                "spectral_norm": 1.0380829572677612,
                "alpha": 1.2048273858471865,
                "alpha_hat": 1.4746364485124468
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=8_scaler_type=identity_seed=1011": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 8,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1011,
        "scores": {
            "smape": 0.08412753790616989,
            "mse": 501454272.0,
            "mae": 2008.160888671875,
            "r2_score": 0.8916789889335632,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.07626628875732422,
                "median": 0.06497296690940857,
                "std": 0.16063737869262695,
                "max": 0.3811747431755066,
                "min": -0.27973026037216187,
                "frobenius_norm": 1.7422995567321777,
                "spectral_norm": 1.002007007598877,
                "alpha": 1.6286691893869794,
                "alpha_hat": 2.411802701205784
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0709340050816536,
                "median": 0.0828191414475441,
                "std": 0.22750364243984222,
                "max": 0.4588623046875,
                "min": -0.3069383203983307,
                "frobenius_norm": 1.9064445495605469,
                "spectral_norm": 1.2555307149887085,
                "alpha": 1.1832742614480394,
                "alpha_hat": 1.9336538742681766
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07655283808708191,
                "median": 0.028098929673433304,
                "std": 0.24059925973415375,
                "max": 0.5571374893188477,
                "min": -0.308480441570282,
                "frobenius_norm": 2.0198748111724854,
                "spectral_norm": 1.3676722049713135,
                "alpha": 1.1960042535183553,
                "alpha_hat": 3.2057029501939955
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.09828326106071472,
                "median": 0.10485588014125824,
                "std": 0.18985861539840698,
                "max": 0.4828213155269623,
                "min": -0.27311480045318604,
                "frobenius_norm": 1.7103151082992554,
                "spectral_norm": 1.0509381294250488,
                "alpha": 1.232278577193826,
                "alpha_hat": 1.52062584833849
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=8_scaler_type=identity_seed=1617": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 8,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1617,
        "scores": {
            "smape": 0.08512692898511887,
            "mse": 507108128.0,
            "mae": 2000.183349609375,
            "r2_score": 0.8904576301574707,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.07626628875732422,
                "median": 0.06497296690940857,
                "std": 0.16063737869262695,
                "max": 0.3811747431755066,
                "min": -0.27973026037216187,
                "frobenius_norm": 1.7422995567321777,
                "spectral_norm": 1.002007007598877,
                "alpha": 1.6286691893869794,
                "alpha_hat": 2.411802701205784
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0709340050816536,
                "median": 0.0828191414475441,
                "std": 0.22750364243984222,
                "max": 0.4588623046875,
                "min": -0.3069383203983307,
                "frobenius_norm": 1.9064445495605469,
                "spectral_norm": 1.2555307149887085,
                "alpha": 1.1832742614480394,
                "alpha_hat": 1.9336538742681766
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07655283808708191,
                "median": 0.028098929673433304,
                "std": 0.24059925973415375,
                "max": 0.5571374893188477,
                "min": -0.308480441570282,
                "frobenius_norm": 2.0198748111724854,
                "spectral_norm": 1.3676722049713135,
                "alpha": 1.1960042535183553,
                "alpha_hat": 3.2057029501939955
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.09828326106071472,
                "median": 0.10485588014125824,
                "std": 0.18985861539840698,
                "max": 0.4828213155269623,
                "min": -0.27311480045318604,
                "frobenius_norm": 1.7103151082992554,
                "spectral_norm": 1.0509381294250488,
                "alpha": 1.232278577193826,
                "alpha_hat": 1.52062584833849
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=8_scaler_type=identity_seed=1213": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 8,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1213,
        "scores": {
            "smape": 0.08446649461984634,
            "mse": 480126944.0,
            "mae": 1986.3302001953125,
            "r2_score": 0.8962859511375427,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.07626628875732422,
                "median": 0.06497296690940857,
                "std": 0.16063737869262695,
                "max": 0.3811747431755066,
                "min": -0.27973026037216187,
                "frobenius_norm": 1.7422995567321777,
                "spectral_norm": 1.002007007598877,
                "alpha": 1.6286691893869794,
                "alpha_hat": 2.411802701205784
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0709340050816536,
                "median": 0.0828191414475441,
                "std": 0.22750364243984222,
                "max": 0.4588623046875,
                "min": -0.3069383203983307,
                "frobenius_norm": 1.9064445495605469,
                "spectral_norm": 1.2555307149887085,
                "alpha": 1.1832742614480394,
                "alpha_hat": 1.9336538742681766
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07655283808708191,
                "median": 0.028098929673433304,
                "std": 0.24059925973415375,
                "max": 0.5571374893188477,
                "min": -0.308480441570282,
                "frobenius_norm": 2.0198748111724854,
                "spectral_norm": 1.3676722049713135,
                "alpha": 1.1960042535183553,
                "alpha_hat": 3.2057029501939955
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.09828326106071472,
                "median": 0.10485588014125824,
                "std": 0.18985861539840698,
                "max": 0.4828213155269623,
                "min": -0.27311480045318604,
                "frobenius_norm": 1.7103151082992554,
                "spectral_norm": 1.0509381294250488,
                "alpha": 1.232278577193826,
                "alpha_hat": 1.52062584833849
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=8_scaler_type=identity_seed=1415": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 8,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1415,
        "scores": {
            "smape": 0.08806939423084259,
            "mse": 549309504.0,
            "mae": 2075.94775390625,
            "r2_score": 0.8813415765762329,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.07626628875732422,
                "median": 0.06497296690940857,
                "std": 0.16063737869262695,
                "max": 0.3811747431755066,
                "min": -0.27973026037216187,
                "frobenius_norm": 1.7422995567321777,
                "spectral_norm": 1.002007007598877,
                "alpha": 1.6286691893869794,
                "alpha_hat": 2.411802701205784
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0709340050816536,
                "median": 0.0828191414475441,
                "std": 0.22750364243984222,
                "max": 0.4588623046875,
                "min": -0.3069383203983307,
                "frobenius_norm": 1.9064445495605469,
                "spectral_norm": 1.2555307149887085,
                "alpha": 1.1832742614480394,
                "alpha_hat": 1.9336538742681766
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07655283808708191,
                "median": 0.028098929673433304,
                "std": 0.24059925973415375,
                "max": 0.5571374893188477,
                "min": -0.308480441570282,
                "frobenius_norm": 2.0198748111724854,
                "spectral_norm": 1.3676722049713135,
                "alpha": 1.1960042535183553,
                "alpha_hat": 3.2057029501939955
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.09828326106071472,
                "median": 0.10485588014125824,
                "std": 0.18985861539840698,
                "max": 0.4828213155269623,
                "min": -0.27311480045318604,
                "frobenius_norm": 1.7103151082992554,
                "spectral_norm": 1.0509381294250488,
                "alpha": 1.232278577193826,
                "alpha_hat": 1.52062584833849
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=8_scaler_type=identity_seed=2021": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 8,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 2021,
        "scores": {
            "smape": 0.08463209122419357,
            "mse": 484061632.0,
            "mae": 1990.8170166015625,
            "r2_score": 0.8954360485076904,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.023921439424157143,
                "median": 0.04691255837678909,
                "std": 0.1824379563331604,
                "max": 0.3578391373157501,
                "min": -0.4277966320514679,
                "frobenius_norm": 1.8028203248977661,
                "spectral_norm": 1.0658600330352783,
                "alpha": 1.682952513094353,
                "alpha_hat": 2.2024014519687802
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.004414301365613937,
                "median": 0.04307017847895622,
                "std": 0.22529587149620056,
                "max": 0.35803282260894775,
                "min": -0.5128962993621826,
                "frobenius_norm": 1.8027127981185913,
                "spectral_norm": 1.0624406337738037,
                "alpha": 1.292886832482674,
                "alpha_hat": 1.6472895456004055
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.012386209331452847,
                "median": -0.008283987641334534,
                "std": 0.23997026681900024,
                "max": 0.6452137231826782,
                "min": -0.3878283202648163,
                "frobenius_norm": 1.9223177433013916,
                "spectral_norm": 1.1652311086654663,
                "alpha": 1.2081090992315224,
                "alpha_hat": 2.3413241756167436
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03319341689348221,
                "median": 0.010650325566530228,
                "std": 0.1950491964817047,
                "max": 0.4605502188205719,
                "min": -0.2832624912261963,
                "frobenius_norm": 1.5828276872634888,
                "spectral_norm": 0.8859544396400452,
                "alpha": 1.2534093736946177,
                "alpha_hat": 1.1742140018287281
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=8_scaler_type=identity_seed=1819": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 8,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1819,
        "scores": {
            "smape": 0.0872640609741211,
            "mse": 514772480.0,
            "mae": 2031.382080078125,
            "r2_score": 0.8888020515441895,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.023921439424157143,
                "median": 0.04691255837678909,
                "std": 0.1824379563331604,
                "max": 0.3578391373157501,
                "min": -0.4277966320514679,
                "frobenius_norm": 1.8028203248977661,
                "spectral_norm": 1.0658600330352783,
                "alpha": 1.682952513094353,
                "alpha_hat": 2.2024014519687802
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.004414301365613937,
                "median": 0.04307017847895622,
                "std": 0.22529587149620056,
                "max": 0.35803282260894775,
                "min": -0.5128962993621826,
                "frobenius_norm": 1.8027127981185913,
                "spectral_norm": 1.0624406337738037,
                "alpha": 1.292886832482674,
                "alpha_hat": 1.6472895456004055
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.012386209331452847,
                "median": -0.008283987641334534,
                "std": 0.23997026681900024,
                "max": 0.6452137231826782,
                "min": -0.3878283202648163,
                "frobenius_norm": 1.9223177433013916,
                "spectral_norm": 1.1652311086654663,
                "alpha": 1.2081090992315224,
                "alpha_hat": 2.3413241756167436
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03319341689348221,
                "median": 0.010650325566530228,
                "std": 0.1950491964817047,
                "max": 0.4605502188205719,
                "min": -0.2832624912261963,
                "frobenius_norm": 1.5828276872634888,
                "spectral_norm": 0.8859544396400452,
                "alpha": 1.2534093736946177,
                "alpha_hat": 1.1742140018287281
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=8_scaler_type=standard_seed=42": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 8,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 42,
        "scores": {
            "smape": 0.07723238319158554,
            "mse": 570119808.0,
            "mae": 2097.43798828125,
            "r2_score": 0.8768462538719177,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.023921439424157143,
                "median": 0.04691255837678909,
                "std": 0.1824379563331604,
                "max": 0.3578391373157501,
                "min": -0.4277966320514679,
                "frobenius_norm": 1.8028203248977661,
                "spectral_norm": 1.0658600330352783,
                "alpha": 1.682952513094353,
                "alpha_hat": 2.2024014519687802
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.004414301365613937,
                "median": 0.04307017847895622,
                "std": 0.22529587149620056,
                "max": 0.35803282260894775,
                "min": -0.5128962993621826,
                "frobenius_norm": 1.8027127981185913,
                "spectral_norm": 1.0624406337738037,
                "alpha": 1.292886832482674,
                "alpha_hat": 1.6472895456004055
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.012386209331452847,
                "median": -0.008283987641334534,
                "std": 0.23997026681900024,
                "max": 0.6452137231826782,
                "min": -0.3878283202648163,
                "frobenius_norm": 1.9223177433013916,
                "spectral_norm": 1.1652311086654663,
                "alpha": 1.2081090992315224,
                "alpha_hat": 2.3413241756167436
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03319341689348221,
                "median": 0.010650325566530228,
                "std": 0.1950491964817047,
                "max": 0.4605502188205719,
                "min": -0.2832624912261963,
                "frobenius_norm": 1.5828276872634888,
                "spectral_norm": 0.8859544396400452,
                "alpha": 1.2534093736946177,
                "alpha_hat": 1.1742140018287281
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=8_scaler_type=standard_seed=123": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 8,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 123,
        "scores": {
            "smape": 0.07739417999982834,
            "mse": 567264320.0,
            "mae": 2089.7548828125,
            "r2_score": 0.8774631023406982,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.023921439424157143,
                "median": 0.04691255837678909,
                "std": 0.1824379563331604,
                "max": 0.3578391373157501,
                "min": -0.4277966320514679,
                "frobenius_norm": 1.8028203248977661,
                "spectral_norm": 1.0658600330352783,
                "alpha": 1.682952513094353,
                "alpha_hat": 2.2024014519687802
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.004414301365613937,
                "median": 0.04307017847895622,
                "std": 0.22529587149620056,
                "max": 0.35803282260894775,
                "min": -0.5128962993621826,
                "frobenius_norm": 1.8027127981185913,
                "spectral_norm": 1.0624406337738037,
                "alpha": 1.292886832482674,
                "alpha_hat": 1.6472895456004055
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.012386209331452847,
                "median": -0.008283987641334534,
                "std": 0.23997026681900024,
                "max": 0.6452137231826782,
                "min": -0.3878283202648163,
                "frobenius_norm": 1.9223177433013916,
                "spectral_norm": 1.1652311086654663,
                "alpha": 1.2081090992315224,
                "alpha_hat": 2.3413241756167436
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03319341689348221,
                "median": 0.010650325566530228,
                "std": 0.1950491964817047,
                "max": 0.4605502188205719,
                "min": -0.2832624912261963,
                "frobenius_norm": 1.5828276872634888,
                "spectral_norm": 0.8859544396400452,
                "alpha": 1.2534093736946177,
                "alpha_hat": 1.1742140018287281
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=8_scaler_type=standard_seed=789": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 8,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 789,
        "scores": {
            "smape": 0.07678248733282089,
            "mse": 562627648.0,
            "mae": 2094.9052734375,
            "r2_score": 0.8784646987915039,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.022485947236418724,
                "median": 0.041345126926898956,
                "std": 0.18363989889621735,
                "max": 0.40555596351623535,
                "min": -0.43251270055770874,
                "frobenius_norm": 1.8127343654632568,
                "spectral_norm": 1.0521231889724731,
                "alpha": 1.6996970454567917,
                "alpha_hat": 2.2077938476527197
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01573105901479721,
                "median": 0.04091176390647888,
                "std": 0.22793787717819214,
                "max": 0.35316577553749084,
                "min": -0.5031670928001404,
                "frobenius_norm": 1.8278405666351318,
                "spectral_norm": 1.0549228191375732,
                "alpha": 1.2108625486181723,
                "alpha_hat": 1.5389999815551607
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.005292147863656282,
                "median": -0.025165235623717308,
                "std": 0.23210367560386658,
                "max": 0.4810800850391388,
                "min": -0.34783077239990234,
                "frobenius_norm": 1.8573119640350342,
                "spectral_norm": 1.1968573331832886,
                "alpha": 1.227987977689825,
                "alpha_hat": 2.3419157345867996
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03575700521469116,
                "median": 0.020975150167942047,
                "std": 0.19584092497825623,
                "max": 0.4696429669857025,
                "min": -0.28202924132347107,
                "frobenius_norm": 1.5926276445388794,
                "spectral_norm": 0.906416118144989,
                "alpha": 1.2693469643911142,
                "alpha_hat": 1.2012084915878412
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=8_scaler_type=standard_seed=1011": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 8,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1011,
        "scores": {
            "smape": 0.07744345813989639,
            "mse": 571384384.0,
            "mae": 2098.36962890625,
            "r2_score": 0.8765730857849121,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.022485947236418724,
                "median": 0.041345126926898956,
                "std": 0.18363989889621735,
                "max": 0.40555596351623535,
                "min": -0.43251270055770874,
                "frobenius_norm": 1.8127343654632568,
                "spectral_norm": 1.0521231889724731,
                "alpha": 1.6996970454567917,
                "alpha_hat": 2.2077938476527197
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01573105901479721,
                "median": 0.04091176390647888,
                "std": 0.22793787717819214,
                "max": 0.35316577553749084,
                "min": -0.5031670928001404,
                "frobenius_norm": 1.8278405666351318,
                "spectral_norm": 1.0549228191375732,
                "alpha": 1.2108625486181723,
                "alpha_hat": 1.5389999815551607
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.005292147863656282,
                "median": -0.025165235623717308,
                "std": 0.23210367560386658,
                "max": 0.4810800850391388,
                "min": -0.34783077239990234,
                "frobenius_norm": 1.8573119640350342,
                "spectral_norm": 1.1968573331832886,
                "alpha": 1.227987977689825,
                "alpha_hat": 2.3419157345867996
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03575700521469116,
                "median": 0.020975150167942047,
                "std": 0.19584092497825623,
                "max": 0.4696429669857025,
                "min": -0.28202924132347107,
                "frobenius_norm": 1.5926276445388794,
                "spectral_norm": 0.906416118144989,
                "alpha": 1.2693469643911142,
                "alpha_hat": 1.2012084915878412
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=8_scaler_type=standard_seed=456": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 8,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 456,
        "scores": {
            "smape": 0.07725396007299423,
            "mse": 563074496.0,
            "mae": 2089.7509765625,
            "r2_score": 0.8783681392669678,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.022485947236418724,
                "median": 0.041345126926898956,
                "std": 0.18363989889621735,
                "max": 0.40555596351623535,
                "min": -0.43251270055770874,
                "frobenius_norm": 1.8127343654632568,
                "spectral_norm": 1.0521231889724731,
                "alpha": 1.6996970454567917,
                "alpha_hat": 2.2077938476527197
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01573105901479721,
                "median": 0.04091176390647888,
                "std": 0.22793787717819214,
                "max": 0.35316577553749084,
                "min": -0.5031670928001404,
                "frobenius_norm": 1.8278405666351318,
                "spectral_norm": 1.0549228191375732,
                "alpha": 1.2108625486181723,
                "alpha_hat": 1.5389999815551607
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.005292147863656282,
                "median": -0.025165235623717308,
                "std": 0.23210367560386658,
                "max": 0.4810800850391388,
                "min": -0.34783077239990234,
                "frobenius_norm": 1.8573119640350342,
                "spectral_norm": 1.1968573331832886,
                "alpha": 1.227987977689825,
                "alpha_hat": 2.3419157345867996
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03575700521469116,
                "median": 0.020975150167942047,
                "std": 0.19584092497825623,
                "max": 0.4696429669857025,
                "min": -0.28202924132347107,
                "frobenius_norm": 1.5926276445388794,
                "spectral_norm": 0.906416118144989,
                "alpha": 1.2693469643911142,
                "alpha_hat": 1.2012084915878412
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=8_scaler_type=standard_seed=1213": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 8,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1213,
        "scores": {
            "smape": 0.07731121778488159,
            "mse": 572251776.0,
            "mae": 2094.9521484375,
            "r2_score": 0.8763857483863831,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.022485947236418724,
                "median": 0.041345126926898956,
                "std": 0.18363989889621735,
                "max": 0.40555596351623535,
                "min": -0.43251270055770874,
                "frobenius_norm": 1.8127343654632568,
                "spectral_norm": 1.0521231889724731,
                "alpha": 1.6996970454567917,
                "alpha_hat": 2.2077938476527197
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01573105901479721,
                "median": 0.04091176390647888,
                "std": 0.22793787717819214,
                "max": 0.35316577553749084,
                "min": -0.5031670928001404,
                "frobenius_norm": 1.8278405666351318,
                "spectral_norm": 1.0549228191375732,
                "alpha": 1.2108625486181723,
                "alpha_hat": 1.5389999815551607
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.005292147863656282,
                "median": -0.025165235623717308,
                "std": 0.23210367560386658,
                "max": 0.4810800850391388,
                "min": -0.34783077239990234,
                "frobenius_norm": 1.8573119640350342,
                "spectral_norm": 1.1968573331832886,
                "alpha": 1.227987977689825,
                "alpha_hat": 2.3419157345867996
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03575700521469116,
                "median": 0.020975150167942047,
                "std": 0.19584092497825623,
                "max": 0.4696429669857025,
                "min": -0.28202924132347107,
                "frobenius_norm": 1.5926276445388794,
                "spectral_norm": 0.906416118144989,
                "alpha": 1.2693469643911142,
                "alpha_hat": 1.2012084915878412
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=8_scaler_type=standard_seed=1819": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 8,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1819,
        "scores": {
            "smape": 0.07645963132381439,
            "mse": 469308032.0,
            "mae": 2015.46435546875,
            "r2_score": 0.898622989654541,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.025391491129994392,
                "median": 0.04455309361219406,
                "std": 0.1829126626253128,
                "max": 0.34892764687538147,
                "min": -0.4252776801586151,
                "frobenius_norm": 1.8093562126159668,
                "spectral_norm": 1.0713227987289429,
                "alpha": 1.6537252655075476,
                "alpha_hat": 2.1289946818538943
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.009431784972548485,
                "median": 0.04902338981628418,
                "std": 0.23683564364910126,
                "max": 0.41661903262138367,
                "min": -0.5229147672653198,
                "frobenius_norm": 1.8961870670318604,
                "spectral_norm": 1.1439170837402344,
                "alpha": 1.3139379423132025,
                "alpha_hat": 1.4829373044296588
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.00952419824898243,
                "median": -0.002812714083120227,
                "std": 0.24380134046077728,
                "max": 0.6375495791435242,
                "min": -0.36518216133117676,
                "frobenius_norm": 1.951898455619812,
                "spectral_norm": 1.1926438808441162,
                "alpha": 1.1738608887695614,
                "alpha_hat": 2.2895136642744394
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.027175340801477432,
                "median": 0.004849724471569061,
                "std": 0.19349956512451172,
                "max": 0.41617152094841003,
                "min": -0.2837413549423218,
                "frobenius_norm": 1.563188076019287,
                "spectral_norm": 0.8457284569740295,
                "alpha": 1.2405988905599734,
                "alpha_hat": 1.1351850581562863
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=8_scaler_type=standard_seed=1617": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 8,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1617,
        "scores": {
            "smape": 0.0770035833120346,
            "mse": 485922688.0,
            "mae": 2039.0675048828125,
            "r2_score": 0.8950340151786804,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.025391491129994392,
                "median": 0.04455309361219406,
                "std": 0.1829126626253128,
                "max": 0.34892764687538147,
                "min": -0.4252776801586151,
                "frobenius_norm": 1.8093562126159668,
                "spectral_norm": 1.0713227987289429,
                "alpha": 1.6537252655075476,
                "alpha_hat": 2.1289946818538943
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.009431784972548485,
                "median": 0.04902338981628418,
                "std": 0.23683564364910126,
                "max": 0.41661903262138367,
                "min": -0.5229147672653198,
                "frobenius_norm": 1.8961870670318604,
                "spectral_norm": 1.1439170837402344,
                "alpha": 1.3139379423132025,
                "alpha_hat": 1.4829373044296588
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.00952419824898243,
                "median": -0.002812714083120227,
                "std": 0.24380134046077728,
                "max": 0.6375495791435242,
                "min": -0.36518216133117676,
                "frobenius_norm": 1.951898455619812,
                "spectral_norm": 1.1926438808441162,
                "alpha": 1.1738608887695614,
                "alpha_hat": 2.2895136642744394
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.027175340801477432,
                "median": 0.004849724471569061,
                "std": 0.19349956512451172,
                "max": 0.41617152094841003,
                "min": -0.2837413549423218,
                "frobenius_norm": 1.563188076019287,
                "spectral_norm": 0.8457284569740295,
                "alpha": 1.2405988905599734,
                "alpha_hat": 1.1351850581562863
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=8_scaler_type=standard_seed=1415": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 8,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1415,
        "scores": {
            "smape": 0.07724644243717194,
            "mse": 564836800.0,
            "mae": 2095.36328125,
            "r2_score": 0.8779875040054321,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.025391491129994392,
                "median": 0.04455309361219406,
                "std": 0.1829126626253128,
                "max": 0.34892764687538147,
                "min": -0.4252776801586151,
                "frobenius_norm": 1.8093562126159668,
                "spectral_norm": 1.0713227987289429,
                "alpha": 1.6537252655075476,
                "alpha_hat": 2.1289946818538943
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.009431784972548485,
                "median": 0.04902338981628418,
                "std": 0.23683564364910126,
                "max": 0.41661903262138367,
                "min": -0.5229147672653198,
                "frobenius_norm": 1.8961870670318604,
                "spectral_norm": 1.1439170837402344,
                "alpha": 1.3139379423132025,
                "alpha_hat": 1.4829373044296588
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.00952419824898243,
                "median": -0.002812714083120227,
                "std": 0.24380134046077728,
                "max": 0.6375495791435242,
                "min": -0.36518216133117676,
                "frobenius_norm": 1.951898455619812,
                "spectral_norm": 1.1926438808441162,
                "alpha": 1.1738608887695614,
                "alpha_hat": 2.2895136642744394
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.027175340801477432,
                "median": 0.004849724471569061,
                "std": 0.19349956512451172,
                "max": 0.41617152094841003,
                "min": -0.2837413549423218,
                "frobenius_norm": 1.563188076019287,
                "spectral_norm": 0.8457284569740295,
                "alpha": 1.2405988905599734,
                "alpha_hat": 1.1351850581562863
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=8_scaler_type=standard_seed=2021": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 8,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 2021,
        "scores": {
            "smape": 0.07740552723407745,
            "mse": 562912704.0,
            "mae": 2081.770263671875,
            "r2_score": 0.8784030675888062,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.025391491129994392,
                "median": 0.04455309361219406,
                "std": 0.1829126626253128,
                "max": 0.34892764687538147,
                "min": -0.4252776801586151,
                "frobenius_norm": 1.8093562126159668,
                "spectral_norm": 1.0713227987289429,
                "alpha": 1.6537252655075476,
                "alpha_hat": 2.1289946818538943
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.009431784972548485,
                "median": 0.04902338981628418,
                "std": 0.23683564364910126,
                "max": 0.41661903262138367,
                "min": -0.5229147672653198,
                "frobenius_norm": 1.8961870670318604,
                "spectral_norm": 1.1439170837402344,
                "alpha": 1.3139379423132025,
                "alpha_hat": 1.4829373044296588
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.00952419824898243,
                "median": -0.002812714083120227,
                "std": 0.24380134046077728,
                "max": 0.6375495791435242,
                "min": -0.36518216133117676,
                "frobenius_norm": 1.951898455619812,
                "spectral_norm": 1.1926438808441162,
                "alpha": 1.1738608887695614,
                "alpha_hat": 2.2895136642744394
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.027175340801477432,
                "median": 0.004849724471569061,
                "std": 0.19349956512451172,
                "max": 0.41617152094841003,
                "min": -0.2837413549423218,
                "frobenius_norm": 1.563188076019287,
                "spectral_norm": 0.8457284569740295,
                "alpha": 1.2405988905599734,
                "alpha_hat": 1.1351850581562863
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=8_scaler_type=robust_seed=456": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 8,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 456,
        "scores": {
            "smape": 0.0765223354101181,
            "mse": 631791424.0,
            "mae": 2123.281982421875,
            "r2_score": 0.863524317741394,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.03921027481555939,
                "median": 0.05016233026981354,
                "std": 0.1855117827653885,
                "max": 0.40285882353782654,
                "min": -0.38637101650238037,
                "frobenius_norm": 1.857793927192688,
                "spectral_norm": 1.1436365842819214,
                "alpha": 1.619464314106941,
                "alpha_hat": 2.0071316848920766
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04450082406401634,
                "median": 0.08812092244625092,
                "std": 0.22267138957977295,
                "max": 0.43866246938705444,
                "min": -0.46992138028144836,
                "frobenius_norm": 1.8165968656539917,
                "spectral_norm": 1.132681131362915,
                "alpha": 1.156906692293371,
                "alpha_hat": 1.613387633623371
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.014261282980442047,
                "median": -0.024239832535386086,
                "std": 0.2481560856103897,
                "max": 0.6579493880271912,
                "min": -0.37641003727912903,
                "frobenius_norm": 1.9885241985321045,
                "spectral_norm": 1.1776946783065796,
                "alpha": 1.1717272744839142,
                "alpha_hat": 2.387460698065701
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.043166372925043106,
                "median": 0.02433174103498459,
                "std": 0.1922028362751007,
                "max": 0.4277816712856293,
                "min": -0.25100770592689514,
                "frobenius_norm": 1.575924277305603,
                "spectral_norm": 0.8615782260894775,
                "alpha": 1.210912883884562,
                "alpha_hat": 1.1242876429768365
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=8_scaler_type=robust_seed=123": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 8,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 123,
        "scores": {
            "smape": 0.07709906250238419,
            "mse": 625152320.0,
            "mae": 2118.8212890625,
            "r2_score": 0.8649584650993347,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.03921027481555939,
                "median": 0.05016233026981354,
                "std": 0.1855117827653885,
                "max": 0.40285882353782654,
                "min": -0.38637101650238037,
                "frobenius_norm": 1.857793927192688,
                "spectral_norm": 1.1436365842819214,
                "alpha": 1.619464314106941,
                "alpha_hat": 2.0071316848920766
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04450082406401634,
                "median": 0.08812092244625092,
                "std": 0.22267138957977295,
                "max": 0.43866246938705444,
                "min": -0.46992138028144836,
                "frobenius_norm": 1.8165968656539917,
                "spectral_norm": 1.132681131362915,
                "alpha": 1.156906692293371,
                "alpha_hat": 1.613387633623371
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.014261282980442047,
                "median": -0.024239832535386086,
                "std": 0.2481560856103897,
                "max": 0.6579493880271912,
                "min": -0.37641003727912903,
                "frobenius_norm": 1.9885241985321045,
                "spectral_norm": 1.1776946783065796,
                "alpha": 1.1717272744839142,
                "alpha_hat": 2.387460698065701
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.043166372925043106,
                "median": 0.02433174103498459,
                "std": 0.1922028362751007,
                "max": 0.4277816712856293,
                "min": -0.25100770592689514,
                "frobenius_norm": 1.575924277305603,
                "spectral_norm": 0.8615782260894775,
                "alpha": 1.210912883884562,
                "alpha_hat": 1.1242876429768365
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=8_scaler_type=robust_seed=42": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 8,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 42,
        "scores": {
            "smape": 0.07735851407051086,
            "mse": 632609728.0,
            "mae": 2118.501708984375,
            "r2_score": 0.863347589969635,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.03921027481555939,
                "median": 0.05016233026981354,
                "std": 0.1855117827653885,
                "max": 0.40285882353782654,
                "min": -0.38637101650238037,
                "frobenius_norm": 1.857793927192688,
                "spectral_norm": 1.1436365842819214,
                "alpha": 1.619464314106941,
                "alpha_hat": 2.0071316848920766
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04450082406401634,
                "median": 0.08812092244625092,
                "std": 0.22267138957977295,
                "max": 0.43866246938705444,
                "min": -0.46992138028144836,
                "frobenius_norm": 1.8165968656539917,
                "spectral_norm": 1.132681131362915,
                "alpha": 1.156906692293371,
                "alpha_hat": 1.613387633623371
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.014261282980442047,
                "median": -0.024239832535386086,
                "std": 0.2481560856103897,
                "max": 0.6579493880271912,
                "min": -0.37641003727912903,
                "frobenius_norm": 1.9885241985321045,
                "spectral_norm": 1.1776946783065796,
                "alpha": 1.1717272744839142,
                "alpha_hat": 2.387460698065701
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.043166372925043106,
                "median": 0.02433174103498459,
                "std": 0.1922028362751007,
                "max": 0.4277816712856293,
                "min": -0.25100770592689514,
                "frobenius_norm": 1.575924277305603,
                "spectral_norm": 0.8615782260894775,
                "alpha": 1.210912883884562,
                "alpha_hat": 1.1242876429768365
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=8_scaler_type=robust_seed=789": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 8,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 789,
        "scores": {
            "smape": 0.07732284069061279,
            "mse": 627777344.0,
            "mae": 2114.05712890625,
            "r2_score": 0.8643914461135864,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.03921027481555939,
                "median": 0.05016233026981354,
                "std": 0.1855117827653885,
                "max": 0.40285882353782654,
                "min": -0.38637101650238037,
                "frobenius_norm": 1.857793927192688,
                "spectral_norm": 1.1436365842819214,
                "alpha": 1.619464314106941,
                "alpha_hat": 2.0071316848920766
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04450082406401634,
                "median": 0.08812092244625092,
                "std": 0.22267138957977295,
                "max": 0.43866246938705444,
                "min": -0.46992138028144836,
                "frobenius_norm": 1.8165968656539917,
                "spectral_norm": 1.132681131362915,
                "alpha": 1.156906692293371,
                "alpha_hat": 1.613387633623371
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.014261282980442047,
                "median": -0.024239832535386086,
                "std": 0.2481560856103897,
                "max": 0.6579493880271912,
                "min": -0.37641003727912903,
                "frobenius_norm": 1.9885241985321045,
                "spectral_norm": 1.1776946783065796,
                "alpha": 1.1717272744839142,
                "alpha_hat": 2.387460698065701
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.043166372925043106,
                "median": 0.02433174103498459,
                "std": 0.1922028362751007,
                "max": 0.4277816712856293,
                "min": -0.25100770592689514,
                "frobenius_norm": 1.575924277305603,
                "spectral_norm": 0.8615782260894775,
                "alpha": 1.210912883884562,
                "alpha_hat": 1.1242876429768365
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=8_scaler_type=robust_seed=1213": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 8,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1213,
        "scores": {
            "smape": 0.07718247920274734,
            "mse": 624486528.0,
            "mae": 2113.8642578125,
            "r2_score": 0.8651022911071777,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.03705568239092827,
                "median": 0.049466073513031006,
                "std": 0.18741749227046967,
                "max": 0.39999520778656006,
                "min": -0.4162248969078064,
                "frobenius_norm": 1.8718576431274414,
                "spectral_norm": 1.155868411064148,
                "alpha": 1.61867597325221,
                "alpha_hat": 1.9863280593495707
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04702083766460419,
                "median": 0.08883365988731384,
                "std": 0.2244262546300888,
                "max": 0.42371654510498047,
                "min": -0.4723576605319977,
                "frobenius_norm": 1.8343932628631592,
                "spectral_norm": 1.154068112373352,
                "alpha": 1.2346738059695,
                "alpha_hat": 1.7795433471362074
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.020784344524145126,
                "median": 0.007226580288261175,
                "std": 0.2520011067390442,
                "max": 0.6874384880065918,
                "min": -0.42635834217071533,
                "frobenius_norm": 2.0228543281555176,
                "spectral_norm": 1.244414210319519,
                "alpha": 1.0929736508788235,
                "alpha_hat": 2.2110854372273168
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.043438736349344254,
                "median": 0.025162380188703537,
                "std": 0.19207298755645752,
                "max": 0.4366167485713959,
                "min": -0.25380223989486694,
                "frobenius_norm": 1.5753897428512573,
                "spectral_norm": 0.8595681190490723,
                "alpha": 1.2160609930842035,
                "alpha_hat": 1.1192588699369044
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=8_scaler_type=robust_seed=1415": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 8,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1415,
        "scores": {
            "smape": 0.07719390839338303,
            "mse": 627708032.0,
            "mae": 2115.022705078125,
            "r2_score": 0.864406406879425,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.03705568239092827,
                "median": 0.049466073513031006,
                "std": 0.18741749227046967,
                "max": 0.39999520778656006,
                "min": -0.4162248969078064,
                "frobenius_norm": 1.8718576431274414,
                "spectral_norm": 1.155868411064148,
                "alpha": 1.61867597325221,
                "alpha_hat": 1.9863280593495707
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04702083766460419,
                "median": 0.08883365988731384,
                "std": 0.2244262546300888,
                "max": 0.42371654510498047,
                "min": -0.4723576605319977,
                "frobenius_norm": 1.8343932628631592,
                "spectral_norm": 1.154068112373352,
                "alpha": 1.2346738059695,
                "alpha_hat": 1.7795433471362074
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.020784344524145126,
                "median": 0.007226580288261175,
                "std": 0.2520011067390442,
                "max": 0.6874384880065918,
                "min": -0.42635834217071533,
                "frobenius_norm": 2.0228543281555176,
                "spectral_norm": 1.244414210319519,
                "alpha": 1.0929736508788235,
                "alpha_hat": 2.2110854372273168
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.043438736349344254,
                "median": 0.025162380188703537,
                "std": 0.19207298755645752,
                "max": 0.4366167485713959,
                "min": -0.25380223989486694,
                "frobenius_norm": 1.5753897428512573,
                "spectral_norm": 0.8595681190490723,
                "alpha": 1.2160609930842035,
                "alpha_hat": 1.1192588699369044
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=8_scaler_type=robust_seed=1011": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 8,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1011,
        "scores": {
            "smape": 0.07567308098077774,
            "mse": 608502848.0,
            "mae": 2136.015625,
            "r2_score": 0.8685550093650818,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.03705568239092827,
                "median": 0.049466073513031006,
                "std": 0.18741749227046967,
                "max": 0.39999520778656006,
                "min": -0.4162248969078064,
                "frobenius_norm": 1.8718576431274414,
                "spectral_norm": 1.155868411064148,
                "alpha": 1.61867597325221,
                "alpha_hat": 1.9863280593495707
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04702083766460419,
                "median": 0.08883365988731384,
                "std": 0.2244262546300888,
                "max": 0.42371654510498047,
                "min": -0.4723576605319977,
                "frobenius_norm": 1.8343932628631592,
                "spectral_norm": 1.154068112373352,
                "alpha": 1.2346738059695,
                "alpha_hat": 1.7795433471362074
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.020784344524145126,
                "median": 0.007226580288261175,
                "std": 0.2520011067390442,
                "max": 0.6874384880065918,
                "min": -0.42635834217071533,
                "frobenius_norm": 2.0228543281555176,
                "spectral_norm": 1.244414210319519,
                "alpha": 1.0929736508788235,
                "alpha_hat": 2.2110854372273168
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.043438736349344254,
                "median": 0.025162380188703537,
                "std": 0.19207298755645752,
                "max": 0.4366167485713959,
                "min": -0.25380223989486694,
                "frobenius_norm": 1.5753897428512573,
                "spectral_norm": 0.8595681190490723,
                "alpha": 1.2160609930842035,
                "alpha_hat": 1.1192588699369044
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=8_scaler_type=robust_seed=1617": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 8,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1617,
        "scores": {
            "smape": 0.0772954598069191,
            "mse": 635739776.0,
            "mae": 2126.2255859375,
            "r2_score": 0.862671434879303,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.03705568239092827,
                "median": 0.049466073513031006,
                "std": 0.18741749227046967,
                "max": 0.39999520778656006,
                "min": -0.4162248969078064,
                "frobenius_norm": 1.8718576431274414,
                "spectral_norm": 1.155868411064148,
                "alpha": 1.61867597325221,
                "alpha_hat": 1.9863280593495707
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04702083766460419,
                "median": 0.08883365988731384,
                "std": 0.2244262546300888,
                "max": 0.42371654510498047,
                "min": -0.4723576605319977,
                "frobenius_norm": 1.8343932628631592,
                "spectral_norm": 1.154068112373352,
                "alpha": 1.2346738059695,
                "alpha_hat": 1.7795433471362074
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.020784344524145126,
                "median": 0.007226580288261175,
                "std": 0.2520011067390442,
                "max": 0.6874384880065918,
                "min": -0.42635834217071533,
                "frobenius_norm": 2.0228543281555176,
                "spectral_norm": 1.244414210319519,
                "alpha": 1.0929736508788235,
                "alpha_hat": 2.2110854372273168
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.043438736349344254,
                "median": 0.025162380188703537,
                "std": 0.19207298755645752,
                "max": 0.4366167485713959,
                "min": -0.25380223989486694,
                "frobenius_norm": 1.5753897428512573,
                "spectral_norm": 0.8595681190490723,
                "alpha": 1.2160609930842035,
                "alpha_hat": 1.1192588699369044
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=8_scaler_type=minmax_seed=42": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 8,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 42,
        "scores": {
            "smape": 0.12172586470842361,
            "mse": 1210869120.0,
            "mae": 3070.700927734375,
            "r2_score": 0.7384355664253235,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": -0.005626620724797249,
                "median": 0.0020664941985160112,
                "std": 0.169052854180336,
                "max": 0.4856635332107544,
                "min": -0.3767215609550476,
                "frobenius_norm": 1.6572901010513306,
                "spectral_norm": 0.9181106090545654,
                "alpha": 1.448419945515863,
                "alpha_hat": 1.5039516357291958
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0252707377076149,
                "median": 0.040104690939188004,
                "std": 0.22363537549972534,
                "max": 0.46820834279060364,
                "min": -0.4566103219985962,
                "frobenius_norm": 1.8004690408706665,
                "spectral_norm": 0.9333819150924683,
                "alpha": 1.1726448310496955,
                "alpha_hat": 1.1809759050486317
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04450994357466698,
                "median": 0.06429433822631836,
                "std": 0.19315171241760254,
                "max": 0.42472684383392334,
                "min": -0.4728974401950836,
                "frobenius_norm": 1.5857106447219849,
                "spectral_norm": 1.002935528755188,
                "alpha": 1.4153767007164488,
                "alpha_hat": 2.597696325421942
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0895698219537735,
                "median": 0.11728285253047943,
                "std": 0.22088178992271423,
                "max": 0.4838140308856964,
                "min": -0.31433427333831787,
                "frobenius_norm": 1.906813383102417,
                "spectral_norm": 1.0798587799072266,
                "alpha": 1.2705163266231037,
                "alpha_hat": 1.799167600104363
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=8_scaler_type=minmax_seed=123": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 8,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 123,
        "scores": {
            "smape": 0.10656572878360748,
            "mse": 1055098496.0,
            "mae": 2834.243896484375,
            "r2_score": 0.7720841765403748,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": -0.005626620724797249,
                "median": 0.0020664941985160112,
                "std": 0.169052854180336,
                "max": 0.4856635332107544,
                "min": -0.3767215609550476,
                "frobenius_norm": 1.6572901010513306,
                "spectral_norm": 0.9181106090545654,
                "alpha": 1.448419945515863,
                "alpha_hat": 1.5039516357291958
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0252707377076149,
                "median": 0.040104690939188004,
                "std": 0.22363537549972534,
                "max": 0.46820834279060364,
                "min": -0.4566103219985962,
                "frobenius_norm": 1.8004690408706665,
                "spectral_norm": 0.9333819150924683,
                "alpha": 1.1726448310496955,
                "alpha_hat": 1.1809759050486317
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04450994357466698,
                "median": 0.06429433822631836,
                "std": 0.19315171241760254,
                "max": 0.42472684383392334,
                "min": -0.4728974401950836,
                "frobenius_norm": 1.5857106447219849,
                "spectral_norm": 1.002935528755188,
                "alpha": 1.4153767007164488,
                "alpha_hat": 2.597696325421942
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0895698219537735,
                "median": 0.11728285253047943,
                "std": 0.22088178992271423,
                "max": 0.4838140308856964,
                "min": -0.31433427333831787,
                "frobenius_norm": 1.906813383102417,
                "spectral_norm": 1.0798587799072266,
                "alpha": 1.2705163266231037,
                "alpha_hat": 1.799167600104363
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=8_scaler_type=robust_seed=1819": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 8,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1819,
        "scores": {
            "smape": 0.07663995027542114,
            "mse": 491196896.0,
            "mae": 2049.759033203125,
            "r2_score": 0.8938946723937988,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": -0.005626620724797249,
                "median": 0.0020664941985160112,
                "std": 0.169052854180336,
                "max": 0.4856635332107544,
                "min": -0.3767215609550476,
                "frobenius_norm": 1.6572901010513306,
                "spectral_norm": 0.9181106090545654,
                "alpha": 1.448419945515863,
                "alpha_hat": 1.5039516357291958
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0252707377076149,
                "median": 0.040104690939188004,
                "std": 0.22363537549972534,
                "max": 0.46820834279060364,
                "min": -0.4566103219985962,
                "frobenius_norm": 1.8004690408706665,
                "spectral_norm": 0.9333819150924683,
                "alpha": 1.1726448310496955,
                "alpha_hat": 1.1809759050486317
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04450994357466698,
                "median": 0.06429433822631836,
                "std": 0.19315171241760254,
                "max": 0.42472684383392334,
                "min": -0.4728974401950836,
                "frobenius_norm": 1.5857106447219849,
                "spectral_norm": 1.002935528755188,
                "alpha": 1.4153767007164488,
                "alpha_hat": 2.597696325421942
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0895698219537735,
                "median": 0.11728285253047943,
                "std": 0.22088178992271423,
                "max": 0.4838140308856964,
                "min": -0.31433427333831787,
                "frobenius_norm": 1.906813383102417,
                "spectral_norm": 1.0798587799072266,
                "alpha": 1.2705163266231037,
                "alpha_hat": 1.799167600104363
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=8_scaler_type=robust_seed=2021": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 8,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 2021,
        "scores": {
            "smape": 0.0771074965596199,
            "mse": 526682560.0,
            "mae": 2070.801025390625,
            "r2_score": 0.8862292766571045,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": -0.005626620724797249,
                "median": 0.0020664941985160112,
                "std": 0.169052854180336,
                "max": 0.4856635332107544,
                "min": -0.3767215609550476,
                "frobenius_norm": 1.6572901010513306,
                "spectral_norm": 0.9181106090545654,
                "alpha": 1.448419945515863,
                "alpha_hat": 1.5039516357291958
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0252707377076149,
                "median": 0.040104690939188004,
                "std": 0.22363537549972534,
                "max": 0.46820834279060364,
                "min": -0.4566103219985962,
                "frobenius_norm": 1.8004690408706665,
                "spectral_norm": 0.9333819150924683,
                "alpha": 1.1726448310496955,
                "alpha_hat": 1.1809759050486317
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04450994357466698,
                "median": 0.06429433822631836,
                "std": 0.19315171241760254,
                "max": 0.42472684383392334,
                "min": -0.4728974401950836,
                "frobenius_norm": 1.5857106447219849,
                "spectral_norm": 1.002935528755188,
                "alpha": 1.4153767007164488,
                "alpha_hat": 2.597696325421942
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0895698219537735,
                "median": 0.11728285253047943,
                "std": 0.22088178992271423,
                "max": 0.4838140308856964,
                "min": -0.31433427333831787,
                "frobenius_norm": 1.906813383102417,
                "spectral_norm": 1.0798587799072266,
                "alpha": 1.2705163266231037,
                "alpha_hat": 1.799167600104363
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=8_scaler_type=minmax_seed=456": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 8,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 456,
        "scores": {
            "smape": 0.11418429017066956,
            "mse": 1158592256.0,
            "mae": 2971.7470703125,
            "r2_score": 0.7497280836105347,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.07574417442083359,
                "median": 0.08949451893568039,
                "std": 0.17168977856636047,
                "max": 0.3749365210533142,
                "min": -0.2847588360309601,
                "frobenius_norm": 1.8386400938034058,
                "spectral_norm": 1.1579681634902954,
                "alpha": 1.3551798155836656,
                "alpha_hat": 1.8113308451089316
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.048220038414001465,
                "median": 0.062498629093170166,
                "std": 0.22198902070522308,
                "max": 0.4149414002895355,
                "min": -0.5207023024559021,
                "frobenius_norm": 1.8173264265060425,
                "spectral_norm": 1.0346235036849976,
                "alpha": 1.2492528456256042,
                "alpha_hat": 1.7089243188240872
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.016019083559513092,
                "median": -0.02160670794546604,
                "std": 0.23170225322246552,
                "max": 0.5905418992042542,
                "min": -0.3517802059650421,
                "frobenius_norm": 1.85804283618927,
                "spectral_norm": 1.153320074081421,
                "alpha": 1.2274457575658677,
                "alpha_hat": 2.247869727215862
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.041021741926670074,
                "median": 0.028554551303386688,
                "std": 0.19506777822971344,
                "max": 0.462677925825119,
                "min": -0.2708345651626587,
                "frobenius_norm": 1.5946755409240723,
                "spectral_norm": 0.8868242502212524,
                "alpha": 1.2584107174996793,
                "alpha_hat": 1.1696429367838121
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=8_scaler_type=minmax_seed=1213": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 8,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1213,
        "scores": {
            "smape": 0.112024687230587,
            "mse": 1124764672.0,
            "mae": 2934.653076171875,
            "r2_score": 0.7570353150367737,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.07574417442083359,
                "median": 0.08949451893568039,
                "std": 0.17168977856636047,
                "max": 0.3749365210533142,
                "min": -0.2847588360309601,
                "frobenius_norm": 1.8386400938034058,
                "spectral_norm": 1.1579681634902954,
                "alpha": 1.3551798155836656,
                "alpha_hat": 1.8113308451089316
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.048220038414001465,
                "median": 0.062498629093170166,
                "std": 0.22198902070522308,
                "max": 0.4149414002895355,
                "min": -0.5207023024559021,
                "frobenius_norm": 1.8173264265060425,
                "spectral_norm": 1.0346235036849976,
                "alpha": 1.2492528456256042,
                "alpha_hat": 1.7089243188240872
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.016019083559513092,
                "median": -0.02160670794546604,
                "std": 0.23170225322246552,
                "max": 0.5905418992042542,
                "min": -0.3517802059650421,
                "frobenius_norm": 1.85804283618927,
                "spectral_norm": 1.153320074081421,
                "alpha": 1.2274457575658677,
                "alpha_hat": 2.247869727215862
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.041021741926670074,
                "median": 0.028554551303386688,
                "std": 0.19506777822971344,
                "max": 0.462677925825119,
                "min": -0.2708345651626587,
                "frobenius_norm": 1.5946755409240723,
                "spectral_norm": 0.8868242502212524,
                "alpha": 1.2584107174996793,
                "alpha_hat": 1.1696429367838121
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=8_scaler_type=minmax_seed=1011": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 8,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1011,
        "scores": {
            "smape": 0.11679477989673615,
            "mse": 1145514112.0,
            "mae": 2982.654052734375,
            "r2_score": 0.7525531649589539,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.07574417442083359,
                "median": 0.08949451893568039,
                "std": 0.17168977856636047,
                "max": 0.3749365210533142,
                "min": -0.2847588360309601,
                "frobenius_norm": 1.8386400938034058,
                "spectral_norm": 1.1579681634902954,
                "alpha": 1.3551798155836656,
                "alpha_hat": 1.8113308451089316
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.048220038414001465,
                "median": 0.062498629093170166,
                "std": 0.22198902070522308,
                "max": 0.4149414002895355,
                "min": -0.5207023024559021,
                "frobenius_norm": 1.8173264265060425,
                "spectral_norm": 1.0346235036849976,
                "alpha": 1.2492528456256042,
                "alpha_hat": 1.7089243188240872
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.016019083559513092,
                "median": -0.02160670794546604,
                "std": 0.23170225322246552,
                "max": 0.5905418992042542,
                "min": -0.3517802059650421,
                "frobenius_norm": 1.85804283618927,
                "spectral_norm": 1.153320074081421,
                "alpha": 1.2274457575658677,
                "alpha_hat": 2.247869727215862
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.041021741926670074,
                "median": 0.028554551303386688,
                "std": 0.19506777822971344,
                "max": 0.462677925825119,
                "min": -0.2708345651626587,
                "frobenius_norm": 1.5946755409240723,
                "spectral_norm": 0.8868242502212524,
                "alpha": 1.2584107174996793,
                "alpha_hat": 1.1696429367838121
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=8_scaler_type=minmax_seed=789": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 8,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 789,
        "scores": {
            "smape": 0.1088748499751091,
            "mse": 1102783488.0,
            "mae": 2917.455322265625,
            "r2_score": 0.7617835998535156,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.07574417442083359,
                "median": 0.08949451893568039,
                "std": 0.17168977856636047,
                "max": 0.3749365210533142,
                "min": -0.2847588360309601,
                "frobenius_norm": 1.8386400938034058,
                "spectral_norm": 1.1579681634902954,
                "alpha": 1.3551798155836656,
                "alpha_hat": 1.8113308451089316
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.048220038414001465,
                "median": 0.062498629093170166,
                "std": 0.22198902070522308,
                "max": 0.4149414002895355,
                "min": -0.5207023024559021,
                "frobenius_norm": 1.8173264265060425,
                "spectral_norm": 1.0346235036849976,
                "alpha": 1.2492528456256042,
                "alpha_hat": 1.7089243188240872
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.016019083559513092,
                "median": -0.02160670794546604,
                "std": 0.23170225322246552,
                "max": 0.5905418992042542,
                "min": -0.3517802059650421,
                "frobenius_norm": 1.85804283618927,
                "spectral_norm": 1.153320074081421,
                "alpha": 1.2274457575658677,
                "alpha_hat": 2.247869727215862
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.041021741926670074,
                "median": 0.028554551303386688,
                "std": 0.19506777822971344,
                "max": 0.462677925825119,
                "min": -0.2708345651626587,
                "frobenius_norm": 1.5946755409240723,
                "spectral_norm": 0.8868242502212524,
                "alpha": 1.2584107174996793,
                "alpha_hat": 1.1696429367838121
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=8_scaler_type=minmax_seed=1415": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 8,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1415,
        "scores": {
            "smape": 0.11464013904333115,
            "mse": 1139695744.0,
            "mae": 2956.540283203125,
            "r2_score": 0.7538100481033325,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06619919091463089,
                "median": 0.08371606469154358,
                "std": 0.1741141825914383,
                "max": 0.38560107350349426,
                "min": -0.3059774339199066,
                "frobenius_norm": 1.8251069784164429,
                "spectral_norm": 1.1167579889297485,
                "alpha": 1.4044955146368052,
                "alpha_hat": 1.8298873428636915
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.038858674466609955,
                "median": 0.08307382464408875,
                "std": 0.22549086809158325,
                "max": 0.42971688508987427,
                "min": -0.4393143057823181,
                "frobenius_norm": 1.8305169343948364,
                "spectral_norm": 1.0867831707000732,
                "alpha": 1.1712806337676154,
                "alpha_hat": 1.6924018605650417
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01240504626184702,
                "median": -0.006130723748356104,
                "std": 0.23317645490169525,
                "max": 0.6174147725105286,
                "min": -0.452962726354599,
                "frobenius_norm": 1.8680496215820312,
                "spectral_norm": 1.1728776693344116,
                "alpha": 1.2879805794798524,
                "alpha_hat": 2.229544214550237
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04099477827548981,
                "median": 0.026906363666057587,
                "std": 0.1904279738664627,
                "max": 0.4149455726146698,
                "min": -0.25895363092422485,
                "frobenius_norm": 1.558324933052063,
                "spectral_norm": 0.840070366859436,
                "alpha": 1.2479049574480274,
                "alpha_hat": 1.147000306167428
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=8_scaler_type=minmax_seed=1819": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 8,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1819,
        "scores": {
            "smape": 0.12037646025419235,
            "mse": 1181262848.0,
            "mae": 3036.6787109375,
            "r2_score": 0.7448309659957886,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06619919091463089,
                "median": 0.08371606469154358,
                "std": 0.1741141825914383,
                "max": 0.38560107350349426,
                "min": -0.3059774339199066,
                "frobenius_norm": 1.8251069784164429,
                "spectral_norm": 1.1167579889297485,
                "alpha": 1.4044955146368052,
                "alpha_hat": 1.8298873428636915
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.038858674466609955,
                "median": 0.08307382464408875,
                "std": 0.22549086809158325,
                "max": 0.42971688508987427,
                "min": -0.4393143057823181,
                "frobenius_norm": 1.8305169343948364,
                "spectral_norm": 1.0867831707000732,
                "alpha": 1.1712806337676154,
                "alpha_hat": 1.6924018605650417
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01240504626184702,
                "median": -0.006130723748356104,
                "std": 0.23317645490169525,
                "max": 0.6174147725105286,
                "min": -0.452962726354599,
                "frobenius_norm": 1.8680496215820312,
                "spectral_norm": 1.1728776693344116,
                "alpha": 1.2879805794798524,
                "alpha_hat": 2.229544214550237
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04099477827548981,
                "median": 0.026906363666057587,
                "std": 0.1904279738664627,
                "max": 0.4149455726146698,
                "min": -0.25895363092422485,
                "frobenius_norm": 1.558324933052063,
                "spectral_norm": 0.840070366859436,
                "alpha": 1.2479049574480274,
                "alpha_hat": 1.147000306167428
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=8_scaler_type=minmax_seed=2021": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 8,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 2021,
        "scores": {
            "smape": 0.11558771133422852,
            "mse": 1138490368.0,
            "mae": 2951.64892578125,
            "r2_score": 0.7540704011917114,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06619919091463089,
                "median": 0.08371606469154358,
                "std": 0.1741141825914383,
                "max": 0.38560107350349426,
                "min": -0.3059774339199066,
                "frobenius_norm": 1.8251069784164429,
                "spectral_norm": 1.1167579889297485,
                "alpha": 1.4044955146368052,
                "alpha_hat": 1.8298873428636915
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.038858674466609955,
                "median": 0.08307382464408875,
                "std": 0.22549086809158325,
                "max": 0.42971688508987427,
                "min": -0.4393143057823181,
                "frobenius_norm": 1.8305169343948364,
                "spectral_norm": 1.0867831707000732,
                "alpha": 1.1712806337676154,
                "alpha_hat": 1.6924018605650417
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01240504626184702,
                "median": -0.006130723748356104,
                "std": 0.23317645490169525,
                "max": 0.6174147725105286,
                "min": -0.452962726354599,
                "frobenius_norm": 1.8680496215820312,
                "spectral_norm": 1.1728776693344116,
                "alpha": 1.2879805794798524,
                "alpha_hat": 2.229544214550237
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04099477827548981,
                "median": 0.026906363666057587,
                "std": 0.1904279738664627,
                "max": 0.4149455726146698,
                "min": -0.25895363092422485,
                "frobenius_norm": 1.558324933052063,
                "spectral_norm": 0.840070366859436,
                "alpha": 1.2479049574480274,
                "alpha_hat": 1.147000306167428
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=8_scaler_type=minmax_seed=1617": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 8,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1617,
        "scores": {
            "smape": 0.11856324225664139,
            "mse": 1181102720.0,
            "mae": 3025.720947265625,
            "r2_score": 0.7448655366897583,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06619919091463089,
                "median": 0.08371606469154358,
                "std": 0.1741141825914383,
                "max": 0.38560107350349426,
                "min": -0.3059774339199066,
                "frobenius_norm": 1.8251069784164429,
                "spectral_norm": 1.1167579889297485,
                "alpha": 1.4044955146368052,
                "alpha_hat": 1.8298873428636915
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.038858674466609955,
                "median": 0.08307382464408875,
                "std": 0.22549086809158325,
                "max": 0.42971688508987427,
                "min": -0.4393143057823181,
                "frobenius_norm": 1.8305169343948364,
                "spectral_norm": 1.0867831707000732,
                "alpha": 1.1712806337676154,
                "alpha_hat": 1.6924018605650417
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01240504626184702,
                "median": -0.006130723748356104,
                "std": 0.23317645490169525,
                "max": 0.6174147725105286,
                "min": -0.452962726354599,
                "frobenius_norm": 1.8680496215820312,
                "spectral_norm": 1.1728776693344116,
                "alpha": 1.2879805794798524,
                "alpha_hat": 2.229544214550237
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04099477827548981,
                "median": 0.026906363666057587,
                "std": 0.1904279738664627,
                "max": 0.4149455726146698,
                "min": -0.25895363092422485,
                "frobenius_norm": 1.558324933052063,
                "spectral_norm": 0.840070366859436,
                "alpha": 1.2479049574480274,
                "alpha_hat": 1.147000306167428
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=16_scaler_type=identity_seed=42": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 42,
        "scores": {
            "smape": 0.08345908671617508,
            "mse": 498486688.0,
            "mae": 1985.8211669921875,
            "r2_score": 0.8923200368881226,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06953134387731552,
                "median": 0.07677601277828217,
                "std": 0.15971748530864716,
                "max": 0.3706747591495514,
                "min": -0.30425357818603516,
                "frobenius_norm": 1.7067663669586182,
                "spectral_norm": 0.9558139443397522,
                "alpha": 1.5856083556442502,
                "alpha_hat": 1.9131565929863545
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07728766649961472,
                "median": 0.04332339018583298,
                "std": 0.2156134396791458,
                "max": 0.49313607811927795,
                "min": -0.38139915466308594,
                "frobenius_norm": 1.83237624168396,
                "spectral_norm": 1.3053395748138428,
                "alpha": 1.3294868994983962,
                "alpha_hat": 4.296332839783087
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07837603241205215,
                "median": 0.11924155801534653,
                "std": 0.2215535044670105,
                "max": 0.44144248962402344,
                "min": -0.33933815360069275,
                "frobenius_norm": 1.8800638914108276,
                "spectral_norm": 1.1882838010787964,
                "alpha": 1.2038497121059089,
                "alpha_hat": 1.8844901279739739
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.10187812149524689,
                "median": 0.09861895442008972,
                "std": 0.19209440052509308,
                "max": 0.47218626737594604,
                "min": -0.29367130994796753,
                "frobenius_norm": 1.7395063638687134,
                "spectral_norm": 1.1077699661254883,
                "alpha": 1.1827273439935457,
                "alpha_hat": 1.4134676610232542
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=16_scaler_type=identity_seed=789": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 789,
        "scores": {
            "smape": 0.09808850288391113,
            "mse": 545335808.0,
            "mae": 2268.086669921875,
            "r2_score": 0.8821999430656433,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06953134387731552,
                "median": 0.07677601277828217,
                "std": 0.15971748530864716,
                "max": 0.3706747591495514,
                "min": -0.30425357818603516,
                "frobenius_norm": 1.7067663669586182,
                "spectral_norm": 0.9558139443397522,
                "alpha": 1.5856083556442502,
                "alpha_hat": 1.9131565929863545
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07728766649961472,
                "median": 0.04332339018583298,
                "std": 0.2156134396791458,
                "max": 0.49313607811927795,
                "min": -0.38139915466308594,
                "frobenius_norm": 1.83237624168396,
                "spectral_norm": 1.3053395748138428,
                "alpha": 1.3294868994983962,
                "alpha_hat": 4.296332839783087
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07837603241205215,
                "median": 0.11924155801534653,
                "std": 0.2215535044670105,
                "max": 0.44144248962402344,
                "min": -0.33933815360069275,
                "frobenius_norm": 1.8800638914108276,
                "spectral_norm": 1.1882838010787964,
                "alpha": 1.2038497121059089,
                "alpha_hat": 1.8844901279739739
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.10187812149524689,
                "median": 0.09861895442008972,
                "std": 0.19209440052509308,
                "max": 0.47218626737594604,
                "min": -0.29367130994796753,
                "frobenius_norm": 1.7395063638687134,
                "spectral_norm": 1.1077699661254883,
                "alpha": 1.1827273439935457,
                "alpha_hat": 1.4134676610232542
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=16_scaler_type=identity_seed=123": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 123,
        "scores": {
            "smape": 0.08421538025140762,
            "mse": 501672192.0,
            "mae": 1978.9306640625,
            "r2_score": 0.8916319012641907,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06953134387731552,
                "median": 0.07677601277828217,
                "std": 0.15971748530864716,
                "max": 0.3706747591495514,
                "min": -0.30425357818603516,
                "frobenius_norm": 1.7067663669586182,
                "spectral_norm": 0.9558139443397522,
                "alpha": 1.5856083556442502,
                "alpha_hat": 1.9131565929863545
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07728766649961472,
                "median": 0.04332339018583298,
                "std": 0.2156134396791458,
                "max": 0.49313607811927795,
                "min": -0.38139915466308594,
                "frobenius_norm": 1.83237624168396,
                "spectral_norm": 1.3053395748138428,
                "alpha": 1.3294868994983962,
                "alpha_hat": 4.296332839783087
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07837603241205215,
                "median": 0.11924155801534653,
                "std": 0.2215535044670105,
                "max": 0.44144248962402344,
                "min": -0.33933815360069275,
                "frobenius_norm": 1.8800638914108276,
                "spectral_norm": 1.1882838010787964,
                "alpha": 1.2038497121059089,
                "alpha_hat": 1.8844901279739739
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.10187812149524689,
                "median": 0.09861895442008972,
                "std": 0.19209440052509308,
                "max": 0.47218626737594604,
                "min": -0.29367130994796753,
                "frobenius_norm": 1.7395063638687134,
                "spectral_norm": 1.1077699661254883,
                "alpha": 1.1827273439935457,
                "alpha_hat": 1.4134676610232542
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=16_scaler_type=identity_seed=456": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 456,
        "scores": {
            "smape": 0.08747701346874237,
            "mse": 574616320.0,
            "mae": 2180.454345703125,
            "r2_score": 0.875874936580658,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06953134387731552,
                "median": 0.07677601277828217,
                "std": 0.15971748530864716,
                "max": 0.3706747591495514,
                "min": -0.30425357818603516,
                "frobenius_norm": 1.7067663669586182,
                "spectral_norm": 0.9558139443397522,
                "alpha": 1.5856083556442502,
                "alpha_hat": 1.9131565929863545
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07728766649961472,
                "median": 0.04332339018583298,
                "std": 0.2156134396791458,
                "max": 0.49313607811927795,
                "min": -0.38139915466308594,
                "frobenius_norm": 1.83237624168396,
                "spectral_norm": 1.3053395748138428,
                "alpha": 1.3294868994983962,
                "alpha_hat": 4.296332839783087
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07837603241205215,
                "median": 0.11924155801534653,
                "std": 0.2215535044670105,
                "max": 0.44144248962402344,
                "min": -0.33933815360069275,
                "frobenius_norm": 1.8800638914108276,
                "spectral_norm": 1.1882838010787964,
                "alpha": 1.2038497121059089,
                "alpha_hat": 1.8844901279739739
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.10187812149524689,
                "median": 0.09861895442008972,
                "std": 0.19209440052509308,
                "max": 0.47218626737594604,
                "min": -0.29367130994796753,
                "frobenius_norm": 1.7395063638687134,
                "spectral_norm": 1.1077699661254883,
                "alpha": 1.1827273439935457,
                "alpha_hat": 1.4134676610232542
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=16_scaler_type=identity_seed=1213": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1213,
        "scores": {
            "smape": 0.08397536724805832,
            "mse": 498630752.0,
            "mae": 2005.9493408203125,
            "r2_score": 0.892288863658905,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.0736367404460907,
                "median": 0.06657091528177261,
                "std": 0.16288959980010986,
                "max": 0.3731825053691864,
                "min": -0.29660966992378235,
                "frobenius_norm": 1.7514902353286743,
                "spectral_norm": 0.9970911145210266,
                "alpha": 1.5514660496310497,
                "alpha_hat": 2.224146139205087
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.061582617461681366,
                "median": 0.09198929369449615,
                "std": 0.2315736562013626,
                "max": 0.4478853940963745,
                "min": -0.3519701063632965,
                "frobenius_norm": 1.9169772863388062,
                "spectral_norm": 1.3002264499664307,
                "alpha": 1.2062578440727967,
                "alpha_hat": 2.0599573099367863
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08215706050395966,
                "median": 0.03435821831226349,
                "std": 0.24119620025157928,
                "max": 0.5765715837478638,
                "min": -0.2975947856903076,
                "frobenius_norm": 2.0384368896484375,
                "spectral_norm": 1.3839970827102661,
                "alpha": 1.235867295832699,
                "alpha_hat": 2.852341165000441
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.10779006779193878,
                "median": 0.1162026971578598,
                "std": 0.19228172302246094,
                "max": 0.4974668025970459,
                "min": -0.2712605595588684,
                "frobenius_norm": 1.7634685039520264,
                "spectral_norm": 1.0987762212753296,
                "alpha": 1.100929891850236,
                "alpha_hat": 1.2760779246380973
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=16_scaler_type=identity_seed=1011": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1011,
        "scores": {
            "smape": 0.08329461514949799,
            "mse": 484300960.0,
            "mae": 1983.7764892578125,
            "r2_score": 0.8953843116760254,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.0736367404460907,
                "median": 0.06657091528177261,
                "std": 0.16288959980010986,
                "max": 0.3731825053691864,
                "min": -0.29660966992378235,
                "frobenius_norm": 1.7514902353286743,
                "spectral_norm": 0.9970911145210266,
                "alpha": 1.5514660496310497,
                "alpha_hat": 2.224146139205087
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.061582617461681366,
                "median": 0.09198929369449615,
                "std": 0.2315736562013626,
                "max": 0.4478853940963745,
                "min": -0.3519701063632965,
                "frobenius_norm": 1.9169772863388062,
                "spectral_norm": 1.3002264499664307,
                "alpha": 1.2062578440727967,
                "alpha_hat": 2.0599573099367863
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08215706050395966,
                "median": 0.03435821831226349,
                "std": 0.24119620025157928,
                "max": 0.5765715837478638,
                "min": -0.2975947856903076,
                "frobenius_norm": 2.0384368896484375,
                "spectral_norm": 1.3839970827102661,
                "alpha": 1.235867295832699,
                "alpha_hat": 2.852341165000441
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.10779006779193878,
                "median": 0.1162026971578598,
                "std": 0.19228172302246094,
                "max": 0.4974668025970459,
                "min": -0.2712605595588684,
                "frobenius_norm": 1.7634685039520264,
                "spectral_norm": 1.0987762212753296,
                "alpha": 1.100929891850236,
                "alpha_hat": 1.2760779246380973
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=16_scaler_type=identity_seed=1415": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1415,
        "scores": {
            "smape": 0.08350252360105515,
            "mse": 503541408.0,
            "mae": 1980.0443115234375,
            "r2_score": 0.8912281394004822,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.0736367404460907,
                "median": 0.06657091528177261,
                "std": 0.16288959980010986,
                "max": 0.3731825053691864,
                "min": -0.29660966992378235,
                "frobenius_norm": 1.7514902353286743,
                "spectral_norm": 0.9970911145210266,
                "alpha": 1.5514660496310497,
                "alpha_hat": 2.224146139205087
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.061582617461681366,
                "median": 0.09198929369449615,
                "std": 0.2315736562013626,
                "max": 0.4478853940963745,
                "min": -0.3519701063632965,
                "frobenius_norm": 1.9169772863388062,
                "spectral_norm": 1.3002264499664307,
                "alpha": 1.2062578440727967,
                "alpha_hat": 2.0599573099367863
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08215706050395966,
                "median": 0.03435821831226349,
                "std": 0.24119620025157928,
                "max": 0.5765715837478638,
                "min": -0.2975947856903076,
                "frobenius_norm": 2.0384368896484375,
                "spectral_norm": 1.3839970827102661,
                "alpha": 1.235867295832699,
                "alpha_hat": 2.852341165000441
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.10779006779193878,
                "median": 0.1162026971578598,
                "std": 0.19228172302246094,
                "max": 0.4974668025970459,
                "min": -0.2712605595588684,
                "frobenius_norm": 1.7634685039520264,
                "spectral_norm": 1.0987762212753296,
                "alpha": 1.100929891850236,
                "alpha_hat": 1.2760779246380973
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=16_scaler_type=identity_seed=1617": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1617,
        "scores": {
            "smape": 0.08418682217597961,
            "mse": 500377760.0,
            "mae": 1982.965576171875,
            "r2_score": 0.891911506652832,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.0736367404460907,
                "median": 0.06657091528177261,
                "std": 0.16288959980010986,
                "max": 0.3731825053691864,
                "min": -0.29660966992378235,
                "frobenius_norm": 1.7514902353286743,
                "spectral_norm": 0.9970911145210266,
                "alpha": 1.5514660496310497,
                "alpha_hat": 2.224146139205087
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.061582617461681366,
                "median": 0.09198929369449615,
                "std": 0.2315736562013626,
                "max": 0.4478853940963745,
                "min": -0.3519701063632965,
                "frobenius_norm": 1.9169772863388062,
                "spectral_norm": 1.3002264499664307,
                "alpha": 1.2062578440727967,
                "alpha_hat": 2.0599573099367863
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08215706050395966,
                "median": 0.03435821831226349,
                "std": 0.24119620025157928,
                "max": 0.5765715837478638,
                "min": -0.2975947856903076,
                "frobenius_norm": 2.0384368896484375,
                "spectral_norm": 1.3839970827102661,
                "alpha": 1.235867295832699,
                "alpha_hat": 2.852341165000441
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.10779006779193878,
                "median": 0.1162026971578598,
                "std": 0.19228172302246094,
                "max": 0.4974668025970459,
                "min": -0.2712605595588684,
                "frobenius_norm": 1.7634685039520264,
                "spectral_norm": 1.0987762212753296,
                "alpha": 1.100929891850236,
                "alpha_hat": 1.2760779246380973
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=16_scaler_type=identity_seed=2021": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 2021,
        "scores": {
            "smape": 0.08405626565217972,
            "mse": 485893664.0,
            "mae": 1983.6793212890625,
            "r2_score": 0.8950402736663818,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.026739293709397316,
                "median": 0.037985969334840775,
                "std": 0.19403018057346344,
                "max": 0.3941952586174011,
                "min": -0.4481939375400543,
                "frobenius_norm": 1.9190673828125,
                "spectral_norm": 1.1528699398040771,
                "alpha": 1.5467641040220141,
                "alpha_hat": 1.8948332677990827
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.012442559003829956,
                "median": 0.04896790534257889,
                "std": 0.24390578269958496,
                "max": 0.4473783075809479,
                "min": -0.5584347248077393,
                "frobenius_norm": 1.953783631324768,
                "spectral_norm": 1.1934736967086792,
                "alpha": 1.252147474441672,
                "alpha_hat": 1.4273933217382142
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.012771591544151306,
                "median": 0.014631204307079315,
                "std": 0.2458316534757614,
                "max": 0.652876079082489,
                "min": -0.36193326115608215,
                "frobenius_norm": 1.9693055152893066,
                "spectral_norm": 1.254339337348938,
                "alpha": 1.1521528893544528,
                "alpha_hat": 2.3566886759036363
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04673761874437332,
                "median": 0.02952750399708748,
                "std": 0.19301970303058624,
                "max": 0.43809372186660767,
                "min": -0.24575187265872955,
                "frobenius_norm": 1.5887808799743652,
                "spectral_norm": 0.8752036690711975,
                "alpha": 1.2300299890840352,
                "alpha_hat": 1.1347542966381385
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=16_scaler_type=identity_seed=1819": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1819,
        "scores": {
            "smape": 0.0881488174200058,
            "mse": 499232736.0,
            "mae": 2066.63330078125,
            "r2_score": 0.8921588659286499,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.026739293709397316,
                "median": 0.037985969334840775,
                "std": 0.19403018057346344,
                "max": 0.3941952586174011,
                "min": -0.4481939375400543,
                "frobenius_norm": 1.9190673828125,
                "spectral_norm": 1.1528699398040771,
                "alpha": 1.5467641040220141,
                "alpha_hat": 1.8948332677990827
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.012442559003829956,
                "median": 0.04896790534257889,
                "std": 0.24390578269958496,
                "max": 0.4473783075809479,
                "min": -0.5584347248077393,
                "frobenius_norm": 1.953783631324768,
                "spectral_norm": 1.1934736967086792,
                "alpha": 1.252147474441672,
                "alpha_hat": 1.4273933217382142
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.012771591544151306,
                "median": 0.014631204307079315,
                "std": 0.2458316534757614,
                "max": 0.652876079082489,
                "min": -0.36193326115608215,
                "frobenius_norm": 1.9693055152893066,
                "spectral_norm": 1.254339337348938,
                "alpha": 1.1521528893544528,
                "alpha_hat": 2.3566886759036363
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04673761874437332,
                "median": 0.02952750399708748,
                "std": 0.19301970303058624,
                "max": 0.43809372186660767,
                "min": -0.24575187265872955,
                "frobenius_norm": 1.5887808799743652,
                "spectral_norm": 0.8752036690711975,
                "alpha": 1.2300299890840352,
                "alpha_hat": 1.1347542966381385
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=16_scaler_type=standard_seed=123": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 123,
        "scores": {
            "smape": 0.07693979889154434,
            "mse": 555276672.0,
            "mae": 2081.80419921875,
            "r2_score": 0.8800525665283203,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.026739293709397316,
                "median": 0.037985969334840775,
                "std": 0.19403018057346344,
                "max": 0.3941952586174011,
                "min": -0.4481939375400543,
                "frobenius_norm": 1.9190673828125,
                "spectral_norm": 1.1528699398040771,
                "alpha": 1.5467641040220141,
                "alpha_hat": 1.8948332677990827
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.012442559003829956,
                "median": 0.04896790534257889,
                "std": 0.24390578269958496,
                "max": 0.4473783075809479,
                "min": -0.5584347248077393,
                "frobenius_norm": 1.953783631324768,
                "spectral_norm": 1.1934736967086792,
                "alpha": 1.252147474441672,
                "alpha_hat": 1.4273933217382142
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.012771591544151306,
                "median": 0.014631204307079315,
                "std": 0.2458316534757614,
                "max": 0.652876079082489,
                "min": -0.36193326115608215,
                "frobenius_norm": 1.9693055152893066,
                "spectral_norm": 1.254339337348938,
                "alpha": 1.1521528893544528,
                "alpha_hat": 2.3566886759036363
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04673761874437332,
                "median": 0.02952750399708748,
                "std": 0.19301970303058624,
                "max": 0.43809372186660767,
                "min": -0.24575187265872955,
                "frobenius_norm": 1.5887808799743652,
                "spectral_norm": 0.8752036690711975,
                "alpha": 1.2300299890840352,
                "alpha_hat": 1.1347542966381385
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=16_scaler_type=standard_seed=42": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 42,
        "scores": {
            "smape": 0.07720838487148285,
            "mse": 559061888.0,
            "mae": 2086.22216796875,
            "r2_score": 0.8792349100112915,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.026739293709397316,
                "median": 0.037985969334840775,
                "std": 0.19403018057346344,
                "max": 0.3941952586174011,
                "min": -0.4481939375400543,
                "frobenius_norm": 1.9190673828125,
                "spectral_norm": 1.1528699398040771,
                "alpha": 1.5467641040220141,
                "alpha_hat": 1.8948332677990827
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.012442559003829956,
                "median": 0.04896790534257889,
                "std": 0.24390578269958496,
                "max": 0.4473783075809479,
                "min": -0.5584347248077393,
                "frobenius_norm": 1.953783631324768,
                "spectral_norm": 1.1934736967086792,
                "alpha": 1.252147474441672,
                "alpha_hat": 1.4273933217382142
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.012771591544151306,
                "median": 0.014631204307079315,
                "std": 0.2458316534757614,
                "max": 0.652876079082489,
                "min": -0.36193326115608215,
                "frobenius_norm": 1.9693055152893066,
                "spectral_norm": 1.254339337348938,
                "alpha": 1.1521528893544528,
                "alpha_hat": 2.3566886759036363
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04673761874437332,
                "median": 0.02952750399708748,
                "std": 0.19301970303058624,
                "max": 0.43809372186660767,
                "min": -0.24575187265872955,
                "frobenius_norm": 1.5887808799743652,
                "spectral_norm": 0.8752036690711975,
                "alpha": 1.2300299890840352,
                "alpha_hat": 1.1347542966381385
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=16_scaler_type=standard_seed=789": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 789,
        "scores": {
            "smape": 0.07732927054166794,
            "mse": 563947456.0,
            "mae": 2087.45654296875,
            "r2_score": 0.8781795501708984,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.02331727184355259,
                "median": 0.038162484765052795,
                "std": 0.18576602637767792,
                "max": 0.4359329342842102,
                "min": -0.428994745016098,
                "frobenius_norm": 1.8344101905822754,
                "spectral_norm": 1.1422820091247559,
                "alpha": 1.623015538971942,
                "alpha_hat": 2.034895921346185
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05803322046995163,
                "median": 0.08400028944015503,
                "std": 0.2544040083885193,
                "max": 0.590133547782898,
                "min": -0.48036861419677734,
                "frobenius_norm": 2.0875134468078613,
                "spectral_norm": 1.3254661560058594,
                "alpha": 1.216173251017289,
                "alpha_hat": 2.007581226408307
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03074706345796585,
                "median": 0.04072387516498566,
                "std": 0.2363746464252472,
                "max": 0.41863787174224854,
                "min": -0.373572438955307,
                "frobenius_norm": 1.9069281816482544,
                "spectral_norm": 1.2553443908691406,
                "alpha": 1.1633211543657667,
                "alpha_hat": 2.228458213429011
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.003470577299594879,
                "median": 0.0022444946225732565,
                "std": 0.21171078085899353,
                "max": 0.39364296197891235,
                "min": -0.47468996047973633,
                "frobenius_norm": 1.6939138174057007,
                "spectral_norm": 1.0590589046478271,
                "alpha": 1.2043960743136712,
                "alpha_hat": 2.1946353797753146
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=16_scaler_type=standard_seed=1011": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1011,
        "scores": {
            "smape": 0.07661522179841995,
            "mse": 504278368.0,
            "mae": 2060.065185546875,
            "r2_score": 0.8910689353942871,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.02331727184355259,
                "median": 0.038162484765052795,
                "std": 0.18576602637767792,
                "max": 0.4359329342842102,
                "min": -0.428994745016098,
                "frobenius_norm": 1.8344101905822754,
                "spectral_norm": 1.1422820091247559,
                "alpha": 1.623015538971942,
                "alpha_hat": 2.034895921346185
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05803322046995163,
                "median": 0.08400028944015503,
                "std": 0.2544040083885193,
                "max": 0.590133547782898,
                "min": -0.48036861419677734,
                "frobenius_norm": 2.0875134468078613,
                "spectral_norm": 1.3254661560058594,
                "alpha": 1.216173251017289,
                "alpha_hat": 2.007581226408307
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03074706345796585,
                "median": 0.04072387516498566,
                "std": 0.2363746464252472,
                "max": 0.41863787174224854,
                "min": -0.373572438955307,
                "frobenius_norm": 1.9069281816482544,
                "spectral_norm": 1.2553443908691406,
                "alpha": 1.1633211543657667,
                "alpha_hat": 2.228458213429011
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.003470577299594879,
                "median": 0.0022444946225732565,
                "std": 0.21171078085899353,
                "max": 0.39364296197891235,
                "min": -0.47468996047973633,
                "frobenius_norm": 1.6939138174057007,
                "spectral_norm": 1.0590589046478271,
                "alpha": 1.2043960743136712,
                "alpha_hat": 2.1946353797753146
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=16_scaler_type=standard_seed=1213": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1213,
        "scores": {
            "smape": 0.07724739611148834,
            "mse": 485497920.0,
            "mae": 2059.21923828125,
            "r2_score": 0.8951257467269897,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.02331727184355259,
                "median": 0.038162484765052795,
                "std": 0.18576602637767792,
                "max": 0.4359329342842102,
                "min": -0.428994745016098,
                "frobenius_norm": 1.8344101905822754,
                "spectral_norm": 1.1422820091247559,
                "alpha": 1.623015538971942,
                "alpha_hat": 2.034895921346185
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05803322046995163,
                "median": 0.08400028944015503,
                "std": 0.2544040083885193,
                "max": 0.590133547782898,
                "min": -0.48036861419677734,
                "frobenius_norm": 2.0875134468078613,
                "spectral_norm": 1.3254661560058594,
                "alpha": 1.216173251017289,
                "alpha_hat": 2.007581226408307
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03074706345796585,
                "median": 0.04072387516498566,
                "std": 0.2363746464252472,
                "max": 0.41863787174224854,
                "min": -0.373572438955307,
                "frobenius_norm": 1.9069281816482544,
                "spectral_norm": 1.2553443908691406,
                "alpha": 1.1633211543657667,
                "alpha_hat": 2.228458213429011
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.003470577299594879,
                "median": 0.0022444946225732565,
                "std": 0.21171078085899353,
                "max": 0.39364296197891235,
                "min": -0.47468996047973633,
                "frobenius_norm": 1.6939138174057007,
                "spectral_norm": 1.0590589046478271,
                "alpha": 1.2043960743136712,
                "alpha_hat": 2.1946353797753146
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=16_scaler_type=standard_seed=456": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 456,
        "scores": {
            "smape": 0.07687653601169586,
            "mse": 554434688.0,
            "mae": 2088.212158203125,
            "r2_score": 0.8802344799041748,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.02331727184355259,
                "median": 0.038162484765052795,
                "std": 0.18576602637767792,
                "max": 0.4359329342842102,
                "min": -0.428994745016098,
                "frobenius_norm": 1.8344101905822754,
                "spectral_norm": 1.1422820091247559,
                "alpha": 1.623015538971942,
                "alpha_hat": 2.034895921346185
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05803322046995163,
                "median": 0.08400028944015503,
                "std": 0.2544040083885193,
                "max": 0.590133547782898,
                "min": -0.48036861419677734,
                "frobenius_norm": 2.0875134468078613,
                "spectral_norm": 1.3254661560058594,
                "alpha": 1.216173251017289,
                "alpha_hat": 2.007581226408307
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03074706345796585,
                "median": 0.04072387516498566,
                "std": 0.2363746464252472,
                "max": 0.41863787174224854,
                "min": -0.373572438955307,
                "frobenius_norm": 1.9069281816482544,
                "spectral_norm": 1.2553443908691406,
                "alpha": 1.1633211543657667,
                "alpha_hat": 2.228458213429011
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.003470577299594879,
                "median": 0.0022444946225732565,
                "std": 0.21171078085899353,
                "max": 0.39364296197891235,
                "min": -0.47468996047973633,
                "frobenius_norm": 1.6939138174057007,
                "spectral_norm": 1.0590589046478271,
                "alpha": 1.2043960743136712,
                "alpha_hat": 2.1946353797753146
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=16_scaler_type=standard_seed=1819": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1819,
        "scores": {
            "smape": 0.07681433856487274,
            "mse": 550134592.0,
            "mae": 2080.219970703125,
            "r2_score": 0.8811633586883545,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.03136489540338516,
                "median": 0.03647620975971222,
                "std": 0.1844351887702942,
                "max": 0.49842438101768494,
                "min": -0.2951524257659912,
                "frobenius_norm": 1.8330328464508057,
                "spectral_norm": 1.1428428888320923,
                "alpha": 1.6630157883433343,
                "alpha_hat": 2.093899148187901
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.029129482805728912,
                "median": 0.050897568464279175,
                "std": 0.22808046638965607,
                "max": 0.5064041018486023,
                "min": -0.393128901720047,
                "frobenius_norm": 1.8394646644592285,
                "spectral_norm": 1.1972110271453857,
                "alpha": 1.4969038667661865,
                "alpha_hat": 2.5740360395590414
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03191079571843147,
                "median": 0.06989316642284393,
                "std": 0.2324235737323761,
                "max": 0.48992204666137695,
                "min": -0.4349239766597748,
                "frobenius_norm": 1.8768316507339478,
                "spectral_norm": 1.0922274589538574,
                "alpha": 1.262826684380272,
                "alpha_hat": 1.756730757419486
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08019337803125381,
                "median": 0.11567799001932144,
                "std": 0.21427568793296814,
                "max": 0.49068889021873474,
                "min": -0.3239644467830658,
                "frobenius_norm": 1.8303232192993164,
                "spectral_norm": 1.124459981918335,
                "alpha": 1.4700316912665166,
                "alpha_hat": 2.090733869736085
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=16_scaler_type=standard_seed=2021": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 2021,
        "scores": {
            "smape": 0.07702003419399261,
            "mse": 558835008.0,
            "mae": 2085.99755859375,
            "r2_score": 0.8792839050292969,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.03136489540338516,
                "median": 0.03647620975971222,
                "std": 0.1844351887702942,
                "max": 0.49842438101768494,
                "min": -0.2951524257659912,
                "frobenius_norm": 1.8330328464508057,
                "spectral_norm": 1.1428428888320923,
                "alpha": 1.6630157883433343,
                "alpha_hat": 2.093899148187901
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.029129482805728912,
                "median": 0.050897568464279175,
                "std": 0.22808046638965607,
                "max": 0.5064041018486023,
                "min": -0.393128901720047,
                "frobenius_norm": 1.8394646644592285,
                "spectral_norm": 1.1972110271453857,
                "alpha": 1.4969038667661865,
                "alpha_hat": 2.5740360395590414
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03191079571843147,
                "median": 0.06989316642284393,
                "std": 0.2324235737323761,
                "max": 0.48992204666137695,
                "min": -0.4349239766597748,
                "frobenius_norm": 1.8768316507339478,
                "spectral_norm": 1.0922274589538574,
                "alpha": 1.262826684380272,
                "alpha_hat": 1.756730757419486
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08019337803125381,
                "median": 0.11567799001932144,
                "std": 0.21427568793296814,
                "max": 0.49068889021873474,
                "min": -0.3239644467830658,
                "frobenius_norm": 1.8303232192993164,
                "spectral_norm": 1.124459981918335,
                "alpha": 1.4700316912665166,
                "alpha_hat": 2.090733869736085
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=16_scaler_type=standard_seed=1415": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1415,
        "scores": {
            "smape": 0.07711142301559448,
            "mse": 459636736.0,
            "mae": 2039.215576171875,
            "r2_score": 0.9007121324539185,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.03136489540338516,
                "median": 0.03647620975971222,
                "std": 0.1844351887702942,
                "max": 0.49842438101768494,
                "min": -0.2951524257659912,
                "frobenius_norm": 1.8330328464508057,
                "spectral_norm": 1.1428428888320923,
                "alpha": 1.6630157883433343,
                "alpha_hat": 2.093899148187901
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.029129482805728912,
                "median": 0.050897568464279175,
                "std": 0.22808046638965607,
                "max": 0.5064041018486023,
                "min": -0.393128901720047,
                "frobenius_norm": 1.8394646644592285,
                "spectral_norm": 1.1972110271453857,
                "alpha": 1.4969038667661865,
                "alpha_hat": 2.5740360395590414
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03191079571843147,
                "median": 0.06989316642284393,
                "std": 0.2324235737323761,
                "max": 0.48992204666137695,
                "min": -0.4349239766597748,
                "frobenius_norm": 1.8768316507339478,
                "spectral_norm": 1.0922274589538574,
                "alpha": 1.262826684380272,
                "alpha_hat": 1.756730757419486
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08019337803125381,
                "median": 0.11567799001932144,
                "std": 0.21427568793296814,
                "max": 0.49068889021873474,
                "min": -0.3239644467830658,
                "frobenius_norm": 1.8303232192993164,
                "spectral_norm": 1.124459981918335,
                "alpha": 1.4700316912665166,
                "alpha_hat": 2.090733869736085
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=16_scaler_type=standard_seed=1617": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1617,
        "scores": {
            "smape": 0.07733609527349472,
            "mse": 550389952.0,
            "mae": 2095.493896484375,
            "r2_score": 0.8811081647872925,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.03136489540338516,
                "median": 0.03647620975971222,
                "std": 0.1844351887702942,
                "max": 0.49842438101768494,
                "min": -0.2951524257659912,
                "frobenius_norm": 1.8330328464508057,
                "spectral_norm": 1.1428428888320923,
                "alpha": 1.6630157883433343,
                "alpha_hat": 2.093899148187901
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.029129482805728912,
                "median": 0.050897568464279175,
                "std": 0.22808046638965607,
                "max": 0.5064041018486023,
                "min": -0.393128901720047,
                "frobenius_norm": 1.8394646644592285,
                "spectral_norm": 1.1972110271453857,
                "alpha": 1.4969038667661865,
                "alpha_hat": 2.5740360395590414
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03191079571843147,
                "median": 0.06989316642284393,
                "std": 0.2324235737323761,
                "max": 0.48992204666137695,
                "min": -0.4349239766597748,
                "frobenius_norm": 1.8768316507339478,
                "spectral_norm": 1.0922274589538574,
                "alpha": 1.262826684380272,
                "alpha_hat": 1.756730757419486
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08019337803125381,
                "median": 0.11567799001932144,
                "std": 0.21427568793296814,
                "max": 0.49068889021873474,
                "min": -0.3239644467830658,
                "frobenius_norm": 1.8303232192993164,
                "spectral_norm": 1.124459981918335,
                "alpha": 1.4700316912665166,
                "alpha_hat": 2.090733869736085
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=16_scaler_type=robust_seed=42": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 42,
        "scores": {
            "smape": 0.07637333124876022,
            "mse": 616347328.0,
            "mae": 2119.575439453125,
            "r2_score": 0.8668605089187622,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.044936735183000565,
                "median": 0.05766831338405609,
                "std": 0.1943659484386444,
                "max": 0.45333558320999146,
                "min": -0.42678743600845337,
                "frobenius_norm": 1.9546235799789429,
                "spectral_norm": 1.2493953704833984,
                "alpha": 1.5419233942643777,
                "alpha_hat": 2.0077554585083695
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06383173167705536,
                "median": 0.10991667956113815,
                "std": 0.2289881557226181,
                "max": 0.5156897306442261,
                "min": -0.5383818745613098,
                "frobenius_norm": 1.901747703552246,
                "spectral_norm": 1.2949495315551758,
                "alpha": 1.1615441754815865,
                "alpha_hat": 1.8073510991870405
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.014306936413049698,
                "median": -0.02176196128129959,
                "std": 0.2568298578262329,
                "max": 0.7070379257202148,
                "min": -0.42278993129730225,
                "frobenius_norm": 2.05782413482666,
                "spectral_norm": 1.274444580078125,
                "alpha": 1.1753215901633456,
                "alpha_hat": 2.5995503484766593
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.049018219113349915,
                "median": 0.028252512216567993,
                "std": 0.19222265481948853,
                "max": 0.46100568771362305,
                "min": -0.24549558758735657,
                "frobenius_norm": 1.5869938135147095,
                "spectral_norm": 0.8742268085479736,
                "alpha": 1.2256424005783908,
                "alpha_hat": 1.1380728870784327
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=16_scaler_type=robust_seed=789": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 789,
        "scores": {
            "smape": 0.07679037004709244,
            "mse": 620687680.0,
            "mae": 2124.72998046875,
            "r2_score": 0.8659229278564453,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.044936735183000565,
                "median": 0.05766831338405609,
                "std": 0.1943659484386444,
                "max": 0.45333558320999146,
                "min": -0.42678743600845337,
                "frobenius_norm": 1.9546235799789429,
                "spectral_norm": 1.2493953704833984,
                "alpha": 1.5419233942643777,
                "alpha_hat": 2.0077554585083695
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06383173167705536,
                "median": 0.10991667956113815,
                "std": 0.2289881557226181,
                "max": 0.5156897306442261,
                "min": -0.5383818745613098,
                "frobenius_norm": 1.901747703552246,
                "spectral_norm": 1.2949495315551758,
                "alpha": 1.1615441754815865,
                "alpha_hat": 1.8073510991870405
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.014306936413049698,
                "median": -0.02176196128129959,
                "std": 0.2568298578262329,
                "max": 0.7070379257202148,
                "min": -0.42278993129730225,
                "frobenius_norm": 2.05782413482666,
                "spectral_norm": 1.274444580078125,
                "alpha": 1.1753215901633456,
                "alpha_hat": 2.5995503484766593
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.049018219113349915,
                "median": 0.028252512216567993,
                "std": 0.19222265481948853,
                "max": 0.46100568771362305,
                "min": -0.24549558758735657,
                "frobenius_norm": 1.5869938135147095,
                "spectral_norm": 0.8742268085479736,
                "alpha": 1.2256424005783908,
                "alpha_hat": 1.1380728870784327
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=16_scaler_type=robust_seed=123": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 123,
        "scores": {
            "smape": 0.07621320337057114,
            "mse": 625147456.0,
            "mae": 2124.7197265625,
            "r2_score": 0.8649595379829407,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.044936735183000565,
                "median": 0.05766831338405609,
                "std": 0.1943659484386444,
                "max": 0.45333558320999146,
                "min": -0.42678743600845337,
                "frobenius_norm": 1.9546235799789429,
                "spectral_norm": 1.2493953704833984,
                "alpha": 1.5419233942643777,
                "alpha_hat": 2.0077554585083695
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06383173167705536,
                "median": 0.10991667956113815,
                "std": 0.2289881557226181,
                "max": 0.5156897306442261,
                "min": -0.5383818745613098,
                "frobenius_norm": 1.901747703552246,
                "spectral_norm": 1.2949495315551758,
                "alpha": 1.1615441754815865,
                "alpha_hat": 1.8073510991870405
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.014306936413049698,
                "median": -0.02176196128129959,
                "std": 0.2568298578262329,
                "max": 0.7070379257202148,
                "min": -0.42278993129730225,
                "frobenius_norm": 2.05782413482666,
                "spectral_norm": 1.274444580078125,
                "alpha": 1.1753215901633456,
                "alpha_hat": 2.5995503484766593
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.049018219113349915,
                "median": 0.028252512216567993,
                "std": 0.19222265481948853,
                "max": 0.46100568771362305,
                "min": -0.24549558758735657,
                "frobenius_norm": 1.5869938135147095,
                "spectral_norm": 0.8742268085479736,
                "alpha": 1.2256424005783908,
                "alpha_hat": 1.1380728870784327
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=16_scaler_type=robust_seed=456": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 456,
        "scores": {
            "smape": 0.07640095800161362,
            "mse": 623533696.0,
            "mae": 2121.163818359375,
            "r2_score": 0.8653081059455872,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.044936735183000565,
                "median": 0.05766831338405609,
                "std": 0.1943659484386444,
                "max": 0.45333558320999146,
                "min": -0.42678743600845337,
                "frobenius_norm": 1.9546235799789429,
                "spectral_norm": 1.2493953704833984,
                "alpha": 1.5419233942643777,
                "alpha_hat": 2.0077554585083695
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06383173167705536,
                "median": 0.10991667956113815,
                "std": 0.2289881557226181,
                "max": 0.5156897306442261,
                "min": -0.5383818745613098,
                "frobenius_norm": 1.901747703552246,
                "spectral_norm": 1.2949495315551758,
                "alpha": 1.1615441754815865,
                "alpha_hat": 1.8073510991870405
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.014306936413049698,
                "median": -0.02176196128129959,
                "std": 0.2568298578262329,
                "max": 0.7070379257202148,
                "min": -0.42278993129730225,
                "frobenius_norm": 2.05782413482666,
                "spectral_norm": 1.274444580078125,
                "alpha": 1.1753215901633456,
                "alpha_hat": 2.5995503484766593
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.049018219113349915,
                "median": 0.028252512216567993,
                "std": 0.19222265481948853,
                "max": 0.46100568771362305,
                "min": -0.24549558758735657,
                "frobenius_norm": 1.5869938135147095,
                "spectral_norm": 0.8742268085479736,
                "alpha": 1.2256424005783908,
                "alpha_hat": 1.1380728870784327
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=16_scaler_type=robust_seed=1011": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1011,
        "scores": {
            "smape": 0.07655952870845795,
            "mse": 554638592.0,
            "mae": 2111.772216796875,
            "r2_score": 0.8801904320716858,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.025742366909980774,
                "median": 0.016164790838956833,
                "std": 0.19806724786758423,
                "max": 0.45257139205932617,
                "min": -0.38932210206985474,
                "frobenius_norm": 1.9569764137268066,
                "spectral_norm": 1.272809624671936,
                "alpha": 1.3726103944289592,
                "alpha_hat": 1.6700162292282275
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04739677906036377,
                "median": 0.040656886994838715,
                "std": 0.24787721037864685,
                "max": 0.6331057548522949,
                "min": -0.49297189712524414,
                "frobenius_norm": 2.0189433097839355,
                "spectral_norm": 1.2883845567703247,
                "alpha": 1.0813116659336395,
                "alpha_hat": 1.9167676640679376
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022370461374521255,
                "median": -3.977445885539055e-05,
                "std": 0.246212437748909,
                "max": 0.6275275945663452,
                "min": -0.421345978975296,
                "frobenius_norm": 1.9778131246566772,
                "spectral_norm": 1.3428354263305664,
                "alpha": 1.2214964025691635,
                "alpha_hat": 1.8561067607191293
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.09351567924022675,
                "median": 0.10459290444850922,
                "std": 0.20879025757312775,
                "max": 0.537043035030365,
                "min": -0.34512898325920105,
                "frobenius_norm": 1.8302096128463745,
                "spectral_norm": 1.2286909818649292,
                "alpha": 1.4564771143314599,
                "alpha_hat": 2.412853635690121
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=16_scaler_type=robust_seed=1617": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1617,
        "scores": {
            "smape": 0.07634393870830536,
            "mse": 630792576.0,
            "mae": 2121.473388671875,
            "r2_score": 0.863740086555481,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.025742366909980774,
                "median": 0.016164790838956833,
                "std": 0.19806724786758423,
                "max": 0.45257139205932617,
                "min": -0.38932210206985474,
                "frobenius_norm": 1.9569764137268066,
                "spectral_norm": 1.272809624671936,
                "alpha": 1.3726103944289592,
                "alpha_hat": 1.6700162292282275
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04739677906036377,
                "median": 0.040656886994838715,
                "std": 0.24787721037864685,
                "max": 0.6331057548522949,
                "min": -0.49297189712524414,
                "frobenius_norm": 2.0189433097839355,
                "spectral_norm": 1.2883845567703247,
                "alpha": 1.0813116659336395,
                "alpha_hat": 1.9167676640679376
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022370461374521255,
                "median": -3.977445885539055e-05,
                "std": 0.246212437748909,
                "max": 0.6275275945663452,
                "min": -0.421345978975296,
                "frobenius_norm": 1.9778131246566772,
                "spectral_norm": 1.3428354263305664,
                "alpha": 1.2214964025691635,
                "alpha_hat": 1.8561067607191293
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.09351567924022675,
                "median": 0.10459290444850922,
                "std": 0.20879025757312775,
                "max": 0.537043035030365,
                "min": -0.34512898325920105,
                "frobenius_norm": 1.8302096128463745,
                "spectral_norm": 1.2286909818649292,
                "alpha": 1.4564771143314599,
                "alpha_hat": 2.412853635690121
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=16_scaler_type=robust_seed=1415": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1415,
        "scores": {
            "smape": 0.0764625146985054,
            "mse": 628687296.0,
            "mae": 2132.8447265625,
            "r2_score": 0.8641948699951172,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.025742366909980774,
                "median": 0.016164790838956833,
                "std": 0.19806724786758423,
                "max": 0.45257139205932617,
                "min": -0.38932210206985474,
                "frobenius_norm": 1.9569764137268066,
                "spectral_norm": 1.272809624671936,
                "alpha": 1.3726103944289592,
                "alpha_hat": 1.6700162292282275
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04739677906036377,
                "median": 0.040656886994838715,
                "std": 0.24787721037864685,
                "max": 0.6331057548522949,
                "min": -0.49297189712524414,
                "frobenius_norm": 2.0189433097839355,
                "spectral_norm": 1.2883845567703247,
                "alpha": 1.0813116659336395,
                "alpha_hat": 1.9167676640679376
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022370461374521255,
                "median": -3.977445885539055e-05,
                "std": 0.246212437748909,
                "max": 0.6275275945663452,
                "min": -0.421345978975296,
                "frobenius_norm": 1.9778131246566772,
                "spectral_norm": 1.3428354263305664,
                "alpha": 1.2214964025691635,
                "alpha_hat": 1.8561067607191293
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.09351567924022675,
                "median": 0.10459290444850922,
                "std": 0.20879025757312775,
                "max": 0.537043035030365,
                "min": -0.34512898325920105,
                "frobenius_norm": 1.8302096128463745,
                "spectral_norm": 1.2286909818649292,
                "alpha": 1.4564771143314599,
                "alpha_hat": 2.412853635690121
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=16_scaler_type=robust_seed=1213": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1213,
        "scores": {
            "smape": 0.075214684009552,
            "mse": 578435008.0,
            "mae": 2188.982666015625,
            "r2_score": 0.8750500679016113,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.025742366909980774,
                "median": 0.016164790838956833,
                "std": 0.19806724786758423,
                "max": 0.45257139205932617,
                "min": -0.38932210206985474,
                "frobenius_norm": 1.9569764137268066,
                "spectral_norm": 1.272809624671936,
                "alpha": 1.3726103944289592,
                "alpha_hat": 1.6700162292282275
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04739677906036377,
                "median": 0.040656886994838715,
                "std": 0.24787721037864685,
                "max": 0.6331057548522949,
                "min": -0.49297189712524414,
                "frobenius_norm": 2.0189433097839355,
                "spectral_norm": 1.2883845567703247,
                "alpha": 1.0813116659336395,
                "alpha_hat": 1.9167676640679376
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022370461374521255,
                "median": -3.977445885539055e-05,
                "std": 0.246212437748909,
                "max": 0.6275275945663452,
                "min": -0.421345978975296,
                "frobenius_norm": 1.9778131246566772,
                "spectral_norm": 1.3428354263305664,
                "alpha": 1.2214964025691635,
                "alpha_hat": 1.8561067607191293
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.09351567924022675,
                "median": 0.10459290444850922,
                "std": 0.20879025757312775,
                "max": 0.537043035030365,
                "min": -0.34512898325920105,
                "frobenius_norm": 1.8302096128463745,
                "spectral_norm": 1.2286909818649292,
                "alpha": 1.4564771143314599,
                "alpha_hat": 2.412853635690121
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=16_scaler_type=minmax_seed=42": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 42,
        "scores": {
            "smape": 0.11925066262483597,
            "mse": 1173507072.0,
            "mae": 3022.123291015625,
            "r2_score": 0.7465063333511353,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.04007567837834358,
                "median": 0.04689795523881912,
                "std": 0.19526393711566925,
                "max": 0.45129314064979553,
                "min": -0.4337993264198303,
                "frobenius_norm": 1.9530669450759888,
                "spectral_norm": 1.2439687252044678,
                "alpha": 1.489887315717949,
                "alpha_hat": 1.9420273499355794
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.057298578321933746,
                "median": 0.10061313211917877,
                "std": 0.24070708453655243,
                "max": 0.5431386232376099,
                "min": -0.5098996758460999,
                "frobenius_norm": 1.97946298122406,
                "spectral_norm": 1.3369898796081543,
                "alpha": 1.1360079147939024,
                "alpha_hat": 1.75802819396792
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01854395866394043,
                "median": 0.009172073565423489,
                "std": 0.25078850984573364,
                "max": 0.6770870089530945,
                "min": -0.4035279154777527,
                "frobenius_norm": 2.0117855072021484,
                "spectral_norm": 1.2125911712646484,
                "alpha": 1.1475186770890915,
                "alpha_hat": 2.3746246189938036
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05255226045846939,
                "median": 0.030753443017601967,
                "std": 0.19168655574321747,
                "max": 0.44613441824913025,
                "min": -0.237716406583786,
                "frobenius_norm": 1.5900788307189941,
                "spectral_norm": 0.8824666738510132,
                "alpha": 1.218205193409151,
                "alpha_hat": 1.1466287722297233
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=16_scaler_type=minmax_seed=123": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 123,
        "scores": {
            "smape": 0.1115315854549408,
            "mse": 1112624896.0,
            "mae": 2922.185546875,
            "r2_score": 0.7596576809883118,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.04007567837834358,
                "median": 0.04689795523881912,
                "std": 0.19526393711566925,
                "max": 0.45129314064979553,
                "min": -0.4337993264198303,
                "frobenius_norm": 1.9530669450759888,
                "spectral_norm": 1.2439687252044678,
                "alpha": 1.489887315717949,
                "alpha_hat": 1.9420273499355794
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.057298578321933746,
                "median": 0.10061313211917877,
                "std": 0.24070708453655243,
                "max": 0.5431386232376099,
                "min": -0.5098996758460999,
                "frobenius_norm": 1.97946298122406,
                "spectral_norm": 1.3369898796081543,
                "alpha": 1.1360079147939024,
                "alpha_hat": 1.75802819396792
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01854395866394043,
                "median": 0.009172073565423489,
                "std": 0.25078850984573364,
                "max": 0.6770870089530945,
                "min": -0.4035279154777527,
                "frobenius_norm": 2.0117855072021484,
                "spectral_norm": 1.2125911712646484,
                "alpha": 1.1475186770890915,
                "alpha_hat": 2.3746246189938036
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05255226045846939,
                "median": 0.030753443017601967,
                "std": 0.19168655574321747,
                "max": 0.44613441824913025,
                "min": -0.237716406583786,
                "frobenius_norm": 1.5900788307189941,
                "spectral_norm": 0.8824666738510132,
                "alpha": 1.218205193409151,
                "alpha_hat": 1.1466287722297233
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=16_scaler_type=robust_seed=1819": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1819,
        "scores": {
            "smape": 0.07590119540691376,
            "mse": 616144960.0,
            "mae": 2135.197265625,
            "r2_score": 0.8669041991233826,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.04007567837834358,
                "median": 0.04689795523881912,
                "std": 0.19526393711566925,
                "max": 0.45129314064979553,
                "min": -0.4337993264198303,
                "frobenius_norm": 1.9530669450759888,
                "spectral_norm": 1.2439687252044678,
                "alpha": 1.489887315717949,
                "alpha_hat": 1.9420273499355794
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.057298578321933746,
                "median": 0.10061313211917877,
                "std": 0.24070708453655243,
                "max": 0.5431386232376099,
                "min": -0.5098996758460999,
                "frobenius_norm": 1.97946298122406,
                "spectral_norm": 1.3369898796081543,
                "alpha": 1.1360079147939024,
                "alpha_hat": 1.75802819396792
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01854395866394043,
                "median": 0.009172073565423489,
                "std": 0.25078850984573364,
                "max": 0.6770870089530945,
                "min": -0.4035279154777527,
                "frobenius_norm": 2.0117855072021484,
                "spectral_norm": 1.2125911712646484,
                "alpha": 1.1475186770890915,
                "alpha_hat": 2.3746246189938036
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05255226045846939,
                "median": 0.030753443017601967,
                "std": 0.19168655574321747,
                "max": 0.44613441824913025,
                "min": -0.237716406583786,
                "frobenius_norm": 1.5900788307189941,
                "spectral_norm": 0.8824666738510132,
                "alpha": 1.218205193409151,
                "alpha_hat": 1.1466287722297233
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=16_scaler_type=robust_seed=2021": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 2021,
        "scores": {
            "smape": 0.07676767557859421,
            "mse": 623738880.0,
            "mae": 2120.91259765625,
            "r2_score": 0.865263819694519,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.04007567837834358,
                "median": 0.04689795523881912,
                "std": 0.19526393711566925,
                "max": 0.45129314064979553,
                "min": -0.4337993264198303,
                "frobenius_norm": 1.9530669450759888,
                "spectral_norm": 1.2439687252044678,
                "alpha": 1.489887315717949,
                "alpha_hat": 1.9420273499355794
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.057298578321933746,
                "median": 0.10061313211917877,
                "std": 0.24070708453655243,
                "max": 0.5431386232376099,
                "min": -0.5098996758460999,
                "frobenius_norm": 1.97946298122406,
                "spectral_norm": 1.3369898796081543,
                "alpha": 1.1360079147939024,
                "alpha_hat": 1.75802819396792
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01854395866394043,
                "median": 0.009172073565423489,
                "std": 0.25078850984573364,
                "max": 0.6770870089530945,
                "min": -0.4035279154777527,
                "frobenius_norm": 2.0117855072021484,
                "spectral_norm": 1.2125911712646484,
                "alpha": 1.1475186770890915,
                "alpha_hat": 2.3746246189938036
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05255226045846939,
                "median": 0.030753443017601967,
                "std": 0.19168655574321747,
                "max": 0.44613441824913025,
                "min": -0.237716406583786,
                "frobenius_norm": 1.5900788307189941,
                "spectral_norm": 0.8824666738510132,
                "alpha": 1.218205193409151,
                "alpha_hat": 1.1466287722297233
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=16_scaler_type=minmax_seed=456": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 456,
        "scores": {
            "smape": 0.10906340926885605,
            "mse": 1074491776.0,
            "mae": 2866.42919921875,
            "r2_score": 0.767894983291626,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06494525820016861,
                "median": 0.0781652182340622,
                "std": 0.17529311776161194,
                "max": 0.38778796792030334,
                "min": -0.31534674763679504,
                "frobenius_norm": 1.831604242324829,
                "spectral_norm": 1.1421375274658203,
                "alpha": 1.394140663408164,
                "alpha_hat": 1.8208911243027754
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03515844792127609,
                "median": 0.06262043118476868,
                "std": 0.23129448294639587,
                "max": 0.4313167929649353,
                "min": -0.4761705696582794,
                "frobenius_norm": 1.8716111183166504,
                "spectral_norm": 1.130463719367981,
                "alpha": 1.2463300656482847,
                "alpha_hat": 1.7751915376684724
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.013370406813919544,
                "median": 0.0008623716421425343,
                "std": 0.2363446056842804,
                "max": 0.6181721687316895,
                "min": -0.5227890014648438,
                "frobenius_norm": 1.8937801122665405,
                "spectral_norm": 1.2105859518051147,
                "alpha": 1.3339798204523632,
                "alpha_hat": 2.3439033242717184
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.042599886655807495,
                "median": 0.03097880631685257,
                "std": 0.19177567958831787,
                "max": 0.40169718861579895,
                "min": -0.26851826906204224,
                "frobenius_norm": 1.5716012716293335,
                "spectral_norm": 0.8399001359939575,
                "alpha": 1.2402746048879836,
                "alpha_hat": 1.1392998687192037
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=16_scaler_type=minmax_seed=1011": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1011,
        "scores": {
            "smape": 0.10624286532402039,
            "mse": 1052062464.0,
            "mae": 2820.79931640625,
            "r2_score": 0.7727400064468384,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06494525820016861,
                "median": 0.0781652182340622,
                "std": 0.17529311776161194,
                "max": 0.38778796792030334,
                "min": -0.31534674763679504,
                "frobenius_norm": 1.831604242324829,
                "spectral_norm": 1.1421375274658203,
                "alpha": 1.394140663408164,
                "alpha_hat": 1.8208911243027754
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03515844792127609,
                "median": 0.06262043118476868,
                "std": 0.23129448294639587,
                "max": 0.4313167929649353,
                "min": -0.4761705696582794,
                "frobenius_norm": 1.8716111183166504,
                "spectral_norm": 1.130463719367981,
                "alpha": 1.2463300656482847,
                "alpha_hat": 1.7751915376684724
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.013370406813919544,
                "median": 0.0008623716421425343,
                "std": 0.2363446056842804,
                "max": 0.6181721687316895,
                "min": -0.5227890014648438,
                "frobenius_norm": 1.8937801122665405,
                "spectral_norm": 1.2105859518051147,
                "alpha": 1.3339798204523632,
                "alpha_hat": 2.3439033242717184
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.042599886655807495,
                "median": 0.03097880631685257,
                "std": 0.19177567958831787,
                "max": 0.40169718861579895,
                "min": -0.26851826906204224,
                "frobenius_norm": 1.5716012716293335,
                "spectral_norm": 0.8399001359939575,
                "alpha": 1.2402746048879836,
                "alpha_hat": 1.1392998687192037
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=16_scaler_type=minmax_seed=1213": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1213,
        "scores": {
            "smape": 0.10310795158147812,
            "mse": 1025471936.0,
            "mae": 2822.23876953125,
            "r2_score": 0.7784839272499084,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06494525820016861,
                "median": 0.0781652182340622,
                "std": 0.17529311776161194,
                "max": 0.38778796792030334,
                "min": -0.31534674763679504,
                "frobenius_norm": 1.831604242324829,
                "spectral_norm": 1.1421375274658203,
                "alpha": 1.394140663408164,
                "alpha_hat": 1.8208911243027754
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03515844792127609,
                "median": 0.06262043118476868,
                "std": 0.23129448294639587,
                "max": 0.4313167929649353,
                "min": -0.4761705696582794,
                "frobenius_norm": 1.8716111183166504,
                "spectral_norm": 1.130463719367981,
                "alpha": 1.2463300656482847,
                "alpha_hat": 1.7751915376684724
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.013370406813919544,
                "median": 0.0008623716421425343,
                "std": 0.2363446056842804,
                "max": 0.6181721687316895,
                "min": -0.5227890014648438,
                "frobenius_norm": 1.8937801122665405,
                "spectral_norm": 1.2105859518051147,
                "alpha": 1.3339798204523632,
                "alpha_hat": 2.3439033242717184
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.042599886655807495,
                "median": 0.03097880631685257,
                "std": 0.19177567958831787,
                "max": 0.40169718861579895,
                "min": -0.26851826906204224,
                "frobenius_norm": 1.5716012716293335,
                "spectral_norm": 0.8399001359939575,
                "alpha": 1.2402746048879836,
                "alpha_hat": 1.1392998687192037
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=16_scaler_type=minmax_seed=789": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 789,
        "scores": {
            "smape": 0.11395672708749771,
            "mse": 1131129088.0,
            "mae": 2948.571533203125,
            "r2_score": 0.7556605339050293,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06494525820016861,
                "median": 0.0781652182340622,
                "std": 0.17529311776161194,
                "max": 0.38778796792030334,
                "min": -0.31534674763679504,
                "frobenius_norm": 1.831604242324829,
                "spectral_norm": 1.1421375274658203,
                "alpha": 1.394140663408164,
                "alpha_hat": 1.8208911243027754
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03515844792127609,
                "median": 0.06262043118476868,
                "std": 0.23129448294639587,
                "max": 0.4313167929649353,
                "min": -0.4761705696582794,
                "frobenius_norm": 1.8716111183166504,
                "spectral_norm": 1.130463719367981,
                "alpha": 1.2463300656482847,
                "alpha_hat": 1.7751915376684724
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.013370406813919544,
                "median": 0.0008623716421425343,
                "std": 0.2363446056842804,
                "max": 0.6181721687316895,
                "min": -0.5227890014648438,
                "frobenius_norm": 1.8937801122665405,
                "spectral_norm": 1.2105859518051147,
                "alpha": 1.3339798204523632,
                "alpha_hat": 2.3439033242717184
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.042599886655807495,
                "median": 0.03097880631685257,
                "std": 0.19177567958831787,
                "max": 0.40169718861579895,
                "min": -0.26851826906204224,
                "frobenius_norm": 1.5716012716293335,
                "spectral_norm": 0.8399001359939575,
                "alpha": 1.2402746048879836,
                "alpha_hat": 1.1392998687192037
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=16_scaler_type=minmax_seed=1415": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1415,
        "scores": {
            "smape": 0.11509598046541214,
            "mse": 1141726080.0,
            "mae": 2962.563232421875,
            "r2_score": 0.7533714175224304,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06635735183954239,
                "median": 0.09170152246952057,
                "std": 0.1781982034444809,
                "max": 0.398019403219223,
                "min": -0.31678661704063416,
                "frobenius_norm": 1.8631045818328857,
                "spectral_norm": 1.160811424255371,
                "alpha": 1.4308349825066071,
                "alpha_hat": 1.885524725379013
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03128175809979439,
                "median": 0.06518758833408356,
                "std": 0.22841311991214752,
                "max": 0.44140470027923584,
                "min": -0.4930466115474701,
                "frobenius_norm": 1.8443619012832642,
                "spectral_norm": 1.0856958627700806,
                "alpha": 1.2473279200638843,
                "alpha_hat": 1.7076302330408935
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.013773724436759949,
                "median": 0.006736087612807751,
                "std": 0.23321454226970673,
                "max": 0.6247504949569702,
                "min": -0.4737977385520935,
                "frobenius_norm": 1.8689675331115723,
                "spectral_norm": 1.1903058290481567,
                "alpha": 1.287075103179357,
                "alpha_hat": 2.1454345917713695
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.042398836463689804,
                "median": 0.03000696375966072,
                "std": 0.19133597612380981,
                "max": 0.420639306306839,
                "min": -0.275177538394928,
                "frobenius_norm": 1.5678187608718872,
                "spectral_norm": 0.8419381976127625,
                "alpha": 1.2299555297022247,
                "alpha_hat": 1.135092481129441
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=16_scaler_type=minmax_seed=1617": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1617,
        "scores": {
            "smape": 0.10870657116174698,
            "mse": 1089612544.0,
            "mae": 2883.77685546875,
            "r2_score": 0.7646286487579346,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06635735183954239,
                "median": 0.09170152246952057,
                "std": 0.1781982034444809,
                "max": 0.398019403219223,
                "min": -0.31678661704063416,
                "frobenius_norm": 1.8631045818328857,
                "spectral_norm": 1.160811424255371,
                "alpha": 1.4308349825066071,
                "alpha_hat": 1.885524725379013
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03128175809979439,
                "median": 0.06518758833408356,
                "std": 0.22841311991214752,
                "max": 0.44140470027923584,
                "min": -0.4930466115474701,
                "frobenius_norm": 1.8443619012832642,
                "spectral_norm": 1.0856958627700806,
                "alpha": 1.2473279200638843,
                "alpha_hat": 1.7076302330408935
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.013773724436759949,
                "median": 0.006736087612807751,
                "std": 0.23321454226970673,
                "max": 0.6247504949569702,
                "min": -0.4737977385520935,
                "frobenius_norm": 1.8689675331115723,
                "spectral_norm": 1.1903058290481567,
                "alpha": 1.287075103179357,
                "alpha_hat": 2.1454345917713695
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.042398836463689804,
                "median": 0.03000696375966072,
                "std": 0.19133597612380981,
                "max": 0.420639306306839,
                "min": -0.275177538394928,
                "frobenius_norm": 1.5678187608718872,
                "spectral_norm": 0.8419381976127625,
                "alpha": 1.2299555297022247,
                "alpha_hat": 1.135092481129441
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=16_scaler_type=minmax_seed=1819": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1819,
        "scores": {
            "smape": 0.11613741517066956,
            "mse": 1141445120.0,
            "mae": 2973.773193359375,
            "r2_score": 0.7534321546554565,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06635735183954239,
                "median": 0.09170152246952057,
                "std": 0.1781982034444809,
                "max": 0.398019403219223,
                "min": -0.31678661704063416,
                "frobenius_norm": 1.8631045818328857,
                "spectral_norm": 1.160811424255371,
                "alpha": 1.4308349825066071,
                "alpha_hat": 1.885524725379013
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03128175809979439,
                "median": 0.06518758833408356,
                "std": 0.22841311991214752,
                "max": 0.44140470027923584,
                "min": -0.4930466115474701,
                "frobenius_norm": 1.8443619012832642,
                "spectral_norm": 1.0856958627700806,
                "alpha": 1.2473279200638843,
                "alpha_hat": 1.7076302330408935
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.013773724436759949,
                "median": 0.006736087612807751,
                "std": 0.23321454226970673,
                "max": 0.6247504949569702,
                "min": -0.4737977385520935,
                "frobenius_norm": 1.8689675331115723,
                "spectral_norm": 1.1903058290481567,
                "alpha": 1.287075103179357,
                "alpha_hat": 2.1454345917713695
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.042398836463689804,
                "median": 0.03000696375966072,
                "std": 0.19133597612380981,
                "max": 0.420639306306839,
                "min": -0.275177538394928,
                "frobenius_norm": 1.5678187608718872,
                "spectral_norm": 0.8419381976127625,
                "alpha": 1.2299555297022247,
                "alpha_hat": 1.135092481129441
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=16_scaler_type=minmax_seed=2021": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 2021,
        "scores": {
            "smape": 0.11222411692142487,
            "mse": 1121032192.0,
            "mae": 2933.884521484375,
            "r2_score": 0.7578415870666504,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06635735183954239,
                "median": 0.09170152246952057,
                "std": 0.1781982034444809,
                "max": 0.398019403219223,
                "min": -0.31678661704063416,
                "frobenius_norm": 1.8631045818328857,
                "spectral_norm": 1.160811424255371,
                "alpha": 1.4308349825066071,
                "alpha_hat": 1.885524725379013
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03128175809979439,
                "median": 0.06518758833408356,
                "std": 0.22841311991214752,
                "max": 0.44140470027923584,
                "min": -0.4930466115474701,
                "frobenius_norm": 1.8443619012832642,
                "spectral_norm": 1.0856958627700806,
                "alpha": 1.2473279200638843,
                "alpha_hat": 1.7076302330408935
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.013773724436759949,
                "median": 0.006736087612807751,
                "std": 0.23321454226970673,
                "max": 0.6247504949569702,
                "min": -0.4737977385520935,
                "frobenius_norm": 1.8689675331115723,
                "spectral_norm": 1.1903058290481567,
                "alpha": 1.287075103179357,
                "alpha_hat": 2.1454345917713695
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.042398836463689804,
                "median": 0.03000696375966072,
                "std": 0.19133597612380981,
                "max": 0.420639306306839,
                "min": -0.275177538394928,
                "frobenius_norm": 1.5678187608718872,
                "spectral_norm": 0.8419381976127625,
                "alpha": 1.2299555297022247,
                "alpha_hat": 1.135092481129441
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=32_scaler_type=identity_seed=42": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 42,
        "scores": {
            "smape": 0.08368216454982758,
            "mse": 496542912.0,
            "mae": 1977.1943359375,
            "r2_score": 0.8927398920059204,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.08058429509401321,
                "median": 0.08295070379972458,
                "std": 0.15873543918132782,
                "max": 0.3748532831668854,
                "min": -0.25146254897117615,
                "frobenius_norm": 1.74422287940979,
                "spectral_norm": 0.9961593151092529,
                "alpha": 1.6059630205577502,
                "alpha_hat": 2.3010093535866867
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0624975822865963,
                "median": 0.09039907157421112,
                "std": 0.23366761207580566,
                "max": 0.46220654249191284,
                "min": -0.35984307527542114,
                "frobenius_norm": 1.935049295425415,
                "spectral_norm": 1.2569857835769653,
                "alpha": 1.2061096565471423,
                "alpha_hat": 2.044697551143634
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08519164472818375,
                "median": 0.037671759724617004,
                "std": 0.24562881886959076,
                "max": 0.6540534496307373,
                "min": -0.2964794337749481,
                "frobenius_norm": 2.0798635482788086,
                "spectral_norm": 1.4797914028167725,
                "alpha": 1.1718501879940286,
                "alpha_hat": 3.3606571111772046
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.10109158605337143,
                "median": 0.1118163913488388,
                "std": 0.19003920257091522,
                "max": 0.4790516495704651,
                "min": -0.2663710117340088,
                "frobenius_norm": 1.7220343351364136,
                "spectral_norm": 1.0622256994247437,
                "alpha": 1.2238370086411638,
                "alpha_hat": 1.5247183180816657
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=32_scaler_type=identity_seed=456": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 456,
        "scores": {
            "smape": 0.08547016233205795,
            "mse": 497337472.0,
            "mae": 2014.5040283203125,
            "r2_score": 0.8925682306289673,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.08058429509401321,
                "median": 0.08295070379972458,
                "std": 0.15873543918132782,
                "max": 0.3748532831668854,
                "min": -0.25146254897117615,
                "frobenius_norm": 1.74422287940979,
                "spectral_norm": 0.9961593151092529,
                "alpha": 1.6059630205577502,
                "alpha_hat": 2.3010093535866867
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0624975822865963,
                "median": 0.09039907157421112,
                "std": 0.23366761207580566,
                "max": 0.46220654249191284,
                "min": -0.35984307527542114,
                "frobenius_norm": 1.935049295425415,
                "spectral_norm": 1.2569857835769653,
                "alpha": 1.2061096565471423,
                "alpha_hat": 2.044697551143634
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08519164472818375,
                "median": 0.037671759724617004,
                "std": 0.24562881886959076,
                "max": 0.6540534496307373,
                "min": -0.2964794337749481,
                "frobenius_norm": 2.0798635482788086,
                "spectral_norm": 1.4797914028167725,
                "alpha": 1.1718501879940286,
                "alpha_hat": 3.3606571111772046
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.10109158605337143,
                "median": 0.1118163913488388,
                "std": 0.19003920257091522,
                "max": 0.4790516495704651,
                "min": -0.2663710117340088,
                "frobenius_norm": 1.7220343351364136,
                "spectral_norm": 1.0622256994247437,
                "alpha": 1.2238370086411638,
                "alpha_hat": 1.5247183180816657
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=32_scaler_type=identity_seed=123": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 123,
        "scores": {
            "smape": 0.08299360424280167,
            "mse": 499679008.0,
            "mae": 1977.89404296875,
            "r2_score": 0.8920624256134033,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.08058429509401321,
                "median": 0.08295070379972458,
                "std": 0.15873543918132782,
                "max": 0.3748532831668854,
                "min": -0.25146254897117615,
                "frobenius_norm": 1.74422287940979,
                "spectral_norm": 0.9961593151092529,
                "alpha": 1.6059630205577502,
                "alpha_hat": 2.3010093535866867
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0624975822865963,
                "median": 0.09039907157421112,
                "std": 0.23366761207580566,
                "max": 0.46220654249191284,
                "min": -0.35984307527542114,
                "frobenius_norm": 1.935049295425415,
                "spectral_norm": 1.2569857835769653,
                "alpha": 1.2061096565471423,
                "alpha_hat": 2.044697551143634
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08519164472818375,
                "median": 0.037671759724617004,
                "std": 0.24562881886959076,
                "max": 0.6540534496307373,
                "min": -0.2964794337749481,
                "frobenius_norm": 2.0798635482788086,
                "spectral_norm": 1.4797914028167725,
                "alpha": 1.1718501879940286,
                "alpha_hat": 3.3606571111772046
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.10109158605337143,
                "median": 0.1118163913488388,
                "std": 0.19003920257091522,
                "max": 0.4790516495704651,
                "min": -0.2663710117340088,
                "frobenius_norm": 1.7220343351364136,
                "spectral_norm": 1.0622256994247437,
                "alpha": 1.2238370086411638,
                "alpha_hat": 1.5247183180816657
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=32_scaler_type=identity_seed=789": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 789,
        "scores": {
            "smape": 0.08427764475345612,
            "mse": 485741984.0,
            "mae": 1983.32373046875,
            "r2_score": 0.8950730562210083,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.08058429509401321,
                "median": 0.08295070379972458,
                "std": 0.15873543918132782,
                "max": 0.3748532831668854,
                "min": -0.25146254897117615,
                "frobenius_norm": 1.74422287940979,
                "spectral_norm": 0.9961593151092529,
                "alpha": 1.6059630205577502,
                "alpha_hat": 2.3010093535866867
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0624975822865963,
                "median": 0.09039907157421112,
                "std": 0.23366761207580566,
                "max": 0.46220654249191284,
                "min": -0.35984307527542114,
                "frobenius_norm": 1.935049295425415,
                "spectral_norm": 1.2569857835769653,
                "alpha": 1.2061096565471423,
                "alpha_hat": 2.044697551143634
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08519164472818375,
                "median": 0.037671759724617004,
                "std": 0.24562881886959076,
                "max": 0.6540534496307373,
                "min": -0.2964794337749481,
                "frobenius_norm": 2.0798635482788086,
                "spectral_norm": 1.4797914028167725,
                "alpha": 1.1718501879940286,
                "alpha_hat": 3.3606571111772046
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.10109158605337143,
                "median": 0.1118163913488388,
                "std": 0.19003920257091522,
                "max": 0.4790516495704651,
                "min": -0.2663710117340088,
                "frobenius_norm": 1.7220343351364136,
                "spectral_norm": 1.0622256994247437,
                "alpha": 1.2238370086411638,
                "alpha_hat": 1.5247183180816657
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=32_scaler_type=identity_seed=1213": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1213,
        "scores": {
            "smape": 0.08328066766262054,
            "mse": 502300576.0,
            "mae": 1980.2432861328125,
            "r2_score": 0.8914961814880371,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.08069374412298203,
                "median": 0.08225281536579132,
                "std": 0.16060519218444824,
                "max": 0.3764488697052002,
                "min": -0.2970786690711975,
                "frobenius_norm": 1.761059045791626,
                "spectral_norm": 1.0175889730453491,
                "alpha": 1.5864010383764866,
                "alpha_hat": 2.284921763269516
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0674939900636673,
                "median": 0.07471829652786255,
                "std": 0.2305753380060196,
                "max": 0.46118560433387756,
                "min": -0.38664302229881287,
                "frobenius_norm": 1.9220060110092163,
                "spectral_norm": 1.2687914371490479,
                "alpha": 1.2118632219177963,
                "alpha_hat": 2.1686602933615
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08385802060365677,
                "median": 0.03306911885738373,
                "std": 0.2481776773929596,
                "max": 0.6670498251914978,
                "min": -0.30353227257728577,
                "frobenius_norm": 2.0956995487213135,
                "spectral_norm": 1.486318826675415,
                "alpha": 1.157906651065271,
                "alpha_hat": 3.523983649357585
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.10137072205543518,
                "median": 0.11383694410324097,
                "std": 0.1893828958272934,
                "max": 0.4763464331626892,
                "min": -0.2696748375892639,
                "frobenius_norm": 1.718453288078308,
                "spectral_norm": 1.0611002445220947,
                "alpha": 1.2232321016909857,
                "alpha_hat": 1.5254468151542426
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=32_scaler_type=identity_seed=1617": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1617,
        "scores": {
            "smape": 0.08351746201515198,
            "mse": 482003680.0,
            "mae": 1970.580810546875,
            "r2_score": 0.8958805799484253,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.08069374412298203,
                "median": 0.08225281536579132,
                "std": 0.16060519218444824,
                "max": 0.3764488697052002,
                "min": -0.2970786690711975,
                "frobenius_norm": 1.761059045791626,
                "spectral_norm": 1.0175889730453491,
                "alpha": 1.5864010383764866,
                "alpha_hat": 2.284921763269516
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0674939900636673,
                "median": 0.07471829652786255,
                "std": 0.2305753380060196,
                "max": 0.46118560433387756,
                "min": -0.38664302229881287,
                "frobenius_norm": 1.9220060110092163,
                "spectral_norm": 1.2687914371490479,
                "alpha": 1.2118632219177963,
                "alpha_hat": 2.1686602933615
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08385802060365677,
                "median": 0.03306911885738373,
                "std": 0.2481776773929596,
                "max": 0.6670498251914978,
                "min": -0.30353227257728577,
                "frobenius_norm": 2.0956995487213135,
                "spectral_norm": 1.486318826675415,
                "alpha": 1.157906651065271,
                "alpha_hat": 3.523983649357585
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.10137072205543518,
                "median": 0.11383694410324097,
                "std": 0.1893828958272934,
                "max": 0.4763464331626892,
                "min": -0.2696748375892639,
                "frobenius_norm": 1.718453288078308,
                "spectral_norm": 1.0611002445220947,
                "alpha": 1.2232321016909857,
                "alpha_hat": 1.5254468151542426
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=32_scaler_type=identity_seed=1415": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1415,
        "scores": {
            "smape": 0.08288214355707169,
            "mse": 484896672.0,
            "mae": 1976.5872802734375,
            "r2_score": 0.8952556252479553,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.08069374412298203,
                "median": 0.08225281536579132,
                "std": 0.16060519218444824,
                "max": 0.3764488697052002,
                "min": -0.2970786690711975,
                "frobenius_norm": 1.761059045791626,
                "spectral_norm": 1.0175889730453491,
                "alpha": 1.5864010383764866,
                "alpha_hat": 2.284921763269516
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0674939900636673,
                "median": 0.07471829652786255,
                "std": 0.2305753380060196,
                "max": 0.46118560433387756,
                "min": -0.38664302229881287,
                "frobenius_norm": 1.9220060110092163,
                "spectral_norm": 1.2687914371490479,
                "alpha": 1.2118632219177963,
                "alpha_hat": 2.1686602933615
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08385802060365677,
                "median": 0.03306911885738373,
                "std": 0.2481776773929596,
                "max": 0.6670498251914978,
                "min": -0.30353227257728577,
                "frobenius_norm": 2.0956995487213135,
                "spectral_norm": 1.486318826675415,
                "alpha": 1.157906651065271,
                "alpha_hat": 3.523983649357585
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.10137072205543518,
                "median": 0.11383694410324097,
                "std": 0.1893828958272934,
                "max": 0.4763464331626892,
                "min": -0.2696748375892639,
                "frobenius_norm": 1.718453288078308,
                "spectral_norm": 1.0611002445220947,
                "alpha": 1.2232321016909857,
                "alpha_hat": 1.5254468151542426
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=32_scaler_type=identity_seed=1011": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1011,
        "scores": {
            "smape": 0.08350258320569992,
            "mse": 478566656.0,
            "mae": 1968.9886474609375,
            "r2_score": 0.8966230154037476,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.08069374412298203,
                "median": 0.08225281536579132,
                "std": 0.16060519218444824,
                "max": 0.3764488697052002,
                "min": -0.2970786690711975,
                "frobenius_norm": 1.761059045791626,
                "spectral_norm": 1.0175889730453491,
                "alpha": 1.5864010383764866,
                "alpha_hat": 2.284921763269516
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0674939900636673,
                "median": 0.07471829652786255,
                "std": 0.2305753380060196,
                "max": 0.46118560433387756,
                "min": -0.38664302229881287,
                "frobenius_norm": 1.9220060110092163,
                "spectral_norm": 1.2687914371490479,
                "alpha": 1.2118632219177963,
                "alpha_hat": 2.1686602933615
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08385802060365677,
                "median": 0.03306911885738373,
                "std": 0.2481776773929596,
                "max": 0.6670498251914978,
                "min": -0.30353227257728577,
                "frobenius_norm": 2.0956995487213135,
                "spectral_norm": 1.486318826675415,
                "alpha": 1.157906651065271,
                "alpha_hat": 3.523983649357585
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.10137072205543518,
                "median": 0.11383694410324097,
                "std": 0.1893828958272934,
                "max": 0.4763464331626892,
                "min": -0.2696748375892639,
                "frobenius_norm": 1.718453288078308,
                "spectral_norm": 1.0611002445220947,
                "alpha": 1.2232321016909857,
                "alpha_hat": 1.5254468151542426
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=32_scaler_type=identity_seed=2021": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 2021,
        "scores": {
            "smape": 0.0859033539891243,
            "mse": 498097920.0,
            "mae": 2054.57861328125,
            "r2_score": 0.8924039602279663,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.051640164107084274,
                "median": 0.04574878513813019,
                "std": 0.20920711755752563,
                "max": 0.5869887471199036,
                "min": -0.4483833312988281,
                "frobenius_norm": 2.11132550239563,
                "spectral_norm": 1.2475395202636719,
                "alpha": 1.5828306461847106,
                "alpha_hat": 2.433674046419121
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05608006566762924,
                "median": 0.0892002284526825,
                "std": 0.24518252909183502,
                "max": 0.4859878718852997,
                "min": -0.6348837614059448,
                "frobenius_norm": 2.0121145248413086,
                "spectral_norm": 1.2552008628845215,
                "alpha": 1.1635344455551462,
                "alpha_hat": 1.7448936008275
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.027625005692243576,
                "median": 0.04767787829041481,
                "std": 0.24041315913200378,
                "max": 0.6567273139953613,
                "min": -0.3693758249282837,
                "frobenius_norm": 1.9359608888626099,
                "spectral_norm": 1.1668975353240967,
                "alpha": 1.2400525260364579,
                "alpha_hat": 2.0916957699714906
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08846817910671234,
                "median": 0.10399670153856277,
                "std": 0.2082240879535675,
                "max": 0.5621757507324219,
                "min": -0.3361286222934723,
                "frobenius_norm": 1.8099085092544556,
                "spectral_norm": 1.3787798881530762,
                "alpha": 1.1244679437543779,
                "alpha_hat": 3.251208440207159
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=32_scaler_type=identity_seed=1819": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1819,
        "scores": {
            "smape": 0.08084657788276672,
            "mse": 476446400.0,
            "mae": 2005.2210693359375,
            "r2_score": 0.8970810174942017,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.051640164107084274,
                "median": 0.04574878513813019,
                "std": 0.20920711755752563,
                "max": 0.5869887471199036,
                "min": -0.4483833312988281,
                "frobenius_norm": 2.11132550239563,
                "spectral_norm": 1.2475395202636719,
                "alpha": 1.5828306461847106,
                "alpha_hat": 2.433674046419121
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05608006566762924,
                "median": 0.0892002284526825,
                "std": 0.24518252909183502,
                "max": 0.4859878718852997,
                "min": -0.6348837614059448,
                "frobenius_norm": 2.0121145248413086,
                "spectral_norm": 1.2552008628845215,
                "alpha": 1.1635344455551462,
                "alpha_hat": 1.7448936008275
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.027625005692243576,
                "median": 0.04767787829041481,
                "std": 0.24041315913200378,
                "max": 0.6567273139953613,
                "min": -0.3693758249282837,
                "frobenius_norm": 1.9359608888626099,
                "spectral_norm": 1.1668975353240967,
                "alpha": 1.2400525260364579,
                "alpha_hat": 2.0916957699714906
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08846817910671234,
                "median": 0.10399670153856277,
                "std": 0.2082240879535675,
                "max": 0.5621757507324219,
                "min": -0.3361286222934723,
                "frobenius_norm": 1.8099085092544556,
                "spectral_norm": 1.3787798881530762,
                "alpha": 1.1244679437543779,
                "alpha_hat": 3.251208440207159
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=32_scaler_type=standard_seed=123": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 123,
        "scores": {
            "smape": 0.07671640813350677,
            "mse": 549611968.0,
            "mae": 2076.447509765625,
            "r2_score": 0.8812762498855591,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.051640164107084274,
                "median": 0.04574878513813019,
                "std": 0.20920711755752563,
                "max": 0.5869887471199036,
                "min": -0.4483833312988281,
                "frobenius_norm": 2.11132550239563,
                "spectral_norm": 1.2475395202636719,
                "alpha": 1.5828306461847106,
                "alpha_hat": 2.433674046419121
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05608006566762924,
                "median": 0.0892002284526825,
                "std": 0.24518252909183502,
                "max": 0.4859878718852997,
                "min": -0.6348837614059448,
                "frobenius_norm": 2.0121145248413086,
                "spectral_norm": 1.2552008628845215,
                "alpha": 1.1635344455551462,
                "alpha_hat": 1.7448936008275
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.027625005692243576,
                "median": 0.04767787829041481,
                "std": 0.24041315913200378,
                "max": 0.6567273139953613,
                "min": -0.3693758249282837,
                "frobenius_norm": 1.9359608888626099,
                "spectral_norm": 1.1668975353240967,
                "alpha": 1.2400525260364579,
                "alpha_hat": 2.0916957699714906
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08846817910671234,
                "median": 0.10399670153856277,
                "std": 0.2082240879535675,
                "max": 0.5621757507324219,
                "min": -0.3361286222934723,
                "frobenius_norm": 1.8099085092544556,
                "spectral_norm": 1.3787798881530762,
                "alpha": 1.1244679437543779,
                "alpha_hat": 3.251208440207159
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=32_scaler_type=standard_seed=42": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 42,
        "scores": {
            "smape": 0.07677515596151352,
            "mse": 469319872.0,
            "mae": 2078.32958984375,
            "r2_score": 0.8986204266548157,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.051640164107084274,
                "median": 0.04574878513813019,
                "std": 0.20920711755752563,
                "max": 0.5869887471199036,
                "min": -0.4483833312988281,
                "frobenius_norm": 2.11132550239563,
                "spectral_norm": 1.2475395202636719,
                "alpha": 1.5828306461847106,
                "alpha_hat": 2.433674046419121
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05608006566762924,
                "median": 0.0892002284526825,
                "std": 0.24518252909183502,
                "max": 0.4859878718852997,
                "min": -0.6348837614059448,
                "frobenius_norm": 2.0121145248413086,
                "spectral_norm": 1.2552008628845215,
                "alpha": 1.1635344455551462,
                "alpha_hat": 1.7448936008275
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.027625005692243576,
                "median": 0.04767787829041481,
                "std": 0.24041315913200378,
                "max": 0.6567273139953613,
                "min": -0.3693758249282837,
                "frobenius_norm": 1.9359608888626099,
                "spectral_norm": 1.1668975353240967,
                "alpha": 1.2400525260364579,
                "alpha_hat": 2.0916957699714906
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08846817910671234,
                "median": 0.10399670153856277,
                "std": 0.2082240879535675,
                "max": 0.5621757507324219,
                "min": -0.3361286222934723,
                "frobenius_norm": 1.8099085092544556,
                "spectral_norm": 1.3787798881530762,
                "alpha": 1.1244679437543779,
                "alpha_hat": 3.251208440207159
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=32_scaler_type=standard_seed=456": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 456,
        "scores": {
            "smape": 0.07702462375164032,
            "mse": 488277152.0,
            "mae": 2043.02880859375,
            "r2_score": 0.894525408744812,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.028222477063536644,
                "median": 0.013630112633109093,
                "std": 0.2104627937078476,
                "max": 0.5799334049224854,
                "min": -0.39212092757225037,
                "frobenius_norm": 2.080563545227051,
                "spectral_norm": 1.305517554283142,
                "alpha": 1.3833485319311531,
                "alpha_hat": 2.180217443441062
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05466438829898834,
                "median": 0.05796210467815399,
                "std": 0.2324451357126236,
                "max": 0.6425473093986511,
                "min": -0.3909013569355011,
                "frobenius_norm": 1.910291075706482,
                "spectral_norm": 1.2607017755508423,
                "alpha": 1.183041482243939,
                "alpha_hat": 1.5689274820434578
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.012929167598485947,
                "median": -0.027138572186231613,
                "std": 0.22483313083648682,
                "max": 0.47656920552253723,
                "min": -0.36837929487228394,
                "frobenius_norm": 1.8016366958618164,
                "spectral_norm": 1.0776952505111694,
                "alpha": 1.208815454141505,
                "alpha_hat": 1.9357211479339953
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.015393219888210297,
                "median": -0.010323946364223957,
                "std": 0.211541086435318,
                "max": 0.4151466190814972,
                "min": -0.5326151847839355,
                "frobenius_norm": 1.696803331375122,
                "spectral_norm": 1.0526044368743896,
                "alpha": 1.2363899250844264,
                "alpha_hat": 1.667896760541742
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=32_scaler_type=standard_seed=1011": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1011,
        "scores": {
            "smape": 0.07660535722970963,
            "mse": 550113216.0,
            "mae": 2078.2158203125,
            "r2_score": 0.8811679482460022,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.028222477063536644,
                "median": 0.013630112633109093,
                "std": 0.2104627937078476,
                "max": 0.5799334049224854,
                "min": -0.39212092757225037,
                "frobenius_norm": 2.080563545227051,
                "spectral_norm": 1.305517554283142,
                "alpha": 1.3833485319311531,
                "alpha_hat": 2.180217443441062
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05466438829898834,
                "median": 0.05796210467815399,
                "std": 0.2324451357126236,
                "max": 0.6425473093986511,
                "min": -0.3909013569355011,
                "frobenius_norm": 1.910291075706482,
                "spectral_norm": 1.2607017755508423,
                "alpha": 1.183041482243939,
                "alpha_hat": 1.5689274820434578
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.012929167598485947,
                "median": -0.027138572186231613,
                "std": 0.22483313083648682,
                "max": 0.47656920552253723,
                "min": -0.36837929487228394,
                "frobenius_norm": 1.8016366958618164,
                "spectral_norm": 1.0776952505111694,
                "alpha": 1.208815454141505,
                "alpha_hat": 1.9357211479339953
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.015393219888210297,
                "median": -0.010323946364223957,
                "std": 0.211541086435318,
                "max": 0.4151466190814972,
                "min": -0.5326151847839355,
                "frobenius_norm": 1.696803331375122,
                "spectral_norm": 1.0526044368743896,
                "alpha": 1.2363899250844264,
                "alpha_hat": 1.667896760541742
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=32_scaler_type=standard_seed=1213": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1213,
        "scores": {
            "smape": 0.07665719836950302,
            "mse": 548250496.0,
            "mae": 2073.459716796875,
            "r2_score": 0.8815703392028809,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.028222477063536644,
                "median": 0.013630112633109093,
                "std": 0.2104627937078476,
                "max": 0.5799334049224854,
                "min": -0.39212092757225037,
                "frobenius_norm": 2.080563545227051,
                "spectral_norm": 1.305517554283142,
                "alpha": 1.3833485319311531,
                "alpha_hat": 2.180217443441062
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05466438829898834,
                "median": 0.05796210467815399,
                "std": 0.2324451357126236,
                "max": 0.6425473093986511,
                "min": -0.3909013569355011,
                "frobenius_norm": 1.910291075706482,
                "spectral_norm": 1.2607017755508423,
                "alpha": 1.183041482243939,
                "alpha_hat": 1.5689274820434578
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.012929167598485947,
                "median": -0.027138572186231613,
                "std": 0.22483313083648682,
                "max": 0.47656920552253723,
                "min": -0.36837929487228394,
                "frobenius_norm": 1.8016366958618164,
                "spectral_norm": 1.0776952505111694,
                "alpha": 1.208815454141505,
                "alpha_hat": 1.9357211479339953
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.015393219888210297,
                "median": -0.010323946364223957,
                "std": 0.211541086435318,
                "max": 0.4151466190814972,
                "min": -0.5326151847839355,
                "frobenius_norm": 1.696803331375122,
                "spectral_norm": 1.0526044368743896,
                "alpha": 1.2363899250844264,
                "alpha_hat": 1.667896760541742
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=32_scaler_type=standard_seed=789": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 789,
        "scores": {
            "smape": 0.07636211812496185,
            "mse": 496203392.0,
            "mae": 2055.58544921875,
            "r2_score": 0.8928132057189941,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.028222477063536644,
                "median": 0.013630112633109093,
                "std": 0.2104627937078476,
                "max": 0.5799334049224854,
                "min": -0.39212092757225037,
                "frobenius_norm": 2.080563545227051,
                "spectral_norm": 1.305517554283142,
                "alpha": 1.3833485319311531,
                "alpha_hat": 2.180217443441062
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05466438829898834,
                "median": 0.05796210467815399,
                "std": 0.2324451357126236,
                "max": 0.6425473093986511,
                "min": -0.3909013569355011,
                "frobenius_norm": 1.910291075706482,
                "spectral_norm": 1.2607017755508423,
                "alpha": 1.183041482243939,
                "alpha_hat": 1.5689274820434578
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.012929167598485947,
                "median": -0.027138572186231613,
                "std": 0.22483313083648682,
                "max": 0.47656920552253723,
                "min": -0.36837929487228394,
                "frobenius_norm": 1.8016366958618164,
                "spectral_norm": 1.0776952505111694,
                "alpha": 1.208815454141505,
                "alpha_hat": 1.9357211479339953
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.015393219888210297,
                "median": -0.010323946364223957,
                "std": 0.211541086435318,
                "max": 0.4151466190814972,
                "min": -0.5326151847839355,
                "frobenius_norm": 1.696803331375122,
                "spectral_norm": 1.0526044368743896,
                "alpha": 1.2363899250844264,
                "alpha_hat": 1.667896760541742
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=32_scaler_type=standard_seed=1819": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1819,
        "scores": {
            "smape": 0.07596972584724426,
            "mse": 500409696.0,
            "mae": 2060.760498046875,
            "r2_score": 0.8919045925140381,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.026028653606772423,
                "median": 0.034822363406419754,
                "std": 0.19805042445659637,
                "max": 0.41209444403648376,
                "min": -0.44383615255355835,
                "frobenius_norm": 1.9571765661239624,
                "spectral_norm": 1.136259913444519,
                "alpha": 1.5132707773500111,
                "alpha_hat": 1.9132455447839325
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01302745845168829,
                "median": 0.06575566530227661,
                "std": 0.2504451870918274,
                "max": 0.4766933023929596,
                "min": -0.5939041972160339,
                "frobenius_norm": 2.006270408630371,
                "spectral_norm": 1.2790818214416504,
                "alpha": 1.3997226209109146,
                "alpha_hat": 1.7834555957632474
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.017005322501063347,
                "median": 0.012747159227728844,
                "std": 0.25052204728126526,
                "max": 0.6610753536224365,
                "min": -0.4210575222969055,
                "frobenius_norm": 2.0087883472442627,
                "spectral_norm": 1.247098445892334,
                "alpha": 1.2615535424794069,
                "alpha_hat": 2.777038444413135
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05470452830195427,
                "median": 0.03125333413481712,
                "std": 0.1912120133638382,
                "max": 0.44684284925460815,
                "min": -0.23485167324543,
                "frobenius_norm": 1.5910674333572388,
                "spectral_norm": 0.8853909373283386,
                "alpha": 1.2248049625263335,
                "alpha_hat": 1.1549870872160417
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=32_scaler_type=standard_seed=1617": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1617,
        "scores": {
            "smape": 0.07671242952346802,
            "mse": 496474720.0,
            "mae": 2057.693115234375,
            "r2_score": 0.8927546143531799,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.026028653606772423,
                "median": 0.034822363406419754,
                "std": 0.19805042445659637,
                "max": 0.41209444403648376,
                "min": -0.44383615255355835,
                "frobenius_norm": 1.9571765661239624,
                "spectral_norm": 1.136259913444519,
                "alpha": 1.5132707773500111,
                "alpha_hat": 1.9132455447839325
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01302745845168829,
                "median": 0.06575566530227661,
                "std": 0.2504451870918274,
                "max": 0.4766933023929596,
                "min": -0.5939041972160339,
                "frobenius_norm": 2.006270408630371,
                "spectral_norm": 1.2790818214416504,
                "alpha": 1.3997226209109146,
                "alpha_hat": 1.7834555957632474
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.017005322501063347,
                "median": 0.012747159227728844,
                "std": 0.25052204728126526,
                "max": 0.6610753536224365,
                "min": -0.4210575222969055,
                "frobenius_norm": 2.0087883472442627,
                "spectral_norm": 1.247098445892334,
                "alpha": 1.2615535424794069,
                "alpha_hat": 2.777038444413135
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05470452830195427,
                "median": 0.03125333413481712,
                "std": 0.1912120133638382,
                "max": 0.44684284925460815,
                "min": -0.23485167324543,
                "frobenius_norm": 1.5910674333572388,
                "spectral_norm": 0.8853909373283386,
                "alpha": 1.2248049625263335,
                "alpha_hat": 1.1549870872160417
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=32_scaler_type=standard_seed=1415": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1415,
        "scores": {
            "smape": 0.07673948258161545,
            "mse": 555047808.0,
            "mae": 2081.09228515625,
            "r2_score": 0.8801020383834839,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.026028653606772423,
                "median": 0.034822363406419754,
                "std": 0.19805042445659637,
                "max": 0.41209444403648376,
                "min": -0.44383615255355835,
                "frobenius_norm": 1.9571765661239624,
                "spectral_norm": 1.136259913444519,
                "alpha": 1.5132707773500111,
                "alpha_hat": 1.9132455447839325
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01302745845168829,
                "median": 0.06575566530227661,
                "std": 0.2504451870918274,
                "max": 0.4766933023929596,
                "min": -0.5939041972160339,
                "frobenius_norm": 2.006270408630371,
                "spectral_norm": 1.2790818214416504,
                "alpha": 1.3997226209109146,
                "alpha_hat": 1.7834555957632474
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.017005322501063347,
                "median": 0.012747159227728844,
                "std": 0.25052204728126526,
                "max": 0.6610753536224365,
                "min": -0.4210575222969055,
                "frobenius_norm": 2.0087883472442627,
                "spectral_norm": 1.247098445892334,
                "alpha": 1.2615535424794069,
                "alpha_hat": 2.777038444413135
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05470452830195427,
                "median": 0.03125333413481712,
                "std": 0.1912120133638382,
                "max": 0.44684284925460815,
                "min": -0.23485167324543,
                "frobenius_norm": 1.5910674333572388,
                "spectral_norm": 0.8853909373283386,
                "alpha": 1.2248049625263335,
                "alpha_hat": 1.1549870872160417
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=32_scaler_type=standard_seed=2021": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 2021,
        "scores": {
            "smape": 0.07663387805223465,
            "mse": 545433984.0,
            "mae": 2069.720458984375,
            "r2_score": 0.8821787238121033,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.026028653606772423,
                "median": 0.034822363406419754,
                "std": 0.19805042445659637,
                "max": 0.41209444403648376,
                "min": -0.44383615255355835,
                "frobenius_norm": 1.9571765661239624,
                "spectral_norm": 1.136259913444519,
                "alpha": 1.5132707773500111,
                "alpha_hat": 1.9132455447839325
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01302745845168829,
                "median": 0.06575566530227661,
                "std": 0.2504451870918274,
                "max": 0.4766933023929596,
                "min": -0.5939041972160339,
                "frobenius_norm": 2.006270408630371,
                "spectral_norm": 1.2790818214416504,
                "alpha": 1.3997226209109146,
                "alpha_hat": 1.7834555957632474
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.017005322501063347,
                "median": 0.012747159227728844,
                "std": 0.25052204728126526,
                "max": 0.6610753536224365,
                "min": -0.4210575222969055,
                "frobenius_norm": 2.0087883472442627,
                "spectral_norm": 1.247098445892334,
                "alpha": 1.2615535424794069,
                "alpha_hat": 2.777038444413135
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05470452830195427,
                "median": 0.03125333413481712,
                "std": 0.1912120133638382,
                "max": 0.44684284925460815,
                "min": -0.23485167324543,
                "frobenius_norm": 1.5910674333572388,
                "spectral_norm": 0.8853909373283386,
                "alpha": 1.2248049625263335,
                "alpha_hat": 1.1549870872160417
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=32_scaler_type=robust_seed=456": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 456,
        "scores": {
            "smape": 0.07619768381118774,
            "mse": 618378816.0,
            "mae": 2124.2900390625,
            "r2_score": 0.866421639919281,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.045065153390169144,
                "median": 0.04823363572359085,
                "std": 0.19800429046154022,
                "max": 0.47195887565612793,
                "min": -0.4348716735839844,
                "frobenius_norm": 1.9896507263183594,
                "spectral_norm": 1.266340970993042,
                "alpha": 1.533565653679318,
                "alpha_hat": 2.0295500681132173
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06505851447582245,
                "median": 0.11015191674232483,
                "std": 0.2362881600856781,
                "max": 0.47797852754592896,
                "min": -0.5764629244804382,
                "frobenius_norm": 1.9606481790542603,
                "spectral_norm": 1.3279820680618286,
                "alpha": 1.1498757181150643,
                "alpha_hat": 1.705119476071586
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.013783765956759453,
                "median": -0.01976199448108673,
                "std": 0.2591315507888794,
                "max": 0.7036893963813782,
                "min": -0.45902854204177856,
                "frobenius_norm": 2.0759830474853516,
                "spectral_norm": 1.2952960729599,
                "alpha": 1.1702742032505409,
                "alpha_hat": 2.599195136957207
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0586114376783371,
                "median": 0.03506295755505562,
                "std": 0.19120579957962036,
                "max": 0.4638887941837311,
                "min": -0.23408886790275574,
                "frobenius_norm": 1.5998990535736084,
                "spectral_norm": 0.8978148698806763,
                "alpha": 1.2273164618966799,
                "alpha_hat": 1.1950015191863852
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=32_scaler_type=robust_seed=123": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 123,
        "scores": {
            "smape": 0.07620134949684143,
            "mse": 621580032.0,
            "mae": 2121.18994140625,
            "r2_score": 0.8657301664352417,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.045065153390169144,
                "median": 0.04823363572359085,
                "std": 0.19800429046154022,
                "max": 0.47195887565612793,
                "min": -0.4348716735839844,
                "frobenius_norm": 1.9896507263183594,
                "spectral_norm": 1.266340970993042,
                "alpha": 1.533565653679318,
                "alpha_hat": 2.0295500681132173
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06505851447582245,
                "median": 0.11015191674232483,
                "std": 0.2362881600856781,
                "max": 0.47797852754592896,
                "min": -0.5764629244804382,
                "frobenius_norm": 1.9606481790542603,
                "spectral_norm": 1.3279820680618286,
                "alpha": 1.1498757181150643,
                "alpha_hat": 1.705119476071586
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.013783765956759453,
                "median": -0.01976199448108673,
                "std": 0.2591315507888794,
                "max": 0.7036893963813782,
                "min": -0.45902854204177856,
                "frobenius_norm": 2.0759830474853516,
                "spectral_norm": 1.2952960729599,
                "alpha": 1.1702742032505409,
                "alpha_hat": 2.599195136957207
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0586114376783371,
                "median": 0.03506295755505562,
                "std": 0.19120579957962036,
                "max": 0.4638887941837311,
                "min": -0.23408886790275574,
                "frobenius_norm": 1.5998990535736084,
                "spectral_norm": 0.8978148698806763,
                "alpha": 1.2273164618966799,
                "alpha_hat": 1.1950015191863852
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=32_scaler_type=robust_seed=42": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 42,
        "scores": {
            "smape": 0.07626362890005112,
            "mse": 575398208.0,
            "mae": 2179.8896484375,
            "r2_score": 0.8757060766220093,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.045065153390169144,
                "median": 0.04823363572359085,
                "std": 0.19800429046154022,
                "max": 0.47195887565612793,
                "min": -0.4348716735839844,
                "frobenius_norm": 1.9896507263183594,
                "spectral_norm": 1.266340970993042,
                "alpha": 1.533565653679318,
                "alpha_hat": 2.0295500681132173
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06505851447582245,
                "median": 0.11015191674232483,
                "std": 0.2362881600856781,
                "max": 0.47797852754592896,
                "min": -0.5764629244804382,
                "frobenius_norm": 1.9606481790542603,
                "spectral_norm": 1.3279820680618286,
                "alpha": 1.1498757181150643,
                "alpha_hat": 1.705119476071586
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.013783765956759453,
                "median": -0.01976199448108673,
                "std": 0.2591315507888794,
                "max": 0.7036893963813782,
                "min": -0.45902854204177856,
                "frobenius_norm": 2.0759830474853516,
                "spectral_norm": 1.2952960729599,
                "alpha": 1.1702742032505409,
                "alpha_hat": 2.599195136957207
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0586114376783371,
                "median": 0.03506295755505562,
                "std": 0.19120579957962036,
                "max": 0.4638887941837311,
                "min": -0.23408886790275574,
                "frobenius_norm": 1.5998990535736084,
                "spectral_norm": 0.8978148698806763,
                "alpha": 1.2273164618966799,
                "alpha_hat": 1.1950015191863852
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=32_scaler_type=robust_seed=789": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 789,
        "scores": {
            "smape": 0.07612988352775574,
            "mse": 609250880.0,
            "mae": 2117.220947265625,
            "r2_score": 0.8683934211730957,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.045065153390169144,
                "median": 0.04823363572359085,
                "std": 0.19800429046154022,
                "max": 0.47195887565612793,
                "min": -0.4348716735839844,
                "frobenius_norm": 1.9896507263183594,
                "spectral_norm": 1.266340970993042,
                "alpha": 1.533565653679318,
                "alpha_hat": 2.0295500681132173
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06505851447582245,
                "median": 0.11015191674232483,
                "std": 0.2362881600856781,
                "max": 0.47797852754592896,
                "min": -0.5764629244804382,
                "frobenius_norm": 1.9606481790542603,
                "spectral_norm": 1.3279820680618286,
                "alpha": 1.1498757181150643,
                "alpha_hat": 1.705119476071586
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.013783765956759453,
                "median": -0.01976199448108673,
                "std": 0.2591315507888794,
                "max": 0.7036893963813782,
                "min": -0.45902854204177856,
                "frobenius_norm": 2.0759830474853516,
                "spectral_norm": 1.2952960729599,
                "alpha": 1.1702742032505409,
                "alpha_hat": 2.599195136957207
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0586114376783371,
                "median": 0.03506295755505562,
                "std": 0.19120579957962036,
                "max": 0.4638887941837311,
                "min": -0.23408886790275574,
                "frobenius_norm": 1.5998990535736084,
                "spectral_norm": 0.8978148698806763,
                "alpha": 1.2273164618966799,
                "alpha_hat": 1.1950015191863852
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=32_scaler_type=robust_seed=1213": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1213,
        "scores": {
            "smape": 0.07621036469936371,
            "mse": 605558592.0,
            "mae": 2113.5712890625,
            "r2_score": 0.8691909909248352,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.040615495294332504,
                "median": 0.045464590191841125,
                "std": 0.1968449503183365,
                "max": 0.46510013937950134,
                "min": -0.44733598828315735,
                "frobenius_norm": 1.9693057537078857,
                "spectral_norm": 1.25135338306427,
                "alpha": 1.4105336388850847,
                "alpha_hat": 1.8336487675847595
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0620047003030777,
                "median": 0.10200555622577667,
                "std": 0.24716435372829437,
                "max": 0.5734043121337891,
                "min": -0.5535804629325867,
                "frobenius_norm": 2.0385844707489014,
                "spectral_norm": 1.3907886743545532,
                "alpha": 1.2299381303708299,
                "alpha_hat": 1.843536298082079
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.00887448713183403,
                "median": -0.024436693638563156,
                "std": 0.2566823661327362,
                "max": 0.7148194909095764,
                "min": -0.4837397634983063,
                "frobenius_norm": 2.0546860694885254,
                "spectral_norm": 1.2740696668624878,
                "alpha": 1.0962457825416232,
                "alpha_hat": 2.3700166688691158
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05504481494426727,
                "median": 0.04489603638648987,
                "std": 0.19120511412620544,
                "max": 0.47477978467941284,
                "min": -0.2779828608036041,
                "frobenius_norm": 1.591765284538269,
                "spectral_norm": 0.9118473529815674,
                "alpha": 1.2347090848570512,
                "alpha_hat": 1.225824548539989
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=32_scaler_type=robust_seed=1011": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1011,
        "scores": {
            "smape": 0.07606538385152817,
            "mse": 619687296.0,
            "mae": 2122.456298828125,
            "r2_score": 0.8661389946937561,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.040615495294332504,
                "median": 0.045464590191841125,
                "std": 0.1968449503183365,
                "max": 0.46510013937950134,
                "min": -0.44733598828315735,
                "frobenius_norm": 1.9693057537078857,
                "spectral_norm": 1.25135338306427,
                "alpha": 1.4105336388850847,
                "alpha_hat": 1.8336487675847595
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0620047003030777,
                "median": 0.10200555622577667,
                "std": 0.24716435372829437,
                "max": 0.5734043121337891,
                "min": -0.5535804629325867,
                "frobenius_norm": 2.0385844707489014,
                "spectral_norm": 1.3907886743545532,
                "alpha": 1.2299381303708299,
                "alpha_hat": 1.843536298082079
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.00887448713183403,
                "median": -0.024436693638563156,
                "std": 0.2566823661327362,
                "max": 0.7148194909095764,
                "min": -0.4837397634983063,
                "frobenius_norm": 2.0546860694885254,
                "spectral_norm": 1.2740696668624878,
                "alpha": 1.0962457825416232,
                "alpha_hat": 2.3700166688691158
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05504481494426727,
                "median": 0.04489603638648987,
                "std": 0.19120511412620544,
                "max": 0.47477978467941284,
                "min": -0.2779828608036041,
                "frobenius_norm": 1.591765284538269,
                "spectral_norm": 0.9118473529815674,
                "alpha": 1.2347090848570512,
                "alpha_hat": 1.225824548539989
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=32_scaler_type=robust_seed=1415": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1415,
        "scores": {
            "smape": 0.0765102282166481,
            "mse": 540620032.0,
            "mae": 2168.736328125,
            "r2_score": 0.8832186460494995,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.040615495294332504,
                "median": 0.045464590191841125,
                "std": 0.1968449503183365,
                "max": 0.46510013937950134,
                "min": -0.44733598828315735,
                "frobenius_norm": 1.9693057537078857,
                "spectral_norm": 1.25135338306427,
                "alpha": 1.4105336388850847,
                "alpha_hat": 1.8336487675847595
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0620047003030777,
                "median": 0.10200555622577667,
                "std": 0.24716435372829437,
                "max": 0.5734043121337891,
                "min": -0.5535804629325867,
                "frobenius_norm": 2.0385844707489014,
                "spectral_norm": 1.3907886743545532,
                "alpha": 1.2299381303708299,
                "alpha_hat": 1.843536298082079
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.00887448713183403,
                "median": -0.024436693638563156,
                "std": 0.2566823661327362,
                "max": 0.7148194909095764,
                "min": -0.4837397634983063,
                "frobenius_norm": 2.0546860694885254,
                "spectral_norm": 1.2740696668624878,
                "alpha": 1.0962457825416232,
                "alpha_hat": 2.3700166688691158
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05504481494426727,
                "median": 0.04489603638648987,
                "std": 0.19120511412620544,
                "max": 0.47477978467941284,
                "min": -0.2779828608036041,
                "frobenius_norm": 1.591765284538269,
                "spectral_norm": 0.9118473529815674,
                "alpha": 1.2347090848570512,
                "alpha_hat": 1.225824548539989
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=32_scaler_type=robust_seed=1617": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1617,
        "scores": {
            "smape": 0.07607550173997879,
            "mse": 609889600.0,
            "mae": 2124.560546875,
            "r2_score": 0.8682554364204407,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.040615495294332504,
                "median": 0.045464590191841125,
                "std": 0.1968449503183365,
                "max": 0.46510013937950134,
                "min": -0.44733598828315735,
                "frobenius_norm": 1.9693057537078857,
                "spectral_norm": 1.25135338306427,
                "alpha": 1.4105336388850847,
                "alpha_hat": 1.8336487675847595
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0620047003030777,
                "median": 0.10200555622577667,
                "std": 0.24716435372829437,
                "max": 0.5734043121337891,
                "min": -0.5535804629325867,
                "frobenius_norm": 2.0385844707489014,
                "spectral_norm": 1.3907886743545532,
                "alpha": 1.2299381303708299,
                "alpha_hat": 1.843536298082079
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.00887448713183403,
                "median": -0.024436693638563156,
                "std": 0.2566823661327362,
                "max": 0.7148194909095764,
                "min": -0.4837397634983063,
                "frobenius_norm": 2.0546860694885254,
                "spectral_norm": 1.2740696668624878,
                "alpha": 1.0962457825416232,
                "alpha_hat": 2.3700166688691158
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05504481494426727,
                "median": 0.04489603638648987,
                "std": 0.19120511412620544,
                "max": 0.47477978467941284,
                "min": -0.2779828608036041,
                "frobenius_norm": 1.591765284538269,
                "spectral_norm": 0.9118473529815674,
                "alpha": 1.2347090848570512,
                "alpha_hat": 1.225824548539989
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=32_scaler_type=robust_seed=1819": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1819,
        "scores": {
            "smape": 0.0762445479631424,
            "mse": 606451392.0,
            "mae": 2106.610595703125,
            "r2_score": 0.8689981698989868,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06825266033411026,
                "median": 0.06943369656801224,
                "std": 0.1807076781988144,
                "max": 0.43924328684806824,
                "min": -0.2835659086704254,
                "frobenius_norm": 1.8926475048065186,
                "spectral_norm": 1.200018286705017,
                "alpha": 1.5208093501194946,
                "alpha_hat": 2.0477343156585035
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03994927927851677,
                "median": 0.06561928987503052,
                "std": 0.2232058048248291,
                "max": 0.3839174211025238,
                "min": -0.5615758299827576,
                "frobenius_norm": 1.8140214681625366,
                "spectral_norm": 1.0737797021865845,
                "alpha": 1.3166965102621822,
                "alpha_hat": 2.2719773919283206
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022913746535778046,
                "median": -0.01867806166410446,
                "std": 0.23626261949539185,
                "max": 0.5694423317909241,
                "min": -0.3519560396671295,
                "frobenius_norm": 1.898969292640686,
                "spectral_norm": 1.1613469123840332,
                "alpha": 1.1916540771856416,
                "alpha_hat": 2.197788108381589
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05639414116740227,
                "median": 0.05845503509044647,
                "std": 0.19457915425300598,
                "max": 0.48725101351737976,
                "min": -0.2464187741279602,
                "frobenius_norm": 1.6206930875778198,
                "spectral_norm": 0.9192954301834106,
                "alpha": 1.263723714413675,
                "alpha_hat": 1.2019007991403903
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=32_scaler_type=minmax_seed=42": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 42,
        "scores": {
            "smape": 0.09168713539838791,
            "mse": 492700128.0,
            "mae": 2311.263671875,
            "r2_score": 0.8935700058937073,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06825266033411026,
                "median": 0.06943369656801224,
                "std": 0.1807076781988144,
                "max": 0.43924328684806824,
                "min": -0.2835659086704254,
                "frobenius_norm": 1.8926475048065186,
                "spectral_norm": 1.200018286705017,
                "alpha": 1.5208093501194946,
                "alpha_hat": 2.0477343156585035
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03994927927851677,
                "median": 0.06561928987503052,
                "std": 0.2232058048248291,
                "max": 0.3839174211025238,
                "min": -0.5615758299827576,
                "frobenius_norm": 1.8140214681625366,
                "spectral_norm": 1.0737797021865845,
                "alpha": 1.3166965102621822,
                "alpha_hat": 2.2719773919283206
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022913746535778046,
                "median": -0.01867806166410446,
                "std": 0.23626261949539185,
                "max": 0.5694423317909241,
                "min": -0.3519560396671295,
                "frobenius_norm": 1.898969292640686,
                "spectral_norm": 1.1613469123840332,
                "alpha": 1.1916540771856416,
                "alpha_hat": 2.197788108381589
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05639414116740227,
                "median": 0.05845503509044647,
                "std": 0.19457915425300598,
                "max": 0.48725101351737976,
                "min": -0.2464187741279602,
                "frobenius_norm": 1.6206930875778198,
                "spectral_norm": 0.9192954301834106,
                "alpha": 1.263723714413675,
                "alpha_hat": 1.2019007991403903
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=32_scaler_type=minmax_seed=123": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 123,
        "scores": {
            "smape": 0.10067937523126602,
            "mse": 1026971776.0,
            "mae": 2793.433837890625,
            "r2_score": 0.7781599760055542,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06825266033411026,
                "median": 0.06943369656801224,
                "std": 0.1807076781988144,
                "max": 0.43924328684806824,
                "min": -0.2835659086704254,
                "frobenius_norm": 1.8926475048065186,
                "spectral_norm": 1.200018286705017,
                "alpha": 1.5208093501194946,
                "alpha_hat": 2.0477343156585035
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03994927927851677,
                "median": 0.06561928987503052,
                "std": 0.2232058048248291,
                "max": 0.3839174211025238,
                "min": -0.5615758299827576,
                "frobenius_norm": 1.8140214681625366,
                "spectral_norm": 1.0737797021865845,
                "alpha": 1.3166965102621822,
                "alpha_hat": 2.2719773919283206
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022913746535778046,
                "median": -0.01867806166410446,
                "std": 0.23626261949539185,
                "max": 0.5694423317909241,
                "min": -0.3519560396671295,
                "frobenius_norm": 1.898969292640686,
                "spectral_norm": 1.1613469123840332,
                "alpha": 1.1916540771856416,
                "alpha_hat": 2.197788108381589
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05639414116740227,
                "median": 0.05845503509044647,
                "std": 0.19457915425300598,
                "max": 0.48725101351737976,
                "min": -0.2464187741279602,
                "frobenius_norm": 1.6206930875778198,
                "spectral_norm": 0.9192954301834106,
                "alpha": 1.263723714413675,
                "alpha_hat": 1.2019007991403903
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=32_scaler_type=robust_seed=2021": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 2021,
        "scores": {
            "smape": 0.07536070793867111,
            "mse": 470064608.0,
            "mae": 2029.1839599609375,
            "r2_score": 0.8984595537185669,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06825266033411026,
                "median": 0.06943369656801224,
                "std": 0.1807076781988144,
                "max": 0.43924328684806824,
                "min": -0.2835659086704254,
                "frobenius_norm": 1.8926475048065186,
                "spectral_norm": 1.200018286705017,
                "alpha": 1.5208093501194946,
                "alpha_hat": 2.0477343156585035
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03994927927851677,
                "median": 0.06561928987503052,
                "std": 0.2232058048248291,
                "max": 0.3839174211025238,
                "min": -0.5615758299827576,
                "frobenius_norm": 1.8140214681625366,
                "spectral_norm": 1.0737797021865845,
                "alpha": 1.3166965102621822,
                "alpha_hat": 2.2719773919283206
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022913746535778046,
                "median": -0.01867806166410446,
                "std": 0.23626261949539185,
                "max": 0.5694423317909241,
                "min": -0.3519560396671295,
                "frobenius_norm": 1.898969292640686,
                "spectral_norm": 1.1613469123840332,
                "alpha": 1.1916540771856416,
                "alpha_hat": 2.197788108381589
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05639414116740227,
                "median": 0.05845503509044647,
                "std": 0.19457915425300598,
                "max": 0.48725101351737976,
                "min": -0.2464187741279602,
                "frobenius_norm": 1.6206930875778198,
                "spectral_norm": 0.9192954301834106,
                "alpha": 1.263723714413675,
                "alpha_hat": 1.2019007991403903
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=32_scaler_type=minmax_seed=1213": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1213,
        "scores": {
            "smape": 0.10937044024467468,
            "mse": 1083481344.0,
            "mae": 2884.694580078125,
            "r2_score": 0.7659531235694885,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.067202627658844,
                "median": 0.0710543841123581,
                "std": 0.17721986770629883,
                "max": 0.4074251651763916,
                "min": -0.28371933102607727,
                "frobenius_norm": 1.8570446968078613,
                "spectral_norm": 1.162327766418457,
                "alpha": 1.411322302453519,
                "alpha_hat": 1.8834440391244007
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02372620441019535,
                "median": 0.06435975432395935,
                "std": 0.23581700026988983,
                "max": 0.4106244146823883,
                "min": -0.5629612803459167,
                "frobenius_norm": 1.896060585975647,
                "spectral_norm": 1.1851727962493896,
                "alpha": 1.3077746742722252,
                "alpha_hat": 1.8645279609195433
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022986195981502533,
                "median": -0.017531633377075195,
                "std": 0.2335992455482483,
                "max": 0.5877452492713928,
                "min": -0.33494874835014343,
                "frobenius_norm": 1.8778196573257446,
                "spectral_norm": 1.1633412837982178,
                "alpha": 1.195190531447754,
                "alpha_hat": 2.2581917142000654
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05951646715402603,
                "median": 0.05848288536071777,
                "std": 0.19349510967731476,
                "max": 0.48732811212539673,
                "min": -0.23485167324543,
                "frobenius_norm": 1.6195321083068848,
                "spectral_norm": 0.9251019358634949,
                "alpha": 1.2604562641824217,
                "alpha_hat": 1.2255965362234973
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=32_scaler_type=minmax_seed=456": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 456,
        "scores": {
            "smape": 0.08156267553567886,
            "mse": 553056768.0,
            "mae": 2287.80517578125,
            "r2_score": 0.8805321455001831,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.067202627658844,
                "median": 0.0710543841123581,
                "std": 0.17721986770629883,
                "max": 0.4074251651763916,
                "min": -0.28371933102607727,
                "frobenius_norm": 1.8570446968078613,
                "spectral_norm": 1.162327766418457,
                "alpha": 1.411322302453519,
                "alpha_hat": 1.8834440391244007
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02372620441019535,
                "median": 0.06435975432395935,
                "std": 0.23581700026988983,
                "max": 0.4106244146823883,
                "min": -0.5629612803459167,
                "frobenius_norm": 1.896060585975647,
                "spectral_norm": 1.1851727962493896,
                "alpha": 1.3077746742722252,
                "alpha_hat": 1.8645279609195433
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022986195981502533,
                "median": -0.017531633377075195,
                "std": 0.2335992455482483,
                "max": 0.5877452492713928,
                "min": -0.33494874835014343,
                "frobenius_norm": 1.8778196573257446,
                "spectral_norm": 1.1633412837982178,
                "alpha": 1.195190531447754,
                "alpha_hat": 2.2581917142000654
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05951646715402603,
                "median": 0.05848288536071777,
                "std": 0.19349510967731476,
                "max": 0.48732811212539673,
                "min": -0.23485167324543,
                "frobenius_norm": 1.6195321083068848,
                "spectral_norm": 0.9251019358634949,
                "alpha": 1.2604562641824217,
                "alpha_hat": 1.2255965362234973
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=32_scaler_type=minmax_seed=789": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 789,
        "scores": {
            "smape": 0.10903821885585785,
            "mse": 1092737536.0,
            "mae": 2890.619140625,
            "r2_score": 0.7639536261558533,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.067202627658844,
                "median": 0.0710543841123581,
                "std": 0.17721986770629883,
                "max": 0.4074251651763916,
                "min": -0.28371933102607727,
                "frobenius_norm": 1.8570446968078613,
                "spectral_norm": 1.162327766418457,
                "alpha": 1.411322302453519,
                "alpha_hat": 1.8834440391244007
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02372620441019535,
                "median": 0.06435975432395935,
                "std": 0.23581700026988983,
                "max": 0.4106244146823883,
                "min": -0.5629612803459167,
                "frobenius_norm": 1.896060585975647,
                "spectral_norm": 1.1851727962493896,
                "alpha": 1.3077746742722252,
                "alpha_hat": 1.8645279609195433
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022986195981502533,
                "median": -0.017531633377075195,
                "std": 0.2335992455482483,
                "max": 0.5877452492713928,
                "min": -0.33494874835014343,
                "frobenius_norm": 1.8778196573257446,
                "spectral_norm": 1.1633412837982178,
                "alpha": 1.195190531447754,
                "alpha_hat": 2.2581917142000654
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05951646715402603,
                "median": 0.05848288536071777,
                "std": 0.19349510967731476,
                "max": 0.48732811212539673,
                "min": -0.23485167324543,
                "frobenius_norm": 1.6195321083068848,
                "spectral_norm": 0.9251019358634949,
                "alpha": 1.2604562641824217,
                "alpha_hat": 1.2255965362234973
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=32_scaler_type=minmax_seed=1011": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1011,
        "scores": {
            "smape": 0.09918835759162903,
            "mse": 996776192.0,
            "mae": 2735.25,
            "r2_score": 0.7846826314926147,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.067202627658844,
                "median": 0.0710543841123581,
                "std": 0.17721986770629883,
                "max": 0.4074251651763916,
                "min": -0.28371933102607727,
                "frobenius_norm": 1.8570446968078613,
                "spectral_norm": 1.162327766418457,
                "alpha": 1.411322302453519,
                "alpha_hat": 1.8834440391244007
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02372620441019535,
                "median": 0.06435975432395935,
                "std": 0.23581700026988983,
                "max": 0.4106244146823883,
                "min": -0.5629612803459167,
                "frobenius_norm": 1.896060585975647,
                "spectral_norm": 1.1851727962493896,
                "alpha": 1.3077746742722252,
                "alpha_hat": 1.8645279609195433
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022986195981502533,
                "median": -0.017531633377075195,
                "std": 0.2335992455482483,
                "max": 0.5877452492713928,
                "min": -0.33494874835014343,
                "frobenius_norm": 1.8778196573257446,
                "spectral_norm": 1.1633412837982178,
                "alpha": 1.195190531447754,
                "alpha_hat": 2.2581917142000654
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05951646715402603,
                "median": 0.05848288536071777,
                "std": 0.19349510967731476,
                "max": 0.48732811212539673,
                "min": -0.23485167324543,
                "frobenius_norm": 1.6195321083068848,
                "spectral_norm": 0.9251019358634949,
                "alpha": 1.2604562641824217,
                "alpha_hat": 1.2255965362234973
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=32_scaler_type=minmax_seed=1617": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1617,
        "scores": {
            "smape": 0.08633989095687866,
            "mse": 480299168.0,
            "mae": 2222.0380859375,
            "r2_score": 0.8962487578392029,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06796444207429886,
                "median": 0.09628359973430634,
                "std": 0.17955045402050018,
                "max": 0.4092329740524292,
                "min": -0.30845990777015686,
                "frobenius_norm": 1.8810430765151978,
                "spectral_norm": 1.185399055480957,
                "alpha": 1.4377121407724835,
                "alpha_hat": 1.940493407420597
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.036139387637376785,
                "median": 0.08311139792203903,
                "std": 0.23227232694625854,
                "max": 0.44540852308273315,
                "min": -0.5315147638320923,
                "frobenius_norm": 1.8805359601974487,
                "spectral_norm": 1.1193161010742188,
                "alpha": 1.2828085862156302,
                "alpha_hat": 1.8787997308927065
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.012560605071485043,
                "median": 0.0011859649093821645,
                "std": 0.23535345494747162,
                "max": 0.6268458366394043,
                "min": -0.47375431656837463,
                "frobenius_norm": 1.8855071067810059,
                "spectral_norm": 1.1935489177703857,
                "alpha": 1.3255968084766767,
                "alpha_hat": 2.260900495825455
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.045067198574543,
                "median": 0.03066936507821083,
                "std": 0.19169355928897858,
                "max": 0.43003547191619873,
                "min": -0.26817119121551514,
                "frobenius_norm": 1.5753597021102905,
                "spectral_norm": 0.8515059351921082,
                "alpha": 1.2387040862085488,
                "alpha_hat": 1.144028723440308
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=32_scaler_type=minmax_seed=2021": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 2021,
        "scores": {
            "smape": 0.10761497169733047,
            "mse": 1072004096.0,
            "mae": 2861.150390625,
            "r2_score": 0.7684323191642761,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06796444207429886,
                "median": 0.09628359973430634,
                "std": 0.17955045402050018,
                "max": 0.4092329740524292,
                "min": -0.30845990777015686,
                "frobenius_norm": 1.8810430765151978,
                "spectral_norm": 1.185399055480957,
                "alpha": 1.4377121407724835,
                "alpha_hat": 1.940493407420597
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.036139387637376785,
                "median": 0.08311139792203903,
                "std": 0.23227232694625854,
                "max": 0.44540852308273315,
                "min": -0.5315147638320923,
                "frobenius_norm": 1.8805359601974487,
                "spectral_norm": 1.1193161010742188,
                "alpha": 1.2828085862156302,
                "alpha_hat": 1.8787997308927065
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.012560605071485043,
                "median": 0.0011859649093821645,
                "std": 0.23535345494747162,
                "max": 0.6268458366394043,
                "min": -0.47375431656837463,
                "frobenius_norm": 1.8855071067810059,
                "spectral_norm": 1.1935489177703857,
                "alpha": 1.3255968084766767,
                "alpha_hat": 2.260900495825455
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.045067198574543,
                "median": 0.03066936507821083,
                "std": 0.19169355928897858,
                "max": 0.43003547191619873,
                "min": -0.26817119121551514,
                "frobenius_norm": 1.5753597021102905,
                "spectral_norm": 0.8515059351921082,
                "alpha": 1.2387040862085488,
                "alpha_hat": 1.144028723440308
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=32_scaler_type=minmax_seed=1415": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1415,
        "scores": {
            "smape": 0.09675159305334091,
            "mse": 580783936.0,
            "mae": 2412.572509765625,
            "r2_score": 0.8745426535606384,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06796444207429886,
                "median": 0.09628359973430634,
                "std": 0.17955045402050018,
                "max": 0.4092329740524292,
                "min": -0.30845990777015686,
                "frobenius_norm": 1.8810430765151978,
                "spectral_norm": 1.185399055480957,
                "alpha": 1.4377121407724835,
                "alpha_hat": 1.940493407420597
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.036139387637376785,
                "median": 0.08311139792203903,
                "std": 0.23227232694625854,
                "max": 0.44540852308273315,
                "min": -0.5315147638320923,
                "frobenius_norm": 1.8805359601974487,
                "spectral_norm": 1.1193161010742188,
                "alpha": 1.2828085862156302,
                "alpha_hat": 1.8787997308927065
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.012560605071485043,
                "median": 0.0011859649093821645,
                "std": 0.23535345494747162,
                "max": 0.6268458366394043,
                "min": -0.47375431656837463,
                "frobenius_norm": 1.8855071067810059,
                "spectral_norm": 1.1935489177703857,
                "alpha": 1.3255968084766767,
                "alpha_hat": 2.260900495825455
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.045067198574543,
                "median": 0.03066936507821083,
                "std": 0.19169355928897858,
                "max": 0.43003547191619873,
                "min": -0.26817119121551514,
                "frobenius_norm": 1.5753597021102905,
                "spectral_norm": 0.8515059351921082,
                "alpha": 1.2387040862085488,
                "alpha_hat": 1.144028723440308
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0005_batch_size=32_scaler_type=minmax_seed=1819": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1819,
        "scores": {
            "smape": 0.08456728607416153,
            "mse": 611280512.0,
            "mae": 2367.759033203125,
            "r2_score": 0.8679549694061279,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06796444207429886,
                "median": 0.09628359973430634,
                "std": 0.17955045402050018,
                "max": 0.4092329740524292,
                "min": -0.30845990777015686,
                "frobenius_norm": 1.8810430765151978,
                "spectral_norm": 1.185399055480957,
                "alpha": 1.4377121407724835,
                "alpha_hat": 1.940493407420597
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.036139387637376785,
                "median": 0.08311139792203903,
                "std": 0.23227232694625854,
                "max": 0.44540852308273315,
                "min": -0.5315147638320923,
                "frobenius_norm": 1.8805359601974487,
                "spectral_norm": 1.1193161010742188,
                "alpha": 1.2828085862156302,
                "alpha_hat": 1.8787997308927065
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.012560605071485043,
                "median": 0.0011859649093821645,
                "std": 0.23535345494747162,
                "max": 0.6268458366394043,
                "min": -0.47375431656837463,
                "frobenius_norm": 1.8855071067810059,
                "spectral_norm": 1.1935489177703857,
                "alpha": 1.3255968084766767,
                "alpha_hat": 2.260900495825455
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.045067198574543,
                "median": 0.03066936507821083,
                "std": 0.19169355928897858,
                "max": 0.43003547191619873,
                "min": -0.26817119121551514,
                "frobenius_norm": 1.5753597021102905,
                "spectral_norm": 0.8515059351921082,
                "alpha": 1.2387040862085488,
                "alpha_hat": 1.144028723440308
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=8_scaler_type=identity_seed=456": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 8,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 456,
        "scores": {
            "smape": 0.7941544055938721,
            "mse": 4316925440.0,
            "mae": 9857.6806640625,
            "r2_score": 0.06748461723327637,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.030041664838790894,
                "median": 0.027696717530488968,
                "std": 0.15849271416664124,
                "max": 0.32602718472480774,
                "min": -0.28157320618629456,
                "frobenius_norm": 1.5805550813674927,
                "spectral_norm": 0.8526355028152466,
                "alpha": 1.640467873430572,
                "alpha_hat": 2.0482684453180515
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.033772967755794525,
                "median": 0.06626567244529724,
                "std": 0.2183418869972229,
                "max": 0.39175134897232056,
                "min": -0.3267247974872589,
                "frobenius_norm": 1.7675074338912964,
                "spectral_norm": 1.0813074111938477,
                "alpha": 1.1381893339097289,
                "alpha_hat": 1.5713981419303586
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.025958316400647163,
                "median": -0.0001268177293241024,
                "std": 0.22263245284557343,
                "max": 0.39357075095176697,
                "min": -0.3051849603652954,
                "frobenius_norm": 1.7931253910064697,
                "spectral_norm": 1.1484105587005615,
                "alpha": 1.322368361543981,
                "alpha_hat": 2.3194173283574226
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04394890367984772,
                "median": 0.030813440680503845,
                "std": 0.1941385716199875,
                "max": 0.38763973116874695,
                "min": -0.2746939957141876,
                "frobenius_norm": 1.5924078226089478,
                "spectral_norm": 0.860450267791748,
                "alpha": 1.211859018043944,
                "alpha_hat": 1.1467620719864768
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=8_scaler_type=identity_seed=42": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 8,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 42,
        "scores": {
            "smape": 0.7973371148109436,
            "mse": 4323999744.0,
            "mae": 9878.439453125,
            "r2_score": 0.0659564733505249,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.030041664838790894,
                "median": 0.027696717530488968,
                "std": 0.15849271416664124,
                "max": 0.32602718472480774,
                "min": -0.28157320618629456,
                "frobenius_norm": 1.5805550813674927,
                "spectral_norm": 0.8526355028152466,
                "alpha": 1.640467873430572,
                "alpha_hat": 2.0482684453180515
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.033772967755794525,
                "median": 0.06626567244529724,
                "std": 0.2183418869972229,
                "max": 0.39175134897232056,
                "min": -0.3267247974872589,
                "frobenius_norm": 1.7675074338912964,
                "spectral_norm": 1.0813074111938477,
                "alpha": 1.1381893339097289,
                "alpha_hat": 1.5713981419303586
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.025958316400647163,
                "median": -0.0001268177293241024,
                "std": 0.22263245284557343,
                "max": 0.39357075095176697,
                "min": -0.3051849603652954,
                "frobenius_norm": 1.7931253910064697,
                "spectral_norm": 1.1484105587005615,
                "alpha": 1.322368361543981,
                "alpha_hat": 2.3194173283574226
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04394890367984772,
                "median": 0.030813440680503845,
                "std": 0.1941385716199875,
                "max": 0.38763973116874695,
                "min": -0.2746939957141876,
                "frobenius_norm": 1.5924078226089478,
                "spectral_norm": 0.860450267791748,
                "alpha": 1.211859018043944,
                "alpha_hat": 1.1467620719864768
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=8_scaler_type=identity_seed=789": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 8,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 789,
        "scores": {
            "smape": 0.7139922976493835,
            "mse": 3328409344.0,
            "mae": 9202.521484375,
            "r2_score": 0.2810177206993103,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.030041664838790894,
                "median": 0.027696717530488968,
                "std": 0.15849271416664124,
                "max": 0.32602718472480774,
                "min": -0.28157320618629456,
                "frobenius_norm": 1.5805550813674927,
                "spectral_norm": 0.8526355028152466,
                "alpha": 1.640467873430572,
                "alpha_hat": 2.0482684453180515
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.033772967755794525,
                "median": 0.06626567244529724,
                "std": 0.2183418869972229,
                "max": 0.39175134897232056,
                "min": -0.3267247974872589,
                "frobenius_norm": 1.7675074338912964,
                "spectral_norm": 1.0813074111938477,
                "alpha": 1.1381893339097289,
                "alpha_hat": 1.5713981419303586
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.025958316400647163,
                "median": -0.0001268177293241024,
                "std": 0.22263245284557343,
                "max": 0.39357075095176697,
                "min": -0.3051849603652954,
                "frobenius_norm": 1.7931253910064697,
                "spectral_norm": 1.1484105587005615,
                "alpha": 1.322368361543981,
                "alpha_hat": 2.3194173283574226
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04394890367984772,
                "median": 0.030813440680503845,
                "std": 0.1941385716199875,
                "max": 0.38763973116874695,
                "min": -0.2746939957141876,
                "frobenius_norm": 1.5924078226089478,
                "spectral_norm": 0.860450267791748,
                "alpha": 1.211859018043944,
                "alpha_hat": 1.1467620719864768
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=8_scaler_type=identity_seed=123": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 8,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 123,
        "scores": {
            "smape": 0.7817901372909546,
            "mse": 4269227008.0,
            "mae": 9753.57421875,
            "r2_score": 0.07778811454772949,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.030041664838790894,
                "median": 0.027696717530488968,
                "std": 0.15849271416664124,
                "max": 0.32602718472480774,
                "min": -0.28157320618629456,
                "frobenius_norm": 1.5805550813674927,
                "spectral_norm": 0.8526355028152466,
                "alpha": 1.640467873430572,
                "alpha_hat": 2.0482684453180515
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.033772967755794525,
                "median": 0.06626567244529724,
                "std": 0.2183418869972229,
                "max": 0.39175134897232056,
                "min": -0.3267247974872589,
                "frobenius_norm": 1.7675074338912964,
                "spectral_norm": 1.0813074111938477,
                "alpha": 1.1381893339097289,
                "alpha_hat": 1.5713981419303586
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.025958316400647163,
                "median": -0.0001268177293241024,
                "std": 0.22263245284557343,
                "max": 0.39357075095176697,
                "min": -0.3051849603652954,
                "frobenius_norm": 1.7931253910064697,
                "spectral_norm": 1.1484105587005615,
                "alpha": 1.322368361543981,
                "alpha_hat": 2.3194173283574226
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04394890367984772,
                "median": 0.030813440680503845,
                "std": 0.1941385716199875,
                "max": 0.38763973116874695,
                "min": -0.2746939957141876,
                "frobenius_norm": 1.5924078226089478,
                "spectral_norm": 0.860450267791748,
                "alpha": 1.211859018043944,
                "alpha_hat": 1.1467620719864768
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=8_scaler_type=identity_seed=1213": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 8,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1213,
        "scores": {
            "smape": 0.7906997799873352,
            "mse": 4302379520.0,
            "mae": 9829.001953125,
            "r2_score": 0.07062673568725586,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.028707658872008324,
                "median": 0.02729984000325203,
                "std": 0.15837092697620392,
                "max": 0.3243749141693115,
                "min": -0.28005099296569824,
                "frobenius_norm": 1.5769990682601929,
                "spectral_norm": 0.8526510000228882,
                "alpha": 1.6297570481769803,
                "alpha_hat": 2.0256071839107808
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.033267632126808167,
                "median": 0.06157998740673065,
                "std": 0.21687988936901093,
                "max": 0.38094231486320496,
                "min": -0.32728904485702515,
                "frobenius_norm": 1.7553324699401855,
                "spectral_norm": 1.0623706579208374,
                "alpha": 1.1116303160610623,
                "alpha_hat": 1.5110642860816696
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.025901447981595993,
                "median": -0.0006340779364109039,
                "std": 0.22247709333896637,
                "max": 0.3915603458881378,
                "min": -0.30633968114852905,
                "frobenius_norm": 1.79183828830719,
                "spectral_norm": 1.145491361618042,
                "alpha": 1.3175588497832735,
                "alpha_hat": 2.3096162945592495
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.042953651398420334,
                "median": 0.03193104267120361,
                "std": 0.1943299025297165,
                "max": 0.3859649896621704,
                "min": -0.2739432752132416,
                "frobenius_norm": 1.592163324356079,
                "spectral_norm": 0.8600443005561829,
                "alpha": 1.2035575006091623,
                "alpha_hat": 1.135123974495765
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=8_scaler_type=identity_seed=1415": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 8,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1415,
        "scores": {
            "smape": 0.8017981648445129,
            "mse": 4342585856.0,
            "mae": 9915.0927734375,
            "r2_score": 0.06194162368774414,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.028707658872008324,
                "median": 0.02729984000325203,
                "std": 0.15837092697620392,
                "max": 0.3243749141693115,
                "min": -0.28005099296569824,
                "frobenius_norm": 1.5769990682601929,
                "spectral_norm": 0.8526510000228882,
                "alpha": 1.6297570481769803,
                "alpha_hat": 2.0256071839107808
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.033267632126808167,
                "median": 0.06157998740673065,
                "std": 0.21687988936901093,
                "max": 0.38094231486320496,
                "min": -0.32728904485702515,
                "frobenius_norm": 1.7553324699401855,
                "spectral_norm": 1.0623706579208374,
                "alpha": 1.1116303160610623,
                "alpha_hat": 1.5110642860816696
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.025901447981595993,
                "median": -0.0006340779364109039,
                "std": 0.22247709333896637,
                "max": 0.3915603458881378,
                "min": -0.30633968114852905,
                "frobenius_norm": 1.79183828830719,
                "spectral_norm": 1.145491361618042,
                "alpha": 1.3175588497832735,
                "alpha_hat": 2.3096162945592495
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.042953651398420334,
                "median": 0.03193104267120361,
                "std": 0.1943299025297165,
                "max": 0.3859649896621704,
                "min": -0.2739432752132416,
                "frobenius_norm": 1.592163324356079,
                "spectral_norm": 0.8600443005561829,
                "alpha": 1.2035575006091623,
                "alpha_hat": 1.135123974495765
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=8_scaler_type=identity_seed=1011": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 8,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1011,
        "scores": {
            "smape": 0.803443193435669,
            "mse": 4342499840.0,
            "mae": 9924.21875,
            "r2_score": 0.06196016073226929,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.028707658872008324,
                "median": 0.02729984000325203,
                "std": 0.15837092697620392,
                "max": 0.3243749141693115,
                "min": -0.28005099296569824,
                "frobenius_norm": 1.5769990682601929,
                "spectral_norm": 0.8526510000228882,
                "alpha": 1.6297570481769803,
                "alpha_hat": 2.0256071839107808
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.033267632126808167,
                "median": 0.06157998740673065,
                "std": 0.21687988936901093,
                "max": 0.38094231486320496,
                "min": -0.32728904485702515,
                "frobenius_norm": 1.7553324699401855,
                "spectral_norm": 1.0623706579208374,
                "alpha": 1.1116303160610623,
                "alpha_hat": 1.5110642860816696
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.025901447981595993,
                "median": -0.0006340779364109039,
                "std": 0.22247709333896637,
                "max": 0.3915603458881378,
                "min": -0.30633968114852905,
                "frobenius_norm": 1.79183828830719,
                "spectral_norm": 1.145491361618042,
                "alpha": 1.3175588497832735,
                "alpha_hat": 2.3096162945592495
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.042953651398420334,
                "median": 0.03193104267120361,
                "std": 0.1943299025297165,
                "max": 0.3859649896621704,
                "min": -0.2739432752132416,
                "frobenius_norm": 1.592163324356079,
                "spectral_norm": 0.8600443005561829,
                "alpha": 1.2035575006091623,
                "alpha_hat": 1.135123974495765
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=8_scaler_type=identity_seed=1617": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 8,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1617,
        "scores": {
            "smape": 0.7978628277778625,
            "mse": 4323453952.0,
            "mae": 9881.2822265625,
            "r2_score": 0.06607437133789062,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.028707658872008324,
                "median": 0.02729984000325203,
                "std": 0.15837092697620392,
                "max": 0.3243749141693115,
                "min": -0.28005099296569824,
                "frobenius_norm": 1.5769990682601929,
                "spectral_norm": 0.8526510000228882,
                "alpha": 1.6297570481769803,
                "alpha_hat": 2.0256071839107808
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.033267632126808167,
                "median": 0.06157998740673065,
                "std": 0.21687988936901093,
                "max": 0.38094231486320496,
                "min": -0.32728904485702515,
                "frobenius_norm": 1.7553324699401855,
                "spectral_norm": 1.0623706579208374,
                "alpha": 1.1116303160610623,
                "alpha_hat": 1.5110642860816696
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.025901447981595993,
                "median": -0.0006340779364109039,
                "std": 0.22247709333896637,
                "max": 0.3915603458881378,
                "min": -0.30633968114852905,
                "frobenius_norm": 1.79183828830719,
                "spectral_norm": 1.145491361618042,
                "alpha": 1.3175588497832735,
                "alpha_hat": 2.3096162945592495
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.042953651398420334,
                "median": 0.03193104267120361,
                "std": 0.1943299025297165,
                "max": 0.3859649896621704,
                "min": -0.2739432752132416,
                "frobenius_norm": 1.592163324356079,
                "spectral_norm": 0.8600443005561829,
                "alpha": 1.2035575006091623,
                "alpha_hat": 1.135123974495765
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=8_scaler_type=identity_seed=2021": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 8,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 2021,
        "scores": {
            "smape": 0.7827768921852112,
            "mse": 4269608960.0,
            "mae": 9761.5107421875,
            "r2_score": 0.07770562171936035,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.008756519295275211,
                "median": 0.03110843524336815,
                "std": 0.15455010533332825,
                "max": 0.29198917746543884,
                "min": -0.2802007496356964,
                "frobenius_norm": 1.5167042016983032,
                "spectral_norm": 0.825058102607727,
                "alpha": 1.5055283285599774,
                "alpha_hat": 1.753752357676382
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01120297983288765,
                "median": 0.05428503453731537,
                "std": 0.21056364476680756,
                "max": 0.3522377908229828,
                "min": -0.368116557598114,
                "frobenius_norm": 1.6868916749954224,
                "spectral_norm": 0.9717497229576111,
                "alpha": 1.1363572610404713,
                "alpha_hat": 1.4217741268498814
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01213025487959385,
                "median": -0.00910583883523941,
                "std": 0.22266142070293427,
                "max": 0.39765819907188416,
                "min": -0.3129567801952362,
                "frobenius_norm": 1.7839326858520508,
                "spectral_norm": 1.1550503969192505,
                "alpha": 1.284690658524832,
                "alpha_hat": 2.103488815032064
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01811530441045761,
                "median": 0.010058239102363586,
                "std": 0.19259555637836456,
                "max": 0.35289597511291504,
                "min": -0.2991441488265991,
                "frobenius_norm": 1.54756498336792,
                "spectral_norm": 0.8004738688468933,
                "alpha": 1.1718362328415213,
                "alpha_hat": 1.050642113325349
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=8_scaler_type=identity_seed=1819": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 8,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1819,
        "scores": {
            "smape": 0.8115137815475464,
            "mse": 4370964480.0,
            "mae": 9984.2041015625,
            "r2_score": 0.05581146478652954,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.008756519295275211,
                "median": 0.03110843524336815,
                "std": 0.15455010533332825,
                "max": 0.29198917746543884,
                "min": -0.2802007496356964,
                "frobenius_norm": 1.5167042016983032,
                "spectral_norm": 0.825058102607727,
                "alpha": 1.5055283285599774,
                "alpha_hat": 1.753752357676382
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01120297983288765,
                "median": 0.05428503453731537,
                "std": 0.21056364476680756,
                "max": 0.3522377908229828,
                "min": -0.368116557598114,
                "frobenius_norm": 1.6868916749954224,
                "spectral_norm": 0.9717497229576111,
                "alpha": 1.1363572610404713,
                "alpha_hat": 1.4217741268498814
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01213025487959385,
                "median": -0.00910583883523941,
                "std": 0.22266142070293427,
                "max": 0.39765819907188416,
                "min": -0.3129567801952362,
                "frobenius_norm": 1.7839326858520508,
                "spectral_norm": 1.1550503969192505,
                "alpha": 1.284690658524832,
                "alpha_hat": 2.103488815032064
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01811530441045761,
                "median": 0.010058239102363586,
                "std": 0.19259555637836456,
                "max": 0.35289597511291504,
                "min": -0.2991441488265991,
                "frobenius_norm": 1.54756498336792,
                "spectral_norm": 0.8004738688468933,
                "alpha": 1.1718362328415213,
                "alpha_hat": 1.050642113325349
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=8_scaler_type=standard_seed=42": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 8,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 42,
        "scores": {
            "smape": 0.08033710718154907,
            "mse": 593860160.0,
            "mae": 2154.385009765625,
            "r2_score": 0.8717180490493774,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.008756519295275211,
                "median": 0.03110843524336815,
                "std": 0.15455010533332825,
                "max": 0.29198917746543884,
                "min": -0.2802007496356964,
                "frobenius_norm": 1.5167042016983032,
                "spectral_norm": 0.825058102607727,
                "alpha": 1.5055283285599774,
                "alpha_hat": 1.753752357676382
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01120297983288765,
                "median": 0.05428503453731537,
                "std": 0.21056364476680756,
                "max": 0.3522377908229828,
                "min": -0.368116557598114,
                "frobenius_norm": 1.6868916749954224,
                "spectral_norm": 0.9717497229576111,
                "alpha": 1.1363572610404713,
                "alpha_hat": 1.4217741268498814
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01213025487959385,
                "median": -0.00910583883523941,
                "std": 0.22266142070293427,
                "max": 0.39765819907188416,
                "min": -0.3129567801952362,
                "frobenius_norm": 1.7839326858520508,
                "spectral_norm": 1.1550503969192505,
                "alpha": 1.284690658524832,
                "alpha_hat": 2.103488815032064
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01811530441045761,
                "median": 0.010058239102363586,
                "std": 0.19259555637836456,
                "max": 0.35289597511291504,
                "min": -0.2991441488265991,
                "frobenius_norm": 1.54756498336792,
                "spectral_norm": 0.8004738688468933,
                "alpha": 1.1718362328415213,
                "alpha_hat": 1.050642113325349
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=8_scaler_type=standard_seed=123": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 8,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 123,
        "scores": {
            "smape": 0.08034145832061768,
            "mse": 595176896.0,
            "mae": 2155.055419921875,
            "r2_score": 0.8714336156845093,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.008756519295275211,
                "median": 0.03110843524336815,
                "std": 0.15455010533332825,
                "max": 0.29198917746543884,
                "min": -0.2802007496356964,
                "frobenius_norm": 1.5167042016983032,
                "spectral_norm": 0.825058102607727,
                "alpha": 1.5055283285599774,
                "alpha_hat": 1.753752357676382
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01120297983288765,
                "median": 0.05428503453731537,
                "std": 0.21056364476680756,
                "max": 0.3522377908229828,
                "min": -0.368116557598114,
                "frobenius_norm": 1.6868916749954224,
                "spectral_norm": 0.9717497229576111,
                "alpha": 1.1363572610404713,
                "alpha_hat": 1.4217741268498814
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01213025487959385,
                "median": -0.00910583883523941,
                "std": 0.22266142070293427,
                "max": 0.39765819907188416,
                "min": -0.3129567801952362,
                "frobenius_norm": 1.7839326858520508,
                "spectral_norm": 1.1550503969192505,
                "alpha": 1.284690658524832,
                "alpha_hat": 2.103488815032064
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01811530441045761,
                "median": 0.010058239102363586,
                "std": 0.19259555637836456,
                "max": 0.35289597511291504,
                "min": -0.2991441488265991,
                "frobenius_norm": 1.54756498336792,
                "spectral_norm": 0.8004738688468933,
                "alpha": 1.1718362328415213,
                "alpha_hat": 1.050642113325349
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=8_scaler_type=standard_seed=456": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 8,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 456,
        "scores": {
            "smape": 0.08032376319169998,
            "mse": 595721024.0,
            "mae": 2155.38037109375,
            "r2_score": 0.8713160753250122,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.008281934075057507,
                "median": 0.031256888061761856,
                "std": 0.1549161970615387,
                "max": 0.2900630831718445,
                "min": -0.28186559677124023,
                "frobenius_norm": 1.52003014087677,
                "spectral_norm": 0.8269774913787842,
                "alpha": 1.506580584229678,
                "alpha_hat": 1.7473532539131629
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01124288234859705,
                "median": 0.050759539008140564,
                "std": 0.21119914948940277,
                "max": 0.35375750064849854,
                "min": -0.3692281246185303,
                "frobenius_norm": 1.6919854879379272,
                "spectral_norm": 0.9797505140304565,
                "alpha": 1.138954808903959,
                "alpha_hat": 1.436425717379778
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.012299351394176483,
                "median": -0.007885916158556938,
                "std": 0.2226315140724182,
                "max": 0.39910227060317993,
                "min": -0.30946218967437744,
                "frobenius_norm": 1.7837679386138916,
                "spectral_norm": 1.1558505296707153,
                "alpha": 1.2853064087617867,
                "alpha_hat": 2.115314225480379
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.020828675478696823,
                "median": 0.012139877304434776,
                "std": 0.19257794320583344,
                "max": 0.3600681722164154,
                "min": -0.2949824631214142,
                "frobenius_norm": 1.549608588218689,
                "spectral_norm": 0.8045085668563843,
                "alpha": 1.1836419160060623,
                "alpha_hat": 1.06561979583101
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=8_scaler_type=standard_seed=1011": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 8,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1011,
        "scores": {
            "smape": 0.08033420890569687,
            "mse": 594983296.0,
            "mae": 2154.957763671875,
            "r2_score": 0.8714753985404968,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.008281934075057507,
                "median": 0.031256888061761856,
                "std": 0.1549161970615387,
                "max": 0.2900630831718445,
                "min": -0.28186559677124023,
                "frobenius_norm": 1.52003014087677,
                "spectral_norm": 0.8269774913787842,
                "alpha": 1.506580584229678,
                "alpha_hat": 1.7473532539131629
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01124288234859705,
                "median": 0.050759539008140564,
                "std": 0.21119914948940277,
                "max": 0.35375750064849854,
                "min": -0.3692281246185303,
                "frobenius_norm": 1.6919854879379272,
                "spectral_norm": 0.9797505140304565,
                "alpha": 1.138954808903959,
                "alpha_hat": 1.436425717379778
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.012299351394176483,
                "median": -0.007885916158556938,
                "std": 0.2226315140724182,
                "max": 0.39910227060317993,
                "min": -0.30946218967437744,
                "frobenius_norm": 1.7837679386138916,
                "spectral_norm": 1.1558505296707153,
                "alpha": 1.2853064087617867,
                "alpha_hat": 2.115314225480379
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.020828675478696823,
                "median": 0.012139877304434776,
                "std": 0.19257794320583344,
                "max": 0.3600681722164154,
                "min": -0.2949824631214142,
                "frobenius_norm": 1.549608588218689,
                "spectral_norm": 0.8045085668563843,
                "alpha": 1.1836419160060623,
                "alpha_hat": 1.06561979583101
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=8_scaler_type=standard_seed=789": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 8,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 789,
        "scores": {
            "smape": 0.08035696297883987,
            "mse": 594488640.0,
            "mae": 2154.944091796875,
            "r2_score": 0.8715822696685791,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.008281934075057507,
                "median": 0.031256888061761856,
                "std": 0.1549161970615387,
                "max": 0.2900630831718445,
                "min": -0.28186559677124023,
                "frobenius_norm": 1.52003014087677,
                "spectral_norm": 0.8269774913787842,
                "alpha": 1.506580584229678,
                "alpha_hat": 1.7473532539131629
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01124288234859705,
                "median": 0.050759539008140564,
                "std": 0.21119914948940277,
                "max": 0.35375750064849854,
                "min": -0.3692281246185303,
                "frobenius_norm": 1.6919854879379272,
                "spectral_norm": 0.9797505140304565,
                "alpha": 1.138954808903959,
                "alpha_hat": 1.436425717379778
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.012299351394176483,
                "median": -0.007885916158556938,
                "std": 0.2226315140724182,
                "max": 0.39910227060317993,
                "min": -0.30946218967437744,
                "frobenius_norm": 1.7837679386138916,
                "spectral_norm": 1.1558505296707153,
                "alpha": 1.2853064087617867,
                "alpha_hat": 2.115314225480379
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.020828675478696823,
                "median": 0.012139877304434776,
                "std": 0.19257794320583344,
                "max": 0.3600681722164154,
                "min": -0.2949824631214142,
                "frobenius_norm": 1.549608588218689,
                "spectral_norm": 0.8045085668563843,
                "alpha": 1.1836419160060623,
                "alpha_hat": 1.06561979583101
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=8_scaler_type=standard_seed=1213": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 8,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1213,
        "scores": {
            "smape": 0.08029510825872421,
            "mse": 595648832.0,
            "mae": 2154.941162109375,
            "r2_score": 0.8713316321372986,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.008281934075057507,
                "median": 0.031256888061761856,
                "std": 0.1549161970615387,
                "max": 0.2900630831718445,
                "min": -0.28186559677124023,
                "frobenius_norm": 1.52003014087677,
                "spectral_norm": 0.8269774913787842,
                "alpha": 1.506580584229678,
                "alpha_hat": 1.7473532539131629
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01124288234859705,
                "median": 0.050759539008140564,
                "std": 0.21119914948940277,
                "max": 0.35375750064849854,
                "min": -0.3692281246185303,
                "frobenius_norm": 1.6919854879379272,
                "spectral_norm": 0.9797505140304565,
                "alpha": 1.138954808903959,
                "alpha_hat": 1.436425717379778
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.012299351394176483,
                "median": -0.007885916158556938,
                "std": 0.2226315140724182,
                "max": 0.39910227060317993,
                "min": -0.30946218967437744,
                "frobenius_norm": 1.7837679386138916,
                "spectral_norm": 1.1558505296707153,
                "alpha": 1.2853064087617867,
                "alpha_hat": 2.115314225480379
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.020828675478696823,
                "median": 0.012139877304434776,
                "std": 0.19257794320583344,
                "max": 0.3600681722164154,
                "min": -0.2949824631214142,
                "frobenius_norm": 1.549608588218689,
                "spectral_norm": 0.8045085668563843,
                "alpha": 1.1836419160060623,
                "alpha_hat": 1.06561979583101
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=8_scaler_type=standard_seed=1819": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 8,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1819,
        "scores": {
            "smape": 0.08035675436258316,
            "mse": 593866496.0,
            "mae": 2154.210205078125,
            "r2_score": 0.8717166781425476,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.009168514050543308,
                "median": 0.027027910575270653,
                "std": 0.15481843054294586,
                "max": 0.2961481213569641,
                "min": -0.27726614475250244,
                "frobenius_norm": 1.5195623636245728,
                "spectral_norm": 0.8270435333251953,
                "alpha": 1.5220730635336976,
                "alpha_hat": 1.7762439264882939
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.010084297508001328,
                "median": 0.0538889542222023,
                "std": 0.21016161143779755,
                "max": 0.3529112935066223,
                "min": -0.36658304929733276,
                "frobenius_norm": 1.683227300643921,
                "spectral_norm": 0.9756863117218018,
                "alpha": 1.1314608738332568,
                "alpha_hat": 1.4211157142964397
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.011399866081774235,
                "median": -0.009121287614107132,
                "std": 0.22239366173744202,
                "max": 0.3978516757488251,
                "min": -0.3103604316711426,
                "frobenius_norm": 1.7814853191375732,
                "spectral_norm": 1.155814528465271,
                "alpha": 1.2732625399573,
                "alpha_hat": 2.074515270312519
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.019520413130521774,
                "median": 0.011719327419996262,
                "std": 0.19239690899848938,
                "max": 0.35883715748786926,
                "min": -0.29717034101486206,
                "frobenius_norm": 1.5470770597457886,
                "spectral_norm": 0.8034583330154419,
                "alpha": 1.1762949627318506,
                "alpha_hat": 1.0560261881779245
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=8_scaler_type=standard_seed=1415": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 8,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1415,
        "scores": {
            "smape": 0.0802876204252243,
            "mse": 593491712.0,
            "mae": 2152.881591796875,
            "r2_score": 0.8717976212501526,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.009168514050543308,
                "median": 0.027027910575270653,
                "std": 0.15481843054294586,
                "max": 0.2961481213569641,
                "min": -0.27726614475250244,
                "frobenius_norm": 1.5195623636245728,
                "spectral_norm": 0.8270435333251953,
                "alpha": 1.5220730635336976,
                "alpha_hat": 1.7762439264882939
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.010084297508001328,
                "median": 0.0538889542222023,
                "std": 0.21016161143779755,
                "max": 0.3529112935066223,
                "min": -0.36658304929733276,
                "frobenius_norm": 1.683227300643921,
                "spectral_norm": 0.9756863117218018,
                "alpha": 1.1314608738332568,
                "alpha_hat": 1.4211157142964397
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.011399866081774235,
                "median": -0.009121287614107132,
                "std": 0.22239366173744202,
                "max": 0.3978516757488251,
                "min": -0.3103604316711426,
                "frobenius_norm": 1.7814853191375732,
                "spectral_norm": 1.155814528465271,
                "alpha": 1.2732625399573,
                "alpha_hat": 2.074515270312519
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.019520413130521774,
                "median": 0.011719327419996262,
                "std": 0.19239690899848938,
                "max": 0.35883715748786926,
                "min": -0.29717034101486206,
                "frobenius_norm": 1.5470770597457886,
                "spectral_norm": 0.8034583330154419,
                "alpha": 1.1762949627318506,
                "alpha_hat": 1.0560261881779245
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=8_scaler_type=standard_seed=1617": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 8,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1617,
        "scores": {
            "smape": 0.08032476156949997,
            "mse": 593845632.0,
            "mae": 2153.7470703125,
            "r2_score": 0.8717211484909058,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.009168514050543308,
                "median": 0.027027910575270653,
                "std": 0.15481843054294586,
                "max": 0.2961481213569641,
                "min": -0.27726614475250244,
                "frobenius_norm": 1.5195623636245728,
                "spectral_norm": 0.8270435333251953,
                "alpha": 1.5220730635336976,
                "alpha_hat": 1.7762439264882939
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.010084297508001328,
                "median": 0.0538889542222023,
                "std": 0.21016161143779755,
                "max": 0.3529112935066223,
                "min": -0.36658304929733276,
                "frobenius_norm": 1.683227300643921,
                "spectral_norm": 0.9756863117218018,
                "alpha": 1.1314608738332568,
                "alpha_hat": 1.4211157142964397
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.011399866081774235,
                "median": -0.009121287614107132,
                "std": 0.22239366173744202,
                "max": 0.3978516757488251,
                "min": -0.3103604316711426,
                "frobenius_norm": 1.7814853191375732,
                "spectral_norm": 1.155814528465271,
                "alpha": 1.2732625399573,
                "alpha_hat": 2.074515270312519
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.019520413130521774,
                "median": 0.011719327419996262,
                "std": 0.19239690899848938,
                "max": 0.35883715748786926,
                "min": -0.29717034101486206,
                "frobenius_norm": 1.5470770597457886,
                "spectral_norm": 0.8034583330154419,
                "alpha": 1.1762949627318506,
                "alpha_hat": 1.0560261881779245
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=8_scaler_type=standard_seed=2021": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 8,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 2021,
        "scores": {
            "smape": 0.08031462132930756,
            "mse": 594435456.0,
            "mae": 2154.024658203125,
            "r2_score": 0.871593713760376,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.009168514050543308,
                "median": 0.027027910575270653,
                "std": 0.15481843054294586,
                "max": 0.2961481213569641,
                "min": -0.27726614475250244,
                "frobenius_norm": 1.5195623636245728,
                "spectral_norm": 0.8270435333251953,
                "alpha": 1.5220730635336976,
                "alpha_hat": 1.7762439264882939
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.010084297508001328,
                "median": 0.0538889542222023,
                "std": 0.21016161143779755,
                "max": 0.3529112935066223,
                "min": -0.36658304929733276,
                "frobenius_norm": 1.683227300643921,
                "spectral_norm": 0.9756863117218018,
                "alpha": 1.1314608738332568,
                "alpha_hat": 1.4211157142964397
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.011399866081774235,
                "median": -0.009121287614107132,
                "std": 0.22239366173744202,
                "max": 0.3978516757488251,
                "min": -0.3103604316711426,
                "frobenius_norm": 1.7814853191375732,
                "spectral_norm": 1.155814528465271,
                "alpha": 1.2732625399573,
                "alpha_hat": 2.074515270312519
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.019520413130521774,
                "median": 0.011719327419996262,
                "std": 0.19239690899848938,
                "max": 0.35883715748786926,
                "min": -0.29717034101486206,
                "frobenius_norm": 1.5470770597457886,
                "spectral_norm": 0.8034583330154419,
                "alpha": 1.1762949627318506,
                "alpha_hat": 1.0560261881779245
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=8_scaler_type=robust_seed=456": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 8,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 456,
        "scores": {
            "smape": 0.08041663467884064,
            "mse": 620278400.0,
            "mae": 2145.51611328125,
            "r2_score": 0.8660113215446472,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.00933291669934988,
                "median": 0.033739008009433746,
                "std": 0.15484356880187988,
                "max": 0.2911989092826843,
                "min": -0.3030009865760803,
                "frobenius_norm": 1.519904375076294,
                "spectral_norm": 0.827295184135437,
                "alpha": 1.4976789058561466,
                "alpha_hat": 1.7915062087835145
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02045479789376259,
                "median": 0.06106153503060341,
                "std": 0.20608679950237274,
                "max": 0.3503129184246063,
                "min": -0.3448430597782135,
                "frobenius_norm": 1.6567951440811157,
                "spectral_norm": 0.9530689716339111,
                "alpha": 1.1645768354669563,
                "alpha_hat": 1.4060689364057064
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.011157837696373463,
                "median": -0.014257483184337616,
                "std": 0.22482970356941223,
                "max": 0.39948028326034546,
                "min": -0.3238251507282257,
                "frobenius_norm": 1.8008513450622559,
                "spectral_norm": 1.1598538160324097,
                "alpha": 1.27786858589712,
                "alpha_hat": 2.1214631952276344
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01893116533756256,
                "median": 0.01595807634294033,
                "std": 0.1923818588256836,
                "max": 0.3604929447174072,
                "min": -0.30083993077278137,
                "frobenius_norm": 1.546488642692566,
                "spectral_norm": 0.8029153347015381,
                "alpha": 1.1600627956089444,
                "alpha_hat": 1.024479427492602
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=8_scaler_type=robust_seed=42": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 8,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 42,
        "scores": {
            "smape": 0.08035556972026825,
            "mse": 621455488.0,
            "mae": 2145.063720703125,
            "r2_score": 0.8657570481300354,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.00933291669934988,
                "median": 0.033739008009433746,
                "std": 0.15484356880187988,
                "max": 0.2911989092826843,
                "min": -0.3030009865760803,
                "frobenius_norm": 1.519904375076294,
                "spectral_norm": 0.827295184135437,
                "alpha": 1.4976789058561466,
                "alpha_hat": 1.7915062087835145
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02045479789376259,
                "median": 0.06106153503060341,
                "std": 0.20608679950237274,
                "max": 0.3503129184246063,
                "min": -0.3448430597782135,
                "frobenius_norm": 1.6567951440811157,
                "spectral_norm": 0.9530689716339111,
                "alpha": 1.1645768354669563,
                "alpha_hat": 1.4060689364057064
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.011157837696373463,
                "median": -0.014257483184337616,
                "std": 0.22482970356941223,
                "max": 0.39948028326034546,
                "min": -0.3238251507282257,
                "frobenius_norm": 1.8008513450622559,
                "spectral_norm": 1.1598538160324097,
                "alpha": 1.27786858589712,
                "alpha_hat": 2.1214631952276344
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01893116533756256,
                "median": 0.01595807634294033,
                "std": 0.1923818588256836,
                "max": 0.3604929447174072,
                "min": -0.30083993077278137,
                "frobenius_norm": 1.546488642692566,
                "spectral_norm": 0.8029153347015381,
                "alpha": 1.1600627956089444,
                "alpha_hat": 1.024479427492602
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=8_scaler_type=robust_seed=123": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 8,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 123,
        "scores": {
            "smape": 0.08041111379861832,
            "mse": 620436672.0,
            "mae": 2145.552978515625,
            "r2_score": 0.8659771084785461,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.00933291669934988,
                "median": 0.033739008009433746,
                "std": 0.15484356880187988,
                "max": 0.2911989092826843,
                "min": -0.3030009865760803,
                "frobenius_norm": 1.519904375076294,
                "spectral_norm": 0.827295184135437,
                "alpha": 1.4976789058561466,
                "alpha_hat": 1.7915062087835145
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02045479789376259,
                "median": 0.06106153503060341,
                "std": 0.20608679950237274,
                "max": 0.3503129184246063,
                "min": -0.3448430597782135,
                "frobenius_norm": 1.6567951440811157,
                "spectral_norm": 0.9530689716339111,
                "alpha": 1.1645768354669563,
                "alpha_hat": 1.4060689364057064
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.011157837696373463,
                "median": -0.014257483184337616,
                "std": 0.22482970356941223,
                "max": 0.39948028326034546,
                "min": -0.3238251507282257,
                "frobenius_norm": 1.8008513450622559,
                "spectral_norm": 1.1598538160324097,
                "alpha": 1.27786858589712,
                "alpha_hat": 2.1214631952276344
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01893116533756256,
                "median": 0.01595807634294033,
                "std": 0.1923818588256836,
                "max": 0.3604929447174072,
                "min": -0.30083993077278137,
                "frobenius_norm": 1.546488642692566,
                "spectral_norm": 0.8029153347015381,
                "alpha": 1.1600627956089444,
                "alpha_hat": 1.024479427492602
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=8_scaler_type=robust_seed=789": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 8,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 789,
        "scores": {
            "smape": 0.08040565252304077,
            "mse": 621028096.0,
            "mae": 2145.67724609375,
            "r2_score": 0.8658493757247925,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.00933291669934988,
                "median": 0.033739008009433746,
                "std": 0.15484356880187988,
                "max": 0.2911989092826843,
                "min": -0.3030009865760803,
                "frobenius_norm": 1.519904375076294,
                "spectral_norm": 0.827295184135437,
                "alpha": 1.4976789058561466,
                "alpha_hat": 1.7915062087835145
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02045479789376259,
                "median": 0.06106153503060341,
                "std": 0.20608679950237274,
                "max": 0.3503129184246063,
                "min": -0.3448430597782135,
                "frobenius_norm": 1.6567951440811157,
                "spectral_norm": 0.9530689716339111,
                "alpha": 1.1645768354669563,
                "alpha_hat": 1.4060689364057064
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.011157837696373463,
                "median": -0.014257483184337616,
                "std": 0.22482970356941223,
                "max": 0.39948028326034546,
                "min": -0.3238251507282257,
                "frobenius_norm": 1.8008513450622559,
                "spectral_norm": 1.1598538160324097,
                "alpha": 1.27786858589712,
                "alpha_hat": 2.1214631952276344
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01893116533756256,
                "median": 0.01595807634294033,
                "std": 0.1923818588256836,
                "max": 0.3604929447174072,
                "min": -0.30083993077278137,
                "frobenius_norm": 1.546488642692566,
                "spectral_norm": 0.8029153347015381,
                "alpha": 1.1600627956089444,
                "alpha_hat": 1.024479427492602
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=8_scaler_type=robust_seed=1213": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 8,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1213,
        "scores": {
            "smape": 0.08041609078645706,
            "mse": 621492096.0,
            "mae": 2146.50439453125,
            "r2_score": 0.8657491207122803,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.009661554358899593,
                "median": 0.033594876527786255,
                "std": 0.15477868914604187,
                "max": 0.2906605899333954,
                "min": -0.3041226267814636,
                "frobenius_norm": 1.5194668769836426,
                "spectral_norm": 0.8265558481216431,
                "alpha": 1.502737924373674,
                "alpha_hat": 1.8112085989927822
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02052028477191925,
                "median": 0.06190641224384308,
                "std": 0.20629875361919403,
                "max": 0.34945255517959595,
                "min": -0.34727591276168823,
                "frobenius_norm": 1.6585345268249512,
                "spectral_norm": 0.9572962522506714,
                "alpha": 1.1663625089231178,
                "alpha_hat": 1.414126223069791
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01190517283976078,
                "median": -0.01187441498041153,
                "std": 0.2242276519536972,
                "max": 0.3999555706977844,
                "min": -0.3224644362926483,
                "frobenius_norm": 1.796347737312317,
                "spectral_norm": 1.1544432640075684,
                "alpha": 1.2816536403822225,
                "alpha_hat": 2.129275901745359
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.019238408654928207,
                "median": 0.016216972842812538,
                "std": 0.19214805960655212,
                "max": 0.3563576340675354,
                "min": -0.29976919293403625,
                "frobenius_norm": 1.5448700189590454,
                "spectral_norm": 0.8005905747413635,
                "alpha": 1.1589254573077599,
                "alpha_hat": 1.0221913524010826
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=8_scaler_type=robust_seed=1617": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 8,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1617,
        "scores": {
            "smape": 0.08040034025907516,
            "mse": 620778368.0,
            "mae": 2145.498046875,
            "r2_score": 0.8659033179283142,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.009661554358899593,
                "median": 0.033594876527786255,
                "std": 0.15477868914604187,
                "max": 0.2906605899333954,
                "min": -0.3041226267814636,
                "frobenius_norm": 1.5194668769836426,
                "spectral_norm": 0.8265558481216431,
                "alpha": 1.502737924373674,
                "alpha_hat": 1.8112085989927822
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02052028477191925,
                "median": 0.06190641224384308,
                "std": 0.20629875361919403,
                "max": 0.34945255517959595,
                "min": -0.34727591276168823,
                "frobenius_norm": 1.6585345268249512,
                "spectral_norm": 0.9572962522506714,
                "alpha": 1.1663625089231178,
                "alpha_hat": 1.414126223069791
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01190517283976078,
                "median": -0.01187441498041153,
                "std": 0.2242276519536972,
                "max": 0.3999555706977844,
                "min": -0.3224644362926483,
                "frobenius_norm": 1.796347737312317,
                "spectral_norm": 1.1544432640075684,
                "alpha": 1.2816536403822225,
                "alpha_hat": 2.129275901745359
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.019238408654928207,
                "median": 0.016216972842812538,
                "std": 0.19214805960655212,
                "max": 0.3563576340675354,
                "min": -0.29976919293403625,
                "frobenius_norm": 1.5448700189590454,
                "spectral_norm": 0.8005905747413635,
                "alpha": 1.1589254573077599,
                "alpha_hat": 1.0221913524010826
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=8_scaler_type=robust_seed=1415": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 8,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1415,
        "scores": {
            "smape": 0.08040699362754822,
            "mse": 621059264.0,
            "mae": 2145.85888671875,
            "r2_score": 0.8658426403999329,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.009661554358899593,
                "median": 0.033594876527786255,
                "std": 0.15477868914604187,
                "max": 0.2906605899333954,
                "min": -0.3041226267814636,
                "frobenius_norm": 1.5194668769836426,
                "spectral_norm": 0.8265558481216431,
                "alpha": 1.502737924373674,
                "alpha_hat": 1.8112085989927822
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02052028477191925,
                "median": 0.06190641224384308,
                "std": 0.20629875361919403,
                "max": 0.34945255517959595,
                "min": -0.34727591276168823,
                "frobenius_norm": 1.6585345268249512,
                "spectral_norm": 0.9572962522506714,
                "alpha": 1.1663625089231178,
                "alpha_hat": 1.414126223069791
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01190517283976078,
                "median": -0.01187441498041153,
                "std": 0.2242276519536972,
                "max": 0.3999555706977844,
                "min": -0.3224644362926483,
                "frobenius_norm": 1.796347737312317,
                "spectral_norm": 1.1544432640075684,
                "alpha": 1.2816536403822225,
                "alpha_hat": 2.129275901745359
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.019238408654928207,
                "median": 0.016216972842812538,
                "std": 0.19214805960655212,
                "max": 0.3563576340675354,
                "min": -0.29976919293403625,
                "frobenius_norm": 1.5448700189590454,
                "spectral_norm": 0.8005905747413635,
                "alpha": 1.1589254573077599,
                "alpha_hat": 1.0221913524010826
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=8_scaler_type=robust_seed=1011": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 8,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1011,
        "scores": {
            "smape": 0.08038683980703354,
            "mse": 621828352.0,
            "mae": 2145.87744140625,
            "r2_score": 0.8656765222549438,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.009661554358899593,
                "median": 0.033594876527786255,
                "std": 0.15477868914604187,
                "max": 0.2906605899333954,
                "min": -0.3041226267814636,
                "frobenius_norm": 1.5194668769836426,
                "spectral_norm": 0.8265558481216431,
                "alpha": 1.502737924373674,
                "alpha_hat": 1.8112085989927822
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02052028477191925,
                "median": 0.06190641224384308,
                "std": 0.20629875361919403,
                "max": 0.34945255517959595,
                "min": -0.34727591276168823,
                "frobenius_norm": 1.6585345268249512,
                "spectral_norm": 0.9572962522506714,
                "alpha": 1.1663625089231178,
                "alpha_hat": 1.414126223069791
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01190517283976078,
                "median": -0.01187441498041153,
                "std": 0.2242276519536972,
                "max": 0.3999555706977844,
                "min": -0.3224644362926483,
                "frobenius_norm": 1.796347737312317,
                "spectral_norm": 1.1544432640075684,
                "alpha": 1.2816536403822225,
                "alpha_hat": 2.129275901745359
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.019238408654928207,
                "median": 0.016216972842812538,
                "std": 0.19214805960655212,
                "max": 0.3563576340675354,
                "min": -0.29976919293403625,
                "frobenius_norm": 1.5448700189590454,
                "spectral_norm": 0.8005905747413635,
                "alpha": 1.1589254573077599,
                "alpha_hat": 1.0221913524010826
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=8_scaler_type=minmax_seed=42": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 8,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 42,
        "scores": {
            "smape": 0.1892414540052414,
            "mse": 1057617920.0,
            "mae": 3757.264892578125,
            "r2_score": 0.7715399265289307,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.0038993842899799347,
                "median": -0.0005016843788325787,
                "std": 0.15472416579723358,
                "max": 0.29925861954689026,
                "min": -0.28697270154953003,
                "frobenius_norm": 1.5164624452590942,
                "spectral_norm": 0.8351380825042725,
                "alpha": 1.4693951627412836,
                "alpha_hat": 1.688689648537402
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.010818155482411385,
                "median": 0.03992736339569092,
                "std": 0.20892830193042755,
                "max": 0.36938515305519104,
                "min": -0.32391980290412903,
                "frobenius_norm": 1.6736656427383423,
                "spectral_norm": 0.9554316401481628,
                "alpha": 1.1150174503824382,
                "alpha_hat": 1.4378385270589702
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02195313759148121,
                "median": 0.05856461077928543,
                "std": 0.20842301845550537,
                "max": 0.3482135832309723,
                "min": -0.33945873379707336,
                "frobenius_norm": 1.6766078472137451,
                "spectral_norm": 0.9381043910980225,
                "alpha": 1.156192844258848,
                "alpha_hat": 1.4151957274074163
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.016572773456573486,
                "median": -0.002280346816405654,
                "std": 0.19315481185913086,
                "max": 0.3707541227340698,
                "min": -0.32017892599105835,
                "frobenius_norm": 1.5509158372879028,
                "spectral_norm": 0.7776100039482117,
                "alpha": 1.1254900729029838,
                "alpha_hat": 1.0226706970376804
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=8_scaler_type=minmax_seed=123": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 8,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 123,
        "scores": {
            "smape": 0.18176119029521942,
            "mse": 1427342592.0,
            "mae": 3931.52587890625,
            "r2_score": 0.6916743516921997,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.0038993842899799347,
                "median": -0.0005016843788325787,
                "std": 0.15472416579723358,
                "max": 0.29925861954689026,
                "min": -0.28697270154953003,
                "frobenius_norm": 1.5164624452590942,
                "spectral_norm": 0.8351380825042725,
                "alpha": 1.4693951627412836,
                "alpha_hat": 1.688689648537402
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.010818155482411385,
                "median": 0.03992736339569092,
                "std": 0.20892830193042755,
                "max": 0.36938515305519104,
                "min": -0.32391980290412903,
                "frobenius_norm": 1.6736656427383423,
                "spectral_norm": 0.9554316401481628,
                "alpha": 1.1150174503824382,
                "alpha_hat": 1.4378385270589702
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02195313759148121,
                "median": 0.05856461077928543,
                "std": 0.20842301845550537,
                "max": 0.3482135832309723,
                "min": -0.33945873379707336,
                "frobenius_norm": 1.6766078472137451,
                "spectral_norm": 0.9381043910980225,
                "alpha": 1.156192844258848,
                "alpha_hat": 1.4151957274074163
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.016572773456573486,
                "median": -0.002280346816405654,
                "std": 0.19315481185913086,
                "max": 0.3707541227340698,
                "min": -0.32017892599105835,
                "frobenius_norm": 1.5509158372879028,
                "spectral_norm": 0.7776100039482117,
                "alpha": 1.1254900729029838,
                "alpha_hat": 1.0226706970376804
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=8_scaler_type=robust_seed=1819": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 8,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1819,
        "scores": {
            "smape": 0.08040755242109299,
            "mse": 620800320.0,
            "mae": 2145.582275390625,
            "r2_score": 0.865898609161377,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.0038993842899799347,
                "median": -0.0005016843788325787,
                "std": 0.15472416579723358,
                "max": 0.29925861954689026,
                "min": -0.28697270154953003,
                "frobenius_norm": 1.5164624452590942,
                "spectral_norm": 0.8351380825042725,
                "alpha": 1.4693951627412836,
                "alpha_hat": 1.688689648537402
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.010818155482411385,
                "median": 0.03992736339569092,
                "std": 0.20892830193042755,
                "max": 0.36938515305519104,
                "min": -0.32391980290412903,
                "frobenius_norm": 1.6736656427383423,
                "spectral_norm": 0.9554316401481628,
                "alpha": 1.1150174503824382,
                "alpha_hat": 1.4378385270589702
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02195313759148121,
                "median": 0.05856461077928543,
                "std": 0.20842301845550537,
                "max": 0.3482135832309723,
                "min": -0.33945873379707336,
                "frobenius_norm": 1.6766078472137451,
                "spectral_norm": 0.9381043910980225,
                "alpha": 1.156192844258848,
                "alpha_hat": 1.4151957274074163
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.016572773456573486,
                "median": -0.002280346816405654,
                "std": 0.19315481185913086,
                "max": 0.3707541227340698,
                "min": -0.32017892599105835,
                "frobenius_norm": 1.5509158372879028,
                "spectral_norm": 0.7776100039482117,
                "alpha": 1.1254900729029838,
                "alpha_hat": 1.0226706970376804
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=8_scaler_type=robust_seed=2021": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 8,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 2021,
        "scores": {
            "smape": 0.08108808845281601,
            "mse": 530921216.0,
            "mae": 2087.239990234375,
            "r2_score": 0.8853136897087097,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.0038993842899799347,
                "median": -0.0005016843788325787,
                "std": 0.15472416579723358,
                "max": 0.29925861954689026,
                "min": -0.28697270154953003,
                "frobenius_norm": 1.5164624452590942,
                "spectral_norm": 0.8351380825042725,
                "alpha": 1.4693951627412836,
                "alpha_hat": 1.688689648537402
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.010818155482411385,
                "median": 0.03992736339569092,
                "std": 0.20892830193042755,
                "max": 0.36938515305519104,
                "min": -0.32391980290412903,
                "frobenius_norm": 1.6736656427383423,
                "spectral_norm": 0.9554316401481628,
                "alpha": 1.1150174503824382,
                "alpha_hat": 1.4378385270589702
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02195313759148121,
                "median": 0.05856461077928543,
                "std": 0.20842301845550537,
                "max": 0.3482135832309723,
                "min": -0.33945873379707336,
                "frobenius_norm": 1.6766078472137451,
                "spectral_norm": 0.9381043910980225,
                "alpha": 1.156192844258848,
                "alpha_hat": 1.4151957274074163
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.016572773456573486,
                "median": -0.002280346816405654,
                "std": 0.19315481185913086,
                "max": 0.3707541227340698,
                "min": -0.32017892599105835,
                "frobenius_norm": 1.5509158372879028,
                "spectral_norm": 0.7776100039482117,
                "alpha": 1.1254900729029838,
                "alpha_hat": 1.0226706970376804
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=8_scaler_type=minmax_seed=456": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 8,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 456,
        "scores": {
            "smape": 0.1817004680633545,
            "mse": 1425370240.0,
            "mae": 3929.689697265625,
            "r2_score": 0.6921004056930542,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.023386267945170403,
                "median": 0.03199561685323715,
                "std": 0.1592511683702469,
                "max": 0.3063381612300873,
                "min": -0.2863127291202545,
                "frobenius_norm": 1.577071189880371,
                "spectral_norm": 0.8500323295593262,
                "alpha": 1.456848018491083,
                "alpha_hat": 1.496378568627759
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02667970210313797,
                "median": 0.06265242397785187,
                "std": 0.21395328640937805,
                "max": 0.37127456068992615,
                "min": -0.3257538676261902,
                "frobenius_norm": 1.7248826026916504,
                "spectral_norm": 0.970264196395874,
                "alpha": 1.1702954952892812,
                "alpha_hat": 1.6153872453760019
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.017298560589551926,
                "median": -0.005221138242632151,
                "std": 0.2253425568342209,
                "max": 0.41255003213882446,
                "min": -0.31198665499687195,
                "frobenius_norm": 1.8080443143844604,
                "spectral_norm": 1.145410180091858,
                "alpha": 1.290688039973174,
                "alpha_hat": 2.1753711775406552
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.020599864423274994,
                "median": 0.01174211222678423,
                "std": 0.19312359392642975,
                "max": 0.3694225251674652,
                "min": -0.29978829622268677,
                "frobenius_norm": 1.553753137588501,
                "spectral_norm": 0.8128655552864075,
                "alpha": 1.181020059354365,
                "alpha_hat": 1.0686333369445715
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=8_scaler_type=minmax_seed=1011": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 8,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1011,
        "scores": {
            "smape": 0.18209949135780334,
            "mse": 1430331648.0,
            "mae": 3937.427978515625,
            "r2_score": 0.6910286545753479,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.023386267945170403,
                "median": 0.03199561685323715,
                "std": 0.1592511683702469,
                "max": 0.3063381612300873,
                "min": -0.2863127291202545,
                "frobenius_norm": 1.577071189880371,
                "spectral_norm": 0.8500323295593262,
                "alpha": 1.456848018491083,
                "alpha_hat": 1.496378568627759
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02667970210313797,
                "median": 0.06265242397785187,
                "std": 0.21395328640937805,
                "max": 0.37127456068992615,
                "min": -0.3257538676261902,
                "frobenius_norm": 1.7248826026916504,
                "spectral_norm": 0.970264196395874,
                "alpha": 1.1702954952892812,
                "alpha_hat": 1.6153872453760019
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.017298560589551926,
                "median": -0.005221138242632151,
                "std": 0.2253425568342209,
                "max": 0.41255003213882446,
                "min": -0.31198665499687195,
                "frobenius_norm": 1.8080443143844604,
                "spectral_norm": 1.145410180091858,
                "alpha": 1.290688039973174,
                "alpha_hat": 2.1753711775406552
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.020599864423274994,
                "median": 0.01174211222678423,
                "std": 0.19312359392642975,
                "max": 0.3694225251674652,
                "min": -0.29978829622268677,
                "frobenius_norm": 1.553753137588501,
                "spectral_norm": 0.8128655552864075,
                "alpha": 1.181020059354365,
                "alpha_hat": 1.0686333369445715
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=8_scaler_type=minmax_seed=789": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 8,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 789,
        "scores": {
            "smape": 0.18116506934165955,
            "mse": 1420280448.0,
            "mae": 3919.885009765625,
            "r2_score": 0.693199872970581,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.023386267945170403,
                "median": 0.03199561685323715,
                "std": 0.1592511683702469,
                "max": 0.3063381612300873,
                "min": -0.2863127291202545,
                "frobenius_norm": 1.577071189880371,
                "spectral_norm": 0.8500323295593262,
                "alpha": 1.456848018491083,
                "alpha_hat": 1.496378568627759
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02667970210313797,
                "median": 0.06265242397785187,
                "std": 0.21395328640937805,
                "max": 0.37127456068992615,
                "min": -0.3257538676261902,
                "frobenius_norm": 1.7248826026916504,
                "spectral_norm": 0.970264196395874,
                "alpha": 1.1702954952892812,
                "alpha_hat": 1.6153872453760019
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.017298560589551926,
                "median": -0.005221138242632151,
                "std": 0.2253425568342209,
                "max": 0.41255003213882446,
                "min": -0.31198665499687195,
                "frobenius_norm": 1.8080443143844604,
                "spectral_norm": 1.145410180091858,
                "alpha": 1.290688039973174,
                "alpha_hat": 2.1753711775406552
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.020599864423274994,
                "median": 0.01174211222678423,
                "std": 0.19312359392642975,
                "max": 0.3694225251674652,
                "min": -0.29978829622268677,
                "frobenius_norm": 1.553753137588501,
                "spectral_norm": 0.8128655552864075,
                "alpha": 1.181020059354365,
                "alpha_hat": 1.0686333369445715
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=8_scaler_type=minmax_seed=1213": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 8,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1213,
        "scores": {
            "smape": 0.18160416185855865,
            "mse": 1423979648.0,
            "mae": 3927.931884765625,
            "r2_score": 0.6924008131027222,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.023386267945170403,
                "median": 0.03199561685323715,
                "std": 0.1592511683702469,
                "max": 0.3063381612300873,
                "min": -0.2863127291202545,
                "frobenius_norm": 1.577071189880371,
                "spectral_norm": 0.8500323295593262,
                "alpha": 1.456848018491083,
                "alpha_hat": 1.496378568627759
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02667970210313797,
                "median": 0.06265242397785187,
                "std": 0.21395328640937805,
                "max": 0.37127456068992615,
                "min": -0.3257538676261902,
                "frobenius_norm": 1.7248826026916504,
                "spectral_norm": 0.970264196395874,
                "alpha": 1.1702954952892812,
                "alpha_hat": 1.6153872453760019
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.017298560589551926,
                "median": -0.005221138242632151,
                "std": 0.2253425568342209,
                "max": 0.41255003213882446,
                "min": -0.31198665499687195,
                "frobenius_norm": 1.8080443143844604,
                "spectral_norm": 1.145410180091858,
                "alpha": 1.290688039973174,
                "alpha_hat": 2.1753711775406552
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.020599864423274994,
                "median": 0.01174211222678423,
                "std": 0.19312359392642975,
                "max": 0.3694225251674652,
                "min": -0.29978829622268677,
                "frobenius_norm": 1.553753137588501,
                "spectral_norm": 0.8128655552864075,
                "alpha": 1.181020059354365,
                "alpha_hat": 1.0686333369445715
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=8_scaler_type=minmax_seed=1819": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 8,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1819,
        "scores": {
            "smape": 0.18101634085178375,
            "mse": 1423609856.0,
            "mae": 3921.475341796875,
            "r2_score": 0.6924806833267212,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.02526269294321537,
                "median": 0.03265250101685524,
                "std": 0.1594088077545166,
                "max": 0.31453126668930054,
                "min": -0.28799259662628174,
                "frobenius_norm": 1.581372857093811,
                "spectral_norm": 0.852338433265686,
                "alpha": 1.450629071052273,
                "alpha_hat": 1.4944920293183246
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.026268132030963898,
                "median": 0.06120801717042923,
                "std": 0.21454916894435883,
                "max": 0.36835774779319763,
                "min": -0.3296608030796051,
                "frobenius_norm": 1.7292100191116333,
                "spectral_norm": 0.9725667834281921,
                "alpha": 1.1760432302116552,
                "alpha_hat": 1.6139185065337325
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01707959733903408,
                "median": -0.005961509421467781,
                "std": 0.22490094602108002,
                "max": 0.41136404871940613,
                "min": -0.31201860308647156,
                "frobenius_norm": 1.804388403892517,
                "spectral_norm": 1.1420156955718994,
                "alpha": 1.2905333547952866,
                "alpha_hat": 2.169160258143202
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.020673708990216255,
                "median": 0.011656892485916615,
                "std": 0.1926700621843338,
                "max": 0.36228132247924805,
                "min": -0.29703617095947266,
                "frobenius_norm": 1.550208330154419,
                "spectral_norm": 0.8066642880439758,
                "alpha": 1.1787208174514363,
                "alpha_hat": 1.062548089618419
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=8_scaler_type=minmax_seed=1617": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 8,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1617,
        "scores": {
            "smape": 0.1820925772190094,
            "mse": 1426415616.0,
            "mae": 3934.041259765625,
            "r2_score": 0.691874623298645,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.02526269294321537,
                "median": 0.03265250101685524,
                "std": 0.1594088077545166,
                "max": 0.31453126668930054,
                "min": -0.28799259662628174,
                "frobenius_norm": 1.581372857093811,
                "spectral_norm": 0.852338433265686,
                "alpha": 1.450629071052273,
                "alpha_hat": 1.4944920293183246
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.026268132030963898,
                "median": 0.06120801717042923,
                "std": 0.21454916894435883,
                "max": 0.36835774779319763,
                "min": -0.3296608030796051,
                "frobenius_norm": 1.7292100191116333,
                "spectral_norm": 0.9725667834281921,
                "alpha": 1.1760432302116552,
                "alpha_hat": 1.6139185065337325
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01707959733903408,
                "median": -0.005961509421467781,
                "std": 0.22490094602108002,
                "max": 0.41136404871940613,
                "min": -0.31201860308647156,
                "frobenius_norm": 1.804388403892517,
                "spectral_norm": 1.1420156955718994,
                "alpha": 1.2905333547952866,
                "alpha_hat": 2.169160258143202
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.020673708990216255,
                "median": 0.011656892485916615,
                "std": 0.1926700621843338,
                "max": 0.36228132247924805,
                "min": -0.29703617095947266,
                "frobenius_norm": 1.550208330154419,
                "spectral_norm": 0.8066642880439758,
                "alpha": 1.1787208174514363,
                "alpha_hat": 1.062548089618419
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=8_scaler_type=minmax_seed=1415": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 8,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1415,
        "scores": {
            "smape": 0.1819016933441162,
            "mse": 1426954112.0,
            "mae": 3933.2568359375,
            "r2_score": 0.6917582750320435,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.02526269294321537,
                "median": 0.03265250101685524,
                "std": 0.1594088077545166,
                "max": 0.31453126668930054,
                "min": -0.28799259662628174,
                "frobenius_norm": 1.581372857093811,
                "spectral_norm": 0.852338433265686,
                "alpha": 1.450629071052273,
                "alpha_hat": 1.4944920293183246
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.026268132030963898,
                "median": 0.06120801717042923,
                "std": 0.21454916894435883,
                "max": 0.36835774779319763,
                "min": -0.3296608030796051,
                "frobenius_norm": 1.7292100191116333,
                "spectral_norm": 0.9725667834281921,
                "alpha": 1.1760432302116552,
                "alpha_hat": 1.6139185065337325
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01707959733903408,
                "median": -0.005961509421467781,
                "std": 0.22490094602108002,
                "max": 0.41136404871940613,
                "min": -0.31201860308647156,
                "frobenius_norm": 1.804388403892517,
                "spectral_norm": 1.1420156955718994,
                "alpha": 1.2905333547952866,
                "alpha_hat": 2.169160258143202
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.020673708990216255,
                "median": 0.011656892485916615,
                "std": 0.1926700621843338,
                "max": 0.36228132247924805,
                "min": -0.29703617095947266,
                "frobenius_norm": 1.550208330154419,
                "spectral_norm": 0.8066642880439758,
                "alpha": 1.1787208174514363,
                "alpha_hat": 1.062548089618419
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=8_scaler_type=minmax_seed=2021": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 8,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 2021,
        "scores": {
            "smape": 0.1819373369216919,
            "mse": 1428411008.0,
            "mae": 3934.00048828125,
            "r2_score": 0.6914435625076294,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.02526269294321537,
                "median": 0.03265250101685524,
                "std": 0.1594088077545166,
                "max": 0.31453126668930054,
                "min": -0.28799259662628174,
                "frobenius_norm": 1.581372857093811,
                "spectral_norm": 0.852338433265686,
                "alpha": 1.450629071052273,
                "alpha_hat": 1.4944920293183246
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.026268132030963898,
                "median": 0.06120801717042923,
                "std": 0.21454916894435883,
                "max": 0.36835774779319763,
                "min": -0.3296608030796051,
                "frobenius_norm": 1.7292100191116333,
                "spectral_norm": 0.9725667834281921,
                "alpha": 1.1760432302116552,
                "alpha_hat": 1.6139185065337325
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01707959733903408,
                "median": -0.005961509421467781,
                "std": 0.22490094602108002,
                "max": 0.41136404871940613,
                "min": -0.31201860308647156,
                "frobenius_norm": 1.804388403892517,
                "spectral_norm": 1.1420156955718994,
                "alpha": 1.2905333547952866,
                "alpha_hat": 2.169160258143202
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.020673708990216255,
                "median": 0.011656892485916615,
                "std": 0.1926700621843338,
                "max": 0.36228132247924805,
                "min": -0.29703617095947266,
                "frobenius_norm": 1.550208330154419,
                "spectral_norm": 0.8066642880439758,
                "alpha": 1.1787208174514363,
                "alpha_hat": 1.062548089618419
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=16_scaler_type=identity_seed=42": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 42,
        "scores": {
            "smape": 0.6823939085006714,
            "mse": 3931024640.0,
            "mae": 8922.455078125,
            "r2_score": 0.1508445143699646,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.036486998200416565,
                "median": 0.03151625022292137,
                "std": 0.15902495384216309,
                "max": 0.3353361189365387,
                "min": -0.2764870822429657,
                "frobenius_norm": 1.5986065864562988,
                "spectral_norm": 0.8549138903617859,
                "alpha": 1.667485582279702,
                "alpha_hat": 2.1233394800782794
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03902648389339447,
                "median": 0.07753199338912964,
                "std": 0.21997970342636108,
                "max": 0.40341824293136597,
                "min": -0.3208760619163513,
                "frobenius_norm": 1.7873178720474243,
                "spectral_norm": 1.1083447933197021,
                "alpha": 1.1321879763226494,
                "alpha_hat": 1.5969401294289118
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02969575859606266,
                "median": 0.004624618217349052,
                "std": 0.22446990013122559,
                "max": 0.40377649664878845,
                "min": -0.3065582513809204,
                "frobenius_norm": 1.811405062675476,
                "spectral_norm": 1.1596184968948364,
                "alpha": 1.3171142969564529,
                "alpha_hat": 2.380378395159843
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05102309584617615,
                "median": 0.03697913885116577,
                "std": 0.19428162276744843,
                "max": 0.39713001251220703,
                "min": -0.265959769487381,
                "frobenius_norm": 1.6069589853286743,
                "spectral_norm": 0.8873695731163025,
                "alpha": 1.2465891825662934,
                "alpha_hat": 1.2118981601189938
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=16_scaler_type=identity_seed=456": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 456,
        "scores": {
            "smape": 0.7110286355018616,
            "mse": 4035023360.0,
            "mae": 9164.619140625,
            "r2_score": 0.12837934494018555,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.036486998200416565,
                "median": 0.03151625022292137,
                "std": 0.15902495384216309,
                "max": 0.3353361189365387,
                "min": -0.2764870822429657,
                "frobenius_norm": 1.5986065864562988,
                "spectral_norm": 0.8549138903617859,
                "alpha": 1.667485582279702,
                "alpha_hat": 2.1233394800782794
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03902648389339447,
                "median": 0.07753199338912964,
                "std": 0.21997970342636108,
                "max": 0.40341824293136597,
                "min": -0.3208760619163513,
                "frobenius_norm": 1.7873178720474243,
                "spectral_norm": 1.1083447933197021,
                "alpha": 1.1321879763226494,
                "alpha_hat": 1.5969401294289118
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02969575859606266,
                "median": 0.004624618217349052,
                "std": 0.22446990013122559,
                "max": 0.40377649664878845,
                "min": -0.3065582513809204,
                "frobenius_norm": 1.811405062675476,
                "spectral_norm": 1.1596184968948364,
                "alpha": 1.3171142969564529,
                "alpha_hat": 2.380378395159843
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05102309584617615,
                "median": 0.03697913885116577,
                "std": 0.19428162276744843,
                "max": 0.39713001251220703,
                "min": -0.265959769487381,
                "frobenius_norm": 1.6069589853286743,
                "spectral_norm": 0.8873695731163025,
                "alpha": 1.2465891825662934,
                "alpha_hat": 1.2118981601189938
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=16_scaler_type=identity_seed=123": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 123,
        "scores": {
            "smape": 0.6817667484283447,
            "mse": 3934246144.0,
            "mae": 8925.439453125,
            "r2_score": 0.15014863014221191,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.036486998200416565,
                "median": 0.03151625022292137,
                "std": 0.15902495384216309,
                "max": 0.3353361189365387,
                "min": -0.2764870822429657,
                "frobenius_norm": 1.5986065864562988,
                "spectral_norm": 0.8549138903617859,
                "alpha": 1.667485582279702,
                "alpha_hat": 2.1233394800782794
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03902648389339447,
                "median": 0.07753199338912964,
                "std": 0.21997970342636108,
                "max": 0.40341824293136597,
                "min": -0.3208760619163513,
                "frobenius_norm": 1.7873178720474243,
                "spectral_norm": 1.1083447933197021,
                "alpha": 1.1321879763226494,
                "alpha_hat": 1.5969401294289118
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02969575859606266,
                "median": 0.004624618217349052,
                "std": 0.22446990013122559,
                "max": 0.40377649664878845,
                "min": -0.3065582513809204,
                "frobenius_norm": 1.811405062675476,
                "spectral_norm": 1.1596184968948364,
                "alpha": 1.3171142969564529,
                "alpha_hat": 2.380378395159843
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05102309584617615,
                "median": 0.03697913885116577,
                "std": 0.19428162276744843,
                "max": 0.39713001251220703,
                "min": -0.265959769487381,
                "frobenius_norm": 1.6069589853286743,
                "spectral_norm": 0.8873695731163025,
                "alpha": 1.2465891825662934,
                "alpha_hat": 1.2118981601189938
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=16_scaler_type=identity_seed=789": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 789,
        "scores": {
            "smape": 0.7040674090385437,
            "mse": 4003662080.0,
            "mae": 9094.0615234375,
            "r2_score": 0.13515383005142212,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.036486998200416565,
                "median": 0.03151625022292137,
                "std": 0.15902495384216309,
                "max": 0.3353361189365387,
                "min": -0.2764870822429657,
                "frobenius_norm": 1.5986065864562988,
                "spectral_norm": 0.8549138903617859,
                "alpha": 1.667485582279702,
                "alpha_hat": 2.1233394800782794
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03902648389339447,
                "median": 0.07753199338912964,
                "std": 0.21997970342636108,
                "max": 0.40341824293136597,
                "min": -0.3208760619163513,
                "frobenius_norm": 1.7873178720474243,
                "spectral_norm": 1.1083447933197021,
                "alpha": 1.1321879763226494,
                "alpha_hat": 1.5969401294289118
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02969575859606266,
                "median": 0.004624618217349052,
                "std": 0.22446990013122559,
                "max": 0.40377649664878845,
                "min": -0.3065582513809204,
                "frobenius_norm": 1.811405062675476,
                "spectral_norm": 1.1596184968948364,
                "alpha": 1.3171142969564529,
                "alpha_hat": 2.380378395159843
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05102309584617615,
                "median": 0.03697913885116577,
                "std": 0.19428162276744843,
                "max": 0.39713001251220703,
                "min": -0.265959769487381,
                "frobenius_norm": 1.6069589853286743,
                "spectral_norm": 0.8873695731163025,
                "alpha": 1.2465891825662934,
                "alpha_hat": 1.2118981601189938
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=16_scaler_type=identity_seed=1617": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1617,
        "scores": {
            "smape": 0.6792404055595398,
            "mse": 3922633472.0,
            "mae": 8899.423828125,
            "r2_score": 0.15265709161758423,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.03842201828956604,
                "median": 0.03172425180673599,
                "std": 0.15937545895576477,
                "max": 0.33782652020454407,
                "min": -0.2785797417163849,
                "frobenius_norm": 1.6062912940979004,
                "spectral_norm": 0.8559141755104065,
                "alpha": 1.6585401930944819,
                "alpha_hat": 2.1304842492309293
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04055958241224289,
                "median": 0.07944954186677933,
                "std": 0.2203163355588913,
                "max": 0.4051756262779236,
                "min": -0.3253366947174072,
                "frobenius_norm": 1.7921494245529175,
                "spectral_norm": 1.1123683452606201,
                "alpha": 1.1054686803244305,
                "alpha_hat": 1.5680399233303106
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.030963947996497154,
                "median": 0.0030899690464138985,
                "std": 0.22517351806163788,
                "max": 0.4069157838821411,
                "min": -0.3067379891872406,
                "frobenius_norm": 1.8183399438858032,
                "spectral_norm": 1.1612014770507812,
                "alpha": 1.3163606598048687,
                "alpha_hat": 2.3885178664752442
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05386814475059509,
                "median": 0.03956996276974678,
                "std": 0.1945430040359497,
                "max": 0.39993223547935486,
                "min": -0.2627984285354614,
                "frobenius_norm": 1.614905595779419,
                "spectral_norm": 0.9008899927139282,
                "alpha": 1.2415086461746132,
                "alpha_hat": 1.2175402972257372
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=16_scaler_type=identity_seed=1213": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1213,
        "scores": {
            "smape": 0.6937350630760193,
            "mse": 3978358528.0,
            "mae": 9024.521484375,
            "r2_score": 0.14061975479125977,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.03842201828956604,
                "median": 0.03172425180673599,
                "std": 0.15937545895576477,
                "max": 0.33782652020454407,
                "min": -0.2785797417163849,
                "frobenius_norm": 1.6062912940979004,
                "spectral_norm": 0.8559141755104065,
                "alpha": 1.6585401930944819,
                "alpha_hat": 2.1304842492309293
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04055958241224289,
                "median": 0.07944954186677933,
                "std": 0.2203163355588913,
                "max": 0.4051756262779236,
                "min": -0.3253366947174072,
                "frobenius_norm": 1.7921494245529175,
                "spectral_norm": 1.1123683452606201,
                "alpha": 1.1054686803244305,
                "alpha_hat": 1.5680399233303106
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.030963947996497154,
                "median": 0.0030899690464138985,
                "std": 0.22517351806163788,
                "max": 0.4069157838821411,
                "min": -0.3067379891872406,
                "frobenius_norm": 1.8183399438858032,
                "spectral_norm": 1.1612014770507812,
                "alpha": 1.3163606598048687,
                "alpha_hat": 2.3885178664752442
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05386814475059509,
                "median": 0.03956996276974678,
                "std": 0.1945430040359497,
                "max": 0.39993223547935486,
                "min": -0.2627984285354614,
                "frobenius_norm": 1.614905595779419,
                "spectral_norm": 0.9008899927139282,
                "alpha": 1.2415086461746132,
                "alpha_hat": 1.2175402972257372
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=16_scaler_type=identity_seed=1011": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1011,
        "scores": {
            "smape": 0.6757227778434753,
            "mse": 3911302400.0,
            "mae": 8873.125,
            "r2_score": 0.15510481595993042,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.03842201828956604,
                "median": 0.03172425180673599,
                "std": 0.15937545895576477,
                "max": 0.33782652020454407,
                "min": -0.2785797417163849,
                "frobenius_norm": 1.6062912940979004,
                "spectral_norm": 0.8559141755104065,
                "alpha": 1.6585401930944819,
                "alpha_hat": 2.1304842492309293
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04055958241224289,
                "median": 0.07944954186677933,
                "std": 0.2203163355588913,
                "max": 0.4051756262779236,
                "min": -0.3253366947174072,
                "frobenius_norm": 1.7921494245529175,
                "spectral_norm": 1.1123683452606201,
                "alpha": 1.1054686803244305,
                "alpha_hat": 1.5680399233303106
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.030963947996497154,
                "median": 0.0030899690464138985,
                "std": 0.22517351806163788,
                "max": 0.4069157838821411,
                "min": -0.3067379891872406,
                "frobenius_norm": 1.8183399438858032,
                "spectral_norm": 1.1612014770507812,
                "alpha": 1.3163606598048687,
                "alpha_hat": 2.3885178664752442
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05386814475059509,
                "median": 0.03956996276974678,
                "std": 0.1945430040359497,
                "max": 0.39993223547935486,
                "min": -0.2627984285354614,
                "frobenius_norm": 1.614905595779419,
                "spectral_norm": 0.9008899927139282,
                "alpha": 1.2415086461746132,
                "alpha_hat": 1.2175402972257372
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=16_scaler_type=identity_seed=1415": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1415,
        "scores": {
            "smape": 0.6831461787223816,
            "mse": 3933401088.0,
            "mae": 8930.7568359375,
            "r2_score": 0.15033119916915894,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.03842201828956604,
                "median": 0.03172425180673599,
                "std": 0.15937545895576477,
                "max": 0.33782652020454407,
                "min": -0.2785797417163849,
                "frobenius_norm": 1.6062912940979004,
                "spectral_norm": 0.8559141755104065,
                "alpha": 1.6585401930944819,
                "alpha_hat": 2.1304842492309293
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04055958241224289,
                "median": 0.07944954186677933,
                "std": 0.2203163355588913,
                "max": 0.4051756262779236,
                "min": -0.3253366947174072,
                "frobenius_norm": 1.7921494245529175,
                "spectral_norm": 1.1123683452606201,
                "alpha": 1.1054686803244305,
                "alpha_hat": 1.5680399233303106
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.030963947996497154,
                "median": 0.0030899690464138985,
                "std": 0.22517351806163788,
                "max": 0.4069157838821411,
                "min": -0.3067379891872406,
                "frobenius_norm": 1.8183399438858032,
                "spectral_norm": 1.1612014770507812,
                "alpha": 1.3163606598048687,
                "alpha_hat": 2.3885178664752442
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05386814475059509,
                "median": 0.03956996276974678,
                "std": 0.1945430040359497,
                "max": 0.39993223547935486,
                "min": -0.2627984285354614,
                "frobenius_norm": 1.614905595779419,
                "spectral_norm": 0.9008899927139282,
                "alpha": 1.2415086461746132,
                "alpha_hat": 1.2175402972257372
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=16_scaler_type=identity_seed=2021": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 2021,
        "scores": {
            "smape": 0.791847825050354,
            "mse": 4544509440.0,
            "mae": 10234.8544921875,
            "r2_score": 0.018323302268981934,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.015396133065223694,
                "median": -0.004385723266750574,
                "std": 0.1815575808286667,
                "max": 0.3244624435901642,
                "min": -0.27997565269470215,
                "frobenius_norm": 1.7852784395217896,
                "spectral_norm": 0.9541435241699219,
                "alpha": 1.274924849691248,
                "alpha_hat": 1.5337416729334492
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.008101912215352058,
                "median": 0.02602485567331314,
                "std": 0.203985333442688,
                "max": 0.3864542543888092,
                "min": -0.32509076595306396,
                "frobenius_norm": 1.6331692934036255,
                "spectral_norm": 0.9402621984481812,
                "alpha": 1.0869076852329527,
                "alpha_hat": 1.6928688313535547
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.028964269906282425,
                "median": 0.03574662655591965,
                "std": 0.2119155079126358,
                "max": 0.37047314643859863,
                "min": -0.3235231935977936,
                "frobenius_norm": 1.7110859155654907,
                "spectral_norm": 1.1069397926330566,
                "alpha": 1.0837521428805756,
                "alpha_hat": 2.237364800014507
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.001516689546406269,
                "median": -0.022182699292898178,
                "std": 0.20119599997997284,
                "max": 0.40320125222206116,
                "min": -0.32579466700553894,
                "frobenius_norm": 1.6096136569976807,
                "spectral_norm": 1.033539056777954,
                "alpha": 1.1180850455940667,
                "alpha_hat": 2.14400473577367
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=16_scaler_type=identity_seed=1819": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1819,
        "scores": {
            "smape": 0.9845306873321533,
            "mse": 4726025728.0,
            "mae": 10904.1884765625,
            "r2_score": -0.020886778831481934,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.015396133065223694,
                "median": -0.004385723266750574,
                "std": 0.1815575808286667,
                "max": 0.3244624435901642,
                "min": -0.27997565269470215,
                "frobenius_norm": 1.7852784395217896,
                "spectral_norm": 0.9541435241699219,
                "alpha": 1.274924849691248,
                "alpha_hat": 1.5337416729334492
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.008101912215352058,
                "median": 0.02602485567331314,
                "std": 0.203985333442688,
                "max": 0.3864542543888092,
                "min": -0.32509076595306396,
                "frobenius_norm": 1.6331692934036255,
                "spectral_norm": 0.9402621984481812,
                "alpha": 1.0869076852329527,
                "alpha_hat": 1.6928688313535547
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.028964269906282425,
                "median": 0.03574662655591965,
                "std": 0.2119155079126358,
                "max": 0.37047314643859863,
                "min": -0.3235231935977936,
                "frobenius_norm": 1.7110859155654907,
                "spectral_norm": 1.1069397926330566,
                "alpha": 1.0837521428805756,
                "alpha_hat": 2.237364800014507
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.001516689546406269,
                "median": -0.022182699292898178,
                "std": 0.20119599997997284,
                "max": 0.40320125222206116,
                "min": -0.32579466700553894,
                "frobenius_norm": 1.6096136569976807,
                "spectral_norm": 1.033539056777954,
                "alpha": 1.1180850455940667,
                "alpha_hat": 2.14400473577367
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=16_scaler_type=standard_seed=42": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 42,
        "scores": {
            "smape": 0.07856141030788422,
            "mse": 586235520.0,
            "mae": 2162.58203125,
            "r2_score": 0.873365044593811,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.015396133065223694,
                "median": -0.004385723266750574,
                "std": 0.1815575808286667,
                "max": 0.3244624435901642,
                "min": -0.27997565269470215,
                "frobenius_norm": 1.7852784395217896,
                "spectral_norm": 0.9541435241699219,
                "alpha": 1.274924849691248,
                "alpha_hat": 1.5337416729334492
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.008101912215352058,
                "median": 0.02602485567331314,
                "std": 0.203985333442688,
                "max": 0.3864542543888092,
                "min": -0.32509076595306396,
                "frobenius_norm": 1.6331692934036255,
                "spectral_norm": 0.9402621984481812,
                "alpha": 1.0869076852329527,
                "alpha_hat": 1.6928688313535547
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.028964269906282425,
                "median": 0.03574662655591965,
                "std": 0.2119155079126358,
                "max": 0.37047314643859863,
                "min": -0.3235231935977936,
                "frobenius_norm": 1.7110859155654907,
                "spectral_norm": 1.1069397926330566,
                "alpha": 1.0837521428805756,
                "alpha_hat": 2.237364800014507
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.001516689546406269,
                "median": -0.022182699292898178,
                "std": 0.20119599997997284,
                "max": 0.40320125222206116,
                "min": -0.32579466700553894,
                "frobenius_norm": 1.6096136569976807,
                "spectral_norm": 1.033539056777954,
                "alpha": 1.1180850455940667,
                "alpha_hat": 2.14400473577367
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=16_scaler_type=standard_seed=123": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 123,
        "scores": {
            "smape": 0.07915154099464417,
            "mse": 455925024.0,
            "mae": 2022.753662109375,
            "r2_score": 0.901513934135437,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.015396133065223694,
                "median": -0.004385723266750574,
                "std": 0.1815575808286667,
                "max": 0.3244624435901642,
                "min": -0.27997565269470215,
                "frobenius_norm": 1.7852784395217896,
                "spectral_norm": 0.9541435241699219,
                "alpha": 1.274924849691248,
                "alpha_hat": 1.5337416729334492
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.008101912215352058,
                "median": 0.02602485567331314,
                "std": 0.203985333442688,
                "max": 0.3864542543888092,
                "min": -0.32509076595306396,
                "frobenius_norm": 1.6331692934036255,
                "spectral_norm": 0.9402621984481812,
                "alpha": 1.0869076852329527,
                "alpha_hat": 1.6928688313535547
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.028964269906282425,
                "median": 0.03574662655591965,
                "std": 0.2119155079126358,
                "max": 0.37047314643859863,
                "min": -0.3235231935977936,
                "frobenius_norm": 1.7110859155654907,
                "spectral_norm": 1.1069397926330566,
                "alpha": 1.0837521428805756,
                "alpha_hat": 2.237364800014507
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.001516689546406269,
                "median": -0.022182699292898178,
                "std": 0.20119599997997284,
                "max": 0.40320125222206116,
                "min": -0.32579466700553894,
                "frobenius_norm": 1.6096136569976807,
                "spectral_norm": 1.033539056777954,
                "alpha": 1.1180850455940667,
                "alpha_hat": 2.14400473577367
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=16_scaler_type=standard_seed=1213": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1213,
        "scores": {
            "smape": 0.0802287682890892,
            "mse": 596043072.0,
            "mae": 2154.04052734375,
            "r2_score": 0.8712464570999146,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.004718770273029804,
                "median": -0.003513994161039591,
                "std": 0.15977631509304047,
                "max": 0.33225685358047485,
                "min": -0.30889323353767395,
                "frobenius_norm": 1.5661643743515015,
                "spectral_norm": 0.8891571164131165,
                "alpha": 1.3855389093979384,
                "alpha_hat": 1.801781746244368
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022478457540273666,
                "median": 0.0428469181060791,
                "std": 0.19631557166576385,
                "max": 0.36706024408340454,
                "min": -0.38642528653144836,
                "frobenius_norm": 1.5807863473892212,
                "spectral_norm": 1.095606803894043,
                "alpha": 1.1822086494831243,
                "alpha_hat": 3.4889254386003876
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05463747680187225,
                "median": 0.13541573286056519,
                "std": 0.21180583536624908,
                "max": 0.3626163601875305,
                "min": -0.32471907138824463,
                "frobenius_norm": 1.7499159574508667,
                "spectral_norm": 0.9257280826568604,
                "alpha": 1.3265057084461067,
                "alpha_hat": 1.4081660784838446
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04252409562468529,
                "median": 0.029430532827973366,
                "std": 0.19347046315670013,
                "max": 0.40647608041763306,
                "min": -0.34689220786094666,
                "frobenius_norm": 1.5847092866897583,
                "spectral_norm": 1.0854958295822144,
                "alpha": 1.2442786203194423,
                "alpha_hat": 2.0216368160342877
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=16_scaler_type=standard_seed=789": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 789,
        "scores": {
            "smape": 0.08112835139036179,
            "mse": 503683776.0,
            "mae": 2096.46826171875,
            "r2_score": 0.8911973834037781,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.004718770273029804,
                "median": -0.003513994161039591,
                "std": 0.15977631509304047,
                "max": 0.33225685358047485,
                "min": -0.30889323353767395,
                "frobenius_norm": 1.5661643743515015,
                "spectral_norm": 0.8891571164131165,
                "alpha": 1.3855389093979384,
                "alpha_hat": 1.801781746244368
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022478457540273666,
                "median": 0.0428469181060791,
                "std": 0.19631557166576385,
                "max": 0.36706024408340454,
                "min": -0.38642528653144836,
                "frobenius_norm": 1.5807863473892212,
                "spectral_norm": 1.095606803894043,
                "alpha": 1.1822086494831243,
                "alpha_hat": 3.4889254386003876
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05463747680187225,
                "median": 0.13541573286056519,
                "std": 0.21180583536624908,
                "max": 0.3626163601875305,
                "min": -0.32471907138824463,
                "frobenius_norm": 1.7499159574508667,
                "spectral_norm": 0.9257280826568604,
                "alpha": 1.3265057084461067,
                "alpha_hat": 1.4081660784838446
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04252409562468529,
                "median": 0.029430532827973366,
                "std": 0.19347046315670013,
                "max": 0.40647608041763306,
                "min": -0.34689220786094666,
                "frobenius_norm": 1.5847092866897583,
                "spectral_norm": 1.0854958295822144,
                "alpha": 1.2442786203194423,
                "alpha_hat": 2.0216368160342877
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=16_scaler_type=standard_seed=456": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 456,
        "scores": {
            "smape": 0.08026371896266937,
            "mse": 595959360.0,
            "mae": 2154.92431640625,
            "r2_score": 0.8712645769119263,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.004718770273029804,
                "median": -0.003513994161039591,
                "std": 0.15977631509304047,
                "max": 0.33225685358047485,
                "min": -0.30889323353767395,
                "frobenius_norm": 1.5661643743515015,
                "spectral_norm": 0.8891571164131165,
                "alpha": 1.3855389093979384,
                "alpha_hat": 1.801781746244368
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022478457540273666,
                "median": 0.0428469181060791,
                "std": 0.19631557166576385,
                "max": 0.36706024408340454,
                "min": -0.38642528653144836,
                "frobenius_norm": 1.5807863473892212,
                "spectral_norm": 1.095606803894043,
                "alpha": 1.1822086494831243,
                "alpha_hat": 3.4889254386003876
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05463747680187225,
                "median": 0.13541573286056519,
                "std": 0.21180583536624908,
                "max": 0.3626163601875305,
                "min": -0.32471907138824463,
                "frobenius_norm": 1.7499159574508667,
                "spectral_norm": 0.9257280826568604,
                "alpha": 1.3265057084461067,
                "alpha_hat": 1.4081660784838446
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04252409562468529,
                "median": 0.029430532827973366,
                "std": 0.19347046315670013,
                "max": 0.40647608041763306,
                "min": -0.34689220786094666,
                "frobenius_norm": 1.5847092866897583,
                "spectral_norm": 1.0854958295822144,
                "alpha": 1.2442786203194423,
                "alpha_hat": 2.0216368160342877
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=16_scaler_type=standard_seed=1011": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1011,
        "scores": {
            "smape": 0.07844755798578262,
            "mse": 557919744.0,
            "mae": 2121.7548828125,
            "r2_score": 0.8794816732406616,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.004718770273029804,
                "median": -0.003513994161039591,
                "std": 0.15977631509304047,
                "max": 0.33225685358047485,
                "min": -0.30889323353767395,
                "frobenius_norm": 1.5661643743515015,
                "spectral_norm": 0.8891571164131165,
                "alpha": 1.3855389093979384,
                "alpha_hat": 1.801781746244368
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022478457540273666,
                "median": 0.0428469181060791,
                "std": 0.19631557166576385,
                "max": 0.36706024408340454,
                "min": -0.38642528653144836,
                "frobenius_norm": 1.5807863473892212,
                "spectral_norm": 1.095606803894043,
                "alpha": 1.1822086494831243,
                "alpha_hat": 3.4889254386003876
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05463747680187225,
                "median": 0.13541573286056519,
                "std": 0.21180583536624908,
                "max": 0.3626163601875305,
                "min": -0.32471907138824463,
                "frobenius_norm": 1.7499159574508667,
                "spectral_norm": 0.9257280826568604,
                "alpha": 1.3265057084461067,
                "alpha_hat": 1.4081660784838446
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04252409562468529,
                "median": 0.029430532827973366,
                "std": 0.19347046315670013,
                "max": 0.40647608041763306,
                "min": -0.34689220786094666,
                "frobenius_norm": 1.5847092866897583,
                "spectral_norm": 1.0854958295822144,
                "alpha": 1.2442786203194423,
                "alpha_hat": 2.0216368160342877
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=16_scaler_type=standard_seed=1415": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1415,
        "scores": {
            "smape": 0.08025721460580826,
            "mse": 595626496.0,
            "mae": 2154.23486328125,
            "r2_score": 0.8713364601135254,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.008611948229372501,
                "median": 0.03351058065891266,
                "std": 0.15498463809490204,
                "max": 0.2922157049179077,
                "min": -0.2828713655471802,
                "frobenius_norm": 1.5208756923675537,
                "spectral_norm": 0.8240543007850647,
                "alpha": 1.521580982735254,
                "alpha_hat": 1.743023533670361
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.009897356852889061,
                "median": 0.04984927177429199,
                "std": 0.21118423342704773,
                "max": 0.35505712032318115,
                "min": -0.3756703734397888,
                "frobenius_norm": 1.6913281679153442,
                "spectral_norm": 0.9781848788261414,
                "alpha": 1.1247192635520245,
                "alpha_hat": 1.4082510578995353
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.011826694011688232,
                "median": -0.011017577722668648,
                "std": 0.22291429340839386,
                "max": 0.3999404311180115,
                "min": -0.3101196587085724,
                "frobenius_norm": 1.7858223915100098,
                "spectral_norm": 1.1574485301971436,
                "alpha": 1.274014204590665,
                "alpha_hat": 2.1018743333014727
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02168985642492771,
                "median": 0.010891469195485115,
                "std": 0.1925450563430786,
                "max": 0.356376588344574,
                "min": -0.29268932342529297,
                "frobenius_norm": 1.5501028299331665,
                "spectral_norm": 0.8029072880744934,
                "alpha": 1.1817571531909026,
                "alpha_hat": 1.0645385241663856
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=16_scaler_type=standard_seed=2021": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 2021,
        "scores": {
            "smape": 0.08023397624492645,
            "mse": 595863424.0,
            "mae": 2154.185546875,
            "r2_score": 0.8712853193283081,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.008611948229372501,
                "median": 0.03351058065891266,
                "std": 0.15498463809490204,
                "max": 0.2922157049179077,
                "min": -0.2828713655471802,
                "frobenius_norm": 1.5208756923675537,
                "spectral_norm": 0.8240543007850647,
                "alpha": 1.521580982735254,
                "alpha_hat": 1.743023533670361
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.009897356852889061,
                "median": 0.04984927177429199,
                "std": 0.21118423342704773,
                "max": 0.35505712032318115,
                "min": -0.3756703734397888,
                "frobenius_norm": 1.6913281679153442,
                "spectral_norm": 0.9781848788261414,
                "alpha": 1.1247192635520245,
                "alpha_hat": 1.4082510578995353
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.011826694011688232,
                "median": -0.011017577722668648,
                "std": 0.22291429340839386,
                "max": 0.3999404311180115,
                "min": -0.3101196587085724,
                "frobenius_norm": 1.7858223915100098,
                "spectral_norm": 1.1574485301971436,
                "alpha": 1.274014204590665,
                "alpha_hat": 2.1018743333014727
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02168985642492771,
                "median": 0.010891469195485115,
                "std": 0.1925450563430786,
                "max": 0.356376588344574,
                "min": -0.29268932342529297,
                "frobenius_norm": 1.5501028299331665,
                "spectral_norm": 0.8029072880744934,
                "alpha": 1.1817571531909026,
                "alpha_hat": 1.0645385241663856
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=16_scaler_type=standard_seed=1617": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1617,
        "scores": {
            "smape": 0.08025211095809937,
            "mse": 596606400.0,
            "mae": 2155.432373046875,
            "r2_score": 0.871124804019928,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.008611948229372501,
                "median": 0.03351058065891266,
                "std": 0.15498463809490204,
                "max": 0.2922157049179077,
                "min": -0.2828713655471802,
                "frobenius_norm": 1.5208756923675537,
                "spectral_norm": 0.8240543007850647,
                "alpha": 1.521580982735254,
                "alpha_hat": 1.743023533670361
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.009897356852889061,
                "median": 0.04984927177429199,
                "std": 0.21118423342704773,
                "max": 0.35505712032318115,
                "min": -0.3756703734397888,
                "frobenius_norm": 1.6913281679153442,
                "spectral_norm": 0.9781848788261414,
                "alpha": 1.1247192635520245,
                "alpha_hat": 1.4082510578995353
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.011826694011688232,
                "median": -0.011017577722668648,
                "std": 0.22291429340839386,
                "max": 0.3999404311180115,
                "min": -0.3101196587085724,
                "frobenius_norm": 1.7858223915100098,
                "spectral_norm": 1.1574485301971436,
                "alpha": 1.274014204590665,
                "alpha_hat": 2.1018743333014727
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02168985642492771,
                "median": 0.010891469195485115,
                "std": 0.1925450563430786,
                "max": 0.356376588344574,
                "min": -0.29268932342529297,
                "frobenius_norm": 1.5501028299331665,
                "spectral_norm": 0.8029072880744934,
                "alpha": 1.1817571531909026,
                "alpha_hat": 1.0645385241663856
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=16_scaler_type=standard_seed=1819": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1819,
        "scores": {
            "smape": 0.08024530112743378,
            "mse": 596284096.0,
            "mae": 2154.762451171875,
            "r2_score": 0.8711944222450256,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.008611948229372501,
                "median": 0.03351058065891266,
                "std": 0.15498463809490204,
                "max": 0.2922157049179077,
                "min": -0.2828713655471802,
                "frobenius_norm": 1.5208756923675537,
                "spectral_norm": 0.8240543007850647,
                "alpha": 1.521580982735254,
                "alpha_hat": 1.743023533670361
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.009897356852889061,
                "median": 0.04984927177429199,
                "std": 0.21118423342704773,
                "max": 0.35505712032318115,
                "min": -0.3756703734397888,
                "frobenius_norm": 1.6913281679153442,
                "spectral_norm": 0.9781848788261414,
                "alpha": 1.1247192635520245,
                "alpha_hat": 1.4082510578995353
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.011826694011688232,
                "median": -0.011017577722668648,
                "std": 0.22291429340839386,
                "max": 0.3999404311180115,
                "min": -0.3101196587085724,
                "frobenius_norm": 1.7858223915100098,
                "spectral_norm": 1.1574485301971436,
                "alpha": 1.274014204590665,
                "alpha_hat": 2.1018743333014727
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02168985642492771,
                "median": 0.010891469195485115,
                "std": 0.1925450563430786,
                "max": 0.356376588344574,
                "min": -0.29268932342529297,
                "frobenius_norm": 1.5501028299331665,
                "spectral_norm": 0.8029072880744934,
                "alpha": 1.1817571531909026,
                "alpha_hat": 1.0645385241663856
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=16_scaler_type=robust_seed=123": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 123,
        "scores": {
            "smape": 0.08110044151544571,
            "mse": 528136896.0,
            "mae": 2096.6328125,
            "r2_score": 0.8859151601791382,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.011084698140621185,
                "median": 0.032801948487758636,
                "std": 0.15468502044677734,
                "max": 0.29565510153770447,
                "min": -0.31173092126846313,
                "frobenius_norm": 1.5194839239120483,
                "spectral_norm": 0.8220246434211731,
                "alpha": 1.5210772983008092,
                "alpha_hat": 1.8308798639678512
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0207825917750597,
                "median": 0.05962633341550827,
                "std": 0.20505140721797943,
                "max": 0.3492875099182129,
                "min": -0.34996336698532104,
                "frobenius_norm": 1.6488152742385864,
                "spectral_norm": 0.9502289295196533,
                "alpha": 1.1686294718220898,
                "alpha_hat": 1.4080163442700324
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.00998079776763916,
                "median": -0.016309654340147972,
                "std": 0.22533857822418213,
                "max": 0.40188735723495483,
                "min": -0.33020418882369995,
                "frobenius_norm": 1.804476022720337,
                "spectral_norm": 1.160225749015808,
                "alpha": 1.274083344140151,
                "alpha_hat": 2.114016132662785
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.019794948399066925,
                "median": 0.015866784378886223,
                "std": 0.1919332593679428,
                "max": 0.35344672203063965,
                "min": -0.2980315685272217,
                "frobenius_norm": 1.5436105728149414,
                "spectral_norm": 0.7986602783203125,
                "alpha": 1.1477043387246777,
                "alpha_hat": 1.0061956590896233
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=16_scaler_type=robust_seed=42": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 42,
        "scores": {
            "smape": 0.07994670420885086,
            "mse": 530954336.0,
            "mae": 2095.02587890625,
            "r2_score": 0.8853065371513367,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.011084698140621185,
                "median": 0.032801948487758636,
                "std": 0.15468502044677734,
                "max": 0.29565510153770447,
                "min": -0.31173092126846313,
                "frobenius_norm": 1.5194839239120483,
                "spectral_norm": 0.8220246434211731,
                "alpha": 1.5210772983008092,
                "alpha_hat": 1.8308798639678512
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0207825917750597,
                "median": 0.05962633341550827,
                "std": 0.20505140721797943,
                "max": 0.3492875099182129,
                "min": -0.34996336698532104,
                "frobenius_norm": 1.6488152742385864,
                "spectral_norm": 0.9502289295196533,
                "alpha": 1.1686294718220898,
                "alpha_hat": 1.4080163442700324
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.00998079776763916,
                "median": -0.016309654340147972,
                "std": 0.22533857822418213,
                "max": 0.40188735723495483,
                "min": -0.33020418882369995,
                "frobenius_norm": 1.804476022720337,
                "spectral_norm": 1.160225749015808,
                "alpha": 1.274083344140151,
                "alpha_hat": 2.114016132662785
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.019794948399066925,
                "median": 0.015866784378886223,
                "std": 0.1919332593679428,
                "max": 0.35344672203063965,
                "min": -0.2980315685272217,
                "frobenius_norm": 1.5436105728149414,
                "spectral_norm": 0.7986602783203125,
                "alpha": 1.1477043387246777,
                "alpha_hat": 1.0061956590896233
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=16_scaler_type=robust_seed=789": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 789,
        "scores": {
            "smape": 0.08026210963726044,
            "mse": 623984640.0,
            "mae": 2145.381591796875,
            "r2_score": 0.8652107119560242,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.011084698140621185,
                "median": 0.032801948487758636,
                "std": 0.15468502044677734,
                "max": 0.29565510153770447,
                "min": -0.31173092126846313,
                "frobenius_norm": 1.5194839239120483,
                "spectral_norm": 0.8220246434211731,
                "alpha": 1.5210772983008092,
                "alpha_hat": 1.8308798639678512
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0207825917750597,
                "median": 0.05962633341550827,
                "std": 0.20505140721797943,
                "max": 0.3492875099182129,
                "min": -0.34996336698532104,
                "frobenius_norm": 1.6488152742385864,
                "spectral_norm": 0.9502289295196533,
                "alpha": 1.1686294718220898,
                "alpha_hat": 1.4080163442700324
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.00998079776763916,
                "median": -0.016309654340147972,
                "std": 0.22533857822418213,
                "max": 0.40188735723495483,
                "min": -0.33020418882369995,
                "frobenius_norm": 1.804476022720337,
                "spectral_norm": 1.160225749015808,
                "alpha": 1.274083344140151,
                "alpha_hat": 2.114016132662785
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.019794948399066925,
                "median": 0.015866784378886223,
                "std": 0.1919332593679428,
                "max": 0.35344672203063965,
                "min": -0.2980315685272217,
                "frobenius_norm": 1.5436105728149414,
                "spectral_norm": 0.7986602783203125,
                "alpha": 1.1477043387246777,
                "alpha_hat": 1.0061956590896233
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=16_scaler_type=robust_seed=456": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 456,
        "scores": {
            "smape": 0.08034555613994598,
            "mse": 623379264.0,
            "mae": 2146.203125,
            "r2_score": 0.8653414845466614,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.011084698140621185,
                "median": 0.032801948487758636,
                "std": 0.15468502044677734,
                "max": 0.29565510153770447,
                "min": -0.31173092126846313,
                "frobenius_norm": 1.5194839239120483,
                "spectral_norm": 0.8220246434211731,
                "alpha": 1.5210772983008092,
                "alpha_hat": 1.8308798639678512
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0207825917750597,
                "median": 0.05962633341550827,
                "std": 0.20505140721797943,
                "max": 0.3492875099182129,
                "min": -0.34996336698532104,
                "frobenius_norm": 1.6488152742385864,
                "spectral_norm": 0.9502289295196533,
                "alpha": 1.1686294718220898,
                "alpha_hat": 1.4080163442700324
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.00998079776763916,
                "median": -0.016309654340147972,
                "std": 0.22533857822418213,
                "max": 0.40188735723495483,
                "min": -0.33020418882369995,
                "frobenius_norm": 1.804476022720337,
                "spectral_norm": 1.160225749015808,
                "alpha": 1.274083344140151,
                "alpha_hat": 2.114016132662785
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.019794948399066925,
                "median": 0.015866784378886223,
                "std": 0.1919332593679428,
                "max": 0.35344672203063965,
                "min": -0.2980315685272217,
                "frobenius_norm": 1.5436105728149414,
                "spectral_norm": 0.7986602783203125,
                "alpha": 1.1477043387246777,
                "alpha_hat": 1.0061956590896233
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=16_scaler_type=robust_seed=1011": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1011,
        "scores": {
            "smape": 0.08023187518119812,
            "mse": 623003136.0,
            "mae": 2144.279541015625,
            "r2_score": 0.8654227256774902,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.009910489432513714,
                "median": 0.03283749520778656,
                "std": 0.15494239330291748,
                "max": 0.2902403771877289,
                "min": -0.31085437536239624,
                "frobenius_norm": 1.5212215185165405,
                "spectral_norm": 0.8233084678649902,
                "alpha": 1.508701987572218,
                "alpha_hat": 1.8046791223724001
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.021433426067233086,
                "median": 0.06178981065750122,
                "std": 0.20579491555690765,
                "max": 0.3533770740032196,
                "min": -0.3536584973335266,
                "frobenius_norm": 1.6552643775939941,
                "spectral_norm": 0.9514082074165344,
                "alpha": 1.172759412443805,
                "alpha_hat": 1.4238094594202673
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.011408638209104538,
                "median": -0.01513481605798006,
                "std": 0.22559016942977905,
                "max": 0.40267738699913025,
                "min": -0.3319850564002991,
                "frobenius_norm": 1.8070276975631714,
                "spectral_norm": 1.1621626615524292,
                "alpha": 1.2793667709006504,
                "alpha_hat": 2.1318661171732645
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.021097645163536072,
                "median": 0.017604827880859375,
                "std": 0.19230131804943085,
                "max": 0.35551464557647705,
                "min": -0.29624515771865845,
                "frobenius_norm": 1.547641634941101,
                "spectral_norm": 0.8018038272857666,
                "alpha": 1.1586242551177337,
                "alpha_hat": 1.0214313600124252
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=16_scaler_type=robust_seed=1213": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1213,
        "scores": {
            "smape": 0.08029394596815109,
            "mse": 622944128.0,
            "mae": 2144.938720703125,
            "r2_score": 0.8654354810714722,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.009910489432513714,
                "median": 0.03283749520778656,
                "std": 0.15494239330291748,
                "max": 0.2902403771877289,
                "min": -0.31085437536239624,
                "frobenius_norm": 1.5212215185165405,
                "spectral_norm": 0.8233084678649902,
                "alpha": 1.508701987572218,
                "alpha_hat": 1.8046791223724001
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.021433426067233086,
                "median": 0.06178981065750122,
                "std": 0.20579491555690765,
                "max": 0.3533770740032196,
                "min": -0.3536584973335266,
                "frobenius_norm": 1.6552643775939941,
                "spectral_norm": 0.9514082074165344,
                "alpha": 1.172759412443805,
                "alpha_hat": 1.4238094594202673
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.011408638209104538,
                "median": -0.01513481605798006,
                "std": 0.22559016942977905,
                "max": 0.40267738699913025,
                "min": -0.3319850564002991,
                "frobenius_norm": 1.8070276975631714,
                "spectral_norm": 1.1621626615524292,
                "alpha": 1.2793667709006504,
                "alpha_hat": 2.1318661171732645
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.021097645163536072,
                "median": 0.017604827880859375,
                "std": 0.19230131804943085,
                "max": 0.35551464557647705,
                "min": -0.29624515771865845,
                "frobenius_norm": 1.547641634941101,
                "spectral_norm": 0.8018038272857666,
                "alpha": 1.1586242551177337,
                "alpha_hat": 1.0214313600124252
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=16_scaler_type=robust_seed=1415": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1415,
        "scores": {
            "smape": 0.0803731232881546,
            "mse": 623310848.0,
            "mae": 2146.84033203125,
            "r2_score": 0.8653562664985657,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.009910489432513714,
                "median": 0.03283749520778656,
                "std": 0.15494239330291748,
                "max": 0.2902403771877289,
                "min": -0.31085437536239624,
                "frobenius_norm": 1.5212215185165405,
                "spectral_norm": 0.8233084678649902,
                "alpha": 1.508701987572218,
                "alpha_hat": 1.8046791223724001
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.021433426067233086,
                "median": 0.06178981065750122,
                "std": 0.20579491555690765,
                "max": 0.3533770740032196,
                "min": -0.3536584973335266,
                "frobenius_norm": 1.6552643775939941,
                "spectral_norm": 0.9514082074165344,
                "alpha": 1.172759412443805,
                "alpha_hat": 1.4238094594202673
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.011408638209104538,
                "median": -0.01513481605798006,
                "std": 0.22559016942977905,
                "max": 0.40267738699913025,
                "min": -0.3319850564002991,
                "frobenius_norm": 1.8070276975631714,
                "spectral_norm": 1.1621626615524292,
                "alpha": 1.2793667709006504,
                "alpha_hat": 2.1318661171732645
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.021097645163536072,
                "median": 0.017604827880859375,
                "std": 0.19230131804943085,
                "max": 0.35551464557647705,
                "min": -0.29624515771865845,
                "frobenius_norm": 1.547641634941101,
                "spectral_norm": 0.8018038272857666,
                "alpha": 1.1586242551177337,
                "alpha_hat": 1.0214313600124252
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=16_scaler_type=robust_seed=1617": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1617,
        "scores": {
            "smape": 0.08032047748565674,
            "mse": 624606272.0,
            "mae": 2146.648193359375,
            "r2_score": 0.8650764226913452,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.009910489432513714,
                "median": 0.03283749520778656,
                "std": 0.15494239330291748,
                "max": 0.2902403771877289,
                "min": -0.31085437536239624,
                "frobenius_norm": 1.5212215185165405,
                "spectral_norm": 0.8233084678649902,
                "alpha": 1.508701987572218,
                "alpha_hat": 1.8046791223724001
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.021433426067233086,
                "median": 0.06178981065750122,
                "std": 0.20579491555690765,
                "max": 0.3533770740032196,
                "min": -0.3536584973335266,
                "frobenius_norm": 1.6552643775939941,
                "spectral_norm": 0.9514082074165344,
                "alpha": 1.172759412443805,
                "alpha_hat": 1.4238094594202673
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.011408638209104538,
                "median": -0.01513481605798006,
                "std": 0.22559016942977905,
                "max": 0.40267738699913025,
                "min": -0.3319850564002991,
                "frobenius_norm": 1.8070276975631714,
                "spectral_norm": 1.1621626615524292,
                "alpha": 1.2793667709006504,
                "alpha_hat": 2.1318661171732645
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.021097645163536072,
                "median": 0.017604827880859375,
                "std": 0.19230131804943085,
                "max": 0.35551464557647705,
                "min": -0.29624515771865845,
                "frobenius_norm": 1.547641634941101,
                "spectral_norm": 0.8018038272857666,
                "alpha": 1.1586242551177337,
                "alpha_hat": 1.0214313600124252
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=16_scaler_type=minmax_seed=42": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 42,
        "scores": {
            "smape": 0.2037152200937271,
            "mse": 1119073024.0,
            "mae": 4070.713623046875,
            "r2_score": 0.7582647800445557,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.009968671947717667,
                "median": 0.033917538821697235,
                "std": 0.1551438271999359,
                "max": 0.2923271656036377,
                "min": -0.31163138151168823,
                "frobenius_norm": 1.523227572441101,
                "spectral_norm": 0.8220261931419373,
                "alpha": 1.5132258474959235,
                "alpha_hat": 1.7968272558097238
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.021866394206881523,
                "median": 0.06215711683034897,
                "std": 0.20589879155158997,
                "max": 0.3574967682361603,
                "min": -0.35203009843826294,
                "frobenius_norm": 1.6564531326293945,
                "spectral_norm": 0.952537477016449,
                "alpha": 1.158685410234326,
                "alpha_hat": 1.3995558572989735
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.011281253769993782,
                "median": -0.01698618195950985,
                "std": 0.2252150923013687,
                "max": 0.40277382731437683,
                "min": -0.32872381806373596,
                "frobenius_norm": 1.8039796352386475,
                "spectral_norm": 1.1589065790176392,
                "alpha": 1.2761885692185702,
                "alpha_hat": 2.123357077238255
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.024765845388174057,
                "median": 0.01793397217988968,
                "std": 0.19215525686740875,
                "max": 0.36478883028030396,
                "min": -0.2903648018836975,
                "frobenius_norm": 1.5499571561813354,
                "spectral_norm": 0.8110975623130798,
                "alpha": 1.1859460736405318,
                "alpha_hat": 1.0573733468855555
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=16_scaler_type=robust_seed=2021": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 2021,
        "scores": {
            "smape": 0.08029580861330032,
            "mse": 623128192.0,
            "mae": 2145.1494140625,
            "r2_score": 0.865395724773407,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.009968671947717667,
                "median": 0.033917538821697235,
                "std": 0.1551438271999359,
                "max": 0.2923271656036377,
                "min": -0.31163138151168823,
                "frobenius_norm": 1.523227572441101,
                "spectral_norm": 0.8220261931419373,
                "alpha": 1.5132258474959235,
                "alpha_hat": 1.7968272558097238
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.021866394206881523,
                "median": 0.06215711683034897,
                "std": 0.20589879155158997,
                "max": 0.3574967682361603,
                "min": -0.35203009843826294,
                "frobenius_norm": 1.6564531326293945,
                "spectral_norm": 0.952537477016449,
                "alpha": 1.158685410234326,
                "alpha_hat": 1.3995558572989735
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.011281253769993782,
                "median": -0.01698618195950985,
                "std": 0.2252150923013687,
                "max": 0.40277382731437683,
                "min": -0.32872381806373596,
                "frobenius_norm": 1.8039796352386475,
                "spectral_norm": 1.1589065790176392,
                "alpha": 1.2761885692185702,
                "alpha_hat": 2.123357077238255
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.024765845388174057,
                "median": 0.01793397217988968,
                "std": 0.19215525686740875,
                "max": 0.36478883028030396,
                "min": -0.2903648018836975,
                "frobenius_norm": 1.5499571561813354,
                "spectral_norm": 0.8110975623130798,
                "alpha": 1.1859460736405318,
                "alpha_hat": 1.0573733468855555
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=16_scaler_type=minmax_seed=123": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 123,
        "scores": {
            "smape": 0.17982806265354156,
            "mse": 1425602944.0,
            "mae": 3910.39306640625,
            "r2_score": 0.6920500993728638,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.009968671947717667,
                "median": 0.033917538821697235,
                "std": 0.1551438271999359,
                "max": 0.2923271656036377,
                "min": -0.31163138151168823,
                "frobenius_norm": 1.523227572441101,
                "spectral_norm": 0.8220261931419373,
                "alpha": 1.5132258474959235,
                "alpha_hat": 1.7968272558097238
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.021866394206881523,
                "median": 0.06215711683034897,
                "std": 0.20589879155158997,
                "max": 0.3574967682361603,
                "min": -0.35203009843826294,
                "frobenius_norm": 1.6564531326293945,
                "spectral_norm": 0.952537477016449,
                "alpha": 1.158685410234326,
                "alpha_hat": 1.3995558572989735
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.011281253769993782,
                "median": -0.01698618195950985,
                "std": 0.2252150923013687,
                "max": 0.40277382731437683,
                "min": -0.32872381806373596,
                "frobenius_norm": 1.8039796352386475,
                "spectral_norm": 1.1589065790176392,
                "alpha": 1.2761885692185702,
                "alpha_hat": 2.123357077238255
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.024765845388174057,
                "median": 0.01793397217988968,
                "std": 0.19215525686740875,
                "max": 0.36478883028030396,
                "min": -0.2903648018836975,
                "frobenius_norm": 1.5499571561813354,
                "spectral_norm": 0.8110975623130798,
                "alpha": 1.1859460736405318,
                "alpha_hat": 1.0573733468855555
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=16_scaler_type=robust_seed=1819": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1819,
        "scores": {
            "smape": 0.08022847771644592,
            "mse": 624670272.0,
            "mae": 2145.058837890625,
            "r2_score": 0.8650625944137573,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.009968671947717667,
                "median": 0.033917538821697235,
                "std": 0.1551438271999359,
                "max": 0.2923271656036377,
                "min": -0.31163138151168823,
                "frobenius_norm": 1.523227572441101,
                "spectral_norm": 0.8220261931419373,
                "alpha": 1.5132258474959235,
                "alpha_hat": 1.7968272558097238
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.021866394206881523,
                "median": 0.06215711683034897,
                "std": 0.20589879155158997,
                "max": 0.3574967682361603,
                "min": -0.35203009843826294,
                "frobenius_norm": 1.6564531326293945,
                "spectral_norm": 0.952537477016449,
                "alpha": 1.158685410234326,
                "alpha_hat": 1.3995558572989735
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.011281253769993782,
                "median": -0.01698618195950985,
                "std": 0.2252150923013687,
                "max": 0.40277382731437683,
                "min": -0.32872381806373596,
                "frobenius_norm": 1.8039796352386475,
                "spectral_norm": 1.1589065790176392,
                "alpha": 1.2761885692185702,
                "alpha_hat": 2.123357077238255
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.024765845388174057,
                "median": 0.01793397217988968,
                "std": 0.19215525686740875,
                "max": 0.36478883028030396,
                "min": -0.2903648018836975,
                "frobenius_norm": 1.5499571561813354,
                "spectral_norm": 0.8110975623130798,
                "alpha": 1.1859460736405318,
                "alpha_hat": 1.0573733468855555
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=16_scaler_type=minmax_seed=789": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 789,
        "scores": {
            "smape": 0.1801239401102066,
            "mse": 1425713536.0,
            "mae": 3913.503662109375,
            "r2_score": 0.6920262575149536,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.023997226729989052,
                "median": 0.03454948216676712,
                "std": 0.15978160500526428,
                "max": 0.3069620430469513,
                "min": -0.28710904717445374,
                "frobenius_norm": 1.5830914974212646,
                "spectral_norm": 0.8540485501289368,
                "alpha": 1.4444275349224975,
                "alpha_hat": 1.4778088181616493
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.034578435122966766,
                "median": 0.07850851863622665,
                "std": 0.21173803508281708,
                "max": 0.37753477692604065,
                "min": -0.33032330870628357,
                "frobenius_norm": 1.7163432836532593,
                "spectral_norm": 0.9734875559806824,
                "alpha": 1.2123243020301475,
                "alpha_hat": 1.6864340467139558
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.016383524984121323,
                "median": -0.00839421059936285,
                "std": 0.22637523710727692,
                "max": 0.412070631980896,
                "min": -0.3171639144420624,
                "frobenius_norm": 1.815738558769226,
                "spectral_norm": 1.1505653858184814,
                "alpha": 1.291909949088335,
                "alpha_hat": 2.1427350089868664
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02232695370912552,
                "median": 0.011770693585276604,
                "std": 0.19283735752105713,
                "max": 0.3622879087924957,
                "min": -0.29508620500564575,
                "frobenius_norm": 1.5530046224594116,
                "spectral_norm": 0.8105900883674622,
                "alpha": 1.1828986809607973,
                "alpha_hat": 1.0740092427200445
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=16_scaler_type=minmax_seed=1213": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1213,
        "scores": {
            "smape": 0.1687275767326355,
            "mse": 970768704.0,
            "mae": 3396.074462890625,
            "r2_score": 0.7903006076812744,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.023997226729989052,
                "median": 0.03454948216676712,
                "std": 0.15978160500526428,
                "max": 0.3069620430469513,
                "min": -0.28710904717445374,
                "frobenius_norm": 1.5830914974212646,
                "spectral_norm": 0.8540485501289368,
                "alpha": 1.4444275349224975,
                "alpha_hat": 1.4778088181616493
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.034578435122966766,
                "median": 0.07850851863622665,
                "std": 0.21173803508281708,
                "max": 0.37753477692604065,
                "min": -0.33032330870628357,
                "frobenius_norm": 1.7163432836532593,
                "spectral_norm": 0.9734875559806824,
                "alpha": 1.2123243020301475,
                "alpha_hat": 1.6864340467139558
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.016383524984121323,
                "median": -0.00839421059936285,
                "std": 0.22637523710727692,
                "max": 0.412070631980896,
                "min": -0.3171639144420624,
                "frobenius_norm": 1.815738558769226,
                "spectral_norm": 1.1505653858184814,
                "alpha": 1.291909949088335,
                "alpha_hat": 2.1427350089868664
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02232695370912552,
                "median": 0.011770693585276604,
                "std": 0.19283735752105713,
                "max": 0.3622879087924957,
                "min": -0.29508620500564575,
                "frobenius_norm": 1.5530046224594116,
                "spectral_norm": 0.8105900883674622,
                "alpha": 1.1828986809607973,
                "alpha_hat": 1.0740092427200445
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=16_scaler_type=minmax_seed=1011": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1011,
        "scores": {
            "smape": 0.16763900220394135,
            "mse": 1100274176.0,
            "mae": 3617.1494140625,
            "r2_score": 0.762325644493103,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.023997226729989052,
                "median": 0.03454948216676712,
                "std": 0.15978160500526428,
                "max": 0.3069620430469513,
                "min": -0.28710904717445374,
                "frobenius_norm": 1.5830914974212646,
                "spectral_norm": 0.8540485501289368,
                "alpha": 1.4444275349224975,
                "alpha_hat": 1.4778088181616493
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.034578435122966766,
                "median": 0.07850851863622665,
                "std": 0.21173803508281708,
                "max": 0.37753477692604065,
                "min": -0.33032330870628357,
                "frobenius_norm": 1.7163432836532593,
                "spectral_norm": 0.9734875559806824,
                "alpha": 1.2123243020301475,
                "alpha_hat": 1.6864340467139558
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.016383524984121323,
                "median": -0.00839421059936285,
                "std": 0.22637523710727692,
                "max": 0.412070631980896,
                "min": -0.3171639144420624,
                "frobenius_norm": 1.815738558769226,
                "spectral_norm": 1.1505653858184814,
                "alpha": 1.291909949088335,
                "alpha_hat": 2.1427350089868664
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02232695370912552,
                "median": 0.011770693585276604,
                "std": 0.19283735752105713,
                "max": 0.3622879087924957,
                "min": -0.29508620500564575,
                "frobenius_norm": 1.5530046224594116,
                "spectral_norm": 0.8105900883674622,
                "alpha": 1.1828986809607973,
                "alpha_hat": 1.0740092427200445
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=16_scaler_type=minmax_seed=456": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 456,
        "scores": {
            "smape": 0.1797560602426529,
            "mse": 1420471552.0,
            "mae": 3905.447265625,
            "r2_score": 0.6931585669517517,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.023997226729989052,
                "median": 0.03454948216676712,
                "std": 0.15978160500526428,
                "max": 0.3069620430469513,
                "min": -0.28710904717445374,
                "frobenius_norm": 1.5830914974212646,
                "spectral_norm": 0.8540485501289368,
                "alpha": 1.4444275349224975,
                "alpha_hat": 1.4778088181616493
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.034578435122966766,
                "median": 0.07850851863622665,
                "std": 0.21173803508281708,
                "max": 0.37753477692604065,
                "min": -0.33032330870628357,
                "frobenius_norm": 1.7163432836532593,
                "spectral_norm": 0.9734875559806824,
                "alpha": 1.2123243020301475,
                "alpha_hat": 1.6864340467139558
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.016383524984121323,
                "median": -0.00839421059936285,
                "std": 0.22637523710727692,
                "max": 0.412070631980896,
                "min": -0.3171639144420624,
                "frobenius_norm": 1.815738558769226,
                "spectral_norm": 1.1505653858184814,
                "alpha": 1.291909949088335,
                "alpha_hat": 2.1427350089868664
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02232695370912552,
                "median": 0.011770693585276604,
                "std": 0.19283735752105713,
                "max": 0.3622879087924957,
                "min": -0.29508620500564575,
                "frobenius_norm": 1.5530046224594116,
                "spectral_norm": 0.8105900883674622,
                "alpha": 1.1828986809607973,
                "alpha_hat": 1.0740092427200445
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=16_scaler_type=minmax_seed=1617": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1617,
        "scores": {
            "smape": 0.18117757141590118,
            "mse": 1431028224.0,
            "mae": 3928.63330078125,
            "r2_score": 0.6908782124519348,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.02607175149023533,
                "median": 0.03252699598670006,
                "std": 0.15988369286060333,
                "max": 0.32593756914138794,
                "min": -0.28732016682624817,
                "frobenius_norm": 1.5872248411178589,
                "spectral_norm": 0.8535376191139221,
                "alpha": 1.4575983313300587,
                "alpha_hat": 1.4955989605485047
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.027675487101078033,
                "median": 0.06346632540225983,
                "std": 0.21469096839427948,
                "max": 0.37679943442344666,
                "min": -0.33078375458717346,
                "frobenius_norm": 1.7317394018173218,
                "spectral_norm": 0.9762769937515259,
                "alpha": 1.1792553118525624,
                "alpha_hat": 1.617688174523636
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.016533924266695976,
                "median": -0.007892412133514881,
                "std": 0.22573958337306976,
                "max": 0.41218072175979614,
                "min": -0.31609949469566345,
                "frobenius_norm": 1.8107541799545288,
                "spectral_norm": 1.1445295810699463,
                "alpha": 1.2891576572808852,
                "alpha_hat": 2.2009754199520266
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022191252559423447,
                "median": 0.011946173384785652,
                "std": 0.19279499351978302,
                "max": 0.36558568477630615,
                "min": -0.2945692837238312,
                "frobenius_norm": 1.5525434017181396,
                "spectral_norm": 0.8103085160255432,
                "alpha": 1.1838698906489717,
                "alpha_hat": 1.0695146263067081
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=16_scaler_type=minmax_seed=1415": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1415,
        "scores": {
            "smape": 0.17982302606105804,
            "mse": 1424428288.0,
            "mae": 3909.7099609375,
            "r2_score": 0.6923038959503174,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.02607175149023533,
                "median": 0.03252699598670006,
                "std": 0.15988369286060333,
                "max": 0.32593756914138794,
                "min": -0.28732016682624817,
                "frobenius_norm": 1.5872248411178589,
                "spectral_norm": 0.8535376191139221,
                "alpha": 1.4575983313300587,
                "alpha_hat": 1.4955989605485047
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.027675487101078033,
                "median": 0.06346632540225983,
                "std": 0.21469096839427948,
                "max": 0.37679943442344666,
                "min": -0.33078375458717346,
                "frobenius_norm": 1.7317394018173218,
                "spectral_norm": 0.9762769937515259,
                "alpha": 1.1792553118525624,
                "alpha_hat": 1.617688174523636
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.016533924266695976,
                "median": -0.007892412133514881,
                "std": 0.22573958337306976,
                "max": 0.41218072175979614,
                "min": -0.31609949469566345,
                "frobenius_norm": 1.8107541799545288,
                "spectral_norm": 1.1445295810699463,
                "alpha": 1.2891576572808852,
                "alpha_hat": 2.2009754199520266
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022191252559423447,
                "median": 0.011946173384785652,
                "std": 0.19279499351978302,
                "max": 0.36558568477630615,
                "min": -0.2945692837238312,
                "frobenius_norm": 1.5525434017181396,
                "spectral_norm": 0.8103085160255432,
                "alpha": 1.1838698906489717,
                "alpha_hat": 1.0695146263067081
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=16_scaler_type=minmax_seed=2021": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 2021,
        "scores": {
            "smape": 0.18002882599830627,
            "mse": 1422655104.0,
            "mae": 3910.0625,
            "r2_score": 0.692686915397644,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.02607175149023533,
                "median": 0.03252699598670006,
                "std": 0.15988369286060333,
                "max": 0.32593756914138794,
                "min": -0.28732016682624817,
                "frobenius_norm": 1.5872248411178589,
                "spectral_norm": 0.8535376191139221,
                "alpha": 1.4575983313300587,
                "alpha_hat": 1.4955989605485047
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.027675487101078033,
                "median": 0.06346632540225983,
                "std": 0.21469096839427948,
                "max": 0.37679943442344666,
                "min": -0.33078375458717346,
                "frobenius_norm": 1.7317394018173218,
                "spectral_norm": 0.9762769937515259,
                "alpha": 1.1792553118525624,
                "alpha_hat": 1.617688174523636
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.016533924266695976,
                "median": -0.007892412133514881,
                "std": 0.22573958337306976,
                "max": 0.41218072175979614,
                "min": -0.31609949469566345,
                "frobenius_norm": 1.8107541799545288,
                "spectral_norm": 1.1445295810699463,
                "alpha": 1.2891576572808852,
                "alpha_hat": 2.2009754199520266
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022191252559423447,
                "median": 0.011946173384785652,
                "std": 0.19279499351978302,
                "max": 0.36558568477630615,
                "min": -0.2945692837238312,
                "frobenius_norm": 1.5525434017181396,
                "spectral_norm": 0.8103085160255432,
                "alpha": 1.1838698906489717,
                "alpha_hat": 1.0695146263067081
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=16_scaler_type=minmax_seed=1819": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1819,
        "scores": {
            "smape": 0.180247962474823,
            "mse": 1427741184.0,
            "mae": 3916.91015625,
            "r2_score": 0.6915882229804993,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.02607175149023533,
                "median": 0.03252699598670006,
                "std": 0.15988369286060333,
                "max": 0.32593756914138794,
                "min": -0.28732016682624817,
                "frobenius_norm": 1.5872248411178589,
                "spectral_norm": 0.8535376191139221,
                "alpha": 1.4575983313300587,
                "alpha_hat": 1.4955989605485047
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.027675487101078033,
                "median": 0.06346632540225983,
                "std": 0.21469096839427948,
                "max": 0.37679943442344666,
                "min": -0.33078375458717346,
                "frobenius_norm": 1.7317394018173218,
                "spectral_norm": 0.9762769937515259,
                "alpha": 1.1792553118525624,
                "alpha_hat": 1.617688174523636
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.016533924266695976,
                "median": -0.007892412133514881,
                "std": 0.22573958337306976,
                "max": 0.41218072175979614,
                "min": -0.31609949469566345,
                "frobenius_norm": 1.8107541799545288,
                "spectral_norm": 1.1445295810699463,
                "alpha": 1.2891576572808852,
                "alpha_hat": 2.2009754199520266
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022191252559423447,
                "median": 0.011946173384785652,
                "std": 0.19279499351978302,
                "max": 0.36558568477630615,
                "min": -0.2945692837238312,
                "frobenius_norm": 1.5525434017181396,
                "spectral_norm": 0.8103085160255432,
                "alpha": 1.1838698906489717,
                "alpha_hat": 1.0695146263067081
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=32_scaler_type=identity_seed=456": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 456,
        "scores": {
            "smape": 0.5923036336898804,
            "mse": 3610623232.0,
            "mae": 8132.26904296875,
            "r2_score": 0.22005563974380493,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.04490109160542488,
                "median": 0.036577872931957245,
                "std": 0.15997672080993652,
                "max": 0.3462882936000824,
                "min": -0.27612635493278503,
                "frobenius_norm": 1.6280145645141602,
                "spectral_norm": 0.8612181544303894,
                "alpha": 1.668766835361401,
                "alpha_hat": 2.1943401579539086
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.047669731080532074,
                "median": 0.08382008969783783,
                "std": 0.22171185910701752,
                "max": 0.4215869605541229,
                "min": -0.31131070852279663,
                "frobenius_norm": 1.8142292499542236,
                "spectral_norm": 1.1519992351531982,
                "alpha": 1.0679719511943722,
                "alpha_hat": 1.5576805338059656
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03561801463365555,
                "median": 0.003900362178683281,
                "std": 0.2267863154411316,
                "max": 0.41731205582618713,
                "min": -0.3029337525367737,
                "frobenius_norm": 1.836530327796936,
                "spectral_norm": 1.1750361919403076,
                "alpha": 1.312782217949673,
                "alpha_hat": 2.4456629267039656
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06143506243824959,
                "median": 0.05004327371716499,
                "std": 0.19467803835868835,
                "max": 0.408231258392334,
                "min": -0.26038941740989685,
                "frobenius_norm": 1.6331331729888916,
                "spectral_norm": 0.9338351488113403,
                "alpha": 1.2611649528588604,
                "alpha_hat": 1.276057888639171
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=32_scaler_type=identity_seed=123": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 123,
        "scores": {
            "smape": 0.5961706042289734,
            "mse": 3629179648.0,
            "mae": 8167.74462890625,
            "r2_score": 0.21604716777801514,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.04490109160542488,
                "median": 0.036577872931957245,
                "std": 0.15997672080993652,
                "max": 0.3462882936000824,
                "min": -0.27612635493278503,
                "frobenius_norm": 1.6280145645141602,
                "spectral_norm": 0.8612181544303894,
                "alpha": 1.668766835361401,
                "alpha_hat": 2.1943401579539086
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.047669731080532074,
                "median": 0.08382008969783783,
                "std": 0.22171185910701752,
                "max": 0.4215869605541229,
                "min": -0.31131070852279663,
                "frobenius_norm": 1.8142292499542236,
                "spectral_norm": 1.1519992351531982,
                "alpha": 1.0679719511943722,
                "alpha_hat": 1.5576805338059656
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03561801463365555,
                "median": 0.003900362178683281,
                "std": 0.2267863154411316,
                "max": 0.41731205582618713,
                "min": -0.3029337525367737,
                "frobenius_norm": 1.836530327796936,
                "spectral_norm": 1.1750361919403076,
                "alpha": 1.312782217949673,
                "alpha_hat": 2.4456629267039656
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06143506243824959,
                "median": 0.05004327371716499,
                "std": 0.19467803835868835,
                "max": 0.408231258392334,
                "min": -0.26038941740989685,
                "frobenius_norm": 1.6331331729888916,
                "spectral_norm": 0.9338351488113403,
                "alpha": 1.2611649528588604,
                "alpha_hat": 1.276057888639171
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=32_scaler_type=identity_seed=42": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 42,
        "scores": {
            "smape": 0.5905895829200745,
            "mse": 3602019584.0,
            "mae": 8113.3056640625,
            "r2_score": 0.2219141125679016,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.04490109160542488,
                "median": 0.036577872931957245,
                "std": 0.15997672080993652,
                "max": 0.3462882936000824,
                "min": -0.27612635493278503,
                "frobenius_norm": 1.6280145645141602,
                "spectral_norm": 0.8612181544303894,
                "alpha": 1.668766835361401,
                "alpha_hat": 2.1943401579539086
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.047669731080532074,
                "median": 0.08382008969783783,
                "std": 0.22171185910701752,
                "max": 0.4215869605541229,
                "min": -0.31131070852279663,
                "frobenius_norm": 1.8142292499542236,
                "spectral_norm": 1.1519992351531982,
                "alpha": 1.0679719511943722,
                "alpha_hat": 1.5576805338059656
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03561801463365555,
                "median": 0.003900362178683281,
                "std": 0.2267863154411316,
                "max": 0.41731205582618713,
                "min": -0.3029337525367737,
                "frobenius_norm": 1.836530327796936,
                "spectral_norm": 1.1750361919403076,
                "alpha": 1.312782217949673,
                "alpha_hat": 2.4456629267039656
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06143506243824959,
                "median": 0.05004327371716499,
                "std": 0.19467803835868835,
                "max": 0.408231258392334,
                "min": -0.26038941740989685,
                "frobenius_norm": 1.6331331729888916,
                "spectral_norm": 0.9338351488113403,
                "alpha": 1.2611649528588604,
                "alpha_hat": 1.276057888639171
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=32_scaler_type=identity_seed=789": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 789,
        "scores": {
            "smape": 0.5935526490211487,
            "mse": 3612417792.0,
            "mae": 8138.509765625,
            "r2_score": 0.2196679711341858,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.04490109160542488,
                "median": 0.036577872931957245,
                "std": 0.15997672080993652,
                "max": 0.3462882936000824,
                "min": -0.27612635493278503,
                "frobenius_norm": 1.6280145645141602,
                "spectral_norm": 0.8612181544303894,
                "alpha": 1.668766835361401,
                "alpha_hat": 2.1943401579539086
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.047669731080532074,
                "median": 0.08382008969783783,
                "std": 0.22171185910701752,
                "max": 0.4215869605541229,
                "min": -0.31131070852279663,
                "frobenius_norm": 1.8142292499542236,
                "spectral_norm": 1.1519992351531982,
                "alpha": 1.0679719511943722,
                "alpha_hat": 1.5576805338059656
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03561801463365555,
                "median": 0.003900362178683281,
                "std": 0.2267863154411316,
                "max": 0.41731205582618713,
                "min": -0.3029337525367737,
                "frobenius_norm": 1.836530327796936,
                "spectral_norm": 1.1750361919403076,
                "alpha": 1.312782217949673,
                "alpha_hat": 2.4456629267039656
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06143506243824959,
                "median": 0.05004327371716499,
                "std": 0.19467803835868835,
                "max": 0.408231258392334,
                "min": -0.26038941740989685,
                "frobenius_norm": 1.6331331729888916,
                "spectral_norm": 0.9338351488113403,
                "alpha": 1.2611649528588604,
                "alpha_hat": 1.276057888639171
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=32_scaler_type=identity_seed=1213": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1213,
        "scores": {
            "smape": 0.5830326676368713,
            "mse": 3565709568.0,
            "mae": 8042.77783203125,
            "r2_score": 0.22975760698318481,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.050315458327531815,
                "median": 0.052853986620903015,
                "std": 0.15737509727478027,
                "max": 0.34735217690467834,
                "min": -0.2563752830028534,
                "frobenius_norm": 1.6188459396362305,
                "spectral_norm": 0.9330011606216431,
                "alpha": 1.5124641835425707,
                "alpha_hat": 1.8914074448224831
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.030801840126514435,
                "median": 0.03599231690168381,
                "std": 0.22025460004806519,
                "max": 0.4052232503890991,
                "min": -0.33984795212745667,
                "frobenius_norm": 1.7791835069656372,
                "spectral_norm": 1.0183395147323608,
                "alpha": 1.2226634320981575,
                "alpha_hat": 1.6409762666081493
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.013285264372825623,
                "median": 0.0013286119792610407,
                "std": 0.2255275994539261,
                "max": 0.4022429287433624,
                "min": -0.3260694146156311,
                "frobenius_norm": 1.807348608970642,
                "spectral_norm": 1.0800701379776,
                "alpha": 1.1596732203746734,
                "alpha_hat": 1.4721133792758052
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04987284541130066,
                "median": 0.05648789182305336,
                "std": 0.21072079241275787,
                "max": 0.4021276831626892,
                "min": -0.29671305418014526,
                "frobenius_norm": 1.7323380708694458,
                "spectral_norm": 1.118080735206604,
                "alpha": 1.3277618026226927,
                "alpha_hat": 3.074188411693892
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=32_scaler_type=identity_seed=1011": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1011,
        "scores": {
            "smape": 0.5995540618896484,
            "mse": 3629903616.0,
            "mae": 8189.2607421875,
            "r2_score": 0.2158907651901245,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.050315458327531815,
                "median": 0.052853986620903015,
                "std": 0.15737509727478027,
                "max": 0.34735217690467834,
                "min": -0.2563752830028534,
                "frobenius_norm": 1.6188459396362305,
                "spectral_norm": 0.9330011606216431,
                "alpha": 1.5124641835425707,
                "alpha_hat": 1.8914074448224831
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.030801840126514435,
                "median": 0.03599231690168381,
                "std": 0.22025460004806519,
                "max": 0.4052232503890991,
                "min": -0.33984795212745667,
                "frobenius_norm": 1.7791835069656372,
                "spectral_norm": 1.0183395147323608,
                "alpha": 1.2226634320981575,
                "alpha_hat": 1.6409762666081493
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.013285264372825623,
                "median": 0.0013286119792610407,
                "std": 0.2255275994539261,
                "max": 0.4022429287433624,
                "min": -0.3260694146156311,
                "frobenius_norm": 1.807348608970642,
                "spectral_norm": 1.0800701379776,
                "alpha": 1.1596732203746734,
                "alpha_hat": 1.4721133792758052
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04987284541130066,
                "median": 0.05648789182305336,
                "std": 0.21072079241275787,
                "max": 0.4021276831626892,
                "min": -0.29671305418014526,
                "frobenius_norm": 1.7323380708694458,
                "spectral_norm": 1.118080735206604,
                "alpha": 1.3277618026226927,
                "alpha_hat": 3.074188411693892
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=32_scaler_type=identity_seed=1415": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1415,
        "scores": {
            "smape": 0.9315180778503418,
            "mse": 4647299072.0,
            "mae": 10770.513671875,
            "r2_score": -0.003880620002746582,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.050315458327531815,
                "median": 0.052853986620903015,
                "std": 0.15737509727478027,
                "max": 0.34735217690467834,
                "min": -0.2563752830028534,
                "frobenius_norm": 1.6188459396362305,
                "spectral_norm": 0.9330011606216431,
                "alpha": 1.5124641835425707,
                "alpha_hat": 1.8914074448224831
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.030801840126514435,
                "median": 0.03599231690168381,
                "std": 0.22025460004806519,
                "max": 0.4052232503890991,
                "min": -0.33984795212745667,
                "frobenius_norm": 1.7791835069656372,
                "spectral_norm": 1.0183395147323608,
                "alpha": 1.2226634320981575,
                "alpha_hat": 1.6409762666081493
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.013285264372825623,
                "median": 0.0013286119792610407,
                "std": 0.2255275994539261,
                "max": 0.4022429287433624,
                "min": -0.3260694146156311,
                "frobenius_norm": 1.807348608970642,
                "spectral_norm": 1.0800701379776,
                "alpha": 1.1596732203746734,
                "alpha_hat": 1.4721133792758052
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04987284541130066,
                "median": 0.05648789182305336,
                "std": 0.21072079241275787,
                "max": 0.4021276831626892,
                "min": -0.29671305418014526,
                "frobenius_norm": 1.7323380708694458,
                "spectral_norm": 1.118080735206604,
                "alpha": 1.3277618026226927,
                "alpha_hat": 3.074188411693892
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=32_scaler_type=identity_seed=1617": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1617,
        "scores": {
            "smape": 0.7351881265640259,
            "mse": 3611110144.0,
            "mae": 9399.8544921875,
            "r2_score": 0.21995043754577637,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.050315458327531815,
                "median": 0.052853986620903015,
                "std": 0.15737509727478027,
                "max": 0.34735217690467834,
                "min": -0.2563752830028534,
                "frobenius_norm": 1.6188459396362305,
                "spectral_norm": 0.9330011606216431,
                "alpha": 1.5124641835425707,
                "alpha_hat": 1.8914074448224831
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.030801840126514435,
                "median": 0.03599231690168381,
                "std": 0.22025460004806519,
                "max": 0.4052232503890991,
                "min": -0.33984795212745667,
                "frobenius_norm": 1.7791835069656372,
                "spectral_norm": 1.0183395147323608,
                "alpha": 1.2226634320981575,
                "alpha_hat": 1.6409762666081493
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.013285264372825623,
                "median": 0.0013286119792610407,
                "std": 0.2255275994539261,
                "max": 0.4022429287433624,
                "min": -0.3260694146156311,
                "frobenius_norm": 1.807348608970642,
                "spectral_norm": 1.0800701379776,
                "alpha": 1.1596732203746734,
                "alpha_hat": 1.4721133792758052
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04987284541130066,
                "median": 0.05648789182305336,
                "std": 0.21072079241275787,
                "max": 0.4021276831626892,
                "min": -0.29671305418014526,
                "frobenius_norm": 1.7323380708694458,
                "spectral_norm": 1.118080735206604,
                "alpha": 1.3277618026226927,
                "alpha_hat": 3.074188411693892
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=32_scaler_type=identity_seed=2021": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 2021,
        "scores": {
            "smape": 0.5808033347129822,
            "mse": 3566003968.0,
            "mae": 8034.71630859375,
            "r2_score": 0.22969400882720947,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.006249664817005396,
                "median": -0.005366221070289612,
                "std": 0.1532154530286789,
                "max": 0.28383585810661316,
                "min": -0.2989940345287323,
                "frobenius_norm": 1.5024470090866089,
                "spectral_norm": 0.8415310978889465,
                "alpha": 1.546822060288704,
                "alpha_hat": 1.9301605124559413
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.012008389458060265,
                "median": 0.054017625749111176,
                "std": 0.20830795168876648,
                "max": 0.38313040137290955,
                "min": -0.353350967168808,
                "frobenius_norm": 1.6692304611206055,
                "spectral_norm": 0.9796121120452881,
                "alpha": 1.1288415487735404,
                "alpha_hat": 1.3906669766060384
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.015646617859601974,
                "median": 0.05597102269530296,
                "std": 0.210890531539917,
                "max": 0.35594087839126587,
                "min": -0.33371198177337646,
                "frobenius_norm": 1.6917613744735718,
                "spectral_norm": 0.9376251101493835,
                "alpha": 1.2178289911322189,
                "alpha_hat": 1.686709691228287
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.009786195121705532,
                "median": -0.015238369815051556,
                "std": 0.1963900923728943,
                "max": 0.3439275324344635,
                "min": -0.339403361082077,
                "frobenius_norm": 1.5730701684951782,
                "spectral_norm": 0.8370747566223145,
                "alpha": 1.3250419879789517,
                "alpha_hat": 1.3907579170712172
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=32_scaler_type=identity_seed=1819": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "seed": 1819,
        "scores": {
            "smape": 0.6014470458030701,
            "mse": 3645401600.0,
            "mae": 8214.9052734375,
            "r2_score": 0.21254301071166992,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.006249664817005396,
                "median": -0.005366221070289612,
                "std": 0.1532154530286789,
                "max": 0.28383585810661316,
                "min": -0.2989940345287323,
                "frobenius_norm": 1.5024470090866089,
                "spectral_norm": 0.8415310978889465,
                "alpha": 1.546822060288704,
                "alpha_hat": 1.9301605124559413
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.012008389458060265,
                "median": 0.054017625749111176,
                "std": 0.20830795168876648,
                "max": 0.38313040137290955,
                "min": -0.353350967168808,
                "frobenius_norm": 1.6692304611206055,
                "spectral_norm": 0.9796121120452881,
                "alpha": 1.1288415487735404,
                "alpha_hat": 1.3906669766060384
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.015646617859601974,
                "median": 0.05597102269530296,
                "std": 0.210890531539917,
                "max": 0.35594087839126587,
                "min": -0.33371198177337646,
                "frobenius_norm": 1.6917613744735718,
                "spectral_norm": 0.9376251101493835,
                "alpha": 1.2178289911322189,
                "alpha_hat": 1.686709691228287
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.009786195121705532,
                "median": -0.015238369815051556,
                "std": 0.1963900923728943,
                "max": 0.3439275324344635,
                "min": -0.339403361082077,
                "frobenius_norm": 1.5730701684951782,
                "spectral_norm": 0.8370747566223145,
                "alpha": 1.3250419879789517,
                "alpha_hat": 1.3907579170712172
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=32_scaler_type=standard_seed=42": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 42,
        "scores": {
            "smape": 0.08047657459974289,
            "mse": 512749696.0,
            "mae": 2104.6396484375,
            "r2_score": 0.8892390131950378,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.006249664817005396,
                "median": -0.005366221070289612,
                "std": 0.1532154530286789,
                "max": 0.28383585810661316,
                "min": -0.2989940345287323,
                "frobenius_norm": 1.5024470090866089,
                "spectral_norm": 0.8415310978889465,
                "alpha": 1.546822060288704,
                "alpha_hat": 1.9301605124559413
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.012008389458060265,
                "median": 0.054017625749111176,
                "std": 0.20830795168876648,
                "max": 0.38313040137290955,
                "min": -0.353350967168808,
                "frobenius_norm": 1.6692304611206055,
                "spectral_norm": 0.9796121120452881,
                "alpha": 1.1288415487735404,
                "alpha_hat": 1.3906669766060384
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.015646617859601974,
                "median": 0.05597102269530296,
                "std": 0.210890531539917,
                "max": 0.35594087839126587,
                "min": -0.33371198177337646,
                "frobenius_norm": 1.6917613744735718,
                "spectral_norm": 0.9376251101493835,
                "alpha": 1.2178289911322189,
                "alpha_hat": 1.686709691228287
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.009786195121705532,
                "median": -0.015238369815051556,
                "std": 0.1963900923728943,
                "max": 0.3439275324344635,
                "min": -0.339403361082077,
                "frobenius_norm": 1.5730701684951782,
                "spectral_norm": 0.8370747566223145,
                "alpha": 1.3250419879789517,
                "alpha_hat": 1.3907579170712172
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=32_scaler_type=standard_seed=123": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 123,
        "scores": {
            "smape": 0.08062462508678436,
            "mse": 523189184.0,
            "mae": 2102.941162109375,
            "r2_score": 0.8869839310646057,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.006249664817005396,
                "median": -0.005366221070289612,
                "std": 0.1532154530286789,
                "max": 0.28383585810661316,
                "min": -0.2989940345287323,
                "frobenius_norm": 1.5024470090866089,
                "spectral_norm": 0.8415310978889465,
                "alpha": 1.546822060288704,
                "alpha_hat": 1.9301605124559413
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.012008389458060265,
                "median": 0.054017625749111176,
                "std": 0.20830795168876648,
                "max": 0.38313040137290955,
                "min": -0.353350967168808,
                "frobenius_norm": 1.6692304611206055,
                "spectral_norm": 0.9796121120452881,
                "alpha": 1.1288415487735404,
                "alpha_hat": 1.3906669766060384
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.015646617859601974,
                "median": 0.05597102269530296,
                "std": 0.210890531539917,
                "max": 0.35594087839126587,
                "min": -0.33371198177337646,
                "frobenius_norm": 1.6917613744735718,
                "spectral_norm": 0.9376251101493835,
                "alpha": 1.2178289911322189,
                "alpha_hat": 1.686709691228287
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.009786195121705532,
                "median": -0.015238369815051556,
                "std": 0.1963900923728943,
                "max": 0.3439275324344635,
                "min": -0.339403361082077,
                "frobenius_norm": 1.5730701684951782,
                "spectral_norm": 0.8370747566223145,
                "alpha": 1.3250419879789517,
                "alpha_hat": 1.3907579170712172
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=32_scaler_type=standard_seed=789": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 789,
        "scores": {
            "smape": 0.08021756261587143,
            "mse": 597227904.0,
            "mae": 2155.48193359375,
            "r2_score": 0.870990514755249,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.008512687869369984,
                "median": 0.029487479478120804,
                "std": 0.15496015548706055,
                "max": 0.2942953407764435,
                "min": -0.2829827070236206,
                "frobenius_norm": 1.5205824375152588,
                "spectral_norm": 0.8218914270401001,
                "alpha": 1.534062189887927,
                "alpha_hat": 1.7592196070659003
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.009983695112168789,
                "median": 0.05278686434030533,
                "std": 0.21104606986045837,
                "max": 0.35681140422821045,
                "min": -0.38059917092323303,
                "frobenius_norm": 1.6902567148208618,
                "spectral_norm": 0.979745090007782,
                "alpha": 1.1092010583019802,
                "alpha_hat": 1.3713757360983312
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.011420266702771187,
                "median": -0.010717160999774933,
                "std": 0.2233869582414627,
                "max": 0.40178945660591125,
                "min": -0.3100443482398987,
                "frobenius_norm": 1.7894295454025269,
                "spectral_norm": 1.1575993299484253,
                "alpha": 1.2679153022225678,
                "alpha_hat": 2.082987451665127
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022451071068644524,
                "median": 0.011227475479245186,
                "std": 0.19254660606384277,
                "max": 0.36056697368621826,
                "min": -0.2915574014186859,
                "frobenius_norm": 1.5508087873458862,
                "spectral_norm": 0.8070371150970459,
                "alpha": 1.189450774526943,
                "alpha_hat": 1.0713896808011831
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=32_scaler_type=standard_seed=456": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 456,
        "scores": {
            "smape": 0.08019319176673889,
            "mse": 597391168.0,
            "mae": 2155.241943359375,
            "r2_score": 0.8709552884101868,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.008512687869369984,
                "median": 0.029487479478120804,
                "std": 0.15496015548706055,
                "max": 0.2942953407764435,
                "min": -0.2829827070236206,
                "frobenius_norm": 1.5205824375152588,
                "spectral_norm": 0.8218914270401001,
                "alpha": 1.534062189887927,
                "alpha_hat": 1.7592196070659003
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.009983695112168789,
                "median": 0.05278686434030533,
                "std": 0.21104606986045837,
                "max": 0.35681140422821045,
                "min": -0.38059917092323303,
                "frobenius_norm": 1.6902567148208618,
                "spectral_norm": 0.979745090007782,
                "alpha": 1.1092010583019802,
                "alpha_hat": 1.3713757360983312
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.011420266702771187,
                "median": -0.010717160999774933,
                "std": 0.2233869582414627,
                "max": 0.40178945660591125,
                "min": -0.3100443482398987,
                "frobenius_norm": 1.7894295454025269,
                "spectral_norm": 1.1575993299484253,
                "alpha": 1.2679153022225678,
                "alpha_hat": 2.082987451665127
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022451071068644524,
                "median": 0.011227475479245186,
                "std": 0.19254660606384277,
                "max": 0.36056697368621826,
                "min": -0.2915574014186859,
                "frobenius_norm": 1.5508087873458862,
                "spectral_norm": 0.8070371150970459,
                "alpha": 1.189450774526943,
                "alpha_hat": 1.0713896808011831
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=32_scaler_type=standard_seed=1213": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1213,
        "scores": {
            "smape": 0.08020521700382233,
            "mse": 596662272.0,
            "mae": 2154.481689453125,
            "r2_score": 0.8711127042770386,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.008512687869369984,
                "median": 0.029487479478120804,
                "std": 0.15496015548706055,
                "max": 0.2942953407764435,
                "min": -0.2829827070236206,
                "frobenius_norm": 1.5205824375152588,
                "spectral_norm": 0.8218914270401001,
                "alpha": 1.534062189887927,
                "alpha_hat": 1.7592196070659003
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.009983695112168789,
                "median": 0.05278686434030533,
                "std": 0.21104606986045837,
                "max": 0.35681140422821045,
                "min": -0.38059917092323303,
                "frobenius_norm": 1.6902567148208618,
                "spectral_norm": 0.979745090007782,
                "alpha": 1.1092010583019802,
                "alpha_hat": 1.3713757360983312
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.011420266702771187,
                "median": -0.010717160999774933,
                "std": 0.2233869582414627,
                "max": 0.40178945660591125,
                "min": -0.3100443482398987,
                "frobenius_norm": 1.7894295454025269,
                "spectral_norm": 1.1575993299484253,
                "alpha": 1.2679153022225678,
                "alpha_hat": 2.082987451665127
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022451071068644524,
                "median": 0.011227475479245186,
                "std": 0.19254660606384277,
                "max": 0.36056697368621826,
                "min": -0.2915574014186859,
                "frobenius_norm": 1.5508087873458862,
                "spectral_norm": 0.8070371150970459,
                "alpha": 1.189450774526943,
                "alpha_hat": 1.0713896808011831
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=32_scaler_type=standard_seed=1011": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1011,
        "scores": {
            "smape": 0.08021710067987442,
            "mse": 597159232.0,
            "mae": 2155.401123046875,
            "r2_score": 0.8710053563117981,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.008512687869369984,
                "median": 0.029487479478120804,
                "std": 0.15496015548706055,
                "max": 0.2942953407764435,
                "min": -0.2829827070236206,
                "frobenius_norm": 1.5205824375152588,
                "spectral_norm": 0.8218914270401001,
                "alpha": 1.534062189887927,
                "alpha_hat": 1.7592196070659003
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.009983695112168789,
                "median": 0.05278686434030533,
                "std": 0.21104606986045837,
                "max": 0.35681140422821045,
                "min": -0.38059917092323303,
                "frobenius_norm": 1.6902567148208618,
                "spectral_norm": 0.979745090007782,
                "alpha": 1.1092010583019802,
                "alpha_hat": 1.3713757360983312
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.011420266702771187,
                "median": -0.010717160999774933,
                "std": 0.2233869582414627,
                "max": 0.40178945660591125,
                "min": -0.3100443482398987,
                "frobenius_norm": 1.7894295454025269,
                "spectral_norm": 1.1575993299484253,
                "alpha": 1.2679153022225678,
                "alpha_hat": 2.082987451665127
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022451071068644524,
                "median": 0.011227475479245186,
                "std": 0.19254660606384277,
                "max": 0.36056697368621826,
                "min": -0.2915574014186859,
                "frobenius_norm": 1.5508087873458862,
                "spectral_norm": 0.8070371150970459,
                "alpha": 1.189450774526943,
                "alpha_hat": 1.0713896808011831
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=32_scaler_type=standard_seed=1415": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1415,
        "scores": {
            "smape": 0.08017732203006744,
            "mse": 596182912.0,
            "mae": 2153.4833984375,
            "r2_score": 0.8712162971496582,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.008426501415669918,
                "median": 0.033685360103845596,
                "std": 0.15494872629642487,
                "max": 0.2923017740249634,
                "min": -0.287200003862381,
                "frobenius_norm": 1.5204246044158936,
                "spectral_norm": 0.822300910949707,
                "alpha": 1.531762529393792,
                "alpha_hat": 1.7522064040015453
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.010286696255207062,
                "median": 0.04590889811515808,
                "std": 0.2112513780593872,
                "max": 0.3568724989891052,
                "min": -0.3798913061618805,
                "frobenius_norm": 1.6920135021209717,
                "spectral_norm": 0.9795038104057312,
                "alpha": 1.0846522792599498,
                "alpha_hat": 1.344303584897282
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.012141804210841656,
                "median": -0.010849103331565857,
                "std": 0.2234228551387787,
                "max": 0.4023514986038208,
                "min": -0.3100033402442932,
                "frobenius_norm": 1.790020227432251,
                "spectral_norm": 1.1572723388671875,
                "alpha": 1.2747057650994316,
                "alpha_hat": 2.118282369467774
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02317296527326107,
                "median": 0.011317789554595947,
                "std": 0.19253697991371155,
                "max": 0.36199915409088135,
                "min": -0.29008302092552185,
                "frobenius_norm": 1.551411747932434,
                "spectral_norm": 0.8088500499725342,
                "alpha": 1.189715431718469,
                "alpha_hat": 1.0722884067749199
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=32_scaler_type=standard_seed=2021": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 2021,
        "scores": {
            "smape": 0.08020064234733582,
            "mse": 596712064.0,
            "mae": 2154.3994140625,
            "r2_score": 0.871101975440979,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.008426501415669918,
                "median": 0.033685360103845596,
                "std": 0.15494872629642487,
                "max": 0.2923017740249634,
                "min": -0.287200003862381,
                "frobenius_norm": 1.5204246044158936,
                "spectral_norm": 0.822300910949707,
                "alpha": 1.531762529393792,
                "alpha_hat": 1.7522064040015453
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.010286696255207062,
                "median": 0.04590889811515808,
                "std": 0.2112513780593872,
                "max": 0.3568724989891052,
                "min": -0.3798913061618805,
                "frobenius_norm": 1.6920135021209717,
                "spectral_norm": 0.9795038104057312,
                "alpha": 1.0846522792599498,
                "alpha_hat": 1.344303584897282
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.012141804210841656,
                "median": -0.010849103331565857,
                "std": 0.2234228551387787,
                "max": 0.4023514986038208,
                "min": -0.3100033402442932,
                "frobenius_norm": 1.790020227432251,
                "spectral_norm": 1.1572723388671875,
                "alpha": 1.2747057650994316,
                "alpha_hat": 2.118282369467774
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02317296527326107,
                "median": 0.011317789554595947,
                "std": 0.19253697991371155,
                "max": 0.36199915409088135,
                "min": -0.29008302092552185,
                "frobenius_norm": 1.551411747932434,
                "spectral_norm": 0.8088500499725342,
                "alpha": 1.189715431718469,
                "alpha_hat": 1.0722884067749199
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=32_scaler_type=standard_seed=1819": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1819,
        "scores": {
            "smape": 0.08018992096185684,
            "mse": 596847808.0,
            "mae": 2154.556396484375,
            "r2_score": 0.8710726499557495,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.008426501415669918,
                "median": 0.033685360103845596,
                "std": 0.15494872629642487,
                "max": 0.2923017740249634,
                "min": -0.287200003862381,
                "frobenius_norm": 1.5204246044158936,
                "spectral_norm": 0.822300910949707,
                "alpha": 1.531762529393792,
                "alpha_hat": 1.7522064040015453
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.010286696255207062,
                "median": 0.04590889811515808,
                "std": 0.2112513780593872,
                "max": 0.3568724989891052,
                "min": -0.3798913061618805,
                "frobenius_norm": 1.6920135021209717,
                "spectral_norm": 0.9795038104057312,
                "alpha": 1.0846522792599498,
                "alpha_hat": 1.344303584897282
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.012141804210841656,
                "median": -0.010849103331565857,
                "std": 0.2234228551387787,
                "max": 0.4023514986038208,
                "min": -0.3100033402442932,
                "frobenius_norm": 1.790020227432251,
                "spectral_norm": 1.1572723388671875,
                "alpha": 1.2747057650994316,
                "alpha_hat": 2.118282369467774
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02317296527326107,
                "median": 0.011317789554595947,
                "std": 0.19253697991371155,
                "max": 0.36199915409088135,
                "min": -0.29008302092552185,
                "frobenius_norm": 1.551411747932434,
                "spectral_norm": 0.8088500499725342,
                "alpha": 1.189715431718469,
                "alpha_hat": 1.0722884067749199
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=32_scaler_type=standard_seed=1617": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 320
        },
        "seed": 1617,
        "scores": {
            "smape": 0.08021841198205948,
            "mse": 596269440.0,
            "mae": 2154.370849609375,
            "r2_score": 0.8711975812911987,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.008426501415669918,
                "median": 0.033685360103845596,
                "std": 0.15494872629642487,
                "max": 0.2923017740249634,
                "min": -0.287200003862381,
                "frobenius_norm": 1.5204246044158936,
                "spectral_norm": 0.822300910949707,
                "alpha": 1.531762529393792,
                "alpha_hat": 1.7522064040015453
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.010286696255207062,
                "median": 0.04590889811515808,
                "std": 0.2112513780593872,
                "max": 0.3568724989891052,
                "min": -0.3798913061618805,
                "frobenius_norm": 1.6920135021209717,
                "spectral_norm": 0.9795038104057312,
                "alpha": 1.0846522792599498,
                "alpha_hat": 1.344303584897282
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.012141804210841656,
                "median": -0.010849103331565857,
                "std": 0.2234228551387787,
                "max": 0.4023514986038208,
                "min": -0.3100033402442932,
                "frobenius_norm": 1.790020227432251,
                "spectral_norm": 1.1572723388671875,
                "alpha": 1.2747057650994316,
                "alpha_hat": 2.118282369467774
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02317296527326107,
                "median": 0.011317789554595947,
                "std": 0.19253697991371155,
                "max": 0.36199915409088135,
                "min": -0.29008302092552185,
                "frobenius_norm": 1.551411747932434,
                "spectral_norm": 0.8088500499725342,
                "alpha": 1.189715431718469,
                "alpha_hat": 1.0722884067749199
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=32_scaler_type=robust_seed=789": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 789,
        "scores": {
            "smape": 0.08022895455360413,
            "mse": 625785536.0,
            "mae": 2145.85693359375,
            "r2_score": 0.8648216724395752,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.005059372168034315,
                "median": 0.000793665531091392,
                "std": 0.15703028440475464,
                "max": 0.3098128139972687,
                "min": -0.32801002264022827,
                "frobenius_norm": 1.539374589920044,
                "spectral_norm": 0.8573864698410034,
                "alpha": 1.3833502988714619,
                "alpha_hat": 1.7268829515894764
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.00871012732386589,
                "median": -0.03370235860347748,
                "std": 0.19516167044639587,
                "max": 0.3274138271808624,
                "min": -0.3582198917865753,
                "frobenius_norm": 1.56284761428833,
                "spectral_norm": 1.0453228950500488,
                "alpha": 1.3080796617076467,
                "alpha_hat": 3.097444731363739
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022479962557554245,
                "median": 0.026357008144259453,
                "std": 0.20394650101661682,
                "max": 0.37622830271720886,
                "min": -0.34830421209335327,
                "frobenius_norm": 1.641453504562378,
                "spectral_norm": 0.9630939960479736,
                "alpha": 1.2037153527368023,
                "alpha_hat": 1.67708486757419
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.036800842732191086,
                "median": -0.0467667430639267,
                "std": 0.19609716534614563,
                "max": 0.3394538164138794,
                "min": -0.3395078480243683,
                "frobenius_norm": 1.5961635112762451,
                "spectral_norm": 0.9111999869346619,
                "alpha": 1.2864559806621436,
                "alpha_hat": 2.365596387014674
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=32_scaler_type=robust_seed=42": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 42,
        "scores": {
            "smape": 0.08016788214445114,
            "mse": 625211264.0,
            "mae": 2144.44775390625,
            "r2_score": 0.8649457693099976,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.005059372168034315,
                "median": 0.000793665531091392,
                "std": 0.15703028440475464,
                "max": 0.3098128139972687,
                "min": -0.32801002264022827,
                "frobenius_norm": 1.539374589920044,
                "spectral_norm": 0.8573864698410034,
                "alpha": 1.3833502988714619,
                "alpha_hat": 1.7268829515894764
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.00871012732386589,
                "median": -0.03370235860347748,
                "std": 0.19516167044639587,
                "max": 0.3274138271808624,
                "min": -0.3582198917865753,
                "frobenius_norm": 1.56284761428833,
                "spectral_norm": 1.0453228950500488,
                "alpha": 1.3080796617076467,
                "alpha_hat": 3.097444731363739
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022479962557554245,
                "median": 0.026357008144259453,
                "std": 0.20394650101661682,
                "max": 0.37622830271720886,
                "min": -0.34830421209335327,
                "frobenius_norm": 1.641453504562378,
                "spectral_norm": 0.9630939960479736,
                "alpha": 1.2037153527368023,
                "alpha_hat": 1.67708486757419
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.036800842732191086,
                "median": -0.0467667430639267,
                "std": 0.19609716534614563,
                "max": 0.3394538164138794,
                "min": -0.3395078480243683,
                "frobenius_norm": 1.5961635112762451,
                "spectral_norm": 0.9111999869346619,
                "alpha": 1.2864559806621436,
                "alpha_hat": 2.365596387014674
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=32_scaler_type=robust_seed=123": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 123,
        "scores": {
            "smape": 0.08018292486667633,
            "mse": 626795008.0,
            "mae": 2145.890625,
            "r2_score": 0.8646036386489868,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.005059372168034315,
                "median": 0.000793665531091392,
                "std": 0.15703028440475464,
                "max": 0.3098128139972687,
                "min": -0.32801002264022827,
                "frobenius_norm": 1.539374589920044,
                "spectral_norm": 0.8573864698410034,
                "alpha": 1.3833502988714619,
                "alpha_hat": 1.7268829515894764
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.00871012732386589,
                "median": -0.03370235860347748,
                "std": 0.19516167044639587,
                "max": 0.3274138271808624,
                "min": -0.3582198917865753,
                "frobenius_norm": 1.56284761428833,
                "spectral_norm": 1.0453228950500488,
                "alpha": 1.3080796617076467,
                "alpha_hat": 3.097444731363739
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022479962557554245,
                "median": 0.026357008144259453,
                "std": 0.20394650101661682,
                "max": 0.37622830271720886,
                "min": -0.34830421209335327,
                "frobenius_norm": 1.641453504562378,
                "spectral_norm": 0.9630939960479736,
                "alpha": 1.2037153527368023,
                "alpha_hat": 1.67708486757419
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.036800842732191086,
                "median": -0.0467667430639267,
                "std": 0.19609716534614563,
                "max": 0.3394538164138794,
                "min": -0.3395078480243683,
                "frobenius_norm": 1.5961635112762451,
                "spectral_norm": 0.9111999869346619,
                "alpha": 1.2864559806621436,
                "alpha_hat": 2.365596387014674
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=32_scaler_type=robust_seed=456": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 456,
        "scores": {
            "smape": 0.08164558559656143,
            "mse": 472196864.0,
            "mae": 2040.3731689453125,
            "r2_score": 0.8979989886283875,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.005059372168034315,
                "median": 0.000793665531091392,
                "std": 0.15703028440475464,
                "max": 0.3098128139972687,
                "min": -0.32801002264022827,
                "frobenius_norm": 1.539374589920044,
                "spectral_norm": 0.8573864698410034,
                "alpha": 1.3833502988714619,
                "alpha_hat": 1.7268829515894764
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.00871012732386589,
                "median": -0.03370235860347748,
                "std": 0.19516167044639587,
                "max": 0.3274138271808624,
                "min": -0.3582198917865753,
                "frobenius_norm": 1.56284761428833,
                "spectral_norm": 1.0453228950500488,
                "alpha": 1.3080796617076467,
                "alpha_hat": 3.097444731363739
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022479962557554245,
                "median": 0.026357008144259453,
                "std": 0.20394650101661682,
                "max": 0.37622830271720886,
                "min": -0.34830421209335327,
                "frobenius_norm": 1.641453504562378,
                "spectral_norm": 0.9630939960479736,
                "alpha": 1.2037153527368023,
                "alpha_hat": 1.67708486757419
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.036800842732191086,
                "median": -0.0467667430639267,
                "std": 0.19609716534614563,
                "max": 0.3394538164138794,
                "min": -0.3395078480243683,
                "frobenius_norm": 1.5961635112762451,
                "spectral_norm": 0.9111999869346619,
                "alpha": 1.2864559806621436,
                "alpha_hat": 2.365596387014674
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=32_scaler_type=robust_seed=1213": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1213,
        "scores": {
            "smape": 0.08026458323001862,
            "mse": 625962880.0,
            "mae": 2146.717529296875,
            "r2_score": 0.8647834062576294,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.012010636739432812,
                "median": 0.035156916826963425,
                "std": 0.15484391152858734,
                "max": 0.29303625226020813,
                "min": -0.31123077869415283,
                "frobenius_norm": 1.5217114686965942,
                "spectral_norm": 0.8217513561248779,
                "alpha": 1.533921403237284,
                "alpha_hat": 1.840025160740223
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022381076589226723,
                "median": 0.0576479434967041,
                "std": 0.20449045300483704,
                "max": 0.35614678263664246,
                "min": -0.3578942120075226,
                "frobenius_norm": 1.6456927061080933,
                "spectral_norm": 0.9403130412101746,
                "alpha": 1.1775517063082206,
                "alpha_hat": 1.4126470145423504
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.010777206160128117,
                "median": -0.015642913058400154,
                "std": 0.2255815863609314,
                "max": 0.4041740596294403,
                "min": -0.3345089256763458,
                "frobenius_norm": 1.8067110776901245,
                "spectral_norm": 1.1597968339920044,
                "alpha": 1.2804270739559178,
                "alpha_hat": 2.1376807760005243
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.025073042139410973,
                "median": 0.018845729529857635,
                "std": 0.19176499545574188,
                "max": 0.35902559757232666,
                "min": -0.28913944959640503,
                "frobenius_norm": 1.5471775531768799,
                "spectral_norm": 0.8040469288825989,
                "alpha": 1.162413216161363,
                "alpha_hat": 1.0254508726130878
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=32_scaler_type=robust_seed=1415": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1415,
        "scores": {
            "smape": 0.08021743595600128,
            "mse": 625842304.0,
            "mae": 2146.077880859375,
            "r2_score": 0.8648094534873962,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.012010636739432812,
                "median": 0.035156916826963425,
                "std": 0.15484391152858734,
                "max": 0.29303625226020813,
                "min": -0.31123077869415283,
                "frobenius_norm": 1.5217114686965942,
                "spectral_norm": 0.8217513561248779,
                "alpha": 1.533921403237284,
                "alpha_hat": 1.840025160740223
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022381076589226723,
                "median": 0.0576479434967041,
                "std": 0.20449045300483704,
                "max": 0.35614678263664246,
                "min": -0.3578942120075226,
                "frobenius_norm": 1.6456927061080933,
                "spectral_norm": 0.9403130412101746,
                "alpha": 1.1775517063082206,
                "alpha_hat": 1.4126470145423504
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.010777206160128117,
                "median": -0.015642913058400154,
                "std": 0.2255815863609314,
                "max": 0.4041740596294403,
                "min": -0.3345089256763458,
                "frobenius_norm": 1.8067110776901245,
                "spectral_norm": 1.1597968339920044,
                "alpha": 1.2804270739559178,
                "alpha_hat": 2.1376807760005243
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.025073042139410973,
                "median": 0.018845729529857635,
                "std": 0.19176499545574188,
                "max": 0.35902559757232666,
                "min": -0.28913944959640503,
                "frobenius_norm": 1.5471775531768799,
                "spectral_norm": 0.8040469288825989,
                "alpha": 1.162413216161363,
                "alpha_hat": 1.0254508726130878
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=32_scaler_type=robust_seed=1011": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1011,
        "scores": {
            "smape": 0.08020815998315811,
            "mse": 625030208.0,
            "mae": 2145.012451171875,
            "r2_score": 0.8649848699569702,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.012010636739432812,
                "median": 0.035156916826963425,
                "std": 0.15484391152858734,
                "max": 0.29303625226020813,
                "min": -0.31123077869415283,
                "frobenius_norm": 1.5217114686965942,
                "spectral_norm": 0.8217513561248779,
                "alpha": 1.533921403237284,
                "alpha_hat": 1.840025160740223
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022381076589226723,
                "median": 0.0576479434967041,
                "std": 0.20449045300483704,
                "max": 0.35614678263664246,
                "min": -0.3578942120075226,
                "frobenius_norm": 1.6456927061080933,
                "spectral_norm": 0.9403130412101746,
                "alpha": 1.1775517063082206,
                "alpha_hat": 1.4126470145423504
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.010777206160128117,
                "median": -0.015642913058400154,
                "std": 0.2255815863609314,
                "max": 0.4041740596294403,
                "min": -0.3345089256763458,
                "frobenius_norm": 1.8067110776901245,
                "spectral_norm": 1.1597968339920044,
                "alpha": 1.2804270739559178,
                "alpha_hat": 2.1376807760005243
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.025073042139410973,
                "median": 0.018845729529857635,
                "std": 0.19176499545574188,
                "max": 0.35902559757232666,
                "min": -0.28913944959640503,
                "frobenius_norm": 1.5471775531768799,
                "spectral_norm": 0.8040469288825989,
                "alpha": 1.162413216161363,
                "alpha_hat": 1.0254508726130878
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=32_scaler_type=robust_seed=1617": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1617,
        "scores": {
            "smape": 0.08022014796733856,
            "mse": 625892480.0,
            "mae": 2146.10693359375,
            "r2_score": 0.8647986054420471,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.012010636739432812,
                "median": 0.035156916826963425,
                "std": 0.15484391152858734,
                "max": 0.29303625226020813,
                "min": -0.31123077869415283,
                "frobenius_norm": 1.5217114686965942,
                "spectral_norm": 0.8217513561248779,
                "alpha": 1.533921403237284,
                "alpha_hat": 1.840025160740223
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022381076589226723,
                "median": 0.0576479434967041,
                "std": 0.20449045300483704,
                "max": 0.35614678263664246,
                "min": -0.3578942120075226,
                "frobenius_norm": 1.6456927061080933,
                "spectral_norm": 0.9403130412101746,
                "alpha": 1.1775517063082206,
                "alpha_hat": 1.4126470145423504
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.010777206160128117,
                "median": -0.015642913058400154,
                "std": 0.2255815863609314,
                "max": 0.4041740596294403,
                "min": -0.3345089256763458,
                "frobenius_norm": 1.8067110776901245,
                "spectral_norm": 1.1597968339920044,
                "alpha": 1.2804270739559178,
                "alpha_hat": 2.1376807760005243
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.025073042139410973,
                "median": 0.018845729529857635,
                "std": 0.19176499545574188,
                "max": 0.35902559757232666,
                "min": -0.28913944959640503,
                "frobenius_norm": 1.5471775531768799,
                "spectral_norm": 0.8040469288825989,
                "alpha": 1.162413216161363,
                "alpha_hat": 1.0254508726130878
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=32_scaler_type=minmax_seed=42": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 42,
        "scores": {
            "smape": 0.1795484870672226,
            "mse": 1421981056.0,
            "mae": 3904.076171875,
            "r2_score": 0.6928324699401855,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.01063502673059702,
                "median": 0.031451284885406494,
                "std": 0.15514132380485535,
                "max": 0.28902703523635864,
                "min": -0.3150389492511749,
                "frobenius_norm": 1.523635745048523,
                "spectral_norm": 0.8216984868049622,
                "alpha": 1.523984111790643,
                "alpha_hat": 1.806564934605011
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022776497527956963,
                "median": 0.06457439064979553,
                "std": 0.2057378739118576,
                "max": 0.35563281178474426,
                "min": -0.35586026310920715,
                "frobenius_norm": 1.6559582948684692,
                "spectral_norm": 0.950180172920227,
                "alpha": 1.169180323999416,
                "alpha_hat": 1.4028825031034564
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.010388296097517014,
                "median": -0.016293328255414963,
                "std": 0.2260444164276123,
                "max": 0.4038739800453186,
                "min": -0.3334985375404358,
                "frobenius_norm": 1.8102638721466064,
                "spectral_norm": 1.1636195182800293,
                "alpha": 1.2763639269445566,
                "alpha_hat": 2.147236583754737
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.023872382938861847,
                "median": 0.017553871497511864,
                "std": 0.1920490264892578,
                "max": 0.361070841550827,
                "min": -0.29227057099342346,
                "frobenius_norm": 1.548216462135315,
                "spectral_norm": 0.8048757314682007,
                "alpha": 1.1719914381475265,
                "alpha_hat": 1.0376134556451453
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=32_scaler_type=robust_seed=1819": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 1819,
        "scores": {
            "smape": 0.08020694553852081,
            "mse": 625880256.0,
            "mae": 2145.5693359375,
            "r2_score": 0.8648012280464172,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.01063502673059702,
                "median": 0.031451284885406494,
                "std": 0.15514132380485535,
                "max": 0.28902703523635864,
                "min": -0.3150389492511749,
                "frobenius_norm": 1.523635745048523,
                "spectral_norm": 0.8216984868049622,
                "alpha": 1.523984111790643,
                "alpha_hat": 1.806564934605011
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022776497527956963,
                "median": 0.06457439064979553,
                "std": 0.2057378739118576,
                "max": 0.35563281178474426,
                "min": -0.35586026310920715,
                "frobenius_norm": 1.6559582948684692,
                "spectral_norm": 0.950180172920227,
                "alpha": 1.169180323999416,
                "alpha_hat": 1.4028825031034564
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.010388296097517014,
                "median": -0.016293328255414963,
                "std": 0.2260444164276123,
                "max": 0.4038739800453186,
                "min": -0.3334985375404358,
                "frobenius_norm": 1.8102638721466064,
                "spectral_norm": 1.1636195182800293,
                "alpha": 1.2763639269445566,
                "alpha_hat": 2.147236583754737
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.023872382938861847,
                "median": 0.017553871497511864,
                "std": 0.1920490264892578,
                "max": 0.361070841550827,
                "min": -0.29227057099342346,
                "frobenius_norm": 1.548216462135315,
                "spectral_norm": 0.8048757314682007,
                "alpha": 1.1719914381475265,
                "alpha_hat": 1.0376134556451453
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=32_scaler_type=robust_seed=2021": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 320
        },
        "seed": 2021,
        "scores": {
            "smape": 0.08023230731487274,
            "mse": 625209344.0,
            "mae": 2145.906494140625,
            "r2_score": 0.864946186542511,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.01063502673059702,
                "median": 0.031451284885406494,
                "std": 0.15514132380485535,
                "max": 0.28902703523635864,
                "min": -0.3150389492511749,
                "frobenius_norm": 1.523635745048523,
                "spectral_norm": 0.8216984868049622,
                "alpha": 1.523984111790643,
                "alpha_hat": 1.806564934605011
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022776497527956963,
                "median": 0.06457439064979553,
                "std": 0.2057378739118576,
                "max": 0.35563281178474426,
                "min": -0.35586026310920715,
                "frobenius_norm": 1.6559582948684692,
                "spectral_norm": 0.950180172920227,
                "alpha": 1.169180323999416,
                "alpha_hat": 1.4028825031034564
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.010388296097517014,
                "median": -0.016293328255414963,
                "std": 0.2260444164276123,
                "max": 0.4038739800453186,
                "min": -0.3334985375404358,
                "frobenius_norm": 1.8102638721466064,
                "spectral_norm": 1.1636195182800293,
                "alpha": 1.2763639269445566,
                "alpha_hat": 2.147236583754737
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.023872382938861847,
                "median": 0.017553871497511864,
                "std": 0.1920490264892578,
                "max": 0.361070841550827,
                "min": -0.29227057099342346,
                "frobenius_norm": 1.548216462135315,
                "spectral_norm": 0.8048757314682007,
                "alpha": 1.1719914381475265,
                "alpha_hat": 1.0376134556451453
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=32_scaler_type=minmax_seed=123": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 123,
        "scores": {
            "smape": 0.17818006873130798,
            "mse": 1420855680.0,
            "mae": 3890.56494140625,
            "r2_score": 0.6930755972862244,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.01063502673059702,
                "median": 0.031451284885406494,
                "std": 0.15514132380485535,
                "max": 0.28902703523635864,
                "min": -0.3150389492511749,
                "frobenius_norm": 1.523635745048523,
                "spectral_norm": 0.8216984868049622,
                "alpha": 1.523984111790643,
                "alpha_hat": 1.806564934605011
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022776497527956963,
                "median": 0.06457439064979553,
                "std": 0.2057378739118576,
                "max": 0.35563281178474426,
                "min": -0.35586026310920715,
                "frobenius_norm": 1.6559582948684692,
                "spectral_norm": 0.950180172920227,
                "alpha": 1.169180323999416,
                "alpha_hat": 1.4028825031034564
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.010388296097517014,
                "median": -0.016293328255414963,
                "std": 0.2260444164276123,
                "max": 0.4038739800453186,
                "min": -0.3334985375404358,
                "frobenius_norm": 1.8102638721466064,
                "spectral_norm": 1.1636195182800293,
                "alpha": 1.2763639269445566,
                "alpha_hat": 2.147236583754737
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.023872382938861847,
                "median": 0.017553871497511864,
                "std": 0.1920490264892578,
                "max": 0.361070841550827,
                "min": -0.29227057099342346,
                "frobenius_norm": 1.548216462135315,
                "spectral_norm": 0.8048757314682007,
                "alpha": 1.1719914381475265,
                "alpha_hat": 1.0376134556451453
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=32_scaler_type=minmax_seed=456": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 456,
        "scores": {
            "smape": 0.1781947910785675,
            "mse": 1417703680.0,
            "mae": 3888.3046875,
            "r2_score": 0.6937564611434937,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.027772516012191772,
                "median": 0.032890163362026215,
                "std": 0.16014550626277924,
                "max": 0.33225229382514954,
                "min": -0.29154732823371887,
                "frobenius_norm": 1.5925194025039673,
                "spectral_norm": 0.8566070795059204,
                "alpha": 1.453901405639654,
                "alpha_hat": 1.4989775751155128
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.028237156569957733,
                "median": 0.06472998112440109,
                "std": 0.2152564972639084,
                "max": 0.37718942761421204,
                "min": -0.3356286883354187,
                "frobenius_norm": 1.7368053197860718,
                "spectral_norm": 0.9766477346420288,
                "alpha": 1.183544104101894,
                "alpha_hat": 1.6030625840579082
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.015856528654694557,
                "median": -0.009536273777484894,
                "std": 0.22606973350048065,
                "max": 0.41270777583122253,
                "min": -0.32124701142311096,
                "frobenius_norm": 1.8130011558532715,
                "spectral_norm": 1.1467236280441284,
                "alpha": 1.2830906371013138,
                "alpha_hat": 2.211429979536361
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02419355884194374,
                "median": 0.011319099925458431,
                "std": 0.19271530210971832,
                "max": 0.3682851493358612,
                "min": -0.2902261018753052,
                "frobenius_norm": 1.5538240671157837,
                "spectral_norm": 0.8138235807418823,
                "alpha": 1.1943572730540424,
                "alpha_hat": 1.0806899814707902
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=32_scaler_type=minmax_seed=1011": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1011,
        "scores": {
            "smape": 0.18038159608840942,
            "mse": 1428927872.0,
            "mae": 3918.8232421875,
            "r2_score": 0.6913318634033203,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.027772516012191772,
                "median": 0.032890163362026215,
                "std": 0.16014550626277924,
                "max": 0.33225229382514954,
                "min": -0.29154732823371887,
                "frobenius_norm": 1.5925194025039673,
                "spectral_norm": 0.8566070795059204,
                "alpha": 1.453901405639654,
                "alpha_hat": 1.4989775751155128
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.028237156569957733,
                "median": 0.06472998112440109,
                "std": 0.2152564972639084,
                "max": 0.37718942761421204,
                "min": -0.3356286883354187,
                "frobenius_norm": 1.7368053197860718,
                "spectral_norm": 0.9766477346420288,
                "alpha": 1.183544104101894,
                "alpha_hat": 1.6030625840579082
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.015856528654694557,
                "median": -0.009536273777484894,
                "std": 0.22606973350048065,
                "max": 0.41270777583122253,
                "min": -0.32124701142311096,
                "frobenius_norm": 1.8130011558532715,
                "spectral_norm": 1.1467236280441284,
                "alpha": 1.2830906371013138,
                "alpha_hat": 2.211429979536361
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02419355884194374,
                "median": 0.011319099925458431,
                "std": 0.19271530210971832,
                "max": 0.3682851493358612,
                "min": -0.2902261018753052,
                "frobenius_norm": 1.5538240671157837,
                "spectral_norm": 0.8138235807418823,
                "alpha": 1.1943572730540424,
                "alpha_hat": 1.0806899814707902
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=32_scaler_type=minmax_seed=789": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 789,
        "scores": {
            "smape": 0.1784449815750122,
            "mse": 1419372928.0,
            "mae": 3891.993408203125,
            "r2_score": 0.6933958530426025,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.027772516012191772,
                "median": 0.032890163362026215,
                "std": 0.16014550626277924,
                "max": 0.33225229382514954,
                "min": -0.29154732823371887,
                "frobenius_norm": 1.5925194025039673,
                "spectral_norm": 0.8566070795059204,
                "alpha": 1.453901405639654,
                "alpha_hat": 1.4989775751155128
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.028237156569957733,
                "median": 0.06472998112440109,
                "std": 0.2152564972639084,
                "max": 0.37718942761421204,
                "min": -0.3356286883354187,
                "frobenius_norm": 1.7368053197860718,
                "spectral_norm": 0.9766477346420288,
                "alpha": 1.183544104101894,
                "alpha_hat": 1.6030625840579082
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.015856528654694557,
                "median": -0.009536273777484894,
                "std": 0.22606973350048065,
                "max": 0.41270777583122253,
                "min": -0.32124701142311096,
                "frobenius_norm": 1.8130011558532715,
                "spectral_norm": 1.1467236280441284,
                "alpha": 1.2830906371013138,
                "alpha_hat": 2.211429979536361
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02419355884194374,
                "median": 0.011319099925458431,
                "std": 0.19271530210971832,
                "max": 0.3682851493358612,
                "min": -0.2902261018753052,
                "frobenius_norm": 1.5538240671157837,
                "spectral_norm": 0.8138235807418823,
                "alpha": 1.1943572730540424,
                "alpha_hat": 1.0806899814707902
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=32_scaler_type=minmax_seed=1213": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1213,
        "scores": {
            "smape": 0.17866434156894684,
            "mse": 1421266560.0,
            "mae": 3896.1875,
            "r2_score": 0.6929868459701538,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.027772516012191772,
                "median": 0.032890163362026215,
                "std": 0.16014550626277924,
                "max": 0.33225229382514954,
                "min": -0.29154732823371887,
                "frobenius_norm": 1.5925194025039673,
                "spectral_norm": 0.8566070795059204,
                "alpha": 1.453901405639654,
                "alpha_hat": 1.4989775751155128
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.028237156569957733,
                "median": 0.06472998112440109,
                "std": 0.2152564972639084,
                "max": 0.37718942761421204,
                "min": -0.3356286883354187,
                "frobenius_norm": 1.7368053197860718,
                "spectral_norm": 0.9766477346420288,
                "alpha": 1.183544104101894,
                "alpha_hat": 1.6030625840579082
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.015856528654694557,
                "median": -0.009536273777484894,
                "std": 0.22606973350048065,
                "max": 0.41270777583122253,
                "min": -0.32124701142311096,
                "frobenius_norm": 1.8130011558532715,
                "spectral_norm": 1.1467236280441284,
                "alpha": 1.2830906371013138,
                "alpha_hat": 2.211429979536361
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02419355884194374,
                "median": 0.011319099925458431,
                "std": 0.19271530210971832,
                "max": 0.3682851493358612,
                "min": -0.2902261018753052,
                "frobenius_norm": 1.5538240671157837,
                "spectral_norm": 0.8138235807418823,
                "alpha": 1.1943572730540424,
                "alpha_hat": 1.0806899814707902
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=32_scaler_type=minmax_seed=1819": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1819,
        "scores": {
            "smape": 0.178092822432518,
            "mse": 1421168384.0,
            "mae": 3890.5810546875,
            "r2_score": 0.6930080652236938,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.02654494345188141,
                "median": 0.031661201268434525,
                "std": 0.1602742075920105,
                "max": 0.3296565115451813,
                "min": -0.2881344258785248,
                "frobenius_norm": 1.591752290725708,
                "spectral_norm": 0.8557267189025879,
                "alpha": 1.4563817352329393,
                "alpha_hat": 1.5005745435244466
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.028881028294563293,
                "median": 0.06587107479572296,
                "std": 0.214863583445549,
                "max": 0.38178086280822754,
                "min": -0.3309325575828552,
                "frobenius_norm": 1.7343674898147583,
                "spectral_norm": 0.976681649684906,
                "alpha": 1.190868946993679,
                "alpha_hat": 1.6230778989097632
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.016050884500145912,
                "median": -0.010170587338507175,
                "std": 0.22644205391407013,
                "max": 0.412649929523468,
                "min": -0.32120755314826965,
                "frobenius_norm": 1.8160816431045532,
                "spectral_norm": 1.1483798027038574,
                "alpha": 1.284667025450931,
                "alpha_hat": 2.213158520494844
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.024259254336357117,
                "median": 0.010552012361586094,
                "std": 0.19294749200344086,
                "max": 0.3686923086643219,
                "min": -0.29073867201805115,
                "frobenius_norm": 1.5557326078414917,
                "spectral_norm": 0.8148548007011414,
                "alpha": 1.195244809397801,
                "alpha_hat": 1.084093317701635
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=32_scaler_type=minmax_seed=1617": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1617,
        "scores": {
            "smape": 0.18041110038757324,
            "mse": 1427054848.0,
            "mae": 3917.9375,
            "r2_score": 0.6917364597320557,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.02654494345188141,
                "median": 0.031661201268434525,
                "std": 0.1602742075920105,
                "max": 0.3296565115451813,
                "min": -0.2881344258785248,
                "frobenius_norm": 1.591752290725708,
                "spectral_norm": 0.8557267189025879,
                "alpha": 1.4563817352329393,
                "alpha_hat": 1.5005745435244466
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.028881028294563293,
                "median": 0.06587107479572296,
                "std": 0.214863583445549,
                "max": 0.38178086280822754,
                "min": -0.3309325575828552,
                "frobenius_norm": 1.7343674898147583,
                "spectral_norm": 0.976681649684906,
                "alpha": 1.190868946993679,
                "alpha_hat": 1.6230778989097632
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.016050884500145912,
                "median": -0.010170587338507175,
                "std": 0.22644205391407013,
                "max": 0.412649929523468,
                "min": -0.32120755314826965,
                "frobenius_norm": 1.8160816431045532,
                "spectral_norm": 1.1483798027038574,
                "alpha": 1.284667025450931,
                "alpha_hat": 2.213158520494844
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.024259254336357117,
                "median": 0.010552012361586094,
                "std": 0.19294749200344086,
                "max": 0.3686923086643219,
                "min": -0.29073867201805115,
                "frobenius_norm": 1.5557326078414917,
                "spectral_norm": 0.8148548007011414,
                "alpha": 1.195244809397801,
                "alpha_hat": 1.084093317701635
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=32_scaler_type=minmax_seed=1415": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 1415,
        "scores": {
            "smape": 0.17754018306732178,
            "mse": 1415010432.0,
            "mae": 3879.574951171875,
            "r2_score": 0.6943382620811462,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.02654494345188141,
                "median": 0.031661201268434525,
                "std": 0.1602742075920105,
                "max": 0.3296565115451813,
                "min": -0.2881344258785248,
                "frobenius_norm": 1.591752290725708,
                "spectral_norm": 0.8557267189025879,
                "alpha": 1.4563817352329393,
                "alpha_hat": 1.5005745435244466
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.028881028294563293,
                "median": 0.06587107479572296,
                "std": 0.214863583445549,
                "max": 0.38178086280822754,
                "min": -0.3309325575828552,
                "frobenius_norm": 1.7343674898147583,
                "spectral_norm": 0.976681649684906,
                "alpha": 1.190868946993679,
                "alpha_hat": 1.6230778989097632
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.016050884500145912,
                "median": -0.010170587338507175,
                "std": 0.22644205391407013,
                "max": 0.412649929523468,
                "min": -0.32120755314826965,
                "frobenius_norm": 1.8160816431045532,
                "spectral_norm": 1.1483798027038574,
                "alpha": 1.284667025450931,
                "alpha_hat": 2.213158520494844
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.024259254336357117,
                "median": 0.010552012361586094,
                "std": 0.19294749200344086,
                "max": 0.3686923086643219,
                "min": -0.29073867201805115,
                "frobenius_norm": 1.5557326078414917,
                "spectral_norm": 0.8148548007011414,
                "alpha": 1.195244809397801,
                "alpha_hat": 1.084093317701635
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=8_learning_rate=0.0001_batch_size=32_scaler_type=minmax_seed=2021": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 500,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "seed": 2021,
        "scores": {
            "smape": 0.17872802913188934,
            "mse": 1421793280.0,
            "mae": 3897.726806640625,
            "r2_score": 0.6928730607032776,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.02654494345188141,
                "median": 0.031661201268434525,
                "std": 0.1602742075920105,
                "max": 0.3296565115451813,
                "min": -0.2881344258785248,
                "frobenius_norm": 1.591752290725708,
                "spectral_norm": 0.8557267189025879,
                "alpha": 1.4563817352329393,
                "alpha_hat": 1.5005745435244466
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.028881028294563293,
                "median": 0.06587107479572296,
                "std": 0.214863583445549,
                "max": 0.38178086280822754,
                "min": -0.3309325575828552,
                "frobenius_norm": 1.7343674898147583,
                "spectral_norm": 0.976681649684906,
                "alpha": 1.190868946993679,
                "alpha_hat": 1.6230778989097632
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.016050884500145912,
                "median": -0.010170587338507175,
                "std": 0.22644205391407013,
                "max": 0.412649929523468,
                "min": -0.32120755314826965,
                "frobenius_norm": 1.8160816431045532,
                "spectral_norm": 1.1483798027038574,
                "alpha": 1.284667025450931,
                "alpha_hat": 2.213158520494844
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.024259254336357117,
                "median": 0.010552012361586094,
                "std": 0.19294749200344086,
                "max": 0.3686923086643219,
                "min": -0.29073867201805115,
                "frobenius_norm": 1.5557326078414917,
                "spectral_norm": 0.8148548007011414,
                "alpha": 1.195244809397801,
                "alpha_hat": 1.084093317701635
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=8_scaler_type=identity_seed=42": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "identity",
            "total_params": 888
        },
        "seed": 42,
        "scores": {
            "smape": 0.08548817038536072,
            "mse": 463347424.0,
            "mae": 1978.4908447265625,
            "r2_score": 0.899910569190979,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.03962239623069763,
                "median": 0.05037901550531387,
                "std": 0.16993534564971924,
                "max": 0.3793070316314697,
                "min": -0.33160385489463806,
                "frobenius_norm": 2.4178519248962402,
                "spectral_norm": 1.122028112411499,
                "alpha": 1.2732252239164235,
                "alpha_hat": 1.6862671612941293
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.05642915517091751,
                "median": 0.05025262385606766,
                "std": 0.16670994460582733,
                "max": 0.4930332899093628,
                "min": -0.2656952142715454,
                "frobenius_norm": 2.8160207271575928,
                "spectral_norm": 1.753255844116211,
                "alpha": 1.2000792515952052,
                "alpha_hat": 1.953806442557547
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.03901292011141777,
                "median": 0.02724124863743782,
                "std": 0.16663266718387604,
                "max": 0.45040684938430786,
                "min": -0.2609133720397949,
                "frobenius_norm": 2.7382192611694336,
                "spectral_norm": 1.7313109636306763,
                "alpha": 1.151926431207245,
                "alpha_hat": 2.2861572152187826
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.03923603519797325,
                "median": 0.03910055756568909,
                "std": 0.15412212908267975,
                "max": 0.3483451008796692,
                "min": -0.22770972549915314,
                "frobenius_norm": 1.7993100881576538,
                "spectral_norm": 1.0347384214401245,
                "alpha": 1.7946441423936874,
                "alpha_hat": 2.3912056130168513
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=8_scaler_type=identity_seed=456": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "identity",
            "total_params": 888
        },
        "seed": 456,
        "scores": {
            "smape": 0.08856505155563354,
            "mse": 529868960.0,
            "mae": 2109.50048828125,
            "r2_score": 0.8855410218238831,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.03962239623069763,
                "median": 0.05037901550531387,
                "std": 0.16993534564971924,
                "max": 0.3793070316314697,
                "min": -0.33160385489463806,
                "frobenius_norm": 2.4178519248962402,
                "spectral_norm": 1.122028112411499,
                "alpha": 1.2732252239164235,
                "alpha_hat": 1.6862671612941293
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.05642915517091751,
                "median": 0.05025262385606766,
                "std": 0.16670994460582733,
                "max": 0.4930332899093628,
                "min": -0.2656952142715454,
                "frobenius_norm": 2.8160207271575928,
                "spectral_norm": 1.753255844116211,
                "alpha": 1.2000792515952052,
                "alpha_hat": 1.953806442557547
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.03901292011141777,
                "median": 0.02724124863743782,
                "std": 0.16663266718387604,
                "max": 0.45040684938430786,
                "min": -0.2609133720397949,
                "frobenius_norm": 2.7382192611694336,
                "spectral_norm": 1.7313109636306763,
                "alpha": 1.151926431207245,
                "alpha_hat": 2.2861572152187826
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.03923603519797325,
                "median": 0.03910055756568909,
                "std": 0.15412212908267975,
                "max": 0.3483451008796692,
                "min": -0.22770972549915314,
                "frobenius_norm": 1.7993100881576538,
                "spectral_norm": 1.0347384214401245,
                "alpha": 1.7946441423936874,
                "alpha_hat": 2.3912056130168513
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=8_scaler_type=identity_seed=123": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "identity",
            "total_params": 888
        },
        "seed": 123,
        "scores": {
            "smape": 0.09201943874359131,
            "mse": 558463936.0,
            "mae": 2190.944580078125,
            "r2_score": 0.8793641328811646,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.03962239623069763,
                "median": 0.05037901550531387,
                "std": 0.16993534564971924,
                "max": 0.3793070316314697,
                "min": -0.33160385489463806,
                "frobenius_norm": 2.4178519248962402,
                "spectral_norm": 1.122028112411499,
                "alpha": 1.2732252239164235,
                "alpha_hat": 1.6862671612941293
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.05642915517091751,
                "median": 0.05025262385606766,
                "std": 0.16670994460582733,
                "max": 0.4930332899093628,
                "min": -0.2656952142715454,
                "frobenius_norm": 2.8160207271575928,
                "spectral_norm": 1.753255844116211,
                "alpha": 1.2000792515952052,
                "alpha_hat": 1.953806442557547
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.03901292011141777,
                "median": 0.02724124863743782,
                "std": 0.16663266718387604,
                "max": 0.45040684938430786,
                "min": -0.2609133720397949,
                "frobenius_norm": 2.7382192611694336,
                "spectral_norm": 1.7313109636306763,
                "alpha": 1.151926431207245,
                "alpha_hat": 2.2861572152187826
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.03923603519797325,
                "median": 0.03910055756568909,
                "std": 0.15412212908267975,
                "max": 0.3483451008796692,
                "min": -0.22770972549915314,
                "frobenius_norm": 1.7993100881576538,
                "spectral_norm": 1.0347384214401245,
                "alpha": 1.7946441423936874,
                "alpha_hat": 2.3912056130168513
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=8_scaler_type=identity_seed=789": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "identity",
            "total_params": 888
        },
        "seed": 789,
        "scores": {
            "smape": 0.08698057383298874,
            "mse": 538273536.0,
            "mae": 2103.92529296875,
            "r2_score": 0.8837255239486694,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.03962239623069763,
                "median": 0.05037901550531387,
                "std": 0.16993534564971924,
                "max": 0.3793070316314697,
                "min": -0.33160385489463806,
                "frobenius_norm": 2.4178519248962402,
                "spectral_norm": 1.122028112411499,
                "alpha": 1.2732252239164235,
                "alpha_hat": 1.6862671612941293
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.05642915517091751,
                "median": 0.05025262385606766,
                "std": 0.16670994460582733,
                "max": 0.4930332899093628,
                "min": -0.2656952142715454,
                "frobenius_norm": 2.8160207271575928,
                "spectral_norm": 1.753255844116211,
                "alpha": 1.2000792515952052,
                "alpha_hat": 1.953806442557547
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.03901292011141777,
                "median": 0.02724124863743782,
                "std": 0.16663266718387604,
                "max": 0.45040684938430786,
                "min": -0.2609133720397949,
                "frobenius_norm": 2.7382192611694336,
                "spectral_norm": 1.7313109636306763,
                "alpha": 1.151926431207245,
                "alpha_hat": 2.2861572152187826
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.03923603519797325,
                "median": 0.03910055756568909,
                "std": 0.15412212908267975,
                "max": 0.3483451008796692,
                "min": -0.22770972549915314,
                "frobenius_norm": 1.7993100881576538,
                "spectral_norm": 1.0347384214401245,
                "alpha": 1.7946441423936874,
                "alpha_hat": 2.3912056130168513
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=8_scaler_type=identity_seed=1011": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "identity",
            "total_params": 888
        },
        "seed": 1011,
        "scores": {
            "smape": 0.08629760891199112,
            "mse": 502662240.0,
            "mae": 2061.850341796875,
            "r2_score": 0.8914180397987366,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.038614388555288315,
                "median": 0.04233391582965851,
                "std": 0.16891361773014069,
                "max": 0.373697429895401,
                "min": -0.30034011602401733,
                "frobenius_norm": 2.4009151458740234,
                "spectral_norm": 1.0712730884552002,
                "alpha": 1.2951217841357745,
                "alpha_hat": 1.572121585414747
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.05551798641681671,
                "median": 0.049806348979473114,
                "std": 0.1626700609922409,
                "max": 0.4497014880180359,
                "min": -0.2681267261505127,
                "frobenius_norm": 2.750129461288452,
                "spectral_norm": 1.7122904062271118,
                "alpha": 1.1566723049408056,
                "alpha_hat": 1.8619925779173354
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.020070884376764297,
                "median": 0.0015016150427982211,
                "std": 0.164558544754982,
                "max": 0.4464113712310791,
                "min": -0.2807912528514862,
                "frobenius_norm": 2.6524484157562256,
                "spectral_norm": 1.5790516138076782,
                "alpha": 1.1422291709818215,
                "alpha_hat": 2.3228024890506
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.04074380174279213,
                "median": 0.040682073682546616,
                "std": 0.15148328244686127,
                "max": 0.3598600924015045,
                "min": -0.22781474888324738,
                "frobenius_norm": 1.7747470140457153,
                "spectral_norm": 1.0375031232833862,
                "alpha": 1.7611860141307074,
                "alpha_hat": 2.327419185712266
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=8_scaler_type=identity_seed=1415": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "identity",
            "total_params": 888
        },
        "seed": 1415,
        "scores": {
            "smape": 0.08823948353528976,
            "mse": 518747008.0,
            "mae": 2087.466064453125,
            "r2_score": 0.8879435062408447,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.038614388555288315,
                "median": 0.04233391582965851,
                "std": 0.16891361773014069,
                "max": 0.373697429895401,
                "min": -0.30034011602401733,
                "frobenius_norm": 2.4009151458740234,
                "spectral_norm": 1.0712730884552002,
                "alpha": 1.2951217841357745,
                "alpha_hat": 1.572121585414747
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.05551798641681671,
                "median": 0.049806348979473114,
                "std": 0.1626700609922409,
                "max": 0.4497014880180359,
                "min": -0.2681267261505127,
                "frobenius_norm": 2.750129461288452,
                "spectral_norm": 1.7122904062271118,
                "alpha": 1.1566723049408056,
                "alpha_hat": 1.8619925779173354
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.020070884376764297,
                "median": 0.0015016150427982211,
                "std": 0.164558544754982,
                "max": 0.4464113712310791,
                "min": -0.2807912528514862,
                "frobenius_norm": 2.6524484157562256,
                "spectral_norm": 1.5790516138076782,
                "alpha": 1.1422291709818215,
                "alpha_hat": 2.3228024890506
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.04074380174279213,
                "median": 0.040682073682546616,
                "std": 0.15148328244686127,
                "max": 0.3598600924015045,
                "min": -0.22781474888324738,
                "frobenius_norm": 1.7747470140457153,
                "spectral_norm": 1.0375031232833862,
                "alpha": 1.7611860141307074,
                "alpha_hat": 2.327419185712266
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=8_scaler_type=identity_seed=1213": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "identity",
            "total_params": 888
        },
        "seed": 1213,
        "scores": {
            "smape": 0.08647989481687546,
            "mse": 520181952.0,
            "mae": 2056.6669921875,
            "r2_score": 0.8876335024833679,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.038614388555288315,
                "median": 0.04233391582965851,
                "std": 0.16891361773014069,
                "max": 0.373697429895401,
                "min": -0.30034011602401733,
                "frobenius_norm": 2.4009151458740234,
                "spectral_norm": 1.0712730884552002,
                "alpha": 1.2951217841357745,
                "alpha_hat": 1.572121585414747
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.05551798641681671,
                "median": 0.049806348979473114,
                "std": 0.1626700609922409,
                "max": 0.4497014880180359,
                "min": -0.2681267261505127,
                "frobenius_norm": 2.750129461288452,
                "spectral_norm": 1.7122904062271118,
                "alpha": 1.1566723049408056,
                "alpha_hat": 1.8619925779173354
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.020070884376764297,
                "median": 0.0015016150427982211,
                "std": 0.164558544754982,
                "max": 0.4464113712310791,
                "min": -0.2807912528514862,
                "frobenius_norm": 2.6524484157562256,
                "spectral_norm": 1.5790516138076782,
                "alpha": 1.1422291709818215,
                "alpha_hat": 2.3228024890506
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.04074380174279213,
                "median": 0.040682073682546616,
                "std": 0.15148328244686127,
                "max": 0.3598600924015045,
                "min": -0.22781474888324738,
                "frobenius_norm": 1.7747470140457153,
                "spectral_norm": 1.0375031232833862,
                "alpha": 1.7611860141307074,
                "alpha_hat": 2.327419185712266
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=8_scaler_type=identity_seed=1617": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "identity",
            "total_params": 888
        },
        "seed": 1617,
        "scores": {
            "smape": 0.0879460871219635,
            "mse": 455755072.0,
            "mae": 2063.247802734375,
            "r2_score": 0.9015506505966187,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.038614388555288315,
                "median": 0.04233391582965851,
                "std": 0.16891361773014069,
                "max": 0.373697429895401,
                "min": -0.30034011602401733,
                "frobenius_norm": 2.4009151458740234,
                "spectral_norm": 1.0712730884552002,
                "alpha": 1.2951217841357745,
                "alpha_hat": 1.572121585414747
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.05551798641681671,
                "median": 0.049806348979473114,
                "std": 0.1626700609922409,
                "max": 0.4497014880180359,
                "min": -0.2681267261505127,
                "frobenius_norm": 2.750129461288452,
                "spectral_norm": 1.7122904062271118,
                "alpha": 1.1566723049408056,
                "alpha_hat": 1.8619925779173354
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.020070884376764297,
                "median": 0.0015016150427982211,
                "std": 0.164558544754982,
                "max": 0.4464113712310791,
                "min": -0.2807912528514862,
                "frobenius_norm": 2.6524484157562256,
                "spectral_norm": 1.5790516138076782,
                "alpha": 1.1422291709818215,
                "alpha_hat": 2.3228024890506
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.04074380174279213,
                "median": 0.040682073682546616,
                "std": 0.15148328244686127,
                "max": 0.3598600924015045,
                "min": -0.22781474888324738,
                "frobenius_norm": 1.7747470140457153,
                "spectral_norm": 1.0375031232833862,
                "alpha": 1.7611860141307074,
                "alpha_hat": 2.327419185712266
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=8_scaler_type=identity_seed=2021": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "identity",
            "total_params": 888
        },
        "seed": 2021,
        "scores": {
            "smape": 0.08809307962656021,
            "mse": 507526336.0,
            "mae": 2044.03076171875,
            "r2_score": 0.890367329120636,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.03086661361157894,
                "median": 0.04086684808135033,
                "std": 0.208907812833786,
                "max": 0.634556233882904,
                "min": -0.4281146228313446,
                "frobenius_norm": 2.926137924194336,
                "spectral_norm": 1.7052053213119507,
                "alpha": 1.3079383574787586,
                "alpha_hat": 2.264224275148671
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.032238349318504333,
                "median": 0.011335361748933792,
                "std": 0.19331809878349304,
                "max": 0.5455876588821411,
                "min": -0.49662700295448303,
                "frobenius_norm": 3.1358041763305664,
                "spectral_norm": 1.7501436471939087,
                "alpha": 1.127515817794858,
                "alpha_hat": 2.7075216917851743
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.0042249541729688644,
                "median": -0.006294622085988522,
                "std": 0.1782035231590271,
                "max": 0.5903357863426208,
                "min": -0.403329074382782,
                "frobenius_norm": 2.852057456970215,
                "spectral_norm": 1.506467342376709,
                "alpha": 1.1885996039838678,
                "alpha_hat": 2.1632810969391834
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.021519895642995834,
                "median": 0.018957594409585,
                "std": 0.15267513692378998,
                "max": 0.43489933013916016,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.744396448135376,
                "spectral_norm": 1.050284743309021,
                "alpha": 1.8017291271908626,
                "alpha_hat": 2.478266321317489
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=8_scaler_type=identity_seed=1819": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "identity",
            "total_params": 888
        },
        "seed": 1819,
        "scores": {
            "smape": 0.08902323246002197,
            "mse": 534736000.0,
            "mae": 2089.525634765625,
            "r2_score": 0.8844896554946899,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.03086661361157894,
                "median": 0.04086684808135033,
                "std": 0.208907812833786,
                "max": 0.634556233882904,
                "min": -0.4281146228313446,
                "frobenius_norm": 2.926137924194336,
                "spectral_norm": 1.7052053213119507,
                "alpha": 1.3079383574787586,
                "alpha_hat": 2.264224275148671
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.032238349318504333,
                "median": 0.011335361748933792,
                "std": 0.19331809878349304,
                "max": 0.5455876588821411,
                "min": -0.49662700295448303,
                "frobenius_norm": 3.1358041763305664,
                "spectral_norm": 1.7501436471939087,
                "alpha": 1.127515817794858,
                "alpha_hat": 2.7075216917851743
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.0042249541729688644,
                "median": -0.006294622085988522,
                "std": 0.1782035231590271,
                "max": 0.5903357863426208,
                "min": -0.403329074382782,
                "frobenius_norm": 2.852057456970215,
                "spectral_norm": 1.506467342376709,
                "alpha": 1.1885996039838678,
                "alpha_hat": 2.1632810969391834
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.021519895642995834,
                "median": 0.018957594409585,
                "std": 0.15267513692378998,
                "max": 0.43489933013916016,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.744396448135376,
                "spectral_norm": 1.050284743309021,
                "alpha": 1.8017291271908626,
                "alpha_hat": 2.478266321317489
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=8_scaler_type=standard_seed=42": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "standard",
            "total_params": 888
        },
        "seed": 42,
        "scores": {
            "smape": 0.07587496191263199,
            "mse": 484107104.0,
            "mae": 2113.865234375,
            "r2_score": 0.8954262137413025,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.03086661361157894,
                "median": 0.04086684808135033,
                "std": 0.208907812833786,
                "max": 0.634556233882904,
                "min": -0.4281146228313446,
                "frobenius_norm": 2.926137924194336,
                "spectral_norm": 1.7052053213119507,
                "alpha": 1.3079383574787586,
                "alpha_hat": 2.264224275148671
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.032238349318504333,
                "median": 0.011335361748933792,
                "std": 0.19331809878349304,
                "max": 0.5455876588821411,
                "min": -0.49662700295448303,
                "frobenius_norm": 3.1358041763305664,
                "spectral_norm": 1.7501436471939087,
                "alpha": 1.127515817794858,
                "alpha_hat": 2.7075216917851743
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.0042249541729688644,
                "median": -0.006294622085988522,
                "std": 0.1782035231590271,
                "max": 0.5903357863426208,
                "min": -0.403329074382782,
                "frobenius_norm": 2.852057456970215,
                "spectral_norm": 1.506467342376709,
                "alpha": 1.1885996039838678,
                "alpha_hat": 2.1632810969391834
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.021519895642995834,
                "median": 0.018957594409585,
                "std": 0.15267513692378998,
                "max": 0.43489933013916016,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.744396448135376,
                "spectral_norm": 1.050284743309021,
                "alpha": 1.8017291271908626,
                "alpha_hat": 2.478266321317489
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=8_scaler_type=standard_seed=123": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "standard",
            "total_params": 888
        },
        "seed": 123,
        "scores": {
            "smape": 0.07525855302810669,
            "mse": 484308608.0,
            "mae": 2104.73388671875,
            "r2_score": 0.8953826427459717,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.03086661361157894,
                "median": 0.04086684808135033,
                "std": 0.208907812833786,
                "max": 0.634556233882904,
                "min": -0.4281146228313446,
                "frobenius_norm": 2.926137924194336,
                "spectral_norm": 1.7052053213119507,
                "alpha": 1.3079383574787586,
                "alpha_hat": 2.264224275148671
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.032238349318504333,
                "median": 0.011335361748933792,
                "std": 0.19331809878349304,
                "max": 0.5455876588821411,
                "min": -0.49662700295448303,
                "frobenius_norm": 3.1358041763305664,
                "spectral_norm": 1.7501436471939087,
                "alpha": 1.127515817794858,
                "alpha_hat": 2.7075216917851743
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.0042249541729688644,
                "median": -0.006294622085988522,
                "std": 0.1782035231590271,
                "max": 0.5903357863426208,
                "min": -0.403329074382782,
                "frobenius_norm": 2.852057456970215,
                "spectral_norm": 1.506467342376709,
                "alpha": 1.1885996039838678,
                "alpha_hat": 2.1632810969391834
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.021519895642995834,
                "median": 0.018957594409585,
                "std": 0.15267513692378998,
                "max": 0.43489933013916016,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.744396448135376,
                "spectral_norm": 1.050284743309021,
                "alpha": 1.8017291271908626,
                "alpha_hat": 2.478266321317489
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=8_scaler_type=standard_seed=789": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "standard",
            "total_params": 888
        },
        "seed": 789,
        "scores": {
            "smape": 0.0750458762049675,
            "mse": 477651168.0,
            "mae": 2088.54345703125,
            "r2_score": 0.8968207836151123,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.033215370029211044,
                "median": 0.052027951925992966,
                "std": 0.2064831554889679,
                "max": 0.6143794655799866,
                "min": -0.4547913372516632,
                "frobenius_norm": 2.8978962898254395,
                "spectral_norm": 1.6127623319625854,
                "alpha": 1.2924897375651925,
                "alpha_hat": 2.0306780779005393
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.034342095255851746,
                "median": 0.022418834269046783,
                "std": 0.1981329768896103,
                "max": 0.5035330653190613,
                "min": -0.5550568699836731,
                "frobenius_norm": 3.2173948287963867,
                "spectral_norm": 1.8556073904037476,
                "alpha": 1.1375369567592581,
                "alpha_hat": 2.351217190390672
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.001767581794410944,
                "median": -0.003378499997779727,
                "std": 0.1791744828224182,
                "max": 0.5972742438316345,
                "min": -0.4558829665184021,
                "frobenius_norm": 2.8669309616088867,
                "spectral_norm": 1.5818425416946411,
                "alpha": 1.100805890102367,
                "alpha_hat": 1.94009799688491
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.024006996303796768,
                "median": 0.02158471569418907,
                "std": 0.1503470093011856,
                "max": 0.41588345170021057,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.7225306034088135,
                "spectral_norm": 1.001562237739563,
                "alpha": 1.8070671070229825,
                "alpha_hat": 2.2167280496834034
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=8_scaler_type=standard_seed=456": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "standard",
            "total_params": 888
        },
        "seed": 456,
        "scores": {
            "smape": 0.07616919279098511,
            "mse": 497043776.0,
            "mae": 2133.047119140625,
            "r2_score": 0.8926317095756531,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.033215370029211044,
                "median": 0.052027951925992966,
                "std": 0.2064831554889679,
                "max": 0.6143794655799866,
                "min": -0.4547913372516632,
                "frobenius_norm": 2.8978962898254395,
                "spectral_norm": 1.6127623319625854,
                "alpha": 1.2924897375651925,
                "alpha_hat": 2.0306780779005393
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.034342095255851746,
                "median": 0.022418834269046783,
                "std": 0.1981329768896103,
                "max": 0.5035330653190613,
                "min": -0.5550568699836731,
                "frobenius_norm": 3.2173948287963867,
                "spectral_norm": 1.8556073904037476,
                "alpha": 1.1375369567592581,
                "alpha_hat": 2.351217190390672
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.001767581794410944,
                "median": -0.003378499997779727,
                "std": 0.1791744828224182,
                "max": 0.5972742438316345,
                "min": -0.4558829665184021,
                "frobenius_norm": 2.8669309616088867,
                "spectral_norm": 1.5818425416946411,
                "alpha": 1.100805890102367,
                "alpha_hat": 1.94009799688491
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.024006996303796768,
                "median": 0.02158471569418907,
                "std": 0.1503470093011856,
                "max": 0.41588345170021057,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.7225306034088135,
                "spectral_norm": 1.001562237739563,
                "alpha": 1.8070671070229825,
                "alpha_hat": 2.2167280496834034
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=8_scaler_type=standard_seed=1213": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "standard",
            "total_params": 888
        },
        "seed": 1213,
        "scores": {
            "smape": 0.07509779930114746,
            "mse": 456748320.0,
            "mae": 2054.38916015625,
            "r2_score": 0.9013360738754272,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.033215370029211044,
                "median": 0.052027951925992966,
                "std": 0.2064831554889679,
                "max": 0.6143794655799866,
                "min": -0.4547913372516632,
                "frobenius_norm": 2.8978962898254395,
                "spectral_norm": 1.6127623319625854,
                "alpha": 1.2924897375651925,
                "alpha_hat": 2.0306780779005393
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.034342095255851746,
                "median": 0.022418834269046783,
                "std": 0.1981329768896103,
                "max": 0.5035330653190613,
                "min": -0.5550568699836731,
                "frobenius_norm": 3.2173948287963867,
                "spectral_norm": 1.8556073904037476,
                "alpha": 1.1375369567592581,
                "alpha_hat": 2.351217190390672
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.001767581794410944,
                "median": -0.003378499997779727,
                "std": 0.1791744828224182,
                "max": 0.5972742438316345,
                "min": -0.4558829665184021,
                "frobenius_norm": 2.8669309616088867,
                "spectral_norm": 1.5818425416946411,
                "alpha": 1.100805890102367,
                "alpha_hat": 1.94009799688491
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.024006996303796768,
                "median": 0.02158471569418907,
                "std": 0.1503470093011856,
                "max": 0.41588345170021057,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.7225306034088135,
                "spectral_norm": 1.001562237739563,
                "alpha": 1.8070671070229825,
                "alpha_hat": 2.2167280496834034
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=8_scaler_type=standard_seed=1011": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "standard",
            "total_params": 888
        },
        "seed": 1011,
        "scores": {
            "smape": 0.07476011663675308,
            "mse": 485307776.0,
            "mae": 2065.40478515625,
            "r2_score": 0.89516681432724,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.033215370029211044,
                "median": 0.052027951925992966,
                "std": 0.2064831554889679,
                "max": 0.6143794655799866,
                "min": -0.4547913372516632,
                "frobenius_norm": 2.8978962898254395,
                "spectral_norm": 1.6127623319625854,
                "alpha": 1.2924897375651925,
                "alpha_hat": 2.0306780779005393
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.034342095255851746,
                "median": 0.022418834269046783,
                "std": 0.1981329768896103,
                "max": 0.5035330653190613,
                "min": -0.5550568699836731,
                "frobenius_norm": 3.2173948287963867,
                "spectral_norm": 1.8556073904037476,
                "alpha": 1.1375369567592581,
                "alpha_hat": 2.351217190390672
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.001767581794410944,
                "median": -0.003378499997779727,
                "std": 0.1791744828224182,
                "max": 0.5972742438316345,
                "min": -0.4558829665184021,
                "frobenius_norm": 2.8669309616088867,
                "spectral_norm": 1.5818425416946411,
                "alpha": 1.100805890102367,
                "alpha_hat": 1.94009799688491
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.024006996303796768,
                "median": 0.02158471569418907,
                "std": 0.1503470093011856,
                "max": 0.41588345170021057,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.7225306034088135,
                "spectral_norm": 1.001562237739563,
                "alpha": 1.8070671070229825,
                "alpha_hat": 2.2167280496834034
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=8_scaler_type=standard_seed=1415": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "standard",
            "total_params": 888
        },
        "seed": 1415,
        "scores": {
            "smape": 0.07515912503004074,
            "mse": 477767520.0,
            "mae": 2070.455810546875,
            "r2_score": 0.8967956304550171,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.03201395645737648,
                "median": 0.01648586243391037,
                "std": 0.20826485753059387,
                "max": 0.6213263273239136,
                "min": -0.3999626338481903,
                "frobenius_norm": 2.9196977615356445,
                "spectral_norm": 1.6584402322769165,
                "alpha": 1.3262456339686297,
                "alpha_hat": 2.2473971774603423
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.03374885767698288,
                "median": 0.02504858747124672,
                "std": 0.1975613683462143,
                "max": 0.5889832377433777,
                "min": -0.505930483341217,
                "frobenius_norm": 3.2067718505859375,
                "spectral_norm": 1.7421584129333496,
                "alpha": 1.2891088803103332,
                "alpha_hat": 3.2080683886670953
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.002307097427546978,
                "median": 0.007809202186763287,
                "std": 0.18150842189788818,
                "max": 0.589948832988739,
                "min": -0.42750680446624756,
                "frobenius_norm": 2.904369354248047,
                "spectral_norm": 1.531053066253662,
                "alpha": 1.13792548253458,
                "alpha_hat": 1.914802716899178
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.02735024318099022,
                "median": 0.040252164006233215,
                "std": 0.15464575588703156,
                "max": 0.47043001651763916,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.7767689228057861,
                "spectral_norm": 1.0716538429260254,
                "alpha": 1.7287450460490326,
                "alpha_hat": 2.390251429409454
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=8_scaler_type=standard_seed=2021": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "standard",
            "total_params": 888
        },
        "seed": 2021,
        "scores": {
            "smape": 0.07471286505460739,
            "mse": 444605440.0,
            "mae": 2028.2119140625,
            "r2_score": 0.9039590954780579,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.03201395645737648,
                "median": 0.01648586243391037,
                "std": 0.20826485753059387,
                "max": 0.6213263273239136,
                "min": -0.3999626338481903,
                "frobenius_norm": 2.9196977615356445,
                "spectral_norm": 1.6584402322769165,
                "alpha": 1.3262456339686297,
                "alpha_hat": 2.2473971774603423
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.03374885767698288,
                "median": 0.02504858747124672,
                "std": 0.1975613683462143,
                "max": 0.5889832377433777,
                "min": -0.505930483341217,
                "frobenius_norm": 3.2067718505859375,
                "spectral_norm": 1.7421584129333496,
                "alpha": 1.2891088803103332,
                "alpha_hat": 3.2080683886670953
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.002307097427546978,
                "median": 0.007809202186763287,
                "std": 0.18150842189788818,
                "max": 0.589948832988739,
                "min": -0.42750680446624756,
                "frobenius_norm": 2.904369354248047,
                "spectral_norm": 1.531053066253662,
                "alpha": 1.13792548253458,
                "alpha_hat": 1.914802716899178
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.02735024318099022,
                "median": 0.040252164006233215,
                "std": 0.15464575588703156,
                "max": 0.47043001651763916,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.7767689228057861,
                "spectral_norm": 1.0716538429260254,
                "alpha": 1.7287450460490326,
                "alpha_hat": 2.390251429409454
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=8_scaler_type=standard_seed=1617": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "standard",
            "total_params": 888
        },
        "seed": 1617,
        "scores": {
            "smape": 0.07538712024688721,
            "mse": 463357216.0,
            "mae": 2079.678466796875,
            "r2_score": 0.8999084830284119,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.03201395645737648,
                "median": 0.01648586243391037,
                "std": 0.20826485753059387,
                "max": 0.6213263273239136,
                "min": -0.3999626338481903,
                "frobenius_norm": 2.9196977615356445,
                "spectral_norm": 1.6584402322769165,
                "alpha": 1.3262456339686297,
                "alpha_hat": 2.2473971774603423
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.03374885767698288,
                "median": 0.02504858747124672,
                "std": 0.1975613683462143,
                "max": 0.5889832377433777,
                "min": -0.505930483341217,
                "frobenius_norm": 3.2067718505859375,
                "spectral_norm": 1.7421584129333496,
                "alpha": 1.2891088803103332,
                "alpha_hat": 3.2080683886670953
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.002307097427546978,
                "median": 0.007809202186763287,
                "std": 0.18150842189788818,
                "max": 0.589948832988739,
                "min": -0.42750680446624756,
                "frobenius_norm": 2.904369354248047,
                "spectral_norm": 1.531053066253662,
                "alpha": 1.13792548253458,
                "alpha_hat": 1.914802716899178
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.02735024318099022,
                "median": 0.040252164006233215,
                "std": 0.15464575588703156,
                "max": 0.47043001651763916,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.7767689228057861,
                "spectral_norm": 1.0716538429260254,
                "alpha": 1.7287450460490326,
                "alpha_hat": 2.390251429409454
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=8_scaler_type=standard_seed=1819": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "standard",
            "total_params": 888
        },
        "seed": 1819,
        "scores": {
            "smape": 0.07424087077379227,
            "mse": 463915072.0,
            "mae": 2047.56884765625,
            "r2_score": 0.899787962436676,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.03201395645737648,
                "median": 0.01648586243391037,
                "std": 0.20826485753059387,
                "max": 0.6213263273239136,
                "min": -0.3999626338481903,
                "frobenius_norm": 2.9196977615356445,
                "spectral_norm": 1.6584402322769165,
                "alpha": 1.3262456339686297,
                "alpha_hat": 2.2473971774603423
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.03374885767698288,
                "median": 0.02504858747124672,
                "std": 0.1975613683462143,
                "max": 0.5889832377433777,
                "min": -0.505930483341217,
                "frobenius_norm": 3.2067718505859375,
                "spectral_norm": 1.7421584129333496,
                "alpha": 1.2891088803103332,
                "alpha_hat": 3.2080683886670953
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.002307097427546978,
                "median": 0.007809202186763287,
                "std": 0.18150842189788818,
                "max": 0.589948832988739,
                "min": -0.42750680446624756,
                "frobenius_norm": 2.904369354248047,
                "spectral_norm": 1.531053066253662,
                "alpha": 1.13792548253458,
                "alpha_hat": 1.914802716899178
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.02735024318099022,
                "median": 0.040252164006233215,
                "std": 0.15464575588703156,
                "max": 0.47043001651763916,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.7767689228057861,
                "spectral_norm": 1.0716538429260254,
                "alpha": 1.7287450460490326,
                "alpha_hat": 2.390251429409454
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=8_scaler_type=robust_seed=42": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "robust",
            "total_params": 888
        },
        "seed": 42,
        "scores": {
            "smape": 0.07464416325092316,
            "mse": 484373536.0,
            "mae": 2094.4775390625,
            "r2_score": 0.8953686356544495,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.036897823214530945,
                "median": 0.03529763221740723,
                "std": 0.21124419569969177,
                "max": 0.5861299633979797,
                "min": -0.37723422050476074,
                "frobenius_norm": 2.9714016914367676,
                "spectral_norm": 1.5726816654205322,
                "alpha": 1.3058817888590157,
                "alpha_hat": 2.0485589659196695
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.03328891471028328,
                "median": 0.03979243338108063,
                "std": 0.19245366752147675,
                "max": 0.4548349678516388,
                "min": -0.46880441904067993,
                "frobenius_norm": 3.124983310699463,
                "spectral_norm": 1.8539817333221436,
                "alpha": 1.1743532936338437,
                "alpha_hat": 3.00509645957794
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.01407250203192234,
                "median": 0.017812691628932953,
                "std": 0.1786126047372818,
                "max": 0.553538978099823,
                "min": -0.3554651141166687,
                "frobenius_norm": 2.8666579723358154,
                "spectral_norm": 1.6984046697616577,
                "alpha": 1.1764220121414473,
                "alpha_hat": 2.2256730186090152
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.03035835735499859,
                "median": 0.03875221312046051,
                "std": 0.15362316370010376,
                "max": 0.41334983706474304,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.7716598510742188,
                "spectral_norm": 1.0297540426254272,
                "alpha": 1.8061633856020087,
                "alpha_hat": 2.4319893803198314
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=8_scaler_type=robust_seed=456": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "robust",
            "total_params": 888
        },
        "seed": 456,
        "scores": {
            "smape": 0.07512036710977554,
            "mse": 531948224.0,
            "mae": 2164.11767578125,
            "r2_score": 0.8850918412208557,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.036897823214530945,
                "median": 0.03529763221740723,
                "std": 0.21124419569969177,
                "max": 0.5861299633979797,
                "min": -0.37723422050476074,
                "frobenius_norm": 2.9714016914367676,
                "spectral_norm": 1.5726816654205322,
                "alpha": 1.3058817888590157,
                "alpha_hat": 2.0485589659196695
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.03328891471028328,
                "median": 0.03979243338108063,
                "std": 0.19245366752147675,
                "max": 0.4548349678516388,
                "min": -0.46880441904067993,
                "frobenius_norm": 3.124983310699463,
                "spectral_norm": 1.8539817333221436,
                "alpha": 1.1743532936338437,
                "alpha_hat": 3.00509645957794
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.01407250203192234,
                "median": 0.017812691628932953,
                "std": 0.1786126047372818,
                "max": 0.553538978099823,
                "min": -0.3554651141166687,
                "frobenius_norm": 2.8666579723358154,
                "spectral_norm": 1.6984046697616577,
                "alpha": 1.1764220121414473,
                "alpha_hat": 2.2256730186090152
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.03035835735499859,
                "median": 0.03875221312046051,
                "std": 0.15362316370010376,
                "max": 0.41334983706474304,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.7716598510742188,
                "spectral_norm": 1.0297540426254272,
                "alpha": 1.8061633856020087,
                "alpha_hat": 2.4319893803198314
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=8_scaler_type=robust_seed=789": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "robust",
            "total_params": 888
        },
        "seed": 789,
        "scores": {
            "smape": 0.07378897815942764,
            "mse": 507979104.0,
            "mae": 2079.398193359375,
            "r2_score": 0.8902695178985596,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.036897823214530945,
                "median": 0.03529763221740723,
                "std": 0.21124419569969177,
                "max": 0.5861299633979797,
                "min": -0.37723422050476074,
                "frobenius_norm": 2.9714016914367676,
                "spectral_norm": 1.5726816654205322,
                "alpha": 1.3058817888590157,
                "alpha_hat": 2.0485589659196695
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.03328891471028328,
                "median": 0.03979243338108063,
                "std": 0.19245366752147675,
                "max": 0.4548349678516388,
                "min": -0.46880441904067993,
                "frobenius_norm": 3.124983310699463,
                "spectral_norm": 1.8539817333221436,
                "alpha": 1.1743532936338437,
                "alpha_hat": 3.00509645957794
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.01407250203192234,
                "median": 0.017812691628932953,
                "std": 0.1786126047372818,
                "max": 0.553538978099823,
                "min": -0.3554651141166687,
                "frobenius_norm": 2.8666579723358154,
                "spectral_norm": 1.6984046697616577,
                "alpha": 1.1764220121414473,
                "alpha_hat": 2.2256730186090152
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.03035835735499859,
                "median": 0.03875221312046051,
                "std": 0.15362316370010376,
                "max": 0.41334983706474304,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.7716598510742188,
                "spectral_norm": 1.0297540426254272,
                "alpha": 1.8061633856020087,
                "alpha_hat": 2.4319893803198314
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=8_scaler_type=robust_seed=123": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "robust",
            "total_params": 888
        },
        "seed": 123,
        "scores": {
            "smape": 0.07446035742759705,
            "mse": 487405728.0,
            "mae": 2102.17578125,
            "r2_score": 0.8947136402130127,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.036897823214530945,
                "median": 0.03529763221740723,
                "std": 0.21124419569969177,
                "max": 0.5861299633979797,
                "min": -0.37723422050476074,
                "frobenius_norm": 2.9714016914367676,
                "spectral_norm": 1.5726816654205322,
                "alpha": 1.3058817888590157,
                "alpha_hat": 2.0485589659196695
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.03328891471028328,
                "median": 0.03979243338108063,
                "std": 0.19245366752147675,
                "max": 0.4548349678516388,
                "min": -0.46880441904067993,
                "frobenius_norm": 3.124983310699463,
                "spectral_norm": 1.8539817333221436,
                "alpha": 1.1743532936338437,
                "alpha_hat": 3.00509645957794
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.01407250203192234,
                "median": 0.017812691628932953,
                "std": 0.1786126047372818,
                "max": 0.553538978099823,
                "min": -0.3554651141166687,
                "frobenius_norm": 2.8666579723358154,
                "spectral_norm": 1.6984046697616577,
                "alpha": 1.1764220121414473,
                "alpha_hat": 2.2256730186090152
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.03035835735499859,
                "median": 0.03875221312046051,
                "std": 0.15362316370010376,
                "max": 0.41334983706474304,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.7716598510742188,
                "spectral_norm": 1.0297540426254272,
                "alpha": 1.8061633856020087,
                "alpha_hat": 2.4319893803198314
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=8_scaler_type=robust_seed=1011": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "robust",
            "total_params": 888
        },
        "seed": 1011,
        "scores": {
            "smape": 0.07454405725002289,
            "mse": 489456000.0,
            "mae": 2095.193359375,
            "r2_score": 0.8942707777023315,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.042203277349472046,
                "median": 0.03710773587226868,
                "std": 0.2070671021938324,
                "max": 0.6245793700218201,
                "min": -0.4919838607311249,
                "frobenius_norm": 2.9281935691833496,
                "spectral_norm": 1.6804701089859009,
                "alpha": 1.2899258927695274,
                "alpha_hat": 2.161949163390946
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.04499877244234085,
                "median": 0.04587806016206741,
                "std": 0.193200021982193,
                "max": 0.5037699937820435,
                "min": -0.4266897141933441,
                "frobenius_norm": 3.1739392280578613,
                "spectral_norm": 2.043971300125122,
                "alpha": 1.1385384830643612,
                "alpha_hat": 2.968288033669001
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.008940642699599266,
                "median": -0.019336801022291183,
                "std": 0.18027475476264954,
                "max": 0.5423847436904907,
                "min": -0.5700852870941162,
                "frobenius_norm": 2.8879411220550537,
                "spectral_norm": 1.6732120513916016,
                "alpha": 1.2354310393024215,
                "alpha_hat": 2.2089701232372003
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.01705240271985531,
                "median": 0.03163202106952667,
                "std": 0.14721184968948364,
                "max": 0.45034217834472656,
                "min": -0.25669482350349426,
                "frobenius_norm": 1.676648497581482,
                "spectral_norm": 0.9309227466583252,
                "alpha": 1.8330155609447236,
                "alpha_hat": 2.3332334624192494
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=8_scaler_type=robust_seed=1213": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "robust",
            "total_params": 888
        },
        "seed": 1213,
        "scores": {
            "smape": 0.07406914234161377,
            "mse": 483963712.0,
            "mae": 2074.64990234375,
            "r2_score": 0.8954571485519409,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.042203277349472046,
                "median": 0.03710773587226868,
                "std": 0.2070671021938324,
                "max": 0.6245793700218201,
                "min": -0.4919838607311249,
                "frobenius_norm": 2.9281935691833496,
                "spectral_norm": 1.6804701089859009,
                "alpha": 1.2899258927695274,
                "alpha_hat": 2.161949163390946
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.04499877244234085,
                "median": 0.04587806016206741,
                "std": 0.193200021982193,
                "max": 0.5037699937820435,
                "min": -0.4266897141933441,
                "frobenius_norm": 3.1739392280578613,
                "spectral_norm": 2.043971300125122,
                "alpha": 1.1385384830643612,
                "alpha_hat": 2.968288033669001
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.008940642699599266,
                "median": -0.019336801022291183,
                "std": 0.18027475476264954,
                "max": 0.5423847436904907,
                "min": -0.5700852870941162,
                "frobenius_norm": 2.8879411220550537,
                "spectral_norm": 1.6732120513916016,
                "alpha": 1.2354310393024215,
                "alpha_hat": 2.2089701232372003
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.01705240271985531,
                "median": 0.03163202106952667,
                "std": 0.14721184968948364,
                "max": 0.45034217834472656,
                "min": -0.25669482350349426,
                "frobenius_norm": 1.676648497581482,
                "spectral_norm": 0.9309227466583252,
                "alpha": 1.8330155609447236,
                "alpha_hat": 2.3332334624192494
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=8_scaler_type=robust_seed=1617": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "robust",
            "total_params": 888
        },
        "seed": 1617,
        "scores": {
            "smape": 0.07429264485836029,
            "mse": 485629472.0,
            "mae": 2081.62158203125,
            "r2_score": 0.8950973749160767,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.042203277349472046,
                "median": 0.03710773587226868,
                "std": 0.2070671021938324,
                "max": 0.6245793700218201,
                "min": -0.4919838607311249,
                "frobenius_norm": 2.9281935691833496,
                "spectral_norm": 1.6804701089859009,
                "alpha": 1.2899258927695274,
                "alpha_hat": 2.161949163390946
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.04499877244234085,
                "median": 0.04587806016206741,
                "std": 0.193200021982193,
                "max": 0.5037699937820435,
                "min": -0.4266897141933441,
                "frobenius_norm": 3.1739392280578613,
                "spectral_norm": 2.043971300125122,
                "alpha": 1.1385384830643612,
                "alpha_hat": 2.968288033669001
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.008940642699599266,
                "median": -0.019336801022291183,
                "std": 0.18027475476264954,
                "max": 0.5423847436904907,
                "min": -0.5700852870941162,
                "frobenius_norm": 2.8879411220550537,
                "spectral_norm": 1.6732120513916016,
                "alpha": 1.2354310393024215,
                "alpha_hat": 2.2089701232372003
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.01705240271985531,
                "median": 0.03163202106952667,
                "std": 0.14721184968948364,
                "max": 0.45034217834472656,
                "min": -0.25669482350349426,
                "frobenius_norm": 1.676648497581482,
                "spectral_norm": 0.9309227466583252,
                "alpha": 1.8330155609447236,
                "alpha_hat": 2.3332334624192494
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=8_scaler_type=robust_seed=1415": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "robust",
            "total_params": 888
        },
        "seed": 1415,
        "scores": {
            "smape": 0.0745764747262001,
            "mse": 498360288.0,
            "mae": 2114.62841796875,
            "r2_score": 0.8923473358154297,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.042203277349472046,
                "median": 0.03710773587226868,
                "std": 0.2070671021938324,
                "max": 0.6245793700218201,
                "min": -0.4919838607311249,
                "frobenius_norm": 2.9281935691833496,
                "spectral_norm": 1.6804701089859009,
                "alpha": 1.2899258927695274,
                "alpha_hat": 2.161949163390946
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.04499877244234085,
                "median": 0.04587806016206741,
                "std": 0.193200021982193,
                "max": 0.5037699937820435,
                "min": -0.4266897141933441,
                "frobenius_norm": 3.1739392280578613,
                "spectral_norm": 2.043971300125122,
                "alpha": 1.1385384830643612,
                "alpha_hat": 2.968288033669001
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.008940642699599266,
                "median": -0.019336801022291183,
                "std": 0.18027475476264954,
                "max": 0.5423847436904907,
                "min": -0.5700852870941162,
                "frobenius_norm": 2.8879411220550537,
                "spectral_norm": 1.6732120513916016,
                "alpha": 1.2354310393024215,
                "alpha_hat": 2.2089701232372003
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.01705240271985531,
                "median": 0.03163202106952667,
                "std": 0.14721184968948364,
                "max": 0.45034217834472656,
                "min": -0.25669482350349426,
                "frobenius_norm": 1.676648497581482,
                "spectral_norm": 0.9309227466583252,
                "alpha": 1.8330155609447236,
                "alpha_hat": 2.3332334624192494
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=8_scaler_type=minmax_seed=42": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "minmax",
            "total_params": 888
        },
        "seed": 42,
        "scores": {
            "smape": 0.0798247829079628,
            "mse": 505335616.0,
            "mae": 2216.602783203125,
            "r2_score": 0.8908405303955078,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.04710151255130768,
                "median": 0.04989902302622795,
                "std": 0.2101924568414688,
                "max": 0.6114869713783264,
                "min": -0.46644672751426697,
                "frobenius_norm": 2.9847428798675537,
                "spectral_norm": 1.6529240608215332,
                "alpha": 1.3307489736383333,
                "alpha_hat": 2.073582571266016
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.05404355376958847,
                "median": 0.05991668999195099,
                "std": 0.18867723643779755,
                "max": 0.49091947078704834,
                "min": -0.46355801820755005,
                "frobenius_norm": 3.1402339935302734,
                "spectral_norm": 1.9336097240447998,
                "alpha": 1.178778734533227,
                "alpha_hat": 2.54857660604068
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.001361202448606491,
                "median": 0.0026447586715221405,
                "std": 0.18166351318359375,
                "max": 0.592290997505188,
                "min": -0.4337593615055084,
                "frobenius_norm": 2.906697988510132,
                "spectral_norm": 1.649911880493164,
                "alpha": 1.1548304283014805,
                "alpha_hat": 1.9396301975077097
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.020232494920492172,
                "median": 0.02847660332918167,
                "std": 0.14970819652080536,
                "max": 0.41076868772506714,
                "min": -0.2654254734516144,
                "frobenius_norm": 1.7091526985168457,
                "spectral_norm": 0.972936749458313,
                "alpha": 1.7835615539590428,
                "alpha_hat": 2.2407644481756113
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=8_scaler_type=minmax_seed=123": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "minmax",
            "total_params": 888
        },
        "seed": 123,
        "scores": {
            "smape": 0.0803779810667038,
            "mse": 555732928.0,
            "mae": 2301.86376953125,
            "r2_score": 0.8799540400505066,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.04710151255130768,
                "median": 0.04989902302622795,
                "std": 0.2101924568414688,
                "max": 0.6114869713783264,
                "min": -0.46644672751426697,
                "frobenius_norm": 2.9847428798675537,
                "spectral_norm": 1.6529240608215332,
                "alpha": 1.3307489736383333,
                "alpha_hat": 2.073582571266016
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.05404355376958847,
                "median": 0.05991668999195099,
                "std": 0.18867723643779755,
                "max": 0.49091947078704834,
                "min": -0.46355801820755005,
                "frobenius_norm": 3.1402339935302734,
                "spectral_norm": 1.9336097240447998,
                "alpha": 1.178778734533227,
                "alpha_hat": 2.54857660604068
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.001361202448606491,
                "median": 0.0026447586715221405,
                "std": 0.18166351318359375,
                "max": 0.592290997505188,
                "min": -0.4337593615055084,
                "frobenius_norm": 2.906697988510132,
                "spectral_norm": 1.649911880493164,
                "alpha": 1.1548304283014805,
                "alpha_hat": 1.9396301975077097
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.020232494920492172,
                "median": 0.02847660332918167,
                "std": 0.14970819652080536,
                "max": 0.41076868772506714,
                "min": -0.2654254734516144,
                "frobenius_norm": 1.7091526985168457,
                "spectral_norm": 0.972936749458313,
                "alpha": 1.7835615539590428,
                "alpha_hat": 2.2407644481756113
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=8_scaler_type=robust_seed=2021": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "robust",
            "total_params": 888
        },
        "seed": 2021,
        "scores": {
            "smape": 0.07434388250112534,
            "mse": 481797632.0,
            "mae": 2088.5087890625,
            "r2_score": 0.8959250450134277,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.04710151255130768,
                "median": 0.04989902302622795,
                "std": 0.2101924568414688,
                "max": 0.6114869713783264,
                "min": -0.46644672751426697,
                "frobenius_norm": 2.9847428798675537,
                "spectral_norm": 1.6529240608215332,
                "alpha": 1.3307489736383333,
                "alpha_hat": 2.073582571266016
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.05404355376958847,
                "median": 0.05991668999195099,
                "std": 0.18867723643779755,
                "max": 0.49091947078704834,
                "min": -0.46355801820755005,
                "frobenius_norm": 3.1402339935302734,
                "spectral_norm": 1.9336097240447998,
                "alpha": 1.178778734533227,
                "alpha_hat": 2.54857660604068
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.001361202448606491,
                "median": 0.0026447586715221405,
                "std": 0.18166351318359375,
                "max": 0.592290997505188,
                "min": -0.4337593615055084,
                "frobenius_norm": 2.906697988510132,
                "spectral_norm": 1.649911880493164,
                "alpha": 1.1548304283014805,
                "alpha_hat": 1.9396301975077097
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.020232494920492172,
                "median": 0.02847660332918167,
                "std": 0.14970819652080536,
                "max": 0.41076868772506714,
                "min": -0.2654254734516144,
                "frobenius_norm": 1.7091526985168457,
                "spectral_norm": 0.972936749458313,
                "alpha": 1.7835615539590428,
                "alpha_hat": 2.2407644481756113
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=8_scaler_type=robust_seed=1819": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "robust",
            "total_params": 888
        },
        "seed": 1819,
        "scores": {
            "smape": 0.07446249574422836,
            "mse": 520721440.0,
            "mae": 2118.481201171875,
            "r2_score": 0.887516975402832,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.04710151255130768,
                "median": 0.04989902302622795,
                "std": 0.2101924568414688,
                "max": 0.6114869713783264,
                "min": -0.46644672751426697,
                "frobenius_norm": 2.9847428798675537,
                "spectral_norm": 1.6529240608215332,
                "alpha": 1.3307489736383333,
                "alpha_hat": 2.073582571266016
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.05404355376958847,
                "median": 0.05991668999195099,
                "std": 0.18867723643779755,
                "max": 0.49091947078704834,
                "min": -0.46355801820755005,
                "frobenius_norm": 3.1402339935302734,
                "spectral_norm": 1.9336097240447998,
                "alpha": 1.178778734533227,
                "alpha_hat": 2.54857660604068
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.001361202448606491,
                "median": 0.0026447586715221405,
                "std": 0.18166351318359375,
                "max": 0.592290997505188,
                "min": -0.4337593615055084,
                "frobenius_norm": 2.906697988510132,
                "spectral_norm": 1.649911880493164,
                "alpha": 1.1548304283014805,
                "alpha_hat": 1.9396301975077097
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.020232494920492172,
                "median": 0.02847660332918167,
                "std": 0.14970819652080536,
                "max": 0.41076868772506714,
                "min": -0.2654254734516144,
                "frobenius_norm": 1.7091526985168457,
                "spectral_norm": 0.972936749458313,
                "alpha": 1.7835615539590428,
                "alpha_hat": 2.2407644481756113
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=8_scaler_type=minmax_seed=1011": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "minmax",
            "total_params": 888
        },
        "seed": 1011,
        "scores": {
            "smape": 0.07855851203203201,
            "mse": 538201600.0,
            "mae": 2206.728759765625,
            "r2_score": 0.883741021156311,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.05235510692000389,
                "median": 0.05967245250940323,
                "std": 0.18733914196491241,
                "max": 0.5009618401527405,
                "min": -0.39912229776382446,
                "frobenius_norm": 2.695312023162842,
                "spectral_norm": 1.5170711278915405,
                "alpha": 1.1928713262921171,
                "alpha_hat": 1.8140686515540563
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.019090881571173668,
                "median": 0.01562819629907608,
                "std": 0.17700733244419098,
                "max": 0.4029194712638855,
                "min": -0.3926592767238617,
                "frobenius_norm": 2.8485419750213623,
                "spectral_norm": 1.687809705734253,
                "alpha": 1.1258490734560285,
                "alpha_hat": 1.708425419486817
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.007214171811938286,
                "median": -0.005763364490121603,
                "std": 0.16216404736042023,
                "max": 0.4351428151130676,
                "min": -0.41884756088256836,
                "frobenius_norm": 2.5971908569335938,
                "spectral_norm": 1.4130103588104248,
                "alpha": 1.1816324620042442,
                "alpha_hat": 2.0079165496436424
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.01615474373102188,
                "median": 0.011442826129496098,
                "std": 0.14570635557174683,
                "max": 0.4153161644935608,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.6585803031921387,
                "spectral_norm": 0.8838525414466858,
                "alpha": 1.8262416387627842,
                "alpha_hat": 2.0984795245784613
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=8_scaler_type=minmax_seed=456": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "minmax",
            "total_params": 888
        },
        "seed": 456,
        "scores": {
            "smape": 0.0802302211523056,
            "mse": 480014912.0,
            "mae": 2227.267822265625,
            "r2_score": 0.8963101506233215,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.05235510692000389,
                "median": 0.05967245250940323,
                "std": 0.18733914196491241,
                "max": 0.5009618401527405,
                "min": -0.39912229776382446,
                "frobenius_norm": 2.695312023162842,
                "spectral_norm": 1.5170711278915405,
                "alpha": 1.1928713262921171,
                "alpha_hat": 1.8140686515540563
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.019090881571173668,
                "median": 0.01562819629907608,
                "std": 0.17700733244419098,
                "max": 0.4029194712638855,
                "min": -0.3926592767238617,
                "frobenius_norm": 2.8485419750213623,
                "spectral_norm": 1.687809705734253,
                "alpha": 1.1258490734560285,
                "alpha_hat": 1.708425419486817
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.007214171811938286,
                "median": -0.005763364490121603,
                "std": 0.16216404736042023,
                "max": 0.4351428151130676,
                "min": -0.41884756088256836,
                "frobenius_norm": 2.5971908569335938,
                "spectral_norm": 1.4130103588104248,
                "alpha": 1.1816324620042442,
                "alpha_hat": 2.0079165496436424
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.01615474373102188,
                "median": 0.011442826129496098,
                "std": 0.14570635557174683,
                "max": 0.4153161644935608,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.6585803031921387,
                "spectral_norm": 0.8838525414466858,
                "alpha": 1.8262416387627842,
                "alpha_hat": 2.0984795245784613
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=8_scaler_type=minmax_seed=789": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "minmax",
            "total_params": 888
        },
        "seed": 789,
        "scores": {
            "smape": 0.07974717766046524,
            "mse": 526214240.0,
            "mae": 2258.636962890625,
            "r2_score": 0.8863304853439331,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.05235510692000389,
                "median": 0.05967245250940323,
                "std": 0.18733914196491241,
                "max": 0.5009618401527405,
                "min": -0.39912229776382446,
                "frobenius_norm": 2.695312023162842,
                "spectral_norm": 1.5170711278915405,
                "alpha": 1.1928713262921171,
                "alpha_hat": 1.8140686515540563
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.019090881571173668,
                "median": 0.01562819629907608,
                "std": 0.17700733244419098,
                "max": 0.4029194712638855,
                "min": -0.3926592767238617,
                "frobenius_norm": 2.8485419750213623,
                "spectral_norm": 1.687809705734253,
                "alpha": 1.1258490734560285,
                "alpha_hat": 1.708425419486817
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.007214171811938286,
                "median": -0.005763364490121603,
                "std": 0.16216404736042023,
                "max": 0.4351428151130676,
                "min": -0.41884756088256836,
                "frobenius_norm": 2.5971908569335938,
                "spectral_norm": 1.4130103588104248,
                "alpha": 1.1816324620042442,
                "alpha_hat": 2.0079165496436424
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.01615474373102188,
                "median": 0.011442826129496098,
                "std": 0.14570635557174683,
                "max": 0.4153161644935608,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.6585803031921387,
                "spectral_norm": 0.8838525414466858,
                "alpha": 1.8262416387627842,
                "alpha_hat": 2.0984795245784613
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=8_scaler_type=minmax_seed=1213": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "minmax",
            "total_params": 888
        },
        "seed": 1213,
        "scores": {
            "smape": 0.07832362502813339,
            "mse": 507483552.0,
            "mae": 2215.891845703125,
            "r2_score": 0.8903765678405762,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.05235510692000389,
                "median": 0.05967245250940323,
                "std": 0.18733914196491241,
                "max": 0.5009618401527405,
                "min": -0.39912229776382446,
                "frobenius_norm": 2.695312023162842,
                "spectral_norm": 1.5170711278915405,
                "alpha": 1.1928713262921171,
                "alpha_hat": 1.8140686515540563
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.019090881571173668,
                "median": 0.01562819629907608,
                "std": 0.17700733244419098,
                "max": 0.4029194712638855,
                "min": -0.3926592767238617,
                "frobenius_norm": 2.8485419750213623,
                "spectral_norm": 1.687809705734253,
                "alpha": 1.1258490734560285,
                "alpha_hat": 1.708425419486817
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.007214171811938286,
                "median": -0.005763364490121603,
                "std": 0.16216404736042023,
                "max": 0.4351428151130676,
                "min": -0.41884756088256836,
                "frobenius_norm": 2.5971908569335938,
                "spectral_norm": 1.4130103588104248,
                "alpha": 1.1816324620042442,
                "alpha_hat": 2.0079165496436424
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.01615474373102188,
                "median": 0.011442826129496098,
                "std": 0.14570635557174683,
                "max": 0.4153161644935608,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.6585803031921387,
                "spectral_norm": 0.8838525414466858,
                "alpha": 1.8262416387627842,
                "alpha_hat": 2.0984795245784613
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=8_scaler_type=minmax_seed=2021": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "minmax",
            "total_params": 888
        },
        "seed": 2021,
        "scores": {
            "smape": 0.08036580681800842,
            "mse": 547789312.0,
            "mae": 2298.96240234375,
            "r2_score": 0.8816699385643005,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.05900854989886284,
                "median": 0.06334545463323593,
                "std": 0.1902160942554474,
                "max": 0.5232560634613037,
                "min": -0.3913463056087494,
                "frobenius_norm": 2.7596232891082764,
                "spectral_norm": 1.6157034635543823,
                "alpha": 1.2107636797208086,
                "alpha_hat": 1.9027688912411929
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.030569065362215042,
                "median": 0.03822692483663559,
                "std": 0.17405113577842712,
                "max": 0.4031426012516022,
                "min": -0.40825507044792175,
                "frobenius_norm": 2.8274433612823486,
                "spectral_norm": 1.6934260129928589,
                "alpha": 1.1780482918140942,
                "alpha_hat": 1.8516987085923442
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.014433786273002625,
                "median": -0.02125118300318718,
                "std": 0.1667344570159912,
                "max": 0.4267697036266327,
                "min": -0.495712548494339,
                "frobenius_norm": 2.6777288913726807,
                "spectral_norm": 1.417688012123108,
                "alpha": 1.168896659972063,
                "alpha_hat": 1.8737904471841313
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.015295562334358692,
                "median": 0.012384701520204544,
                "std": 0.14598362147808075,
                "max": 0.38750964403152466,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.660657286643982,
                "spectral_norm": 0.893760621547699,
                "alpha": 1.8448623750304005,
                "alpha_hat": 2.133754624661142
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=8_scaler_type=minmax_seed=1415": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "minmax",
            "total_params": 888
        },
        "seed": 1415,
        "scores": {
            "smape": 0.07973333448171616,
            "mse": 478055744.0,
            "mae": 2189.974365234375,
            "r2_score": 0.8967334032058716,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.05900854989886284,
                "median": 0.06334545463323593,
                "std": 0.1902160942554474,
                "max": 0.5232560634613037,
                "min": -0.3913463056087494,
                "frobenius_norm": 2.7596232891082764,
                "spectral_norm": 1.6157034635543823,
                "alpha": 1.2107636797208086,
                "alpha_hat": 1.9027688912411929
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.030569065362215042,
                "median": 0.03822692483663559,
                "std": 0.17405113577842712,
                "max": 0.4031426012516022,
                "min": -0.40825507044792175,
                "frobenius_norm": 2.8274433612823486,
                "spectral_norm": 1.6934260129928589,
                "alpha": 1.1780482918140942,
                "alpha_hat": 1.8516987085923442
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.014433786273002625,
                "median": -0.02125118300318718,
                "std": 0.1667344570159912,
                "max": 0.4267697036266327,
                "min": -0.495712548494339,
                "frobenius_norm": 2.6777288913726807,
                "spectral_norm": 1.417688012123108,
                "alpha": 1.168896659972063,
                "alpha_hat": 1.8737904471841313
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.015295562334358692,
                "median": 0.012384701520204544,
                "std": 0.14598362147808075,
                "max": 0.38750964403152466,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.660657286643982,
                "spectral_norm": 0.893760621547699,
                "alpha": 1.8448623750304005,
                "alpha_hat": 2.133754624661142
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=8_scaler_type=minmax_seed=1617": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "minmax",
            "total_params": 888
        },
        "seed": 1617,
        "scores": {
            "smape": 0.08023916929960251,
            "mse": 506478208.0,
            "mae": 2260.89697265625,
            "r2_score": 0.8905937075614929,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.05900854989886284,
                "median": 0.06334545463323593,
                "std": 0.1902160942554474,
                "max": 0.5232560634613037,
                "min": -0.3913463056087494,
                "frobenius_norm": 2.7596232891082764,
                "spectral_norm": 1.6157034635543823,
                "alpha": 1.2107636797208086,
                "alpha_hat": 1.9027688912411929
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.030569065362215042,
                "median": 0.03822692483663559,
                "std": 0.17405113577842712,
                "max": 0.4031426012516022,
                "min": -0.40825507044792175,
                "frobenius_norm": 2.8274433612823486,
                "spectral_norm": 1.6934260129928589,
                "alpha": 1.1780482918140942,
                "alpha_hat": 1.8516987085923442
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.014433786273002625,
                "median": -0.02125118300318718,
                "std": 0.1667344570159912,
                "max": 0.4267697036266327,
                "min": -0.495712548494339,
                "frobenius_norm": 2.6777288913726807,
                "spectral_norm": 1.417688012123108,
                "alpha": 1.168896659972063,
                "alpha_hat": 1.8737904471841313
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.015295562334358692,
                "median": 0.012384701520204544,
                "std": 0.14598362147808075,
                "max": 0.38750964403152466,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.660657286643982,
                "spectral_norm": 0.893760621547699,
                "alpha": 1.8448623750304005,
                "alpha_hat": 2.133754624661142
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=8_scaler_type=minmax_seed=1819": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 8,
            "scaler_type": "minmax",
            "total_params": 888
        },
        "seed": 1819,
        "scores": {
            "smape": 0.08069781959056854,
            "mse": 571770304.0,
            "mae": 2308.55908203125,
            "r2_score": 0.8764897584915161,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.05900854989886284,
                "median": 0.06334545463323593,
                "std": 0.1902160942554474,
                "max": 0.5232560634613037,
                "min": -0.3913463056087494,
                "frobenius_norm": 2.7596232891082764,
                "spectral_norm": 1.6157034635543823,
                "alpha": 1.2107636797208086,
                "alpha_hat": 1.9027688912411929
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.030569065362215042,
                "median": 0.03822692483663559,
                "std": 0.17405113577842712,
                "max": 0.4031426012516022,
                "min": -0.40825507044792175,
                "frobenius_norm": 2.8274433612823486,
                "spectral_norm": 1.6934260129928589,
                "alpha": 1.1780482918140942,
                "alpha_hat": 1.8516987085923442
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.014433786273002625,
                "median": -0.02125118300318718,
                "std": 0.1667344570159912,
                "max": 0.4267697036266327,
                "min": -0.495712548494339,
                "frobenius_norm": 2.6777288913726807,
                "spectral_norm": 1.417688012123108,
                "alpha": 1.168896659972063,
                "alpha_hat": 1.8737904471841313
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.015295562334358692,
                "median": 0.012384701520204544,
                "std": 0.14598362147808075,
                "max": 0.38750964403152466,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.660657286643982,
                "spectral_norm": 0.893760621547699,
                "alpha": 1.8448623750304005,
                "alpha_hat": 2.133754624661142
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=16_scaler_type=identity_seed=123": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 888
        },
        "seed": 123,
        "scores": {
            "smape": 0.08527415990829468,
            "mse": 497996544.0,
            "mae": 2075.95361328125,
            "r2_score": 0.8924258947372437,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.04570131376385689,
                "median": 0.06429770588874817,
                "std": 0.17061375081539154,
                "max": 0.3870789408683777,
                "min": -0.32322829961776733,
                "frobenius_norm": 2.4474377632141113,
                "spectral_norm": 1.1619735956192017,
                "alpha": 1.2754466866701457,
                "alpha_hat": 1.5625940325354641
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.06048855558037758,
                "median": 0.06821499764919281,
                "std": 0.16721303761005402,
                "max": 0.481283038854599,
                "min": -0.391664981842041,
                "frobenius_norm": 2.8450801372528076,
                "spectral_norm": 1.8411036729812622,
                "alpha": 1.1983615062943507,
                "alpha_hat": 2.1374205497288217
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.03115910105407238,
                "median": 0.037526391446590424,
                "std": 0.16287630796432495,
                "max": 0.44387122988700867,
                "min": -0.286335825920105,
                "frobenius_norm": 2.6532795429229736,
                "spectral_norm": 1.533565878868103,
                "alpha": 1.1805716077761612,
                "alpha_hat": 2.2984652895113395
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.03498335927724838,
                "median": 0.028145212680101395,
                "std": 0.1642850637435913,
                "max": 0.332678884267807,
                "min": -0.26661479473114014,
                "frobenius_norm": 1.9003466367721558,
                "spectral_norm": 1.0599697828292847,
                "alpha": 1.6134748009041309,
                "alpha_hat": 2.285753595739574
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=16_scaler_type=identity_seed=456": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 888
        },
        "seed": 456,
        "scores": {
            "smape": 0.08771762996912003,
            "mse": 518862848.0,
            "mae": 2107.729248046875,
            "r2_score": 0.8879184722900391,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.04570131376385689,
                "median": 0.06429770588874817,
                "std": 0.17061375081539154,
                "max": 0.3870789408683777,
                "min": -0.32322829961776733,
                "frobenius_norm": 2.4474377632141113,
                "spectral_norm": 1.1619735956192017,
                "alpha": 1.2754466866701457,
                "alpha_hat": 1.5625940325354641
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.06048855558037758,
                "median": 0.06821499764919281,
                "std": 0.16721303761005402,
                "max": 0.481283038854599,
                "min": -0.391664981842041,
                "frobenius_norm": 2.8450801372528076,
                "spectral_norm": 1.8411036729812622,
                "alpha": 1.1983615062943507,
                "alpha_hat": 2.1374205497288217
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.03115910105407238,
                "median": 0.037526391446590424,
                "std": 0.16287630796432495,
                "max": 0.44387122988700867,
                "min": -0.286335825920105,
                "frobenius_norm": 2.6532795429229736,
                "spectral_norm": 1.533565878868103,
                "alpha": 1.1805716077761612,
                "alpha_hat": 2.2984652895113395
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.03498335927724838,
                "median": 0.028145212680101395,
                "std": 0.1642850637435913,
                "max": 0.332678884267807,
                "min": -0.26661479473114014,
                "frobenius_norm": 1.9003466367721558,
                "spectral_norm": 1.0599697828292847,
                "alpha": 1.6134748009041309,
                "alpha_hat": 2.285753595739574
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=16_scaler_type=identity_seed=789": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 888
        },
        "seed": 789,
        "scores": {
            "smape": 0.08799968659877777,
            "mse": 480595072.0,
            "mae": 2077.868408203125,
            "r2_score": 0.8961848616600037,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.04570131376385689,
                "median": 0.06429770588874817,
                "std": 0.17061375081539154,
                "max": 0.3870789408683777,
                "min": -0.32322829961776733,
                "frobenius_norm": 2.4474377632141113,
                "spectral_norm": 1.1619735956192017,
                "alpha": 1.2754466866701457,
                "alpha_hat": 1.5625940325354641
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.06048855558037758,
                "median": 0.06821499764919281,
                "std": 0.16721303761005402,
                "max": 0.481283038854599,
                "min": -0.391664981842041,
                "frobenius_norm": 2.8450801372528076,
                "spectral_norm": 1.8411036729812622,
                "alpha": 1.1983615062943507,
                "alpha_hat": 2.1374205497288217
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.03115910105407238,
                "median": 0.037526391446590424,
                "std": 0.16287630796432495,
                "max": 0.44387122988700867,
                "min": -0.286335825920105,
                "frobenius_norm": 2.6532795429229736,
                "spectral_norm": 1.533565878868103,
                "alpha": 1.1805716077761612,
                "alpha_hat": 2.2984652895113395
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.03498335927724838,
                "median": 0.028145212680101395,
                "std": 0.1642850637435913,
                "max": 0.332678884267807,
                "min": -0.26661479473114014,
                "frobenius_norm": 1.9003466367721558,
                "spectral_norm": 1.0599697828292847,
                "alpha": 1.6134748009041309,
                "alpha_hat": 2.285753595739574
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=16_scaler_type=identity_seed=42": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 888
        },
        "seed": 42,
        "scores": {
            "smape": 0.08338429778814316,
            "mse": 498159584.0,
            "mae": 2049.8779296875,
            "r2_score": 0.8923906683921814,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.04570131376385689,
                "median": 0.06429770588874817,
                "std": 0.17061375081539154,
                "max": 0.3870789408683777,
                "min": -0.32322829961776733,
                "frobenius_norm": 2.4474377632141113,
                "spectral_norm": 1.1619735956192017,
                "alpha": 1.2754466866701457,
                "alpha_hat": 1.5625940325354641
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.06048855558037758,
                "median": 0.06821499764919281,
                "std": 0.16721303761005402,
                "max": 0.481283038854599,
                "min": -0.391664981842041,
                "frobenius_norm": 2.8450801372528076,
                "spectral_norm": 1.8411036729812622,
                "alpha": 1.1983615062943507,
                "alpha_hat": 2.1374205497288217
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.03115910105407238,
                "median": 0.037526391446590424,
                "std": 0.16287630796432495,
                "max": 0.44387122988700867,
                "min": -0.286335825920105,
                "frobenius_norm": 2.6532795429229736,
                "spectral_norm": 1.533565878868103,
                "alpha": 1.1805716077761612,
                "alpha_hat": 2.2984652895113395
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.03498335927724838,
                "median": 0.028145212680101395,
                "std": 0.1642850637435913,
                "max": 0.332678884267807,
                "min": -0.26661479473114014,
                "frobenius_norm": 1.9003466367721558,
                "spectral_norm": 1.0599697828292847,
                "alpha": 1.6134748009041309,
                "alpha_hat": 2.285753595739574
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=16_scaler_type=identity_seed=1213": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 888
        },
        "seed": 1213,
        "scores": {
            "smape": 0.08477288484573364,
            "mse": 508703168.0,
            "mae": 2087.369140625,
            "r2_score": 0.890113115310669,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.04619060084223747,
                "median": 0.05938556045293808,
                "std": 0.1693819910287857,
                "max": 0.37220853567123413,
                "min": -0.3038066327571869,
                "frobenius_norm": 2.432730197906494,
                "spectral_norm": 1.1538724899291992,
                "alpha": 1.299600982760046,
                "alpha_hat": 1.6089767080910855
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.05520752817392349,
                "median": 0.052428726106882095,
                "std": 0.16901880502700806,
                "max": 0.5584967732429504,
                "min": -0.27054762840270996,
                "frobenius_norm": 2.844907283782959,
                "spectral_norm": 1.7570791244506836,
                "alpha": 1.1531976749298265,
                "alpha_hat": 2.084636030629195
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.03415185585618019,
                "median": 0.026654820889234543,
                "std": 0.16582010686397552,
                "max": 0.46446701884269714,
                "min": -0.28559228777885437,
                "frobenius_norm": 2.708807945251465,
                "spectral_norm": 1.6675235033035278,
                "alpha": 1.1647629770865784,
                "alpha_hat": 2.1418859360988542
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.04121886193752289,
                "median": 0.04249701648950577,
                "std": 0.1539865881204605,
                "max": 0.3319094777107239,
                "min": -0.236368790268898,
                "frobenius_norm": 1.8034940958023071,
                "spectral_norm": 1.0322200059890747,
                "alpha": 1.7878125135536693,
                "alpha_hat": 2.402706390804143
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=16_scaler_type=identity_seed=1617": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 888
        },
        "seed": 1617,
        "scores": {
            "smape": 0.08383099734783173,
            "mse": 486320416.0,
            "mae": 2042.2515869140625,
            "r2_score": 0.8949481248855591,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.04619060084223747,
                "median": 0.05938556045293808,
                "std": 0.1693819910287857,
                "max": 0.37220853567123413,
                "min": -0.3038066327571869,
                "frobenius_norm": 2.432730197906494,
                "spectral_norm": 1.1538724899291992,
                "alpha": 1.299600982760046,
                "alpha_hat": 1.6089767080910855
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.05520752817392349,
                "median": 0.052428726106882095,
                "std": 0.16901880502700806,
                "max": 0.5584967732429504,
                "min": -0.27054762840270996,
                "frobenius_norm": 2.844907283782959,
                "spectral_norm": 1.7570791244506836,
                "alpha": 1.1531976749298265,
                "alpha_hat": 2.084636030629195
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.03415185585618019,
                "median": 0.026654820889234543,
                "std": 0.16582010686397552,
                "max": 0.46446701884269714,
                "min": -0.28559228777885437,
                "frobenius_norm": 2.708807945251465,
                "spectral_norm": 1.6675235033035278,
                "alpha": 1.1647629770865784,
                "alpha_hat": 2.1418859360988542
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.04121886193752289,
                "median": 0.04249701648950577,
                "std": 0.1539865881204605,
                "max": 0.3319094777107239,
                "min": -0.236368790268898,
                "frobenius_norm": 1.8034940958023071,
                "spectral_norm": 1.0322200059890747,
                "alpha": 1.7878125135536693,
                "alpha_hat": 2.402706390804143
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=16_scaler_type=identity_seed=1011": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 888
        },
        "seed": 1011,
        "scores": {
            "smape": 0.0874965637922287,
            "mse": 523234688.0,
            "mae": 2137.83935546875,
            "r2_score": 0.8869740962982178,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.04619060084223747,
                "median": 0.05938556045293808,
                "std": 0.1693819910287857,
                "max": 0.37220853567123413,
                "min": -0.3038066327571869,
                "frobenius_norm": 2.432730197906494,
                "spectral_norm": 1.1538724899291992,
                "alpha": 1.299600982760046,
                "alpha_hat": 1.6089767080910855
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.05520752817392349,
                "median": 0.052428726106882095,
                "std": 0.16901880502700806,
                "max": 0.5584967732429504,
                "min": -0.27054762840270996,
                "frobenius_norm": 2.844907283782959,
                "spectral_norm": 1.7570791244506836,
                "alpha": 1.1531976749298265,
                "alpha_hat": 2.084636030629195
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.03415185585618019,
                "median": 0.026654820889234543,
                "std": 0.16582010686397552,
                "max": 0.46446701884269714,
                "min": -0.28559228777885437,
                "frobenius_norm": 2.708807945251465,
                "spectral_norm": 1.6675235033035278,
                "alpha": 1.1647629770865784,
                "alpha_hat": 2.1418859360988542
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.04121886193752289,
                "median": 0.04249701648950577,
                "std": 0.1539865881204605,
                "max": 0.3319094777107239,
                "min": -0.236368790268898,
                "frobenius_norm": 1.8034940958023071,
                "spectral_norm": 1.0322200059890747,
                "alpha": 1.7878125135536693,
                "alpha_hat": 2.402706390804143
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=16_scaler_type=identity_seed=1415": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 888
        },
        "seed": 1415,
        "scores": {
            "smape": 0.08557446300983429,
            "mse": 498620096.0,
            "mae": 2043.288330078125,
            "r2_score": 0.8922911882400513,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.04619060084223747,
                "median": 0.05938556045293808,
                "std": 0.1693819910287857,
                "max": 0.37220853567123413,
                "min": -0.3038066327571869,
                "frobenius_norm": 2.432730197906494,
                "spectral_norm": 1.1538724899291992,
                "alpha": 1.299600982760046,
                "alpha_hat": 1.6089767080910855
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.05520752817392349,
                "median": 0.052428726106882095,
                "std": 0.16901880502700806,
                "max": 0.5584967732429504,
                "min": -0.27054762840270996,
                "frobenius_norm": 2.844907283782959,
                "spectral_norm": 1.7570791244506836,
                "alpha": 1.1531976749298265,
                "alpha_hat": 2.084636030629195
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.03415185585618019,
                "median": 0.026654820889234543,
                "std": 0.16582010686397552,
                "max": 0.46446701884269714,
                "min": -0.28559228777885437,
                "frobenius_norm": 2.708807945251465,
                "spectral_norm": 1.6675235033035278,
                "alpha": 1.1647629770865784,
                "alpha_hat": 2.1418859360988542
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.04121886193752289,
                "median": 0.04249701648950577,
                "std": 0.1539865881204605,
                "max": 0.3319094777107239,
                "min": -0.236368790268898,
                "frobenius_norm": 1.8034940958023071,
                "spectral_norm": 1.0322200059890747,
                "alpha": 1.7878125135536693,
                "alpha_hat": 2.402706390804143
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=16_scaler_type=identity_seed=1819": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 888
        },
        "seed": 1819,
        "scores": {
            "smape": 0.086112841963768,
            "mse": 503913568.0,
            "mae": 2064.068359375,
            "r2_score": 0.8911477327346802,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.026659123599529266,
                "median": 0.026209058240056038,
                "std": 0.21319721639156342,
                "max": 0.6060943007469177,
                "min": -0.4035874009132385,
                "frobenius_norm": 2.9771533012390137,
                "spectral_norm": 1.6548779010772705,
                "alpha": 1.2870173837481373,
                "alpha_hat": 2.1729053732095736
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0361250676214695,
                "median": 0.034070126712322235,
                "std": 0.21657578647136688,
                "max": 0.6457281708717346,
                "min": -0.551132321357727,
                "frobenius_norm": 3.513087272644043,
                "spectral_norm": 2.0153284072875977,
                "alpha": 1.1793863859963325,
                "alpha_hat": 3.3765544429915666
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.004007960669696331,
                "median": -0.013998246751725674,
                "std": 0.19382011890411377,
                "max": 0.560911238193512,
                "min": -0.486903578042984,
                "frobenius_norm": 3.1017847061157227,
                "spectral_norm": 1.7348928451538086,
                "alpha": 1.1468716840818318,
                "alpha_hat": 2.167394831186572
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.0299028679728508,
                "median": 0.04525710642337799,
                "std": 0.15136785805225372,
                "max": 0.46821266412734985,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.745628833770752,
                "spectral_norm": 1.063139796257019,
                "alpha": 1.698328855178142,
                "alpha_hat": 2.282243787111209
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=16_scaler_type=identity_seed=2021": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 888
        },
        "seed": 2021,
        "scores": {
            "smape": 0.08836597949266434,
            "mse": 531632960.0,
            "mae": 2160.28759765625,
            "r2_score": 0.885159969329834,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.026659123599529266,
                "median": 0.026209058240056038,
                "std": 0.21319721639156342,
                "max": 0.6060943007469177,
                "min": -0.4035874009132385,
                "frobenius_norm": 2.9771533012390137,
                "spectral_norm": 1.6548779010772705,
                "alpha": 1.2870173837481373,
                "alpha_hat": 2.1729053732095736
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0361250676214695,
                "median": 0.034070126712322235,
                "std": 0.21657578647136688,
                "max": 0.6457281708717346,
                "min": -0.551132321357727,
                "frobenius_norm": 3.513087272644043,
                "spectral_norm": 2.0153284072875977,
                "alpha": 1.1793863859963325,
                "alpha_hat": 3.3765544429915666
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.004007960669696331,
                "median": -0.013998246751725674,
                "std": 0.19382011890411377,
                "max": 0.560911238193512,
                "min": -0.486903578042984,
                "frobenius_norm": 3.1017847061157227,
                "spectral_norm": 1.7348928451538086,
                "alpha": 1.1468716840818318,
                "alpha_hat": 2.167394831186572
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.0299028679728508,
                "median": 0.04525710642337799,
                "std": 0.15136785805225372,
                "max": 0.46821266412734985,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.745628833770752,
                "spectral_norm": 1.063139796257019,
                "alpha": 1.698328855178142,
                "alpha_hat": 2.282243787111209
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=16_scaler_type=standard_seed=42": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 888
        },
        "seed": 42,
        "scores": {
            "smape": 0.07449643313884735,
            "mse": 444597376.0,
            "mae": 2019.1339111328125,
            "r2_score": 0.9039608240127563,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.026659123599529266,
                "median": 0.026209058240056038,
                "std": 0.21319721639156342,
                "max": 0.6060943007469177,
                "min": -0.4035874009132385,
                "frobenius_norm": 2.9771533012390137,
                "spectral_norm": 1.6548779010772705,
                "alpha": 1.2870173837481373,
                "alpha_hat": 2.1729053732095736
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0361250676214695,
                "median": 0.034070126712322235,
                "std": 0.21657578647136688,
                "max": 0.6457281708717346,
                "min": -0.551132321357727,
                "frobenius_norm": 3.513087272644043,
                "spectral_norm": 2.0153284072875977,
                "alpha": 1.1793863859963325,
                "alpha_hat": 3.3765544429915666
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.004007960669696331,
                "median": -0.013998246751725674,
                "std": 0.19382011890411377,
                "max": 0.560911238193512,
                "min": -0.486903578042984,
                "frobenius_norm": 3.1017847061157227,
                "spectral_norm": 1.7348928451538086,
                "alpha": 1.1468716840818318,
                "alpha_hat": 2.167394831186572
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.0299028679728508,
                "median": 0.04525710642337799,
                "std": 0.15136785805225372,
                "max": 0.46821266412734985,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.745628833770752,
                "spectral_norm": 1.063139796257019,
                "alpha": 1.698328855178142,
                "alpha_hat": 2.282243787111209
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=16_scaler_type=standard_seed=123": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 888
        },
        "seed": 123,
        "scores": {
            "smape": 0.07482767850160599,
            "mse": 468447520.0,
            "mae": 2063.160400390625,
            "r2_score": 0.8988088965415955,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.026659123599529266,
                "median": 0.026209058240056038,
                "std": 0.21319721639156342,
                "max": 0.6060943007469177,
                "min": -0.4035874009132385,
                "frobenius_norm": 2.9771533012390137,
                "spectral_norm": 1.6548779010772705,
                "alpha": 1.2870173837481373,
                "alpha_hat": 2.1729053732095736
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0361250676214695,
                "median": 0.034070126712322235,
                "std": 0.21657578647136688,
                "max": 0.6457281708717346,
                "min": -0.551132321357727,
                "frobenius_norm": 3.513087272644043,
                "spectral_norm": 2.0153284072875977,
                "alpha": 1.1793863859963325,
                "alpha_hat": 3.3765544429915666
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.004007960669696331,
                "median": -0.013998246751725674,
                "std": 0.19382011890411377,
                "max": 0.560911238193512,
                "min": -0.486903578042984,
                "frobenius_norm": 3.1017847061157227,
                "spectral_norm": 1.7348928451538086,
                "alpha": 1.1468716840818318,
                "alpha_hat": 2.167394831186572
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.0299028679728508,
                "median": 0.04525710642337799,
                "std": 0.15136785805225372,
                "max": 0.46821266412734985,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.745628833770752,
                "spectral_norm": 1.063139796257019,
                "alpha": 1.698328855178142,
                "alpha_hat": 2.282243787111209
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=16_scaler_type=standard_seed=456": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 888
        },
        "seed": 456,
        "scores": {
            "smape": 0.07400573045015335,
            "mse": 474845376.0,
            "mae": 2040.8353271484375,
            "r2_score": 0.8974268436431885,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.02542024664580822,
                "median": 0.020657576620578766,
                "std": 0.2139042317867279,
                "max": 0.607178807258606,
                "min": -0.5653864741325378,
                "frobenius_norm": 2.984800100326538,
                "spectral_norm": 1.628819465637207,
                "alpha": 1.3117157748344948,
                "alpha_hat": 2.2272329673030233
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.03486230596899986,
                "median": 0.0434725284576416,
                "std": 0.22004841268062592,
                "max": 0.593582272529602,
                "min": -0.5981430411338806,
                "frobenius_norm": 3.5646867752075195,
                "spectral_norm": 1.9635952711105347,
                "alpha": 1.0940865410148597,
                "alpha_hat": 2.988611280396354
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0024782447144389153,
                "median": -0.004021978005766869,
                "std": 0.20215710997581482,
                "max": 0.5652589201927185,
                "min": -0.5738495588302612,
                "frobenius_norm": 3.2347567081451416,
                "spectral_norm": 1.8694325685501099,
                "alpha": 1.2408898680626912,
                "alpha_hat": 2.881844520196297
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.03242378681898117,
                "median": 0.04872715473175049,
                "std": 0.155973881483078,
                "max": 0.5164734721183777,
                "min": -0.2472999393939972,
                "frobenius_norm": 1.8023682832717896,
                "spectral_norm": 1.0641295909881592,
                "alpha": 1.7435793830046726,
                "alpha_hat": 2.4962177378817954
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=16_scaler_type=standard_seed=1011": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 888
        },
        "seed": 1011,
        "scores": {
            "smape": 0.07455293089151382,
            "mse": 470904416.0,
            "mae": 2047.2564697265625,
            "r2_score": 0.8982781767845154,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.02542024664580822,
                "median": 0.020657576620578766,
                "std": 0.2139042317867279,
                "max": 0.607178807258606,
                "min": -0.5653864741325378,
                "frobenius_norm": 2.984800100326538,
                "spectral_norm": 1.628819465637207,
                "alpha": 1.3117157748344948,
                "alpha_hat": 2.2272329673030233
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.03486230596899986,
                "median": 0.0434725284576416,
                "std": 0.22004841268062592,
                "max": 0.593582272529602,
                "min": -0.5981430411338806,
                "frobenius_norm": 3.5646867752075195,
                "spectral_norm": 1.9635952711105347,
                "alpha": 1.0940865410148597,
                "alpha_hat": 2.988611280396354
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0024782447144389153,
                "median": -0.004021978005766869,
                "std": 0.20215710997581482,
                "max": 0.5652589201927185,
                "min": -0.5738495588302612,
                "frobenius_norm": 3.2347567081451416,
                "spectral_norm": 1.8694325685501099,
                "alpha": 1.2408898680626912,
                "alpha_hat": 2.881844520196297
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.03242378681898117,
                "median": 0.04872715473175049,
                "std": 0.155973881483078,
                "max": 0.5164734721183777,
                "min": -0.2472999393939972,
                "frobenius_norm": 1.8023682832717896,
                "spectral_norm": 1.0641295909881592,
                "alpha": 1.7435793830046726,
                "alpha_hat": 2.4962177378817954
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=16_scaler_type=standard_seed=789": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 888
        },
        "seed": 789,
        "scores": {
            "smape": 0.07484316825866699,
            "mse": 461223264.0,
            "mae": 2066.995361328125,
            "r2_score": 0.90036940574646,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.02542024664580822,
                "median": 0.020657576620578766,
                "std": 0.2139042317867279,
                "max": 0.607178807258606,
                "min": -0.5653864741325378,
                "frobenius_norm": 2.984800100326538,
                "spectral_norm": 1.628819465637207,
                "alpha": 1.3117157748344948,
                "alpha_hat": 2.2272329673030233
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.03486230596899986,
                "median": 0.0434725284576416,
                "std": 0.22004841268062592,
                "max": 0.593582272529602,
                "min": -0.5981430411338806,
                "frobenius_norm": 3.5646867752075195,
                "spectral_norm": 1.9635952711105347,
                "alpha": 1.0940865410148597,
                "alpha_hat": 2.988611280396354
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0024782447144389153,
                "median": -0.004021978005766869,
                "std": 0.20215710997581482,
                "max": 0.5652589201927185,
                "min": -0.5738495588302612,
                "frobenius_norm": 3.2347567081451416,
                "spectral_norm": 1.8694325685501099,
                "alpha": 1.2408898680626912,
                "alpha_hat": 2.881844520196297
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.03242378681898117,
                "median": 0.04872715473175049,
                "std": 0.155973881483078,
                "max": 0.5164734721183777,
                "min": -0.2472999393939972,
                "frobenius_norm": 1.8023682832717896,
                "spectral_norm": 1.0641295909881592,
                "alpha": 1.7435793830046726,
                "alpha_hat": 2.4962177378817954
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size=16_learning_rate=0.001_batch_size=16_scaler_type=standard_seed=1213": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 500,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 888
        },
        "seed": 1213,
        "scores": {
            "smape": 0.07393259555101395,
            "mse": 453321344.0,
            "mae": 2044.4520263671875,
            "r2_score": 0.9020763635635376,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.02542024664580822,
                "median": 0.020657576620578766,
                "std": 0.2139042317867279,
                "max": 0.607178807258606,
                "min": -0.5653864741325378,
                "frobenius_norm": 2.984800100326538,
                "spectral_norm": 1.628819465637207,
                "alpha": 1.3117157748344948,
                "alpha_hat": 2.2272329673030233
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.03486230596899986,
                "median": 0.0434725284576416,
                "std": 0.22004841268062592,
                "max": 0.593582272529602,
                "min": -0.5981430411338806,
                "frobenius_norm": 3.5646867752075195,
                "spectral_norm": 1.9635952711105347,
                "alpha": 1.0940865410148597,
                "alpha_hat": 2.988611280396354
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0024782447144389153,
                "median": -0.004021978005766869,
                "std": 0.20215710997581482,
                "max": 0.5652589201927185,
                "min": -0.5738495588302612,
                "frobenius_norm": 3.2347567081451416,
                "spectral_norm": 1.8694325685501099,
                "alpha": 1.2408898680626912,
                "alpha_hat": 2.881844520196297
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.03242378681898117,
                "median": 0.04872715473175049,
                "std": 0.155973881483078,
                "max": 0.5164734721183777,
                "min": -0.2472999393939972,
                "frobenius_norm": 1.8023682832717896,
                "spectral_norm": 1.0641295909881592,
                "alpha": 1.7435793830046726,
                "alpha_hat": 2.4962177378817954
            }
        }
    }
}