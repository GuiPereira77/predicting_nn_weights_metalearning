{
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.01_batch_size_16_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.08496472239494324,
            "mse": 499801696.0,
            "mae": 2121.606201171875,
            "r2_score": 0.892035961151123,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.057075660675764084,
                "median": 0.030779611319303513,
                "std": 0.21275359392166138,
                "max": 0.6022335886955261,
                "min": -0.3672715127468109,
                "frobenius_norm": 2.158259868621826,
                "spectral_norm": 1.4340661764144897,
                "num_singular_values": 8,
                "alpha": 1.5989310468889264
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.015997081995010376,
                "median": 0.06387767195701599,
                "std": 0.40554341673851013,
                "max": 0.9459500312805176,
                "min": -2.27146577835083,
                "frobenius_norm": 3.246870279312134,
                "spectral_norm": 2.5442206859588623,
                "num_singular_values": 8,
                "alpha": 1.2780459759667204
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.062528595328331,
                "median": 0.0023537781089544296,
                "std": 0.2829282879829407,
                "max": 1.0307533740997314,
                "min": -0.4786122441291809,
                "frobenius_norm": 2.3180439472198486,
                "spectral_norm": 1.5458310842514038,
                "num_singular_values": 8,
                "alpha": 1.1663975137067215
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.09997554123401642,
                "median": 0.10106540471315384,
                "std": 0.2298855036497116,
                "max": 0.6036242246627808,
                "min": -0.37672027945518494,
                "frobenius_norm": 2.00547194480896,
                "spectral_norm": 1.5607082843780518,
                "num_singular_values": 8,
                "alpha": 1.146323433536225
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.01_batch_size_16_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07128199189901352,
            "mse": 408600384.0,
            "mae": 1872.508056640625,
            "r2_score": 0.9117366671562195,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.16612650454044342,
                "median": 0.09675970673561096,
                "std": 0.3990243375301361,
                "max": 1.2481019496917725,
                "min": -0.9274566769599915,
                "frobenius_norm": 4.234922409057617,
                "spectral_norm": 3.0020124912261963,
                "num_singular_values": 8,
                "alpha": 1.501888701497447
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.040647175163030624,
                "median": 0.05333220213651657,
                "std": 0.641320526599884,
                "max": 1.860498070716858,
                "min": -1.949965238571167,
                "frobenius_norm": 5.1408586502075195,
                "spectral_norm": 3.4930636882781982,
                "num_singular_values": 8,
                "alpha": 1.208991164066254
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.1379200518131256,
                "median": 0.06299833953380585,
                "std": 0.4501773715019226,
                "max": 1.7283260822296143,
                "min": -0.6664753556251526,
                "frobenius_norm": 3.766645908355713,
                "spectral_norm": 3.3970630168914795,
                "num_singular_values": 8,
                "alpha": 1.154112696188832
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05982375144958496,
                "median": 0.06886579096317291,
                "std": 0.18252143263816833,
                "max": 0.3950447142124176,
                "min": -0.2765914797782898,
                "frobenius_norm": 1.5366030931472778,
                "spectral_norm": 0.8957505822181702,
                "num_singular_values": 8,
                "alpha": 1.1333927935409238
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.01_batch_size_16_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07254238426685333,
            "mse": 464895648.0,
            "mae": 1984.06298828125,
            "r2_score": 0.8995761275291443,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.19426433742046356,
                "median": 0.07075350731611252,
                "std": 0.47410449385643005,
                "max": 1.823448657989502,
                "min": -0.9546876549720764,
                "frobenius_norm": 5.0200910568237305,
                "spectral_norm": 3.6155216693878174,
                "num_singular_values": 8,
                "alpha": 1.4454107796188338
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.027458127588033676,
                "median": 0.10505906492471695,
                "std": 0.6477859020233154,
                "max": 1.2280375957489014,
                "min": -2.2026214599609375,
                "frobenius_norm": 5.186941146850586,
                "spectral_norm": 3.2434427738189697,
                "num_singular_values": 8,
                "alpha": 1.1936009343270952
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.036262236535549164,
                "median": 0.020476164296269417,
                "std": 0.3096591830253601,
                "max": 1.0711361169815063,
                "min": -0.8115169405937195,
                "frobenius_norm": 2.494201421737671,
                "spectral_norm": 1.6827605962753296,
                "num_singular_values": 8,
                "alpha": 1.3804035120706206
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03575660288333893,
                "median": -0.0026797358877956867,
                "std": 0.19942106306552887,
                "max": 0.43995893001556396,
                "min": -0.6922083497047424,
                "frobenius_norm": 1.6208105087280273,
                "spectral_norm": 0.9036180973052979,
                "num_singular_values": 8,
                "alpha": 1.1785510822103737
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.01_batch_size_16_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "scores": {
            "smape": 0.077363021671772,
            "mse": 498615904.0,
            "mae": 2166.0859375,
            "r2_score": 0.8922920823097229,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.17009179294109344,
                "median": 0.08919743448495865,
                "std": 0.4293130934238434,
                "max": 1.6486400365829468,
                "min": -0.975166380405426,
                "frobenius_norm": 4.524503707885742,
                "spectral_norm": 3.8182356357574463,
                "num_singular_values": 8,
                "alpha": 1.3613846204325795
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.11549996584653854,
                "median": -0.07913538813591003,
                "std": 0.4556894302368164,
                "max": 0.7685714960098267,
                "min": -2.5650951862335205,
                "frobenius_norm": 3.7607922554016113,
                "spectral_norm": 2.914585828781128,
                "num_singular_values": 8,
                "alpha": 1.1311061127652786
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.009011572226881981,
                "median": -0.01640038937330246,
                "std": 0.22453263401985168,
                "max": 0.6871021389961243,
                "min": -0.3609045743942261,
                "frobenius_norm": 1.797707200050354,
                "spectral_norm": 1.2427995204925537,
                "num_singular_values": 8,
                "alpha": 1.2580864526732363
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06478292495012283,
                "median": 0.11088236421346664,
                "std": 0.1935894638299942,
                "max": 0.5320809483528137,
                "min": -0.5217068195343018,
                "frobenius_norm": 1.6331310272216797,
                "spectral_norm": 1.1114006042480469,
                "num_singular_values": 8,
                "alpha": 1.2260290903950672
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.01_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.08357184380292892,
            "mse": 474259968.0,
            "mae": 1975.935546875,
            "r2_score": 0.8975533246994019,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.04917896166443825,
                "median": 0.022664301097393036,
                "std": 0.22933626174926758,
                "max": 0.7233275175094604,
                "min": -0.43341967463493347,
                "frobenius_norm": 2.2981109619140625,
                "spectral_norm": 1.4060635566711426,
                "num_singular_values": 8,
                "alpha": 1.6932773779745751
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.025185275822877884,
                "median": 0.05262983590364456,
                "std": 0.34103336930274963,
                "max": 0.9445385336875916,
                "min": -1.3089163303375244,
                "frobenius_norm": 2.73569655418396,
                "spectral_norm": 1.9720157384872437,
                "num_singular_values": 8,
                "alpha": 1.3173446227464405
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.14754077792167664,
                "median": 0.052901819348335266,
                "std": 0.4162294864654541,
                "max": 1.52959406375885,
                "min": -0.6105380654335022,
                "frobenius_norm": 3.5328428745269775,
                "spectral_norm": 3.068901538848877,
                "num_singular_values": 8,
                "alpha": 1.149321771982059
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.036186765879392624,
                "median": 0.10653313994407654,
                "std": 0.37537431716918945,
                "max": 0.5354964733123779,
                "min": -0.9235976338386536,
                "frobenius_norm": 3.016916036605835,
                "spectral_norm": 2.7369866371154785,
                "num_singular_values": 8,
                "alpha": 1.0915741015592832
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.01_batch_size_32_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07244873046875,
            "mse": 490655712.0,
            "mae": 2111.577880859375,
            "r2_score": 0.8940116167068481,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.12761050462722778,
                "median": 0.06935425847768784,
                "std": 0.41029804944992065,
                "max": 1.280882477760315,
                "min": -0.8780800104141235,
                "frobenius_norm": 4.210032939910889,
                "spectral_norm": 2.9678237438201904,
                "num_singular_values": 8,
                "alpha": 1.3018538664836405
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.020116038620471954,
                "median": 0.10528454184532166,
                "std": 0.5955317616462708,
                "max": 0.9466238617897034,
                "min": -2.487671375274658,
                "frobenius_norm": 4.766971111297607,
                "spectral_norm": 3.4206302165985107,
                "num_singular_values": 8,
                "alpha": 1.229370709931408
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.07100460678339005,
                "median": -0.020052112638950348,
                "std": 0.39802706241607666,
                "max": 0.8457913994789124,
                "min": -1.046582579612732,
                "frobenius_norm": 3.2344861030578613,
                "spectral_norm": 1.9845095872879028,
                "num_singular_values": 8,
                "alpha": 1.1903010109727274
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.08917325735092163,
                "median": 0.03283733129501343,
                "std": 0.4558653235435486,
                "max": 0.5316535830497742,
                "min": -1.6497904062271118,
                "frobenius_norm": 3.7160415649414062,
                "spectral_norm": 3.3946053981781006,
                "num_singular_values": 8,
                "alpha": 1.142663831572119
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.01_batch_size_32_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07428357005119324,
            "mse": 515805760.0,
            "mae": 2125.99072265625,
            "r2_score": 0.8885788321495056,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.14851351082324982,
                "median": 0.0829712301492691,
                "std": 0.47544047236442566,
                "max": 2.57535457611084,
                "min": -0.8277192115783691,
                "frobenius_norm": 4.880327224731445,
                "spectral_norm": 3.6206912994384766,
                "num_singular_values": 8,
                "alpha": 1.4919240193582117
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.09615269303321838,
                "median": 0.061682455241680145,
                "std": 0.7274897694587708,
                "max": 1.1597427129745483,
                "min": -2.689574718475342,
                "frobenius_norm": 5.870532512664795,
                "spectral_norm": 4.329150199890137,
                "num_singular_values": 8,
                "alpha": 1.2062295180313016
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.09380366653203964,
                "median": -0.07193874567747116,
                "std": 0.3040978014469147,
                "max": 0.5870632529258728,
                "min": -0.9527783393859863,
                "frobenius_norm": 2.545893669128418,
                "spectral_norm": 1.5608919858932495,
                "num_singular_values": 8,
                "alpha": 1.2523952846175046
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08750293403863907,
                "median": 0.11459414660930634,
                "std": 0.22551614046096802,
                "max": 0.5723406672477722,
                "min": -0.9156826138496399,
                "frobenius_norm": 1.9351783990859985,
                "spectral_norm": 1.4904814958572388,
                "num_singular_values": 8,
                "alpha": 1.1683484786180842
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.01_batch_size_32_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07925496995449066,
            "mse": 507204544.0,
            "mae": 2183.546630859375,
            "r2_score": 0.8904368281364441,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.17601589858531952,
                "median": 0.05616330727934837,
                "std": 0.44505223631858826,
                "max": 1.9001824855804443,
                "min": -0.6901634931564331,
                "frobenius_norm": 4.689252853393555,
                "spectral_norm": 4.223132610321045,
                "num_singular_values": 8,
                "alpha": 1.4673746160528827
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.024425730109214783,
                "median": -0.0006188719999045134,
                "std": 0.4621257781982422,
                "max": 2.2507054805755615,
                "min": -0.9562368392944336,
                "frobenius_norm": 3.7021665573120117,
                "spectral_norm": 2.6887528896331787,
                "num_singular_values": 8,
                "alpha": 1.217248122957277
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.03516925126314163,
                "median": -0.038195498287677765,
                "std": 0.24074113368988037,
                "max": 0.5921279191970825,
                "min": -0.4979895353317261,
                "frobenius_norm": 1.9463717937469482,
                "spectral_norm": 1.150452733039856,
                "num_singular_values": 8,
                "alpha": 1.183893495557732
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.049909818917512894,
                "median": 0.06088787317276001,
                "std": 0.2383454144001007,
                "max": 0.6661156415939331,
                "min": -0.6302976608276367,
                "frobenius_norm": 1.9481195211410522,
                "spectral_norm": 1.3086613416671753,
                "num_singular_values": 8,
                "alpha": 1.1739749029020021
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.01_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.117548368871212,
            "mse": 562935808.0,
            "mae": 2617.76806640625,
            "r2_score": 0.8783981204032898,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.07119128108024597,
                "median": 0.03392355144023895,
                "std": 0.22873297333717346,
                "max": 0.7635360360145569,
                "min": -0.3678957223892212,
                "frobenius_norm": 2.3471577167510986,
                "spectral_norm": 1.4132543802261353,
                "num_singular_values": 8,
                "alpha": 1.3595770105665435
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.006836548447608948,
                "median": 0.03660903126001358,
                "std": 0.29717332124710083,
                "max": 0.7418290972709656,
                "min": -0.92023766040802,
                "frobenius_norm": 2.3780155181884766,
                "spectral_norm": 1.372702956199646,
                "num_singular_values": 8,
                "alpha": 1.2024019145408253
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.15783411264419556,
                "median": 0.1072363629937172,
                "std": 0.38760387897491455,
                "max": 1.528151273727417,
                "min": -0.5383281111717224,
                "frobenius_norm": 3.3480582237243652,
                "spectral_norm": 2.8703367710113525,
                "num_singular_values": 8,
                "alpha": 1.309192112448525
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.15378695726394653,
                "median": 0.16158819198608398,
                "std": 0.227858766913414,
                "max": 0.6449129581451416,
                "min": -0.38921919465065,
                "frobenius_norm": 2.199200391769409,
                "spectral_norm": 1.5218476057052612,
                "num_singular_values": 8,
                "alpha": 1.2477552505790837
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.01_batch_size_64_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 64,
            "scaler_type": "standard",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07320746779441833,
            "mse": 474088384.0,
            "mae": 2017.36669921875,
            "r2_score": 0.8975903987884521,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.05069121718406677,
                "median": -0.0029142017010599375,
                "std": 0.3928258419036865,
                "max": 1.126060128211975,
                "min": -1.2485905885696411,
                "frobenius_norm": 3.880805015563965,
                "spectral_norm": 2.58796763420105,
                "num_singular_values": 8,
                "alpha": 1.4118157634386859
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.12038068473339081,
                "median": -0.03009115159511566,
                "std": 0.7197059392929077,
                "max": 1.7127406597137451,
                "min": -2.7029826641082764,
                "frobenius_norm": 5.83763313293457,
                "spectral_norm": 4.159128189086914,
                "num_singular_values": 8,
                "alpha": 1.2194284152250832
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.011736979708075523,
                "median": -0.036495961248874664,
                "std": 0.3451533019542694,
                "max": 1.406376838684082,
                "min": -0.8527560234069824,
                "frobenius_norm": 2.762822389602661,
                "spectral_norm": 2.0738630294799805,
                "num_singular_values": 8,
                "alpha": 1.333852468399027
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.016727175563573837,
                "median": -0.03876727819442749,
                "std": 0.25783035159111023,
                "max": 0.5624693036079407,
                "min": -0.42318132519721985,
                "frobenius_norm": 2.066979169845581,
                "spectral_norm": 1.6487431526184082,
                "num_singular_values": 8,
                "alpha": 1.191055841149126
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.01_batch_size_64_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 64,
            "scaler_type": "robust",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07296580076217651,
            "mse": 533368032.0,
            "mae": 2097.808349609375,
            "r2_score": 0.8847851753234863,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.042895153164863586,
                "median": -0.0022975648753345013,
                "std": 0.3594328463077545,
                "max": 1.4822850227355957,
                "min": -0.936103105545044,
                "frobenius_norm": 3.5466980934143066,
                "spectral_norm": 2.4847075939178467,
                "num_singular_values": 8,
                "alpha": 1.5348230062301602
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.13179412484169006,
                "median": -0.0445890948176384,
                "std": 0.7619157433509827,
                "max": 1.3009060621261597,
                "min": -3.039950132369995,
                "frobenius_norm": 6.185843467712402,
                "spectral_norm": 4.466225624084473,
                "num_singular_values": 8,
                "alpha": 1.2051195464919453
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.0059702638536691666,
                "median": -0.0809955894947052,
                "std": 0.34572020173072815,
                "max": 1.1970129013061523,
                "min": -0.6573484539985657,
                "frobenius_norm": 2.766173839569092,
                "spectral_norm": 1.859445333480835,
                "num_singular_values": 8,
                "alpha": 1.168146746757283
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.09117880463600159,
                "median": 0.08840024471282959,
                "std": 0.20535194873809814,
                "max": 0.6612565517425537,
                "min": -0.39649465680122375,
                "frobenius_norm": 1.797473669052124,
                "spectral_norm": 1.059072732925415,
                "num_singular_values": 8,
                "alpha": 1.300795099679112
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.01_batch_size_64_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 64,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07674041390419006,
            "mse": 503783936.0,
            "mae": 2154.2607421875,
            "r2_score": 0.8911757469177246,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.11713353544473648,
                "median": 0.05478562414646149,
                "std": 0.3720066249370575,
                "max": 1.7220219373703003,
                "min": -1.3601516485214233,
                "frobenius_norm": 3.821319341659546,
                "spectral_norm": 3.396773099899292,
                "num_singular_values": 8,
                "alpha": 1.4025596411521573
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.029279131442308426,
                "median": -0.027851063758134842,
                "std": 0.43334493041038513,
                "max": 1.3669767379760742,
                "min": -1.6396245956420898,
                "frobenius_norm": 3.474663257598877,
                "spectral_norm": 2.2690649032592773,
                "num_singular_values": 8,
                "alpha": 1.2276887588485654
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.03855153173208237,
                "median": -0.0432010143995285,
                "std": 0.28864941000938416,
                "max": 0.570334255695343,
                "min": -1.0785751342773438,
                "frobenius_norm": 2.329699754714966,
                "spectral_norm": 1.7621947526931763,
                "num_singular_values": 8,
                "alpha": 1.2072003292840643
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0867936760187149,
                "median": 0.08935453742742538,
                "std": 0.1867271065711975,
                "max": 0.5385730266571045,
                "min": -0.3089243769645691,
                "frobenius_norm": 1.6473039388656616,
                "spectral_norm": 0.9350728392601013,
                "num_singular_values": 8,
                "alpha": 1.1900819238248874
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.01_batch_size_128_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 128,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.08110900968313217,
            "mse": 448259296.0,
            "mae": 1982.7293701171875,
            "r2_score": 0.9031698107719421,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.014614668674767017,
                "median": -0.013920288532972336,
                "std": 0.2379285991191864,
                "max": 0.6319262385368347,
                "min": -0.549648106098175,
                "frobenius_norm": 2.33560848236084,
                "spectral_norm": 1.6633321046829224,
                "num_singular_values": 8,
                "alpha": 1.433599246970498
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.022564008831977844,
                "median": 0.021069802343845367,
                "std": 0.3275735676288605,
                "max": 0.5491437911987305,
                "min": -1.2511012554168701,
                "frobenius_norm": 2.626798391342163,
                "spectral_norm": 1.9196568727493286,
                "num_singular_values": 8,
                "alpha": 1.222687821951855
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06783400475978851,
                "median": 0.047473371028900146,
                "std": 0.254482239484787,
                "max": 0.5690407156944275,
                "min": -0.5800915956497192,
                "frobenius_norm": 2.106943368911743,
                "spectral_norm": 1.4244052171707153,
                "num_singular_values": 8,
                "alpha": 1.302648946105902
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.17236031591892242,
                "median": 0.19359485805034637,
                "std": 0.19822140038013458,
                "max": 0.5902982950210571,
                "min": -0.29064059257507324,
                "frobenius_norm": 2.1014249324798584,
                "spectral_norm": 1.5742822885513306,
                "num_singular_values": 8,
                "alpha": 1.1619945390868431
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.01_batch_size_128_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 128,
            "scaler_type": "standard",
            "total_params": 320
        },
        "scores": {
            "smape": 0.0709875077009201,
            "mse": 440555584.0,
            "mae": 1915.55810546875,
            "r2_score": 0.9048339128494263,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.20571208000183105,
                "median": 0.13925594091415405,
                "std": 0.3817281126976013,
                "max": 1.3004003763198853,
                "min": -1.010745882987976,
                "frobenius_norm": 4.24867582321167,
                "spectral_norm": 3.0978004932403564,
                "num_singular_values": 8,
                "alpha": 1.4544707299350197
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.03498246520757675,
                "median": 0.022349044680595398,
                "std": 0.5754204988479614,
                "max": 1.3385635614395142,
                "min": -1.808111548423767,
                "frobenius_norm": 4.611863136291504,
                "spectral_norm": 2.993114948272705,
                "num_singular_values": 8,
                "alpha": 1.1561498918654702
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.05586743727326393,
                "median": -0.09754210710525513,
                "std": 0.357500284910202,
                "max": 0.7960971593856812,
                "min": -0.9378821849822998,
                "frobenius_norm": 2.894713878631592,
                "spectral_norm": 1.870307207107544,
                "num_singular_values": 8,
                "alpha": 1.2417370236757024
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.1075734943151474,
                "median": 0.14338386058807373,
                "std": 0.235543355345726,
                "max": 0.5689668655395508,
                "min": -0.40542474389076233,
                "frobenius_norm": 2.071563482284546,
                "spectral_norm": 1.5484319925308228,
                "num_singular_values": 8,
                "alpha": 1.2525295468968767
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.01_batch_size_128_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 128,
            "scaler_type": "robust",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07290985435247421,
            "mse": 549820992.0,
            "mae": 2093.810302734375,
            "r2_score": 0.8812310695648193,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.1763310581445694,
                "median": 0.059992119669914246,
                "std": 0.5011688470840454,
                "max": 2.6075022220611572,
                "min": -0.7765430212020874,
                "frobenius_norm": 5.20550012588501,
                "spectral_norm": 4.175520896911621,
                "num_singular_values": 8,
                "alpha": 1.5094401219976816
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.10258682817220688,
                "median": 0.19339820742607117,
                "std": 0.6065864562988281,
                "max": 1.5125045776367188,
                "min": -2.057164192199707,
                "frobenius_norm": 4.921601295471191,
                "spectral_norm": 3.0627505779266357,
                "num_singular_values": 8,
                "alpha": 1.339322254303971
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.02172309160232544,
                "median": -0.05697330832481384,
                "std": 0.30227982997894287,
                "max": 0.7472389340400696,
                "min": -0.9940011501312256,
                "frobenius_norm": 2.4244751930236816,
                "spectral_norm": 1.5762906074523926,
                "num_singular_values": 8,
                "alpha": 1.142059319328919
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0538305938243866,
                "median": 0.022685036063194275,
                "std": 0.17181719839572906,
                "max": 0.4616645276546478,
                "min": -0.25344470143318176,
                "frobenius_norm": 1.4404195547103882,
                "spectral_norm": 0.8280522227287292,
                "num_singular_values": 8,
                "alpha": 1.1676188463453903
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.01_batch_size_128_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 128,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "scores": {
            "smape": 0.08849292993545532,
            "mse": 621768704.0,
            "mae": 2554.537841796875,
            "r2_score": 0.8656893968582153,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.20663048326969147,
                "median": 0.06651179492473602,
                "std": 0.4696802496910095,
                "max": 2.0421302318573,
                "min": -0.31643199920654297,
                "frobenius_norm": 5.027562618255615,
                "spectral_norm": 4.344020843505859,
                "num_singular_values": 8,
                "alpha": 1.451137205958698
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.03301108628511429,
                "median": -0.042903751134872437,
                "std": 0.47730356454849243,
                "max": 1.1837947368621826,
                "min": -1.7156482934951782,
                "frobenius_norm": 3.827550172805786,
                "spectral_norm": 3.119645357131958,
                "num_singular_values": 8,
                "alpha": 1.3172799131203612
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.07573702931404114,
                "median": -0.09123457223176956,
                "std": 0.2149016112089157,
                "max": 0.347518652677536,
                "min": -0.5588175058364868,
                "frobenius_norm": 1.8228557109832764,
                "spectral_norm": 1.254528522491455,
                "num_singular_values": 8,
                "alpha": 1.260225626980119
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.02169288694858551,
                "median": -0.014766263775527477,
                "std": 0.17710012197494507,
                "max": 0.3503389060497284,
                "min": -0.34516143798828125,
                "frobenius_norm": 1.4273899793624878,
                "spectral_norm": 0.7769322395324707,
                "num_singular_values": 8,
                "alpha": 1.1167229356090382
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.01_batch_size_256_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 256,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.09391295164823532,
            "mse": 523781280.0,
            "mae": 2283.320556640625,
            "r2_score": 0.8868560194969177,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.055425871163606644,
                "median": 0.020770780742168427,
                "std": 0.22820930182933807,
                "max": 0.7234009504318237,
                "min": -0.5053979158401489,
                "frobenius_norm": 2.300987958908081,
                "spectral_norm": 1.437931776046753,
                "num_singular_values": 8,
                "alpha": 1.5212594468713083
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.02322162687778473,
                "median": -0.022099696099758148,
                "std": 0.3330176770687103,
                "max": 1.1992839574813843,
                "min": -0.9964027404785156,
                "frobenius_norm": 2.6706104278564453,
                "spectral_norm": 1.912950873374939,
                "num_singular_values": 8,
                "alpha": 1.1884722621696726
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.15031586587429047,
                "median": 0.10038858652114868,
                "std": 0.3372266888618469,
                "max": 1.2922413349151611,
                "min": -0.41057029366493225,
                "frobenius_norm": 2.9536874294281006,
                "spectral_norm": 2.5659844875335693,
                "num_singular_values": 8,
                "alpha": 1.15050978722177
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.1632547229528427,
                "median": 0.14640092849731445,
                "std": 0.20998990535736084,
                "max": 0.5605563521385193,
                "min": -0.3343859910964966,
                "frobenius_norm": 2.127877712249756,
                "spectral_norm": 1.5848056077957153,
                "num_singular_values": 8,
                "alpha": 1.1611442430467465
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.01_batch_size_256_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 256,
            "scaler_type": "standard",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07359831780195236,
            "mse": 479299296.0,
            "mae": 2107.166748046875,
            "r2_score": 0.8964647650718689,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.04880242049694061,
                "median": 0.052803896367549896,
                "std": 0.33008909225463867,
                "max": 1.1300603151321411,
                "min": -0.8090310096740723,
                "frobenius_norm": 3.269355535507202,
                "spectral_norm": 2.112537384033203,
                "num_singular_values": 8,
                "alpha": 1.3444117358463914
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.1097232773900032,
                "median": -0.013380931690335274,
                "std": 0.5711841583251953,
                "max": 1.0925180912017822,
                "min": -2.235013723373413,
                "frobenius_norm": 4.653019905090332,
                "spectral_norm": 3.1373403072357178,
                "num_singular_values": 8,
                "alpha": 1.2646686516093382
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.028459738940000534,
                "median": 0.033378716558218,
                "std": 0.40831854939460754,
                "max": 0.8594970703125,
                "min": -1.168320655822754,
                "frobenius_norm": 3.2744734287261963,
                "spectral_norm": 1.9605886936187744,
                "num_singular_values": 8,
                "alpha": 1.1883635194783766
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.030157417058944702,
                "median": 0.10945367068052292,
                "std": 0.37767526507377625,
                "max": 0.8427532315254211,
                "min": -0.9941792488098145,
                "frobenius_norm": 3.0310192108154297,
                "spectral_norm": 2.3986597061157227,
                "num_singular_values": 8,
                "alpha": 1.2201263304872239
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.01_batch_size_256_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 256,
            "scaler_type": "robust",
            "total_params": 320
        },
        "scores": {
            "smape": 0.0725506842136383,
            "mse": 460199808.0,
            "mae": 1992.505615234375,
            "r2_score": 0.9005904793739319,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.10026434808969498,
                "median": 0.03067610412836075,
                "std": 0.405904620885849,
                "max": 2.1942834854125977,
                "min": -1.1495575904846191,
                "frobenius_norm": 4.096572399139404,
                "spectral_norm": 3.1847805976867676,
                "num_singular_values": 8,
                "alpha": 1.519054670725618
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.10366857796907425,
                "median": 0.038731954991817474,
                "std": 0.6220338344573975,
                "max": 1.360866904258728,
                "min": -1.9724847078323364,
                "frobenius_norm": 5.044907093048096,
                "spectral_norm": 3.2620925903320312,
                "num_singular_values": 8,
                "alpha": 1.2628661026695849
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.05011859908699989,
                "median": -0.07343430072069168,
                "std": 0.3812832236289978,
                "max": 1.2333770990371704,
                "min": -0.9152172803878784,
                "frobenius_norm": 3.0765044689178467,
                "spectral_norm": 2.027381181716919,
                "num_singular_values": 8,
                "alpha": 1.1442944065071654
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.10464567691087723,
                "median": 0.12341302633285522,
                "std": 0.23388192057609558,
                "max": 0.6147021651268005,
                "min": -0.6119399666786194,
                "frobenius_norm": 2.0498034954071045,
                "spectral_norm": 1.3828123807907104,
                "num_singular_values": 8,
                "alpha": 1.3107451486803958
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.01_batch_size_256_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 256,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07860548794269562,
            "mse": 548607040.0,
            "mae": 2269.02197265625,
            "r2_score": 0.881493330001831,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.09043220430612564,
                "median": 0.014721933752298355,
                "std": 0.4779411852359772,
                "max": 1.8415433168411255,
                "min": -2.712218761444092,
                "frobenius_norm": 4.765937328338623,
                "spectral_norm": 3.881399631500244,
                "num_singular_values": 8,
                "alpha": 1.498785658286852
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.09165727347135544,
                "median": -0.05954296141862869,
                "std": 0.378028929233551,
                "max": 0.9238566160202026,
                "min": -0.9075073003768921,
                "frobenius_norm": 3.1118550300598145,
                "spectral_norm": 2.0657553672790527,
                "num_singular_values": 8,
                "alpha": 1.30278869451094
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.036649707704782486,
                "median": -0.007524740416556597,
                "std": 0.2618192136287689,
                "max": 0.9156344532966614,
                "min": -0.37266042828559875,
                "frobenius_norm": 2.1149752140045166,
                "spectral_norm": 1.3310455083847046,
                "num_singular_values": 8,
                "alpha": 1.2362047896308692
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.046655699610710144,
                "median": 0.04942554980516434,
                "std": 0.20118193328380585,
                "max": 0.5060767531394958,
                "min": -0.44304898381233215,
                "frobenius_norm": 1.6521680355072021,
                "spectral_norm": 0.9033939242362976,
                "num_singular_values": 8,
                "alpha": 1.3357642079506913
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.005_batch_size_16_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.08604332059621811,
            "mse": 509480576.0,
            "mae": 2137.0166015625,
            "r2_score": 0.8899451494216919,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.05116085335612297,
                "median": 0.01789611577987671,
                "std": 0.19852212071418762,
                "max": 0.5077884793281555,
                "min": -0.33945634961128235,
                "frobenius_norm": 2.00866436958313,
                "spectral_norm": 1.1946064233779907,
                "num_singular_values": 8,
                "alpha": 1.5869517977579397
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01679365150630474,
                "median": 0.0495317280292511,
                "std": 0.2615486979484558,
                "max": 0.45346638560295105,
                "min": -0.7489917278289795,
                "frobenius_norm": 2.09669828414917,
                "spectral_norm": 1.3467305898666382,
                "num_singular_values": 8,
                "alpha": 1.2709691962898242
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.13826777040958405,
                "median": 0.13886156678199768,
                "std": 0.3140774369239807,
                "max": 1.0464001893997192,
                "min": -0.3461551368236542,
                "frobenius_norm": 2.7453248500823975,
                "spectral_norm": 2.1493239402770996,
                "num_singular_values": 8,
                "alpha": 1.1286572689376495
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.10222076624631882,
                "median": 0.1382969617843628,
                "std": 0.26160284876823425,
                "max": 0.5615178346633911,
                "min": -0.6583069562911987,
                "frobenius_norm": 2.246919870376587,
                "spectral_norm": 1.8089416027069092,
                "num_singular_values": 8,
                "alpha": 1.2103210403890274
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.005_batch_size_16_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07240565121173859,
            "mse": 478485504.0,
            "mae": 2001.850341796875,
            "r2_score": 0.8966405391693115,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.12900422513484955,
                "median": 0.08277219533920288,
                "std": 0.3465346097946167,
                "max": 1.2178608179092407,
                "min": -0.8263911008834839,
                "frobenius_norm": 3.6229708194732666,
                "spectral_norm": 2.6537740230560303,
                "num_singular_values": 8,
                "alpha": 1.5827657204711167
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.01633485220372677,
                "median": 0.03623034432530403,
                "std": 0.4738132655620575,
                "max": 0.9695194363594055,
                "min": -1.4997838735580444,
                "frobenius_norm": 3.792757987976074,
                "spectral_norm": 2.7543509006500244,
                "num_singular_values": 8,
                "alpha": 1.275665623009514
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.017212804406881332,
                "median": 0.03154055029153824,
                "std": 0.2912321388721466,
                "max": 0.9890666007995605,
                "min": -0.7306013107299805,
                "frobenius_norm": 2.333922863006592,
                "spectral_norm": 1.5197091102600098,
                "num_singular_values": 8,
                "alpha": 1.236837531058788
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.09506481885910034,
                "median": 0.10004475712776184,
                "std": 0.20148953795433044,
                "max": 0.6181735396385193,
                "min": -0.2535311281681061,
                "frobenius_norm": 1.78231942653656,
                "spectral_norm": 1.2283391952514648,
                "num_singular_values": 8,
                "alpha": 1.4117058515445853
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.005_batch_size_16_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07195650786161423,
            "mse": 450100672.0,
            "mae": 1955.248779296875,
            "r2_score": 0.902772068977356,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.10319127887487411,
                "median": 0.05994248390197754,
                "std": 0.3314284682273865,
                "max": 1.1343380212783813,
                "min": -1.0223814249038696,
                "frobenius_norm": 3.4010813236236572,
                "spectral_norm": 2.2934250831604004,
                "num_singular_values": 8,
                "alpha": 1.3776078768368807
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.0072107985615730286,
                "median": 0.09795915335416794,
                "std": 0.47586920857429504,
                "max": 0.6814521551132202,
                "min": -1.4565907716751099,
                "frobenius_norm": 3.8073909282684326,
                "spectral_norm": 2.7773358821868896,
                "num_singular_values": 8,
                "alpha": 1.4325598228482814
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.015350878238677979,
                "median": 0.06488561630249023,
                "std": 0.2861773669719696,
                "max": 0.6986944079399109,
                "min": -0.5732362866401672,
                "frobenius_norm": 2.292710304260254,
                "spectral_norm": 1.4075632095336914,
                "num_singular_values": 8,
                "alpha": 1.2416817560457276
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.09059104323387146,
                "median": 0.0939248651266098,
                "std": 0.1879524439573288,
                "max": 0.6145395636558533,
                "min": -0.25006577372550964,
                "frobenius_norm": 1.6691622734069824,
                "spectral_norm": 1.0465797185897827,
                "num_singular_values": 8,
                "alpha": 1.5195673253541382
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.005_batch_size_16_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "scores": {
            "smape": 0.0769004076719284,
            "mse": 482609216.0,
            "mae": 2138.61767578125,
            "r2_score": 0.8957497477531433,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.0893535241484642,
                "median": 0.05105108022689819,
                "std": 0.25917237997055054,
                "max": 0.9660313129425049,
                "min": -0.5384916663169861,
                "frobenius_norm": 2.6860415935516357,
                "spectral_norm": 2.1966686248779297,
                "num_singular_values": 8,
                "alpha": 1.3896380933707038
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.006488410755991936,
                "median": -0.012828313745558262,
                "std": 0.3622382879257202,
                "max": 0.6436872482299805,
                "min": -1.2884963750839233,
                "frobenius_norm": 2.898371458053589,
                "spectral_norm": 2.080674648284912,
                "num_singular_values": 8,
                "alpha": 1.4004695620751528
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.011447952128946781,
                "median": -0.008836142718791962,
                "std": 0.2346634566783905,
                "max": 0.6517184376716614,
                "min": -0.6065119504928589,
                "frobenius_norm": 1.8795403242111206,
                "spectral_norm": 1.2678451538085938,
                "num_singular_values": 8,
                "alpha": 1.180911468132044
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0669894888997078,
                "median": 0.07543610036373138,
                "std": 0.17455796897411346,
                "max": 0.4675839841365814,
                "min": -0.23485167324543,
                "frobenius_norm": 1.495766282081604,
                "spectral_norm": 0.7479307651519775,
                "num_singular_values": 8,
                "alpha": 1.2962549880947296
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.08113951236009598,
            "mse": 474131968.0,
            "mae": 2066.443359375,
            "r2_score": 0.8975809812545776,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.02521485649049282,
                "median": -0.0044233063235878944,
                "std": 0.21014606952667236,
                "max": 0.6144724488258362,
                "min": -0.3772982954978943,
                "frobenius_norm": 2.0737712383270264,
                "spectral_norm": 1.2873337268829346,
                "num_singular_values": 8,
                "alpha": 1.5063402339680914
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.025800762698054314,
                "median": 0.061365604400634766,
                "std": 0.2598349452018738,
                "max": 0.48176270723342896,
                "min": -0.822961151599884,
                "frobenius_norm": 2.088902235031128,
                "spectral_norm": 1.2842381000518799,
                "num_singular_values": 8,
                "alpha": 1.318913599702537
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08811128884553909,
                "median": 0.05121001973748207,
                "std": 0.25528770685195923,
                "max": 0.6434516906738281,
                "min": -0.3458826243877411,
                "frobenius_norm": 2.160524606704712,
                "spectral_norm": 1.2738862037658691,
                "num_singular_values": 8,
                "alpha": 1.1928148983262024
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.11814364045858383,
                "median": 0.13344216346740723,
                "std": 0.22389726340770721,
                "max": 0.5705747604370117,
                "min": -0.5251810550689697,
                "frobenius_norm": 2.02524733543396,
                "spectral_norm": 1.4254602193832397,
                "num_singular_values": 8,
                "alpha": 1.240755747209039
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.005_batch_size_32_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07368510961532593,
            "mse": 455938144.0,
            "mae": 1991.516845703125,
            "r2_score": 0.9015110731124878,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.1440306156873703,
                "median": 0.0865311473608017,
                "std": 0.3752938508987427,
                "max": 1.8067294359207153,
                "min": -0.7336844801902771,
                "frobenius_norm": 3.938612461090088,
                "spectral_norm": 2.46882700920105,
                "num_singular_values": 8,
                "alpha": 1.3615905174299399
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.0197502039372921,
                "median": -0.006698518991470337,
                "std": 0.5027696490287781,
                "max": 0.9114511609077454,
                "min": -1.5309878587722778,
                "frobenius_norm": 4.025259494781494,
                "spectral_norm": 2.8720996379852295,
                "num_singular_values": 8,
                "alpha": 1.1932230390290812
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.021508285775780678,
                "median": -0.01253250241279602,
                "std": 0.3484707772731781,
                "max": 1.110019564628601,
                "min": -0.9657310247421265,
                "frobenius_norm": 2.7930712699890137,
                "spectral_norm": 1.654674768447876,
                "num_singular_values": 8,
                "alpha": 1.140234865561045
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.028136063367128372,
                "median": 0.019583558663725853,
                "std": 0.33856239914894104,
                "max": 0.4950188398361206,
                "min": -1.3950557708740234,
                "frobenius_norm": 2.7178359031677246,
                "spectral_norm": 2.108584403991699,
                "num_singular_values": 8,
                "alpha": 1.402389027945977
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.005_batch_size_32_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07242526859045029,
            "mse": 475488256.0,
            "mae": 2009.2720947265625,
            "r2_score": 0.8972879648208618,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.1463400423526764,
                "median": 0.061397746205329895,
                "std": 0.3835304379463196,
                "max": 1.6758984327316284,
                "min": -0.7220953702926636,
                "frobenius_norm": 4.022071361541748,
                "spectral_norm": 2.808342456817627,
                "num_singular_values": 8,
                "alpha": 1.4346182526190594
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.062347665429115295,
                "median": 0.1361992359161377,
                "std": 0.5237293243408203,
                "max": 0.8267912864685059,
                "min": -2.108623504638672,
                "frobenius_norm": 4.219419002532959,
                "spectral_norm": 3.393886089324951,
                "num_singular_values": 8,
                "alpha": 1.1909039320863812
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.019181715324521065,
                "median": 0.023114511743187904,
                "std": 0.27062714099884033,
                "max": 0.6140790581703186,
                "min": -0.48428547382354736,
                "frobenius_norm": 2.1704485416412354,
                "spectral_norm": 1.2873203754425049,
                "num_singular_values": 8,
                "alpha": 1.1489817598313614
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06272988766431808,
                "median": 0.1057596504688263,
                "std": 0.18879960477352142,
                "max": 0.44320040941238403,
                "min": -0.3350960314273834,
                "frobenius_norm": 1.5915844440460205,
                "spectral_norm": 0.8771077990531921,
                "num_singular_values": 8,
                "alpha": 1.2274456728795167
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.005_batch_size_32_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07662209868431091,
            "mse": 495558656.0,
            "mae": 2137.512451171875,
            "r2_score": 0.8929525017738342,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.10877088457345963,
                "median": 0.075182244181633,
                "std": 0.3013334572315216,
                "max": 1.2898540496826172,
                "min": -0.4523523151874542,
                "frobenius_norm": 3.138911247253418,
                "spectral_norm": 2.4300894737243652,
                "num_singular_values": 8,
                "alpha": 1.40628620953838
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03572491556406021,
                "median": 0.021050013601779938,
                "std": 0.3696191608905792,
                "max": 0.9699111580848694,
                "min": -1.0535001754760742,
                "frobenius_norm": 2.9707329273223877,
                "spectral_norm": 2.0277557373046875,
                "num_singular_values": 8,
                "alpha": 1.2682733273404043
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.002355692908167839,
                "median": 0.02948656678199768,
                "std": 0.25754112005233765,
                "max": 0.48713168501853943,
                "min": -0.6608889698982239,
                "frobenius_norm": 2.060415029525757,
                "spectral_norm": 1.1865441799163818,
                "num_singular_values": 8,
                "alpha": 1.154547578390051
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0176624096930027,
                "median": 0.0657493844628334,
                "std": 0.27432915568351746,
                "max": 0.48420560359954834,
                "min": -1.037286400794983,
                "frobenius_norm": 2.1991772651672363,
                "spectral_norm": 1.4881476163864136,
                "num_singular_values": 8,
                "alpha": 1.2819508713488987
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.09563363343477249,
            "mse": 535138464.0,
            "mae": 2377.511474609375,
            "r2_score": 0.8844027519226074,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.03034990094602108,
                "median": -0.00182475452311337,
                "std": 0.21327799558639526,
                "max": 0.5401893854141235,
                "min": -0.40840834379196167,
                "frobenius_norm": 2.110740900039673,
                "spectral_norm": 1.3512413501739502,
                "num_singular_values": 8,
                "alpha": 1.6419513896533293
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04200281202793121,
                "median": 0.07711201161146164,
                "std": 0.26332011818885803,
                "max": 0.5401549339294434,
                "min": -0.6721892356872559,
                "frobenius_norm": 2.133192539215088,
                "spectral_norm": 1.3384147882461548,
                "num_singular_values": 8,
                "alpha": 1.2493515462361762
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08360692113637924,
                "median": 0.040594831109046936,
                "std": 0.26995155215263367,
                "max": 0.7991151809692383,
                "min": -0.3549019396305084,
                "frobenius_norm": 2.260817050933838,
                "spectral_norm": 1.3115782737731934,
                "num_singular_values": 8,
                "alpha": 1.1868678791971428
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.14923575520515442,
                "median": 0.17100776731967926,
                "std": 0.20794044435024261,
                "max": 0.5811853408813477,
                "min": -0.31928932666778564,
                "frobenius_norm": 2.0476021766662598,
                "spectral_norm": 1.3727507591247559,
                "num_singular_values": 8,
                "alpha": 1.256479352754831
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.005_batch_size_64_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 64,
            "scaler_type": "standard",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07307885587215424,
            "mse": 504446912.0,
            "mae": 2032.8634033203125,
            "r2_score": 0.8910325169563293,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.1301194429397583,
                "median": 0.05708639323711395,
                "std": 0.42198610305786133,
                "max": 1.6128062009811401,
                "min": -0.7703881859779358,
                "frobenius_norm": 4.326698303222656,
                "spectral_norm": 3.083613157272339,
                "num_singular_values": 8,
                "alpha": 1.333199126130166
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0551760159432888,
                "median": 0.10775911808013916,
                "std": 0.5883399248123169,
                "max": 1.1880831718444824,
                "min": -2.011045455932617,
                "frobenius_norm": 4.727372646331787,
                "spectral_norm": 3.2909767627716064,
                "num_singular_values": 8,
                "alpha": 1.2055598541902934
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.014185133390128613,
                "median": -0.028509942814707756,
                "std": 0.30116674304008484,
                "max": 0.6613823175430298,
                "min": -0.8425518870353699,
                "frobenius_norm": 2.4120051860809326,
                "spectral_norm": 1.5215840339660645,
                "num_singular_values": 8,
                "alpha": 1.269199853702236
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0969807356595993,
                "median": 0.08459913730621338,
                "std": 0.2046191543340683,
                "max": 0.7588887214660645,
                "min": -0.22573450207710266,
                "frobenius_norm": 1.811505675315857,
                "spectral_norm": 1.210715651512146,
                "num_singular_values": 8,
                "alpha": 1.251590405085064
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.005_batch_size_64_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 64,
            "scaler_type": "robust",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07256155461072922,
            "mse": 533176192.0,
            "mae": 2109.1337890625,
            "r2_score": 0.8848266005516052,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.07857077568769455,
                "median": 0.0006085290224291384,
                "std": 0.37554940581321716,
                "max": 1.6932131052017212,
                "min": -0.8561054468154907,
                "frobenius_norm": 3.7592859268188477,
                "spectral_norm": 2.972669839859009,
                "num_singular_values": 8,
                "alpha": 1.4100300933842669
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04765765741467476,
                "median": 0.08180855214595795,
                "std": 0.5094794034957886,
                "max": 1.355995774269104,
                "min": -1.7042468786239624,
                "frobenius_norm": 4.093628406524658,
                "spectral_norm": 2.6931889057159424,
                "num_singular_values": 8,
                "alpha": 1.305547676569844
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04096928983926773,
                "median": 0.025771459564566612,
                "std": 0.31454160809516907,
                "max": 0.7277426719665527,
                "min": -0.5819677710533142,
                "frobenius_norm": 2.537588357925415,
                "spectral_norm": 1.7686338424682617,
                "num_singular_values": 8,
                "alpha": 1.2433157600256834
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08433490991592407,
                "median": 0.10115671157836914,
                "std": 0.19066618382930756,
                "max": 0.419963538646698,
                "min": -0.48001590371131897,
                "frobenius_norm": 1.667879581451416,
                "spectral_norm": 0.969237744808197,
                "num_singular_values": 8,
                "alpha": 1.295605210286153
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.005_batch_size_64_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 64,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07820920646190643,
            "mse": 507271264.0,
            "mae": 2145.8017578125,
            "r2_score": 0.8904224038124084,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.12162838131189346,
                "median": 0.04547959938645363,
                "std": 0.3474009931087494,
                "max": 1.174532413482666,
                "min": -0.726456344127655,
                "frobenius_norm": 3.6064066886901855,
                "spectral_norm": 3.129108190536499,
                "num_singular_values": 8,
                "alpha": 1.3432295725819625
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.033720776438713074,
                "median": 0.02655000425875187,
                "std": 0.34236159920692444,
                "max": 0.7808536887168884,
                "min": -0.9641278386116028,
                "frobenius_norm": 2.752145767211914,
                "spectral_norm": 1.9586515426635742,
                "num_singular_values": 8,
                "alpha": 1.2211983640134265
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.007114037871360779,
                "median": -0.030272092670202255,
                "std": 0.2158193141222,
                "max": 0.47101446986198425,
                "min": -0.6417611837387085,
                "frobenius_norm": 1.727492332458496,
                "spectral_norm": 1.0891199111938477,
                "num_singular_values": 8,
                "alpha": 1.287392422536711
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.042974911630153656,
                "median": 0.034454889595508575,
                "std": 0.17926457524299622,
                "max": 0.47527122497558594,
                "min": -0.28475892543792725,
                "frobenius_norm": 1.474750280380249,
                "spectral_norm": 0.777358889579773,
                "num_singular_values": 8,
                "alpha": 1.2789919960904126
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.005_batch_size_128_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 128,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.08085796982049942,
            "mse": 448722880.0,
            "mae": 1992.2862548828125,
            "r2_score": 0.9030696749687195,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.03406774625182152,
                "median": 0.02061247080564499,
                "std": 0.20464050769805908,
                "max": 0.5405469536781311,
                "min": -0.393180251121521,
                "frobenius_norm": 2.03265380859375,
                "spectral_norm": 1.270979404449463,
                "num_singular_values": 8,
                "alpha": 1.6259004547746625
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06542783975601196,
                "median": 0.10196411609649658,
                "std": 0.2560884654521942,
                "max": 0.7854094505310059,
                "min": -0.39799630641937256,
                "frobenius_norm": 2.1145153045654297,
                "spectral_norm": 1.4094096422195435,
                "num_singular_values": 8,
                "alpha": 1.2513839180222759
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07075219601392746,
                "median": 0.03412161022424698,
                "std": 0.2572750151157379,
                "max": 0.6347015500068665,
                "min": -0.384200781583786,
                "frobenius_norm": 2.134610891342163,
                "spectral_norm": 1.3371027708053589,
                "num_singular_values": 8,
                "alpha": 1.0843874094590082
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.1467432826757431,
                "median": 0.16111910343170166,
                "std": 0.19849549233913422,
                "max": 0.574514627456665,
                "min": -0.33896520733833313,
                "frobenius_norm": 1.9747860431671143,
                "spectral_norm": 1.3760578632354736,
                "num_singular_values": 8,
                "alpha": 1.32580633772371
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.005_batch_size_128_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 128,
            "scaler_type": "standard",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07183767110109329,
            "mse": 474742208.0,
            "mae": 1971.0318603515625,
            "r2_score": 0.8974491357803345,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.1469305455684662,
                "median": 0.06952568143606186,
                "std": 0.38900938630104065,
                "max": 1.4021666049957275,
                "min": -0.7416225671768188,
                "frobenius_norm": 4.074312210083008,
                "spectral_norm": 2.7717695236206055,
                "num_singular_values": 8,
                "alpha": 1.395489244678124
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.026814188808202744,
                "median": 0.060694947838783264,
                "std": 0.5928325653076172,
                "max": 0.9643884897232056,
                "min": -2.358384847640991,
                "frobenius_norm": 4.747509002685547,
                "spectral_norm": 3.839420795440674,
                "num_singular_values": 8,
                "alpha": 1.1713163269988316
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02714303880929947,
                "median": -0.05076739937067032,
                "std": 0.3999711573123932,
                "max": 1.8359864950180054,
                "min": -0.7624253630638123,
                "frobenius_norm": 3.2071287631988525,
                "spectral_norm": 2.599999189376831,
                "num_singular_values": 8,
                "alpha": 1.2807318533429233
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.019661609083414078,
                "median": 0.01966211199760437,
                "std": 0.26286497712135315,
                "max": 0.4680943787097931,
                "min": -0.8243009448051453,
                "frobenius_norm": 2.1087942123413086,
                "spectral_norm": 1.6425803899765015,
                "num_singular_values": 8,
                "alpha": 1.1952688844139572
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.005_batch_size_128_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 128,
            "scaler_type": "robust",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07243585586547852,
            "mse": 486103552.0,
            "mae": 2003.7640380859375,
            "r2_score": 0.8949949145317078,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.14066441357135773,
                "median": 0.043162859976291656,
                "std": 0.39001527428627014,
                "max": 1.5753180980682373,
                "min": -0.8010333776473999,
                "frobenius_norm": 4.062295913696289,
                "spectral_norm": 3.1087608337402344,
                "num_singular_values": 8,
                "alpha": 1.3035958389872286
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.011514069512486458,
                "median": 0.13224680721759796,
                "std": 0.6688051819801331,
                "max": 1.2119545936584473,
                "min": -2.1187705993652344,
                "frobenius_norm": 5.351234436035156,
                "spectral_norm": 3.915703773498535,
                "num_singular_values": 8,
                "alpha": 1.2448538557192195
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.012126605957746506,
                "median": 0.001334137748926878,
                "std": 0.29568198323249817,
                "max": 0.5940728187561035,
                "min": -0.6777547001838684,
                "frobenius_norm": 2.3674445152282715,
                "spectral_norm": 1.3843895196914673,
                "num_singular_values": 8,
                "alpha": 1.2162140992094992
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.00214376300573349,
                "median": 0.02946636453270912,
                "std": 0.22790364921092987,
                "max": 0.4719618558883667,
                "min": -0.5445470809936523,
                "frobenius_norm": 1.8233098983764648,
                "spectral_norm": 1.3564183712005615,
                "num_singular_values": 8,
                "alpha": 1.2098297741227875
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.005_batch_size_128_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 128,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "scores": {
            "smape": 0.0775361955165863,
            "mse": 516774720.0,
            "mae": 2178.1474609375,
            "r2_score": 0.8883695602416992,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.11548338085412979,
                "median": 0.043596044182777405,
                "std": 0.31818562746047974,
                "max": 1.2323399782180786,
                "min": -0.46030157804489136,
                "frobenius_norm": 3.3165550231933594,
                "spectral_norm": 2.7925446033477783,
                "num_singular_values": 8,
                "alpha": 1.56006089917723
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.07366999983787537,
                "median": -0.05740427225828171,
                "std": 0.3846823275089264,
                "max": 0.9526270031929016,
                "min": -1.0346105098724365,
                "frobenius_norm": 3.1333842277526855,
                "spectral_norm": 2.264505624771118,
                "num_singular_values": 8,
                "alpha": 1.1297590484703157
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.009634111076593399,
                "median": -0.047834474593400955,
                "std": 0.2566344738006592,
                "max": 0.7134078741073608,
                "min": -0.7184774875640869,
                "frobenius_norm": 2.0545220375061035,
                "spectral_norm": 1.375830888748169,
                "num_singular_values": 8,
                "alpha": 1.1620598563950482
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.050365038216114044,
                "median": 0.03623899444937706,
                "std": 0.1809840351343155,
                "max": 0.4652276039123535,
                "min": -0.35678553581237793,
                "frobenius_norm": 1.5028901100158691,
                "spectral_norm": 0.7782856225967407,
                "num_singular_values": 8,
                "alpha": 1.165475047634177
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.005_batch_size_256_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 256,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.08268467336893082,
            "mse": 502903072.0,
            "mae": 2070.773681640625,
            "r2_score": 0.8913660049438477,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.0817665234208107,
                "median": 0.07180479168891907,
                "std": 0.19805294275283813,
                "max": 0.5812138915061951,
                "min": -0.32143735885620117,
                "frobenius_norm": 2.0993881225585938,
                "spectral_norm": 1.2744154930114746,
                "num_singular_values": 8,
                "alpha": 1.5730151423508767
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.005241767968982458,
                "median": 0.04807557910680771,
                "std": 0.2794356048107147,
                "max": 0.5001288056373596,
                "min": -0.8737744688987732,
                "frobenius_norm": 2.2358782291412354,
                "spectral_norm": 1.4616779088974,
                "num_singular_values": 8,
                "alpha": 1.2137229727552417
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.14068953692913055,
                "median": 0.07427946478128433,
                "std": 0.34268441796302795,
                "max": 1.336280345916748,
                "min": -0.3506356179714203,
                "frobenius_norm": 2.9635238647460938,
                "spectral_norm": 2.5724945068359375,
                "num_singular_values": 8,
                "alpha": 1.161813748558792
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.1567179560661316,
                "median": 0.15649721026420593,
                "std": 0.19943469762802124,
                "max": 0.5904409885406494,
                "min": -0.30079638957977295,
                "frobenius_norm": 2.0291430950164795,
                "spectral_norm": 1.4739978313446045,
                "num_singular_values": 8,
                "alpha": 1.3127281542531097
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.005_batch_size_256_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 256,
            "scaler_type": "standard",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07326620817184448,
            "mse": 485631264.0,
            "mae": 2128.273193359375,
            "r2_score": 0.8950969576835632,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.13008415699005127,
                "median": 0.08257123827934265,
                "std": 0.35878899693489075,
                "max": 1.699318528175354,
                "min": -0.7355054616928101,
                "frobenius_norm": 3.739323139190674,
                "spectral_norm": 2.3404734134674072,
                "num_singular_values": 8,
                "alpha": 1.252885840018465
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.018150944262742996,
                "median": 0.1137174516916275,
                "std": 0.5984136462211609,
                "max": 1.019758939743042,
                "min": -2.1795918941497803,
                "frobenius_norm": 4.789511203765869,
                "spectral_norm": 3.1229817867279053,
                "num_singular_values": 8,
                "alpha": 1.109001517702332
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.1082286611199379,
                "median": 0.05013151466846466,
                "std": 0.41780945658683777,
                "max": 1.3392225503921509,
                "min": -0.6144869923591614,
                "frobenius_norm": 3.452796697616577,
                "spectral_norm": 2.5045154094696045,
                "num_singular_values": 8,
                "alpha": 1.1079122106944743
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022057490423321724,
                "median": 0.03630857169628143,
                "std": 0.2814474105834961,
                "max": 0.6582685112953186,
                "min": -0.7339985966682434,
                "frobenius_norm": 2.258483409881592,
                "spectral_norm": 1.9138844013214111,
                "num_singular_values": 8,
                "alpha": 1.263570166601441
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.005_batch_size_256_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 256,
            "scaler_type": "robust",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07151074707508087,
            "mse": 472695328.0,
            "mae": 2010.3363037109375,
            "r2_score": 0.8978912830352783,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.08923077583312988,
                "median": 0.0318668968975544,
                "std": 0.3292083144187927,
                "max": 1.499518871307373,
                "min": -0.9014521837234497,
                "frobenius_norm": 3.3419551849365234,
                "spectral_norm": 2.5626277923583984,
                "num_singular_values": 8,
                "alpha": 1.5669372941568138
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.08155088126659393,
                "median": 0.05048419535160065,
                "std": 0.5730922818183899,
                "max": 0.7214099168777466,
                "min": -1.8545145988464355,
                "frobenius_norm": 4.630924224853516,
                "spectral_norm": 3.5078306198120117,
                "num_singular_values": 8,
                "alpha": 1.19656487544065
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.006847304292023182,
                "median": 0.037870172411203384,
                "std": 0.4291628301143646,
                "max": 0.8942050337791443,
                "min": -1.2349517345428467,
                "frobenius_norm": 3.43373966217041,
                "spectral_norm": 2.2082290649414062,
                "num_singular_values": 8,
                "alpha": 1.287561055768849
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07778377830982208,
                "median": 0.11656427383422852,
                "std": 0.3145701587200165,
                "max": 0.7790453433990479,
                "min": -0.9686885476112366,
                "frobenius_norm": 2.5923542976379395,
                "spectral_norm": 1.7701315879821777,
                "num_singular_values": 8,
                "alpha": 1.1275749904306123
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.005_batch_size_256_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 256,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07507389783859253,
            "mse": 477941504.0,
            "mae": 2106.18896484375,
            "r2_score": 0.8967580795288086,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06139853224158287,
                "median": 0.041135773062705994,
                "std": 0.35202187299728394,
                "max": 1.2974119186401367,
                "min": -1.989953637123108,
                "frobenius_norm": 3.5011656284332275,
                "spectral_norm": 2.9784607887268066,
                "num_singular_values": 8,
                "alpha": 1.5069691445445157
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.0851932242512703,
                "median": -0.05983274430036545,
                "std": 0.47001808881759644,
                "max": 0.7364007830619812,
                "min": -2.4485065937042236,
                "frobenius_norm": 3.8214123249053955,
                "spectral_norm": 2.9660656452178955,
                "num_singular_values": 8,
                "alpha": 1.1621244317943573
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04048267751932144,
                "median": 0.048590391874313354,
                "std": 0.29977941513061523,
                "max": 0.7500631809234619,
                "min": -0.8352828025817871,
                "frobenius_norm": 2.420003890991211,
                "spectral_norm": 1.730671763420105,
                "num_singular_values": 8,
                "alpha": 1.1385955849844205
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06975121796131134,
                "median": 0.08753648400306702,
                "std": 0.17501643300056458,
                "max": 0.4288138747215271,
                "min": -0.3200379014015198,
                "frobenius_norm": 1.507230281829834,
                "spectral_norm": 0.8427422642707825,
                "num_singular_values": 8,
                "alpha": 1.2617995652458511
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.001_batch_size_16_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.08628804981708527,
            "mse": 507199136.0,
            "mae": 2051.901123046875,
            "r2_score": 0.8904380202293396,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.07443016767501831,
                "median": 0.0756780207157135,
                "std": 0.16850285232067108,
                "max": 0.3705270290374756,
                "min": -0.34432047605514526,
                "frobenius_norm": 1.8048750162124634,
                "spectral_norm": 1.0015742778778076,
                "num_singular_values": 8,
                "alpha": 1.5862619825721729
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05659926310181618,
                "median": 0.07153192162513733,
                "std": 0.24011991918087006,
                "max": 0.45972979068756104,
                "min": -0.40007805824279785,
                "frobenius_norm": 1.9736026525497437,
                "spectral_norm": 1.3641382455825806,
                "num_singular_values": 8,
                "alpha": 1.2197854190907773
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.11798571795225143,
                "median": 0.07817092537879944,
                "std": 0.27815765142440796,
                "max": 0.8526288270950317,
                "min": -0.3046504557132721,
                "frobenius_norm": 2.4171693325042725,
                "spectral_norm": 1.8977668285369873,
                "num_singular_values": 8,
                "alpha": 1.1502568577047545
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.12218164652585983,
                "median": 0.13336732983589172,
                "std": 0.19350051879882812,
                "max": 0.5227856040000916,
                "min": -0.2582804560661316,
                "frobenius_norm": 1.8307734727859497,
                "spectral_norm": 1.2126376628875732,
                "num_singular_values": 8,
                "alpha": 1.1760815705540715
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.001_batch_size_16_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07344093173742294,
            "mse": 446108768.0,
            "mae": 1980.997314453125,
            "r2_score": 0.9036343693733215,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.0673222616314888,
                "median": 0.0377022922039032,
                "std": 0.2656427025794983,
                "max": 0.7672847509384155,
                "min": -0.602008044719696,
                "frobenius_norm": 2.68503999710083,
                "spectral_norm": 1.7248332500457764,
                "num_singular_values": 8,
                "alpha": 1.3923360824803748
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04092974588274956,
                "median": 0.0885394737124443,
                "std": 0.337487131357193,
                "max": 0.7851142287254333,
                "min": -0.8443630337715149,
                "frobenius_norm": 2.719680070877075,
                "spectral_norm": 1.7589454650878906,
                "num_singular_values": 8,
                "alpha": 1.2627505252168865
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.030429484322667122,
                "median": 0.012603817507624626,
                "std": 0.2828599810600281,
                "max": 0.9334188103675842,
                "min": -0.7148287892341614,
                "frobenius_norm": 2.2759363651275635,
                "spectral_norm": 1.541269063949585,
                "num_singular_values": 8,
                "alpha": 1.1825952470047503
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03752376139163971,
                "median": 0.028937432914972305,
                "std": 0.2096831053495407,
                "max": 0.4769754111766815,
                "min": -0.4263233244419098,
                "frobenius_norm": 1.7041133642196655,
                "spectral_norm": 1.060006856918335,
                "num_singular_values": 8,
                "alpha": 1.4290088207267018
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.001_batch_size_16_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07319051027297974,
            "mse": 449116768.0,
            "mae": 1991.5230712890625,
            "r2_score": 0.902984619140625,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.05280451104044914,
                "median": 0.03519842028617859,
                "std": 0.25594446063041687,
                "max": 0.7254020571708679,
                "min": -0.6211119294166565,
                "frobenius_norm": 2.5605475902557373,
                "spectral_norm": 1.8312249183654785,
                "num_singular_values": 8,
                "alpha": 1.4343086102784846
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06153477728366852,
                "median": 0.10445815324783325,
                "std": 0.3037857711315155,
                "max": 0.6223479509353638,
                "min": -1.0712873935699463,
                "frobenius_norm": 2.479642868041992,
                "spectral_norm": 1.7834594249725342,
                "num_singular_values": 8,
                "alpha": 1.273214746249776
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.034475989639759064,
                "median": 0.06957218050956726,
                "std": 0.2719716727733612,
                "max": 0.9583985209465027,
                "min": -0.604049801826477,
                "frobenius_norm": 2.1931848526000977,
                "spectral_norm": 1.4721065759658813,
                "num_singular_values": 8,
                "alpha": 1.2855299165139775
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.09522800147533417,
                "median": 0.08604570478200912,
                "std": 0.1817135512828827,
                "max": 0.48107755184173584,
                "min": -0.22362062335014343,
                "frobenius_norm": 1.6412324905395508,
                "spectral_norm": 1.0029023885726929,
                "num_singular_values": 8,
                "alpha": 1.193601405749707
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.001_batch_size_16_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "scores": {
            "smape": 0.0797448679804802,
            "mse": 469295968.0,
            "mae": 2147.249267578125,
            "r2_score": 0.8986256122589111,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.0765015110373497,
                "median": 0.06899703294038773,
                "std": 0.2171204388141632,
                "max": 0.6815817356109619,
                "min": -0.393297404050827,
                "frobenius_norm": 2.2555270195007324,
                "spectral_norm": 1.718136191368103,
                "num_singular_values": 8,
                "alpha": 1.3086123346981555
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.040836453437805176,
                "median": 0.0869954526424408,
                "std": 0.29272592067718506,
                "max": 0.5319757461547852,
                "min": -0.9575435519218445,
                "frobenius_norm": 2.364485025405884,
                "spectral_norm": 1.7742081880569458,
                "num_singular_values": 8,
                "alpha": 1.3434094500039924
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.003763108979910612,
                "median": -0.02184668742120266,
                "std": 0.24283713102340698,
                "max": 0.6989940404891968,
                "min": -0.6360443234443665,
                "frobenius_norm": 1.9429302215576172,
                "spectral_norm": 1.228759527206421,
                "num_singular_values": 8,
                "alpha": 1.284004325414351
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06053634732961655,
                "median": 0.044658221304416656,
                "std": 0.18902193009853363,
                "max": 0.4627980589866638,
                "min": -0.25680795311927795,
                "frobenius_norm": 1.5878325700759888,
                "spectral_norm": 0.9035636782646179,
                "num_singular_values": 8,
                "alpha": 1.3045143518781237
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.08480718731880188,
            "mse": 502278464.0,
            "mae": 2046.0982666015625,
            "r2_score": 0.8915009498596191,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.07980922609567642,
                "median": 0.08678668737411499,
                "std": 0.17002449929714203,
                "max": 0.3947596848011017,
                "min": -0.3092288672924042,
                "frobenius_norm": 1.8402916193008423,
                "spectral_norm": 1.0411622524261475,
                "num_singular_values": 8,
                "alpha": 1.58534974329369
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05975539609789848,
                "median": 0.088408462703228,
                "std": 0.24625882506370544,
                "max": 0.48911863565444946,
                "min": -0.4192941188812256,
                "frobenius_norm": 2.02724027633667,
                "spectral_norm": 1.4239469766616821,
                "num_singular_values": 8,
                "alpha": 1.1956461121476258
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.11950594931840897,
                "median": 0.08119899034500122,
                "std": 0.28187108039855957,
                "max": 0.8733039498329163,
                "min": -0.3098834156990051,
                "frobenius_norm": 2.4492673873901367,
                "spectral_norm": 1.9336752891540527,
                "num_singular_values": 8,
                "alpha": 1.1497779729543058
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.12482094764709473,
                "median": 0.13527819514274597,
                "std": 0.19372744858264923,
                "max": 0.521809995174408,
                "min": -0.2571711242198944,
                "frobenius_norm": 1.8436589241027832,
                "spectral_norm": 1.2320997714996338,
                "num_singular_values": 8,
                "alpha": 1.186643420224324
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.001_batch_size_32_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07348014414310455,
            "mse": 450106976.0,
            "mae": 1994.5745849609375,
            "r2_score": 0.9027706980705261,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.0657610222697258,
                "median": 0.04241529852151871,
                "std": 0.276702344417572,
                "max": 0.8175511956214905,
                "min": -0.5598697066307068,
                "frobenius_norm": 2.7866315841674805,
                "spectral_norm": 1.8738924264907837,
                "num_singular_values": 8,
                "alpha": 1.4488252894697649
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02077539637684822,
                "median": 0.04670073464512825,
                "std": 0.3439329266548157,
                "max": 0.8786652088165283,
                "min": -0.9497466087341309,
                "frobenius_norm": 2.756478786468506,
                "spectral_norm": 1.7422629594802856,
                "num_singular_values": 8,
                "alpha": 1.181121529865754
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.035559073090553284,
                "median": 0.033359430730342865,
                "std": 0.2767338156700134,
                "max": 0.9770439863204956,
                "min": -0.48075470328330994,
                "frobenius_norm": 2.232072353363037,
                "spectral_norm": 1.578869104385376,
                "num_singular_values": 8,
                "alpha": 1.1642565148978203
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04873410239815712,
                "median": 0.04508811980485916,
                "std": 0.20399315655231476,
                "max": 0.5189056396484375,
                "min": -0.4762735962867737,
                "frobenius_norm": 1.6778695583343506,
                "spectral_norm": 1.033211588859558,
                "num_singular_values": 8,
                "alpha": 1.1655830796139943
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.001_batch_size_32_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07314690202474594,
            "mse": 452895072.0,
            "mae": 1989.9705810546875,
            "r2_score": 0.9021683931350708,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.08056215196847916,
                "median": 0.07995563000440598,
                "std": 0.2743200659751892,
                "max": 0.7914759516716003,
                "min": -0.738702118396759,
                "frobenius_norm": 2.8012871742248535,
                "spectral_norm": 2.005319356918335,
                "num_singular_values": 8,
                "alpha": 1.4837438231161084
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07286141812801361,
                "median": 0.07224738597869873,
                "std": 0.33024588227272034,
                "max": 0.7667855024337769,
                "min": -1.1296473741531372,
                "frobenius_norm": 2.7055041790008545,
                "spectral_norm": 1.8689299821853638,
                "num_singular_values": 8,
                "alpha": 1.198210662787185
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.049746524542570114,
                "median": 0.05555468052625656,
                "std": 0.2849544882774353,
                "max": 1.0140118598937988,
                "min": -0.5866073369979858,
                "frobenius_norm": 2.3141136169433594,
                "spectral_norm": 1.662785530090332,
                "num_singular_values": 8,
                "alpha": 1.2891955712791374
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07738983631134033,
                "median": 0.07287006080150604,
                "std": 0.19456154108047485,
                "max": 0.4783233106136322,
                "min": -0.25194424390792847,
                "frobenius_norm": 1.6751048564910889,
                "spectral_norm": 0.9828758239746094,
                "num_singular_values": 8,
                "alpha": 1.302707374480702
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.001_batch_size_32_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07925394177436829,
            "mse": 480415040.0,
            "mae": 2176.48095703125,
            "r2_score": 0.8962237238883972,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.11164236068725586,
                "median": 0.10989795625209808,
                "std": 0.23492252826690674,
                "max": 0.6680434942245483,
                "min": -0.5832598209381104,
                "frobenius_norm": 2.5484604835510254,
                "spectral_norm": 1.8015203475952148,
                "num_singular_values": 8,
                "alpha": 1.3880075190323864
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07148416340351105,
                "median": 0.12268093228340149,
                "std": 0.2705060541629791,
                "max": 0.6209089159965515,
                "min": -0.647896945476532,
                "frobenius_norm": 2.238335371017456,
                "spectral_norm": 1.486133098602295,
                "num_singular_values": 8,
                "alpha": 1.2691505826898206
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.005832522176206112,
                "median": -0.0032199230045080185,
                "std": 0.2532975375652313,
                "max": 0.6663780808448792,
                "min": -0.6239965558052063,
                "frobenius_norm": 2.0269172191619873,
                "spectral_norm": 1.2149699926376343,
                "num_singular_values": 8,
                "alpha": 1.3179938609158772
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06401577591896057,
                "median": 0.05273774638772011,
                "std": 0.19036662578582764,
                "max": 0.4892905652523041,
                "min": -0.26174840331077576,
                "frobenius_norm": 1.6067352294921875,
                "spectral_norm": 0.9352431893348694,
                "num_singular_values": 8,
                "alpha": 1.2933764546920332
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.08350923657417297,
            "mse": 497734560.0,
            "mae": 2040.4337158203125,
            "r2_score": 0.8924824595451355,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.08031594008207321,
                "median": 0.08857882022857666,
                "std": 0.1726202815771103,
                "max": 0.4028356075286865,
                "min": -0.3131047487258911,
                "frobenius_norm": 1.865435004234314,
                "spectral_norm": 1.0548406839370728,
                "num_singular_values": 8,
                "alpha": 1.6016513873103464
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05939251556992531,
                "median": 0.08848805725574493,
                "std": 0.2506985664367676,
                "max": 0.4940558075904846,
                "min": -0.45653364062309265,
                "frobenius_norm": 2.0611023902893066,
                "spectral_norm": 1.4866186380386353,
                "num_singular_values": 8,
                "alpha": 1.2032453894400261
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.12320125848054886,
                "median": 0.08698812872171402,
                "std": 0.2890881597995758,
                "max": 0.9049140810966492,
                "min": -0.3117457628250122,
                "frobenius_norm": 2.513967514038086,
                "spectral_norm": 2.0054659843444824,
                "num_singular_values": 8,
                "alpha": 1.1953317349914678
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.13054834306240082,
                "median": 0.1397799551486969,
                "std": 0.19565698504447937,
                "max": 0.5399705171585083,
                "min": -0.2644817531108856,
                "frobenius_norm": 1.8816932439804077,
                "spectral_norm": 1.2870736122131348,
                "num_singular_values": 8,
                "alpha": 1.2102332554995587
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.001_batch_size_64_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "standard",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07424969971179962,
            "mse": 439501216.0,
            "mae": 1976.2091064453125,
            "r2_score": 0.905061662197113,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.08953431993722916,
                "median": 0.056092388927936554,
                "std": 0.28060418367385864,
                "max": 0.8773006796836853,
                "min": -0.5869659185409546,
                "frobenius_norm": 2.8859124183654785,
                "spectral_norm": 2.161100387573242,
                "num_singular_values": 8,
                "alpha": 1.40971223698154
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06350454688072205,
                "median": 0.03852468356490135,
                "std": 0.33397409319877625,
                "max": 0.9417690634727478,
                "min": -1.1727017164230347,
                "frobenius_norm": 2.719665050506592,
                "spectral_norm": 1.9122591018676758,
                "num_singular_values": 8,
                "alpha": 1.2499925948625115
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.020947784185409546,
                "median": 0.01051013357937336,
                "std": 0.27209359407424927,
                "max": 0.9008991122245789,
                "min": -0.4872311055660248,
                "frobenius_norm": 2.183190107345581,
                "spectral_norm": 1.5296964645385742,
                "num_singular_values": 8,
                "alpha": 1.2827437683967182
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0674469918012619,
                "median": 0.04745239391922951,
                "std": 0.18747608363628387,
                "max": 0.4761544167995453,
                "min": -0.23485167324543,
                "frobenius_norm": 1.5939159393310547,
                "spectral_norm": 0.8764170408248901,
                "num_singular_values": 8,
                "alpha": 1.225729902132975
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.001_batch_size_64_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "robust",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07328905165195465,
            "mse": 451227296.0,
            "mae": 1989.4609375,
            "r2_score": 0.902528703212738,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.08149943500757217,
                "median": 0.04481218755245209,
                "std": 0.2686409056186676,
                "max": 0.8198455572128296,
                "min": -0.48013070225715637,
                "frobenius_norm": 2.7505943775177,
                "spectral_norm": 1.9557603597640991,
                "num_singular_values": 8,
                "alpha": 1.437258184675783
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.10059195756912231,
                "median": 0.13299429416656494,
                "std": 0.3344447910785675,
                "max": 0.8223599195480347,
                "min": -1.0055325031280518,
                "frobenius_norm": 2.793959856033325,
                "spectral_norm": 1.9630398750305176,
                "num_singular_values": 8,
                "alpha": 1.2078360527351475
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.0014672502875328064,
                "median": 0.02579527162015438,
                "std": 0.29743868112564087,
                "max": 0.8345187902450562,
                "min": -0.6291640400886536,
                "frobenius_norm": 2.3795385360717773,
                "spectral_norm": 1.561323881149292,
                "num_singular_values": 8,
                "alpha": 1.2998699005752112
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07009746134281158,
                "median": 0.07513860613107681,
                "std": 0.18643811345100403,
                "max": 0.4919794797897339,
                "min": -0.22437112033367157,
                "frobenius_norm": 1.5934430360794067,
                "spectral_norm": 0.8804591298103333,
                "num_singular_values": 8,
                "alpha": 1.2555784018299847
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.001_batch_size_64_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07902365177869797,
            "mse": 470393600.0,
            "mae": 2153.87646484375,
            "r2_score": 0.8983885049819946,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.07090745121240616,
                "median": 0.04745132476091385,
                "std": 0.2312735617160797,
                "max": 0.8074249625205994,
                "min": -0.48252642154693604,
                "frobenius_norm": 2.3701205253601074,
                "spectral_norm": 1.8462600708007812,
                "num_singular_values": 8,
                "alpha": 1.37156868236863
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.055529139935970306,
                "median": 0.09282005578279495,
                "std": 0.29376667737960815,
                "max": 0.5880655646324158,
                "min": -1.1111260652542114,
                "frobenius_norm": 2.3917505741119385,
                "spectral_norm": 1.6242918968200684,
                "num_singular_values": 8,
                "alpha": 1.2868844955692031
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.021762587130069733,
                "median": 0.0156436525285244,
                "std": 0.2551731467247009,
                "max": 0.7465919256210327,
                "min": -0.6747915148735046,
                "frobenius_norm": 2.0487959384918213,
                "spectral_norm": 1.3033413887023926,
                "num_singular_values": 8,
                "alpha": 1.3246288971212283
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.060040343552827835,
                "median": 0.03769664466381073,
                "std": 0.18710929155349731,
                "max": 0.4302436411380768,
                "min": -0.2502038776874542,
                "frobenius_norm": 1.5720504522323608,
                "spectral_norm": 0.8532089591026306,
                "num_singular_values": 8,
                "alpha": 1.250252845270315
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.001_batch_size_128_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 128,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.08262529224157333,
            "mse": 493605248.0,
            "mae": 2045.2755126953125,
            "r2_score": 0.8933744430541992,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.08370975404977798,
                "median": 0.08788034319877625,
                "std": 0.17407438158988953,
                "max": 0.41684988141059875,
                "min": -0.3233875632286072,
                "frobenius_norm": 1.892533779144287,
                "spectral_norm": 1.0858430862426758,
                "num_singular_values": 8,
                "alpha": 1.6186027062033868
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06260517239570618,
                "median": 0.10890661180019379,
                "std": 0.2566068172454834,
                "max": 0.5040722489356995,
                "min": -0.4490683078765869,
                "frobenius_norm": 2.113067388534546,
                "spectral_norm": 1.5790479183197021,
                "num_singular_values": 8,
                "alpha": 1.242069641727041
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.12932062149047852,
                "median": 0.08516112715005875,
                "std": 0.2972148060798645,
                "max": 0.9837921261787415,
                "min": -0.31051215529441833,
                "frobenius_norm": 2.5930426120758057,
                "spectral_norm": 2.113617181777954,
                "num_singular_values": 8,
                "alpha": 1.2061903202081619
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.1335018277168274,
                "median": 0.1436203122138977,
                "std": 0.194680854678154,
                "max": 0.5402257442474365,
                "min": -0.259684681892395,
                "frobenius_norm": 1.8884638547897339,
                "spectral_norm": 1.3022242784500122,
                "num_singular_values": 8,
                "alpha": 1.2291921311032605
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.001_batch_size_128_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 128,
            "scaler_type": "standard",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07375620305538177,
            "mse": 453420736.0,
            "mae": 1975.4637451171875,
            "r2_score": 0.9020548462867737,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.1067289337515831,
                "median": 0.051316604018211365,
                "std": 0.29851576685905457,
                "max": 1.0060347318649292,
                "min": -0.5608258843421936,
                "frobenius_norm": 3.1061649322509766,
                "spectral_norm": 2.388836145401001,
                "num_singular_values": 8,
                "alpha": 1.3936447806082204
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04651700705289841,
                "median": 0.07162579894065857,
                "std": 0.37756866216659546,
                "max": 0.9131072163581848,
                "min": -1.0097742080688477,
                "frobenius_norm": 3.043386697769165,
                "spectral_norm": 2.2304091453552246,
                "num_singular_values": 8,
                "alpha": 1.2287218812037808
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.018175335600972176,
                "median": 0.0136005450040102,
                "std": 0.2742327153682709,
                "max": 0.7640740871429443,
                "min": -0.6332206130027771,
                "frobenius_norm": 2.1986749172210693,
                "spectral_norm": 1.5449717044830322,
                "num_singular_values": 8,
                "alpha": 1.258505034129326
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.060124292969703674,
                "median": 0.038681790232658386,
                "std": 0.18869103491306305,
                "max": 0.4770122170448303,
                "min": -0.23485167324543,
                "frobenius_norm": 1.5843077898025513,
                "spectral_norm": 0.855197548866272,
                "num_singular_values": 8,
                "alpha": 1.2371044448930106
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.001_batch_size_128_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 128,
            "scaler_type": "robust",
            "total_params": 320
        },
        "scores": {
            "smape": 0.0732523649930954,
            "mse": 450151488.0,
            "mae": 2005.7877197265625,
            "r2_score": 0.9027611017227173,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.08709359169006348,
                "median": 0.04977060854434967,
                "std": 0.2538159191608429,
                "max": 0.7563416957855225,
                "min": -0.4564709961414337,
                "frobenius_norm": 2.629211187362671,
                "spectral_norm": 1.8242065906524658,
                "num_singular_values": 8,
                "alpha": 1.4077345809350574
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.11122985184192657,
                "median": 0.10992260277271271,
                "std": 0.3522951602935791,
                "max": 0.6551759243011475,
                "min": -1.102197527885437,
                "frobenius_norm": 2.9554989337921143,
                "spectral_norm": 2.237441301345825,
                "num_singular_values": 8,
                "alpha": 1.2956573115688894
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.044321510940790176,
                "median": 0.11981146782636642,
                "std": 0.2806318700313568,
                "max": 0.7138299345970154,
                "min": -0.7612220644950867,
                "frobenius_norm": 2.2728819847106934,
                "spectral_norm": 1.5287870168685913,
                "num_singular_values": 8,
                "alpha": 1.329723930389123
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06844362616539001,
                "median": 0.07127487659454346,
                "std": 0.1874927133321762,
                "max": 0.48699432611465454,
                "min": -0.23225711286067963,
                "frobenius_norm": 1.5967576503753662,
                "spectral_norm": 0.8746488690376282,
                "num_singular_values": 8,
                "alpha": 1.2453432386673693
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.001_batch_size_128_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 128,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07808900624513626,
            "mse": 461180064.0,
            "mae": 2141.71044921875,
            "r2_score": 0.9003787636756897,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.0822632685303688,
                "median": 0.05197519063949585,
                "std": 0.2383507341146469,
                "max": 0.8093241453170776,
                "min": -0.5607757568359375,
                "frobenius_norm": 2.4705300331115723,
                "spectral_norm": 1.9504154920578003,
                "num_singular_values": 8,
                "alpha": 1.3374851281538218
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03376837819814682,
                "median": 0.09088734537363052,
                "std": 0.31433621048927307,
                "max": 0.5857408046722412,
                "min": -1.1120655536651611,
                "frobenius_norm": 2.529158592224121,
                "spectral_norm": 1.8175678253173828,
                "num_singular_values": 8,
                "alpha": 1.2730983551423383
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.024953074753284454,
                "median": -0.00011524604633450508,
                "std": 0.2517896890640259,
                "max": 0.776792585849762,
                "min": -0.7796838879585266,
                "frobenius_norm": 2.0241849422454834,
                "spectral_norm": 1.3456995487213135,
                "num_singular_values": 8,
                "alpha": 1.109521937701414
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0514887236058712,
                "median": 0.03211173042654991,
                "std": 0.18807877600193024,
                "max": 0.42957112193107605,
                "min": -0.2696077823638916,
                "frobenius_norm": 1.5599942207336426,
                "spectral_norm": 0.8386676907539368,
                "num_singular_values": 8,
                "alpha": 1.247288928613796
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.001_batch_size_256_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 256,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.08419688045978546,
            "mse": 503381792.0,
            "mae": 2063.893310546875,
            "r2_score": 0.8912625908851624,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.08459875732660294,
                "median": 0.09040642529726028,
                "std": 0.17454403638839722,
                "max": 0.4153256416320801,
                "min": -0.3300023078918457,
                "frobenius_norm": 1.9004647731781006,
                "spectral_norm": 1.1026251316070557,
                "num_singular_values": 8,
                "alpha": 1.6067501488604787
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06216878816485405,
                "median": 0.10168291628360748,
                "std": 0.2591158449649811,
                "max": 0.5614026188850403,
                "min": -0.47884678840637207,
                "frobenius_norm": 2.131755828857422,
                "spectral_norm": 1.5790259838104248,
                "num_singular_values": 8,
                "alpha": 1.2170795056747192
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.12290626019239426,
                "median": 0.08725519478321075,
                "std": 0.28722062706947327,
                "max": 0.9143434166908264,
                "min": -0.30894899368286133,
                "frobenius_norm": 2.499300956726074,
                "spectral_norm": 1.9913098812103271,
                "num_singular_values": 8,
                "alpha": 1.2154062268876187
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.1324915885925293,
                "median": 0.14128942787647247,
                "std": 0.19498634338378906,
                "max": 0.5420020222663879,
                "min": -0.2606978714466095,
                "frobenius_norm": 1.8859258890151978,
                "spectral_norm": 1.2984472513198853,
                "num_singular_values": 8,
                "alpha": 1.2269323026734602
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.001_batch_size_256_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 256,
            "scaler_type": "standard",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07387454062700272,
            "mse": 485982624.0,
            "mae": 2041.0150146484375,
            "r2_score": 0.8950210809707642,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.07540199160575867,
                "median": 0.035760365426540375,
                "std": 0.2905234694480896,
                "max": 1.027864694595337,
                "min": -0.5510181784629822,
                "frobenius_norm": 2.9408464431762695,
                "spectral_norm": 1.9955850839614868,
                "num_singular_values": 8,
                "alpha": 1.4861927153771444
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.018079010769724846,
                "median": 0.07183089852333069,
                "std": 0.37565502524375916,
                "max": 1.0408408641815186,
                "min": -1.0946778059005737,
                "frobenius_norm": 3.008718729019165,
                "spectral_norm": 2.0984251499176025,
                "num_singular_values": 8,
                "alpha": 1.1502697751888835
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.026179973036050797,
                "median": -0.015798283740878105,
                "std": 0.2662014365196228,
                "max": 0.8339462876319885,
                "min": -0.5232963562011719,
                "frobenius_norm": 2.139885425567627,
                "spectral_norm": 1.4624371528625488,
                "num_singular_values": 8,
                "alpha": 1.1176913313274597
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04381714388728142,
                "median": 0.04600072279572487,
                "std": 0.1973876804113388,
                "max": 0.4697926938533783,
                "min": -0.43497616052627563,
                "frobenius_norm": 1.6175405979156494,
                "spectral_norm": 0.8860060572624207,
                "num_singular_values": 8,
                "alpha": 1.4930962407029482
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.001_batch_size_256_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 256,
            "scaler_type": "robust",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07315721362829208,
            "mse": 470392384.0,
            "mae": 2037.1531982421875,
            "r2_score": 0.8983887434005737,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.07266617566347122,
                "median": 0.045656267553567886,
                "std": 0.24908863008022308,
                "max": 0.7782819271087646,
                "min": -0.4397113025188446,
                "frobenius_norm": 2.542292356491089,
                "spectral_norm": 1.766021728515625,
                "num_singular_values": 8,
                "alpha": 1.4026364341771775
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.14206084609031677,
                "median": 0.16297870874404907,
                "std": 0.36439457535743713,
                "max": 0.7388671636581421,
                "min": -1.023528814315796,
                "frobenius_norm": 3.1288561820983887,
                "spectral_norm": 2.244292974472046,
                "num_singular_values": 8,
                "alpha": 1.3297161238663322
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04711325466632843,
                "median": 0.07665067911148071,
                "std": 0.2793514132499695,
                "max": 0.5717543959617615,
                "min": -0.8333601355552673,
                "frobenius_norm": 2.266371488571167,
                "spectral_norm": 1.4282002449035645,
                "num_singular_values": 8,
                "alpha": 1.2671758887525737
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07207901775836945,
                "median": 0.0785604789853096,
                "std": 0.19068896770477295,
                "max": 0.47653862833976746,
                "min": -0.4007697105407715,
                "frobenius_norm": 1.630855917930603,
                "spectral_norm": 0.9092541337013245,
                "num_singular_values": 8,
                "alpha": 1.2921115875519185
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.001_batch_size_256_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 256,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07885649800300598,
            "mse": 486322528.0,
            "mae": 2142.05419921875,
            "r2_score": 0.8949476480484009,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06819664686918259,
                "median": 0.03864138573408127,
                "std": 0.2319602519273758,
                "max": 0.7756131887435913,
                "min": -0.5104625225067139,
                "frobenius_norm": 2.3689255714416504,
                "spectral_norm": 1.8375804424285889,
                "num_singular_values": 8,
                "alpha": 1.4561967307289074
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.049398016184568405,
                "median": 0.0997813493013382,
                "std": 0.30429336428642273,
                "max": 0.5922768712043762,
                "min": -1.0506517887115479,
                "frobenius_norm": 2.466214656829834,
                "spectral_norm": 1.7320603132247925,
                "num_singular_values": 8,
                "alpha": 1.1457012067792443
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.035407163202762604,
                "median": 0.029554687440395355,
                "std": 0.2559526860713959,
                "max": 0.7445516586303711,
                "min": -0.587231457233429,
                "frobenius_norm": 2.0671207904815674,
                "spectral_norm": 1.2869422435760498,
                "num_singular_values": 8,
                "alpha": 1.172241692490568
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05680358409881592,
                "median": 0.04324214160442352,
                "std": 0.18709610402584076,
                "max": 0.4140627384185791,
                "min": -0.26215285062789917,
                "frobenius_norm": 1.5642322301864624,
                "spectral_norm": 0.831145167350769,
                "num_singular_values": 8,
                "alpha": 1.2420486899021466
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.0005_batch_size_16_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.08506479859352112,
            "mse": 484369824.0,
            "mae": 1995.7471923828125,
            "r2_score": 0.8953694105148315,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.07532111555337906,
                "median": 0.08276677131652832,
                "std": 0.16176635026931763,
                "max": 0.3686881959438324,
                "min": -0.27154362201690674,
                "frobenius_norm": 1.748369574546814,
                "spectral_norm": 0.9671968817710876,
                "num_singular_values": 8,
                "alpha": 1.591905656038872
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05234874039888382,
                "median": 0.0814736932516098,
                "std": 0.2367057353258133,
                "max": 0.4545690715312958,
                "min": -0.404213547706604,
                "frobenius_norm": 1.9394018650054932,
                "spectral_norm": 1.2643238306045532,
                "num_singular_values": 8,
                "alpha": 1.235130504837229
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.09364989399909973,
                "median": 0.06083811819553375,
                "std": 0.25574490427970886,
                "max": 0.7593439221382141,
                "min": -0.29772424697875977,
                "frobenius_norm": 2.1788179874420166,
                "spectral_norm": 1.6228693723678589,
                "num_singular_values": 8,
                "alpha": 1.0581463705862522
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.10176284611225128,
                "median": 0.10912150144577026,
                "std": 0.19189515709877014,
                "max": 0.48566189408302307,
                "min": -0.2762342393398285,
                "frobenius_norm": 1.737666130065918,
                "spectral_norm": 1.0883443355560303,
                "num_singular_values": 8,
                "alpha": 1.2216627353921
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.0005_batch_size_16_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07461994141340256,
            "mse": 474381056.0,
            "mae": 2016.9149169921875,
            "r2_score": 0.8975271582603455,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.038038235157728195,
                "median": 0.03241842985153198,
                "std": 0.23180650174617767,
                "max": 0.583892822265625,
                "min": -0.5752555131912231,
                "frobenius_norm": 2.3016064167022705,
                "spectral_norm": 1.6035367250442505,
                "num_singular_values": 8,
                "alpha": 1.47582967345254
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03645026683807373,
                "median": 0.09490124136209488,
                "std": 0.27525806427001953,
                "max": 0.6217700839042664,
                "min": -0.6245378255844116,
                "frobenius_norm": 2.221287727355957,
                "spectral_norm": 1.485295057296753,
                "num_singular_values": 8,
                "alpha": 1.1677102787218612
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.024110611528158188,
                "median": 0.009179406799376011,
                "std": 0.2578675150871277,
                "max": 0.8213313221931458,
                "min": -0.4342365264892578,
                "frobenius_norm": 2.0719377994537354,
                "spectral_norm": 1.3425096273422241,
                "num_singular_values": 8,
                "alpha": 1.124667527739815
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07014934718608856,
                "median": 0.07034718990325928,
                "std": 0.20074906945228577,
                "max": 0.5905002951622009,
                "min": -0.29912662506103516,
                "frobenius_norm": 1.7012206315994263,
                "spectral_norm": 1.0799611806869507,
                "num_singular_values": 8,
                "alpha": 1.1280508012138462
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.0005_batch_size_16_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07362601906061172,
            "mse": 483177536.0,
            "mae": 1994.52294921875,
            "r2_score": 0.8956270217895508,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.055945832282304764,
                "median": 0.04637960344552994,
                "std": 0.22561988234519958,
                "max": 0.6166620254516602,
                "min": -0.5716463923454285,
                "frobenius_norm": 2.277562141418457,
                "spectral_norm": 1.601467251777649,
                "num_singular_values": 8,
                "alpha": 1.2758475670984828
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.09471522271633148,
                "median": 0.11760514229536057,
                "std": 0.27150556445121765,
                "max": 0.6630768179893494,
                "min": -0.7128024697303772,
                "frobenius_norm": 2.300417184829712,
                "spectral_norm": 1.5988330841064453,
                "num_singular_values": 8,
                "alpha": 1.110691124757824
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.028507264330983162,
                "median": 0.043129656463861465,
                "std": 0.27284684777259827,
                "max": 0.8899863362312317,
                "min": -0.6243072748184204,
                "frobenius_norm": 2.1946563720703125,
                "spectral_norm": 1.4425638914108276,
                "num_singular_values": 8,
                "alpha": 1.2497043517294426
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06868255138397217,
                "median": 0.07823269069194794,
                "std": 0.1912464052438736,
                "max": 0.4803398549556732,
                "min": -0.29541224241256714,
                "frobenius_norm": 1.6256440877914429,
                "spectral_norm": 0.9290618300437927,
                "num_singular_values": 8,
                "alpha": 1.3920274406548838
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.0005_batch_size_16_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "scores": {
            "smape": 0.08475368469953537,
            "mse": 663032512.0,
            "mae": 2354.627685546875,
            "r2_score": 0.8567758798599243,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.07032070308923721,
                "median": 0.06947411596775055,
                "std": 0.19842404127120972,
                "max": 0.5519267320632935,
                "min": -0.3192073106765747,
                "frobenius_norm": 2.0626296997070312,
                "spectral_norm": 1.4914305210113525,
                "num_singular_values": 8,
                "alpha": 1.3180754741695533
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.042945560067892075,
                "median": 0.09461356699466705,
                "std": 0.26415300369262695,
                "max": 0.48848578333854675,
                "min": -0.8023034334182739,
                "frobenius_norm": 2.140969753265381,
                "spectral_norm": 1.416489839553833,
                "num_singular_values": 8,
                "alpha": 1.348870064583856
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0100720738992095,
                "median": 0.010089639574289322,
                "std": 0.24485307931900024,
                "max": 0.6795213222503662,
                "min": -0.720074474811554,
                "frobenius_norm": 1.9604812860488892,
                "spectral_norm": 1.244621753692627,
                "num_singular_values": 8,
                "alpha": 1.2900904037137146
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05569690093398094,
                "median": 0.03950025141239166,
                "std": 0.18861669301986694,
                "max": 0.4245961904525757,
                "min": -0.26304394006729126,
                "frobenius_norm": 1.5733460187911987,
                "spectral_norm": 0.8545458912849426,
                "num_singular_values": 8,
                "alpha": 1.2179487007691077
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.0005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.08478979766368866,
            "mse": 488033888.0,
            "mae": 2010.7960205078125,
            "r2_score": 0.8945779800415039,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.0775122120976448,
                "median": 0.09051600098609924,
                "std": 0.16512060165405273,
                "max": 0.3794083595275879,
                "min": -0.31576403975486755,
                "frobenius_norm": 1.787233591079712,
                "spectral_norm": 0.998906135559082,
                "num_singular_values": 8,
                "alpha": 1.6017090651782868
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07092301547527313,
                "median": 0.1090279296040535,
                "std": 0.23462729156017303,
                "max": 0.4500328600406647,
                "min": -0.3879365921020508,
                "frobenius_norm": 1.9608983993530273,
                "spectral_norm": 1.3343160152435303,
                "num_singular_values": 8,
                "alpha": 1.2326872269147078
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.09859234094619751,
                "median": 0.06836338341236115,
                "std": 0.25856173038482666,
                "max": 0.7664023041725159,
                "min": -0.3035380244255066,
                "frobenius_norm": 2.2137694358825684,
                "spectral_norm": 1.6651833057403564,
                "num_singular_values": 8,
                "alpha": 1.158833340441677
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.10130126774311066,
                "median": 0.11173228919506073,
                "std": 0.192081481218338,
                "max": 0.4841877818107605,
                "min": -0.2819230258464813,
                "frobenius_norm": 1.737257480621338,
                "spectral_norm": 1.0906394720077515,
                "num_singular_values": 8,
                "alpha": 1.212583397049861
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.0005_batch_size_32_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07424512505531311,
            "mse": 478221504.0,
            "mae": 2013.00927734375,
            "r2_score": 0.8966975808143616,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.04636569321155548,
                "median": 0.04122629761695862,
                "std": 0.23162326216697693,
                "max": 0.5456501245498657,
                "min": -0.6016336679458618,
                "frobenius_norm": 2.314457654953003,
                "spectral_norm": 1.4748793840408325,
                "num_singular_values": 8,
                "alpha": 1.4720516172619629
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05604769289493561,
                "median": 0.10156933963298798,
                "std": 0.2993532419204712,
                "max": 0.6797427535057068,
                "min": -0.7614525556564331,
                "frobenius_norm": 2.4364395141601562,
                "spectral_norm": 1.6483997106552124,
                "num_singular_values": 8,
                "alpha": 1.162352775269313
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.011709615588188171,
                "median": -0.017085786908864975,
                "std": 0.2718139886856079,
                "max": 0.8499462008476257,
                "min": -0.5160104036331177,
                "frobenius_norm": 2.1765286922454834,
                "spectral_norm": 1.4853771924972534,
                "num_singular_values": 8,
                "alpha": 1.2505305967974591
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.047565165907144547,
                "median": 0.042227767407894135,
                "std": 0.19895240664482117,
                "max": 0.48686015605926514,
                "min": -0.35755184292793274,
                "frobenius_norm": 1.636474370956421,
                "spectral_norm": 0.9754347205162048,
                "num_singular_values": 8,
                "alpha": 1.2552954187320189
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.0005_batch_size_32_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 320
        },
        "scores": {
            "smape": 0.0737052634358406,
            "mse": 494704448.0,
            "mae": 2020.574951171875,
            "r2_score": 0.8931370377540588,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06245219707489014,
                "median": 0.057530369609594345,
                "std": 0.23921813070774078,
                "max": 0.6581000685691833,
                "min": -0.5607084631919861,
                "frobenius_norm": 2.422407388687134,
                "spectral_norm": 1.694044828414917,
                "num_singular_values": 8,
                "alpha": 1.3372615623774686
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.09811782091856003,
                "median": 0.11307372152805328,
                "std": 0.28386521339416504,
                "max": 0.6289423108100891,
                "min": -0.8073030114173889,
                "frobenius_norm": 2.402752637863159,
                "spectral_norm": 1.687040090560913,
                "num_singular_values": 8,
                "alpha": 1.2114417723906488
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.030531994998455048,
                "median": 0.04225322604179382,
                "std": 0.2789251208305359,
                "max": 0.8905634880065918,
                "min": -0.5559073090553284,
                "frobenius_norm": 2.24472975730896,
                "spectral_norm": 1.449217438697815,
                "num_singular_values": 8,
                "alpha": 1.2569085256253478
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07720354199409485,
                "median": 0.07361087203025818,
                "std": 0.19047534465789795,
                "max": 0.4932858347892761,
                "min": -0.2532269060611725,
                "frobenius_norm": 1.6442140340805054,
                "spectral_norm": 0.9380156993865967,
                "num_singular_values": 8,
                "alpha": 1.4045806451877911
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.0005_batch_size_32_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "scores": {
            "smape": 0.08181218057870865,
            "mse": 602971776.0,
            "mae": 2285.768310546875,
            "r2_score": 0.8697497844696045,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.10386773198843002,
                "median": 0.11452756822109222,
                "std": 0.21166323125362396,
                "max": 0.5236462950706482,
                "min": -0.4603423476219177,
                "frobenius_norm": 2.3101131916046143,
                "spectral_norm": 1.4876785278320312,
                "num_singular_values": 8,
                "alpha": 1.3915437077415287
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07279781997203827,
                "median": 0.11421728134155273,
                "std": 0.26239335536956787,
                "max": 0.5094027519226074,
                "min": -0.6352941989898682,
                "frobenius_norm": 2.1784369945526123,
                "spectral_norm": 1.3943462371826172,
                "num_singular_values": 8,
                "alpha": 1.2535106708931392
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.007940731942653656,
                "median": 0.00951397605240345,
                "std": 0.24994882941246033,
                "max": 0.6349313259124756,
                "min": -0.5513845682144165,
                "frobenius_norm": 2.0005996227264404,
                "spectral_norm": 1.2077751159667969,
                "num_singular_values": 8,
                "alpha": 1.3419945226573178
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05981139838695526,
                "median": 0.04653380066156387,
                "std": 0.19201049208641052,
                "max": 0.48465561866760254,
                "min": -0.2634662389755249,
                "frobenius_norm": 1.6088839769363403,
                "spectral_norm": 0.9322407841682434,
                "num_singular_values": 8,
                "alpha": 1.3296891807961893
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.0005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.08407821506261826,
            "mse": 500873312.0,
            "mae": 2040.683349609375,
            "r2_score": 0.8918044567108154,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.0785147175192833,
                "median": 0.08474987745285034,
                "std": 0.1668030172586441,
                "max": 0.37648022174835205,
                "min": -0.2962062656879425,
                "frobenius_norm": 1.8063303232192993,
                "spectral_norm": 1.006116509437561,
                "num_singular_values": 8,
                "alpha": 1.5554430776749908
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06140400096774101,
                "median": 0.09408410638570786,
                "std": 0.24485400319099426,
                "max": 0.46076539158821106,
                "min": -0.4405321478843689,
                "frobenius_norm": 2.0194880962371826,
                "spectral_norm": 1.4158470630645752,
                "num_singular_values": 8,
                "alpha": 1.2014971591376904
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.11137466132640839,
                "median": 0.08323013782501221,
                "std": 0.2726331651210785,
                "max": 0.8202990889549255,
                "min": -0.3020407557487488,
                "frobenius_norm": 2.356039524078369,
                "spectral_norm": 1.8108940124511719,
                "num_singular_values": 8,
                "alpha": 1.1255099188342643
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.11730124056339264,
                "median": 0.12725600600242615,
                "std": 0.19374296069145203,
                "max": 0.5140672326087952,
                "min": -0.26419827342033386,
                "frobenius_norm": 1.8118880987167358,
                "spectral_norm": 1.1804744005203247,
                "num_singular_values": 8,
                "alpha": 1.1648990433735606
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.0005_batch_size_64_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "standard",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07440729439258575,
            "mse": 473089664.0,
            "mae": 1991.834228515625,
            "r2_score": 0.8978061079978943,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.05740724503993988,
                "median": 0.04068993777036667,
                "std": 0.24564769864082336,
                "max": 0.6042655110359192,
                "min": -0.5560917258262634,
                "frobenius_norm": 2.4716968536376953,
                "spectral_norm": 1.6198960542678833,
                "num_singular_values": 8,
                "alpha": 1.397957300506789
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.042444564402103424,
                "median": 0.07964517176151276,
                "std": 0.3067498803138733,
                "max": 0.6627792716026306,
                "min": -0.8182348012924194,
                "frobenius_norm": 2.47737979888916,
                "spectral_norm": 1.5474666357040405,
                "num_singular_values": 8,
                "alpha": 1.2332648849071872
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02233302965760231,
                "median": 0.012388983741402626,
                "std": 0.2726680040359497,
                "max": 0.8639000058174133,
                "min": -0.4273964762687683,
                "frobenius_norm": 2.1886487007141113,
                "spectral_norm": 1.4804351329803467,
                "num_singular_values": 8,
                "alpha": 1.2337759498730922
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04351513087749481,
                "median": 0.041053008288145065,
                "std": 0.20059211552143097,
                "max": 0.4891710579395294,
                "min": -0.40254831314086914,
                "frobenius_norm": 1.6420623064041138,
                "spectral_norm": 1.0043963193893433,
                "num_singular_values": 8,
                "alpha": 1.2009237443173315
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.0005_batch_size_64_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "robust",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07366028428077698,
            "mse": 499218304.0,
            "mae": 2030.0968017578125,
            "r2_score": 0.8921619653701782,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06420961767435074,
                "median": 0.05606155842542648,
                "std": 0.24041059613227844,
                "max": 0.6838940978050232,
                "min": -0.5859686136245728,
                "frobenius_norm": 2.4381003379821777,
                "spectral_norm": 1.7233519554138184,
                "num_singular_values": 8,
                "alpha": 1.4155846027638705
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08838927745819092,
                "median": 0.13174954056739807,
                "std": 0.2916090786457062,
                "max": 0.6311544179916382,
                "min": -0.828984260559082,
                "frobenius_norm": 2.4376845359802246,
                "spectral_norm": 1.667425513267517,
                "num_singular_values": 8,
                "alpha": 1.2041333688510532
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03229363262653351,
                "median": 0.041637349873781204,
                "std": 0.2653350830078125,
                "max": 0.9115177989006042,
                "min": -0.44983550906181335,
                "frobenius_norm": 2.1383445262908936,
                "spectral_norm": 1.3885624408721924,
                "num_singular_values": 8,
                "alpha": 1.350575044087352
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07268407940864563,
                "median": 0.07779945433139801,
                "std": 0.19064819812774658,
                "max": 0.4988117218017578,
                "min": -0.2981291115283966,
                "frobenius_norm": 1.6322689056396484,
                "spectral_norm": 0.9362193942070007,
                "num_singular_values": 8,
                "alpha": 1.470435518842763
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.0005_batch_size_64_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "scores": {
            "smape": 0.08162067830562592,
            "mse": 589059712.0,
            "mae": 2250.71923828125,
            "r2_score": 0.8727549910545349,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.10997319221496582,
                "median": 0.10456880927085876,
                "std": 0.21504411101341248,
                "max": 0.5919932126998901,
                "min": -0.34970635175704956,
                "frobenius_norm": 2.366528034210205,
                "spectral_norm": 1.5395565032958984,
                "num_singular_values": 8,
                "alpha": 1.4417646718384711
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07423228770494461,
                "median": 0.10188731551170349,
                "std": 0.2599305808544159,
                "max": 0.5019222497940063,
                "min": -0.6275847554206848,
                "frobenius_norm": 2.162581205368042,
                "spectral_norm": 1.3014134168624878,
                "num_singular_values": 8,
                "alpha": 1.231932007268482
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.004952847026288509,
                "median": -0.00396111560985446,
                "std": 0.25139951705932617,
                "max": 0.6360681056976318,
                "min": -0.6217132210731506,
                "frobenius_norm": 2.0115861892700195,
                "spectral_norm": 1.2240180969238281,
                "num_singular_values": 8,
                "alpha": 1.333631201413556
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05625910311937332,
                "median": 0.03963682800531387,
                "std": 0.19107531011104584,
                "max": 0.47700047492980957,
                "min": -0.2623277008533478,
                "frobenius_norm": 1.5934840440750122,
                "spectral_norm": 0.9149041175842285,
                "num_singular_values": 8,
                "alpha": 1.3447290796331355
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.0005_batch_size_128_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 128,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.08458641916513443,
            "mse": 497768928.0,
            "mae": 2055.1123046875,
            "r2_score": 0.8924750685691833,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.08046253025531769,
                "median": 0.09241089969873428,
                "std": 0.1672164350748062,
                "max": 0.37938567996025085,
                "min": -0.290807843208313,
                "frobenius_norm": 1.8181896209716797,
                "spectral_norm": 1.0222009420394897,
                "num_singular_values": 8,
                "alpha": 1.563390166463097
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06521426886320114,
                "median": 0.10185304284095764,
                "std": 0.2471129149198532,
                "max": 0.466002881526947,
                "min": -0.4377744495868683,
                "frobenius_norm": 2.044586181640625,
                "spectral_norm": 1.4518299102783203,
                "num_singular_values": 8,
                "alpha": 1.2186009121619739
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.11012520641088486,
                "median": 0.0819820910692215,
                "std": 0.2678245007991791,
                "max": 0.7881932258605957,
                "min": -0.3033359944820404,
                "frobenius_norm": 2.316653251647949,
                "spectral_norm": 1.7610722780227661,
                "num_singular_values": 8,
                "alpha": 1.1158225999494893
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.11764267832040787,
                "median": 0.12816962599754333,
                "std": 0.19354148209095,
                "max": 0.5135159492492676,
                "min": -0.26401543617248535,
                "frobenius_norm": 1.8119268417358398,
                "spectral_norm": 1.1824580430984497,
                "num_singular_values": 8,
                "alpha": 1.1748655518067235
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.0005_batch_size_128_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 128,
            "scaler_type": "standard",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07451743632555008,
            "mse": 493086240.0,
            "mae": 2023.3031005859375,
            "r2_score": 0.8934865593910217,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.05818266049027443,
                "median": 0.04551459848880768,
                "std": 0.2448878139257431,
                "max": 0.6198680996894836,
                "min": -0.5259499549865723,
                "frobenius_norm": 2.4661924839019775,
                "spectral_norm": 1.5944995880126953,
                "num_singular_values": 8,
                "alpha": 1.462679955161508
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.023417098447680473,
                "median": 0.050326697528362274,
                "std": 0.30361244082450867,
                "max": 0.7108696699142456,
                "min": -0.8578941226005554,
                "frobenius_norm": 2.4361133575439453,
                "spectral_norm": 1.734264612197876,
                "num_singular_values": 8,
                "alpha": 1.1955281745702475
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02711481600999832,
                "median": 0.02576555497944355,
                "std": 0.26076439023017883,
                "max": 0.8541150093078613,
                "min": -0.44400402903556824,
                "frobenius_norm": 2.097362756729126,
                "spectral_norm": 1.4276902675628662,
                "num_singular_values": 8,
                "alpha": 1.2506583032218845
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05853972211480141,
                "median": 0.04213981330394745,
                "std": 0.1912413388490677,
                "max": 0.4800059497356415,
                "min": -0.23485167324543,
                "frobenius_norm": 1.6000030040740967,
                "spectral_norm": 0.8916206359863281,
                "num_singular_values": 8,
                "alpha": 1.2332169828565456
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.0005_batch_size_128_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 128,
            "scaler_type": "robust",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07335246354341507,
            "mse": 489240800.0,
            "mae": 2007.7122802734375,
            "r2_score": 0.8943172693252563,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06354567408561707,
                "median": 0.05447716265916824,
                "std": 0.22854331135749817,
                "max": 0.6258262395858765,
                "min": -0.538296639919281,
                "frobenius_norm": 2.324205160140991,
                "spectral_norm": 1.5945005416870117,
                "num_singular_values": 8,
                "alpha": 1.4878806144223287
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.09160101413726807,
                "median": 0.12097644805908203,
                "std": 0.30492761731147766,
                "max": 0.5723586082458496,
                "min": -0.8627570271492004,
                "frobenius_norm": 2.547112464904785,
                "spectral_norm": 1.893273115158081,
                "num_singular_values": 8,
                "alpha": 1.2366395280705114
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03581343591213226,
                "median": 0.031874287873506546,
                "std": 0.261057585477829,
                "max": 0.8065372705459595,
                "min": -0.5641807913780212,
                "frobenius_norm": 2.1080214977264404,
                "spectral_norm": 1.4279800653457642,
                "num_singular_values": 8,
                "alpha": 1.120992478484515
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06460517644882202,
                "median": 0.051445361226797104,
                "std": 0.18917006254196167,
                "max": 0.49650001525878906,
                "min": -0.2338700145483017,
                "frobenius_norm": 1.5991826057434082,
                "spectral_norm": 0.8923591375350952,
                "num_singular_values": 8,
                "alpha": 1.234840707811641
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.0005_batch_size_128_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 128,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "scores": {
            "smape": 0.08149462938308716,
            "mse": 597166656.0,
            "mae": 2283.73583984375,
            "r2_score": 0.8710037469863892,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.0748073011636734,
                "median": 0.05919289588928223,
                "std": 0.20331013202667236,
                "max": 0.5870441198348999,
                "min": -0.36162513494491577,
                "frobenius_norm": 2.1225905418395996,
                "spectral_norm": 1.5227879285812378,
                "num_singular_values": 8,
                "alpha": 1.3880694426481552
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04953174293041229,
                "median": 0.08308245241641998,
                "std": 0.26972994208335876,
                "max": 0.4687856435775757,
                "min": -0.8368464112281799,
                "frobenius_norm": 2.1939210891723633,
                "spectral_norm": 1.5657154321670532,
                "num_singular_values": 8,
                "alpha": 1.3279823435175904
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.014106908813118935,
                "median": -0.010971296578645706,
                "std": 0.24434000253677368,
                "max": 0.6572049260139465,
                "min": -0.5677528381347656,
                "frobenius_norm": 1.957975149154663,
                "spectral_norm": 1.1905051469802856,
                "num_singular_values": 8,
                "alpha": 1.3495434973817388
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06088399514555931,
                "median": 0.04059382528066635,
                "std": 0.1916380375623703,
                "max": 0.46890056133270264,
                "min": -0.23485167324543,
                "frobenius_norm": 1.608616828918457,
                "spectral_norm": 0.9041591286659241,
                "num_singular_values": 8,
                "alpha": 1.264381713702951
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.0005_batch_size_256_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 256,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.08579733967781067,
            "mse": 508847744.0,
            "mae": 2080.907958984375,
            "r2_score": 0.8900818824768066,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.07691335678100586,
                "median": 0.08217374980449677,
                "std": 0.16832445561885834,
                "max": 0.37976402044296265,
                "min": -0.3017299771308899,
                "frobenius_norm": 1.8132520914077759,
                "spectral_norm": 1.0275778770446777,
                "num_singular_values": 8,
                "alpha": 1.5273042642596102
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05854075402021408,
                "median": 0.10166703164577484,
                "std": 0.24552655220031738,
                "max": 0.4649023711681366,
                "min": -0.4491054117679596,
                "frobenius_norm": 2.0192723274230957,
                "spectral_norm": 1.4187442064285278,
                "num_singular_values": 8,
                "alpha": 1.2239034933249582
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.11191165447235107,
                "median": 0.0836644321680069,
                "std": 0.27266725897789,
                "max": 0.8076791763305664,
                "min": -0.3039926588535309,
                "frobenius_norm": 2.357919931411743,
                "spectral_norm": 1.8125971555709839,
                "num_singular_values": 8,
                "alpha": 1.1477316295375444
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.11760532855987549,
                "median": 0.12776529788970947,
                "std": 0.19391457736492157,
                "max": 0.5188868045806885,
                "min": -0.2659878134727478,
                "frobenius_norm": 1.8143229484558105,
                "spectral_norm": 1.188462257385254,
                "num_singular_values": 8,
                "alpha": 1.17524869268279
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.0005_batch_size_256_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 256,
            "scaler_type": "standard",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07463441044092178,
            "mse": 489214080.0,
            "mae": 1999.7479248046875,
            "r2_score": 0.8943229913711548,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06861954182386398,
                "median": 0.040400683879852295,
                "std": 0.25569435954093933,
                "max": 0.6741958856582642,
                "min": -0.5462732911109924,
                "frobenius_norm": 2.5939300060272217,
                "spectral_norm": 1.7099705934524536,
                "num_singular_values": 8,
                "alpha": 1.396925728304956
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.053445711731910706,
                "median": 0.05208490788936615,
                "std": 0.3107898533344269,
                "max": 0.7031621932983398,
                "min": -0.8908423781394958,
                "frobenius_norm": 2.5228145122528076,
                "spectral_norm": 1.643365740776062,
                "num_singular_values": 8,
                "alpha": 1.2247729250321875
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.011465922929346561,
                "median": 0.010614367201924324,
                "std": 0.27089977264404297,
                "max": 0.8623925447463989,
                "min": -0.4893079102039337,
                "frobenius_norm": 2.1691384315490723,
                "spectral_norm": 1.5359879732131958,
                "num_singular_values": 8,
                "alpha": 1.2038684931416985
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0466904491186142,
                "median": 0.025753462687134743,
                "std": 0.19281814992427826,
                "max": 0.45989927649497986,
                "min": -0.2959640920162201,
                "frobenius_norm": 1.5871249437332153,
                "spectral_norm": 0.8899365663528442,
                "num_singular_values": 8,
                "alpha": 1.3298564836155684
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.0005_batch_size_256_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 256,
            "scaler_type": "robust",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07350891828536987,
            "mse": 497161248.0,
            "mae": 2003.689208984375,
            "r2_score": 0.8926063179969788,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06982935965061188,
                "median": 0.05124473199248314,
                "std": 0.23582994937896729,
                "max": 0.6526955962181091,
                "min": -0.5439513325691223,
                "frobenius_norm": 2.409817934036255,
                "spectral_norm": 1.6600717306137085,
                "num_singular_values": 8,
                "alpha": 1.4826277027544972
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08714470267295837,
                "median": 0.1499398797750473,
                "std": 0.30486351251602173,
                "max": 0.6385568976402283,
                "min": -0.8701236844062805,
                "frobenius_norm": 2.536592483520508,
                "spectral_norm": 1.8616927862167358,
                "num_singular_values": 8,
                "alpha": 1.2381618855606435
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02526867389678955,
                "median": 0.04619676619768143,
                "std": 0.2661779522895813,
                "max": 0.7894977331161499,
                "min": -0.6264151334762573,
                "frobenius_norm": 2.1389973163604736,
                "spectral_norm": 1.4624042510986328,
                "num_singular_values": 8,
                "alpha": 1.207031669031077
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06576951593160629,
                "median": 0.06573516875505447,
                "std": 0.18776772916316986,
                "max": 0.4767051637172699,
                "min": -0.23860058188438416,
                "frobenius_norm": 1.5916250944137573,
                "spectral_norm": 0.8764283061027527,
                "num_singular_values": 8,
                "alpha": 1.2205539135679664
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.0005_batch_size_256_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 256,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "scores": {
            "smape": 0.08268620073795319,
            "mse": 608164032.0,
            "mae": 2281.779052734375,
            "r2_score": 0.868628203868866,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06736589223146439,
                "median": 0.0565507598221302,
                "std": 0.207128643989563,
                "max": 0.5907687544822693,
                "min": -0.3132377862930298,
                "frobenius_norm": 2.1340761184692383,
                "spectral_norm": 1.5351921319961548,
                "num_singular_values": 8,
                "alpha": 1.3953468920911867
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.041676849126815796,
                "median": 0.08104680478572845,
                "std": 0.2670852839946747,
                "max": 0.523335337638855,
                "min": -0.9355197548866272,
                "frobenius_norm": 2.162539482116699,
                "spectral_norm": 1.4583795070648193,
                "num_singular_values": 8,
                "alpha": 1.2664136004403228
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01841888204216957,
                "median": 0.007153879851102829,
                "std": 0.245216503739357,
                "max": 0.7161890864372253,
                "min": -0.7151986360549927,
                "frobenius_norm": 1.9672582149505615,
                "spectral_norm": 1.231366753578186,
                "num_singular_values": 8,
                "alpha": 1.3292703480510295
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.055144697427749634,
                "median": 0.03193622827529907,
                "std": 0.18861901760101318,
                "max": 0.41629546880722046,
                "min": -0.2501550316810608,
                "frobenius_norm": 1.5721185207366943,
                "spectral_norm": 0.8452983498573303,
                "num_singular_values": 8,
                "alpha": 1.25029807721916
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.0001_batch_size_16_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.31273600459098816,
            "mse": 2360410880.0,
            "mae": 5348.11181640625,
            "r2_score": 0.49011874198913574,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06341070681810379,
                "median": 0.053977616131305695,
                "std": 0.16179780662059784,
                "max": 0.36950939893722534,
                "min": -0.27532336115837097,
                "frobenius_norm": 1.702688217163086,
                "spectral_norm": 0.9327433705329895,
                "num_singular_values": 8,
                "alpha": 1.6593606746805771
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.061154045164585114,
                "median": 0.07442590594291687,
                "std": 0.22570635378360748,
                "max": 0.45677462220191956,
                "min": -0.3214488923549652,
                "frobenius_norm": 1.8707547187805176,
                "spectral_norm": 1.2333605289459229,
                "num_singular_values": 8,
                "alpha": 1.1209244199063004
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05095340311527252,
                "median": 0.004026496782898903,
                "std": 0.2312304824590683,
                "max": 0.433877557516098,
                "min": -0.2987630367279053,
                "frobenius_norm": 1.8942234516143799,
                "spectral_norm": 1.2227420806884766,
                "num_singular_values": 8,
                "alpha": 1.2957377798705028
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08564876765012741,
                "median": 0.07601416856050491,
                "std": 0.19254298508167267,
                "max": 0.4327869117259979,
                "min": -0.2615092396736145,
                "frobenius_norm": 1.685866117477417,
                "spectral_norm": 1.013446569442749,
                "num_singular_values": 8,
                "alpha": 1.2399642211583233
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.0001_batch_size_16_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07927804440259933,
            "mse": 590488000.0,
            "mae": 2129.78857421875,
            "r2_score": 0.8724464178085327,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.011823992244899273,
                "median": 0.039207909256219864,
                "std": 0.15914098918437958,
                "max": 0.29467514157295227,
                "min": -0.28860530257225037,
                "frobenius_norm": 1.5635547637939453,
                "spectral_norm": 0.8123584389686584,
                "num_singular_values": 8,
                "alpha": 1.6499743655295531
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.006589438300579786,
                "median": 0.03820781409740448,
                "std": 0.2153535783290863,
                "max": 0.362737774848938,
                "min": -0.4233301281929016,
                "frobenius_norm": 1.723634958267212,
                "spectral_norm": 1.0017071962356567,
                "num_singular_values": 8,
                "alpha": 1.1610934876849586
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01284894160926342,
                "median": -0.016911501064896584,
                "std": 0.22756725549697876,
                "max": 0.4612717628479004,
                "min": -0.3348327577114105,
                "frobenius_norm": 1.8234376907348633,
                "spectral_norm": 1.1569709777832031,
                "num_singular_values": 8,
                "alpha": 1.2534142434328672
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.028670646250247955,
                "median": 0.012240326963365078,
                "std": 0.19276836514472961,
                "max": 0.3841102719306946,
                "min": -0.28012484312057495,
                "frobenius_norm": 1.5591105222702026,
                "spectral_norm": 0.8276976346969604,
                "num_singular_values": 8,
                "alpha": 1.2262840093197789
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.0001_batch_size_16_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07903740555047989,
            "mse": 634095232.0,
            "mae": 2123.783935546875,
            "r2_score": 0.8630266785621643,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.01591799594461918,
                "median": 0.03806265443563461,
                "std": 0.16019819676876068,
                "max": 0.29047611355781555,
                "min": -0.35112065076828003,
                "frobenius_norm": 1.5773448944091797,
                "spectral_norm": 0.8087849020957947,
                "num_singular_values": 8,
                "alpha": 1.601636946060679
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.029588177800178528,
                "median": 0.0757109522819519,
                "std": 0.2062768191099167,
                "max": 0.3604016602039337,
                "min": -0.3812223970890045,
                "frobenius_norm": 1.6671043634414673,
                "spectral_norm": 0.9414036870002747,
                "num_singular_values": 8,
                "alpha": 1.1426199484802664
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.012198228389024734,
                "median": -0.021690333262085915,
                "std": 0.23228345811367035,
                "max": 0.47973304986953735,
                "min": -0.36011162400245667,
                "frobenius_norm": 1.8608282804489136,
                "spectral_norm": 1.1684211492538452,
                "num_singular_values": 8,
                "alpha": 1.2525918892139245
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03501422703266144,
                "median": 0.015933828428387642,
                "std": 0.19337277114391327,
                "max": 0.4220978915691376,
                "min": -0.2769952118396759,
                "frobenius_norm": 1.5721378326416016,
                "spectral_norm": 0.8629090189933777,
                "num_singular_values": 8,
                "alpha": 1.2422541037352304
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.0001_batch_size_16_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "scores": {
            "smape": 0.1507929116487503,
            "mse": 1433666432.0,
            "mae": 3577.448974609375,
            "r2_score": 0.6903082728385925,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.050873760133981705,
                "median": 0.057355739176273346,
                "std": 0.16948507726192474,
                "max": 0.3999480605125427,
                "min": -0.28842103481292725,
                "frobenius_norm": 1.7338049411773682,
                "spectral_norm": 0.952214777469635,
                "num_singular_values": 8,
                "alpha": 1.447120854317315
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03909999877214432,
                "median": 0.07522213459014893,
                "std": 0.2189134806394577,
                "max": 0.39979317784309387,
                "min": -0.3671247363090515,
                "frobenius_norm": 1.7790229320526123,
                "spectral_norm": 1.0517809391021729,
                "num_singular_values": 8,
                "alpha": 1.1821224391273168
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.016765497624874115,
                "median": -0.013864611275494099,
                "std": 0.23245686292648315,
                "max": 0.48358047008514404,
                "min": -0.3738657832145691,
                "frobenius_norm": 1.8644853830337524,
                "spectral_norm": 1.1631163358688354,
                "num_singular_values": 8,
                "alpha": 1.2876807454676187
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.031064927577972412,
                "median": 0.012488940730690956,
                "std": 0.19338840246200562,
                "max": 0.39662057161331177,
                "min": -0.27832290530204773,
                "frobenius_norm": 1.5669405460357666,
                "spectral_norm": 0.8414639830589294,
                "num_singular_values": 8,
                "alpha": 1.2344612816902132
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.0001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.2541669011116028,
            "mse": 2044282240.0,
            "mae": 4671.13671875,
            "r2_score": 0.5584068894386292,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06904415041208267,
                "median": 0.06448360532522202,
                "std": 0.16046428680419922,
                "max": 0.3723750710487366,
                "min": -0.253218412399292,
                "frobenius_norm": 1.711585521697998,
                "spectral_norm": 0.9536535739898682,
                "num_singular_values": 8,
                "alpha": 1.6725208280930217
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06441847234964371,
                "median": 0.06803103536367416,
                "std": 0.22518351674079895,
                "max": 0.47272613644599915,
                "min": -0.3274695575237274,
                "frobenius_norm": 1.8737318515777588,
                "spectral_norm": 1.2397980690002441,
                "num_singular_values": 8,
                "alpha": 1.1474627233871881
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0532098188996315,
                "median": -0.00019624445121735334,
                "std": 0.23257316648960114,
                "max": 0.43675681948661804,
                "min": -0.3001451790332794,
                "frobenius_norm": 1.9086592197418213,
                "spectral_norm": 1.2394670248031616,
                "num_singular_values": 8,
                "alpha": 1.3025246139396784
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08896395564079285,
                "median": 0.07969152927398682,
                "std": 0.19139839708805084,
                "max": 0.4453262984752655,
                "min": -0.2684379816055298,
                "frobenius_norm": 1.6885104179382324,
                "spectral_norm": 1.0125219821929932,
                "num_singular_values": 8,
                "alpha": 1.199627987528007
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.0001_batch_size_32_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07895591855049133,
            "mse": 593299712.0,
            "mae": 2122.96435546875,
            "r2_score": 0.8718391060829163,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.01124641764909029,
                "median": 0.035781532526016235,
                "std": 0.16067619621753693,
                "max": 0.29173174500465393,
                "min": -0.3055523931980133,
                "frobenius_norm": 1.5781505107879639,
                "spectral_norm": 0.8068809509277344,
                "num_singular_values": 8,
                "alpha": 1.6447000649238415
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.008177638053894043,
                "median": 0.04600872844457626,
                "std": 0.2155066877603531,
                "max": 0.3626043200492859,
                "min": -0.4335760176181793,
                "frobenius_norm": 1.7252943515777588,
                "spectral_norm": 0.9867632985115051,
                "num_singular_values": 8,
                "alpha": 1.196805169168715
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.013571578077971935,
                "median": -0.02001713216304779,
                "std": 0.2293689101934433,
                "max": 0.4746190011501312,
                "min": -0.34574469923973083,
                "frobenius_norm": 1.838160514831543,
                "spectral_norm": 1.163391351699829,
                "num_singular_values": 8,
                "alpha": 1.253816242846772
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03657517582178116,
                "median": 0.014877035282552242,
                "std": 0.1941973716020584,
                "max": 0.43104949593544006,
                "min": -0.27452999353408813,
                "frobenius_norm": 1.5808931589126587,
                "spectral_norm": 0.8767564296722412,
                "num_singular_values": 8,
                "alpha": 1.269486219991116
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.0001_batch_size_32_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07891828566789627,
            "mse": 640330368.0,
            "mae": 2128.23876953125,
            "r2_score": 0.8616797924041748,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.017404921352863312,
                "median": 0.03639844432473183,
                "std": 0.16064317524433136,
                "max": 0.2864837944507599,
                "min": -0.36997365951538086,
                "frobenius_norm": 1.583186388015747,
                "spectral_norm": 0.8112289905548096,
                "num_singular_values": 8,
                "alpha": 1.614866281293578
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03151224926114082,
                "median": 0.08451326191425323,
                "std": 0.20726615190505981,
                "max": 0.375184565782547,
                "min": -0.38503551483154297,
                "frobenius_norm": 1.6771838665008545,
                "spectral_norm": 0.9366478323936462,
                "num_singular_values": 8,
                "alpha": 1.1628734072896034
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.010918580926954746,
                "median": -0.029396677389740944,
                "std": 0.2336018681526184,
                "max": 0.4810570776462555,
                "min": -0.36744922399520874,
                "frobenius_norm": 1.8708552122116089,
                "spectral_norm": 1.1715749502182007,
                "num_singular_values": 8,
                "alpha": 1.2481974347637539
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03602369502186775,
                "median": 0.017851129174232483,
                "std": 0.19225533306598663,
                "max": 0.40765276551246643,
                "min": -0.27108675241470337,
                "frobenius_norm": 1.5648094415664673,
                "spectral_norm": 0.8412979245185852,
                "num_singular_values": 8,
                "alpha": 1.2176610046721588
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.0001_batch_size_32_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "scores": {
            "smape": 0.14935149252414703,
            "mse": 1434004864.0,
            "mae": 3562.284423828125,
            "r2_score": 0.6902351379394531,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.0518762581050396,
                "median": 0.060686565935611725,
                "std": 0.169401615858078,
                "max": 0.4046517610549927,
                "min": -0.30900055170059204,
                "frobenius_norm": 1.735872507095337,
                "spectral_norm": 0.9760088920593262,
                "num_singular_values": 8,
                "alpha": 1.4112718037139222
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0429481640458107,
                "median": 0.07642999291419983,
                "std": 0.21988524496555328,
                "max": 0.4075603187084198,
                "min": -0.35893744230270386,
                "frobenius_norm": 1.7923226356506348,
                "spectral_norm": 1.0626085996627808,
                "num_singular_values": 8,
                "alpha": 1.182847253142225
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01726089045405388,
                "median": -0.010144023224711418,
                "std": 0.2332204282283783,
                "max": 0.48534414172172546,
                "min": -0.38277605175971985,
                "frobenius_norm": 1.8708665370941162,
                "spectral_norm": 1.1625075340270996,
                "num_singular_values": 8,
                "alpha": 1.3076047276164768
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03422416001558304,
                "median": 0.016093239188194275,
                "std": 0.1932620406150818,
                "max": 0.40107855200767517,
                "min": -0.280971884727478,
                "frobenius_norm": 1.5701518058776855,
                "spectral_norm": 0.8400534987449646,
                "num_singular_values": 8,
                "alpha": 1.2117305808546432
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.0001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.16739362478256226,
            "mse": 1375486208.0,
            "mae": 3547.944091796875,
            "r2_score": 0.7028760313987732,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.0713157057762146,
                "median": 0.06047581136226654,
                "std": 0.16029812395572662,
                "max": 0.37577927112579346,
                "min": -0.2736051678657532,
                "frobenius_norm": 1.7190160751342773,
                "spectral_norm": 0.9685356616973877,
                "num_singular_values": 8,
                "alpha": 1.6558700744685675
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.061583422124385834,
                "median": 0.07472681999206543,
                "std": 0.22739055752754211,
                "max": 0.463897168636322,
                "min": -0.33777284622192383,
                "frobenius_norm": 1.8846577405929565,
                "spectral_norm": 1.2464739084243774,
                "num_singular_values": 8,
                "alpha": 1.1280592659650845
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05707896500825882,
                "median": 0.011198675259947777,
                "std": 0.23360320925712585,
                "max": 0.46378347277641296,
                "min": -0.31044480204582214,
                "frobenius_norm": 1.9238040447235107,
                "spectral_norm": 1.2672843933105469,
                "num_singular_values": 8,
                "alpha": 1.3109410481383366
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.09395962953567505,
                "median": 0.08815024793148041,
                "std": 0.18969079852104187,
                "max": 0.4661838412284851,
                "min": -0.2833583354949951,
                "frobenius_norm": 1.6934889554977417,
                "spectral_norm": 1.015977382659912,
                "num_singular_values": 8,
                "alpha": 1.1747133615394116
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.0001_batch_size_64_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "standard",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07904067635536194,
            "mse": 593534784.0,
            "mae": 2126.83349609375,
            "r2_score": 0.8717883229255676,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.01284502912312746,
                "median": 0.03826206922531128,
                "std": 0.16110438108444214,
                "max": 0.29319649934768677,
                "min": -0.3115012049674988,
                "frobenius_norm": 1.5835034847259521,
                "spectral_norm": 0.8119398951530457,
                "num_singular_values": 8,
                "alpha": 1.664884215038326
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.007302623242139816,
                "median": 0.04949623718857765,
                "std": 0.2180679887533188,
                "max": 0.3650677502155304,
                "min": -0.44249051809310913,
                "frobenius_norm": 1.7455217838287354,
                "spectral_norm": 0.9934860467910767,
                "num_singular_values": 8,
                "alpha": 1.1980291984917053
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01346511859446764,
                "median": -0.026918917894363403,
                "std": 0.22825554013252258,
                "max": 0.46962496638298035,
                "min": -0.3168540298938751,
                "frobenius_norm": 1.829218864440918,
                "spectral_norm": 1.1538360118865967,
                "num_singular_values": 8,
                "alpha": 1.227940628293089
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.033087197691202164,
                "median": 0.014049203135073185,
                "std": 0.19287094473838806,
                "max": 0.4017047882080078,
                "min": -0.2748729884624481,
                "frobenius_norm": 1.565507411956787,
                "spectral_norm": 0.8389043807983398,
                "num_singular_values": 8,
                "alpha": 1.2282988216554036
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.0001_batch_size_64_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "robust",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07886060327291489,
            "mse": 642016000.0,
            "mae": 2129.5263671875,
            "r2_score": 0.8613157272338867,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.018410924822092056,
                "median": 0.03649605065584183,
                "std": 0.16136397421360016,
                "max": 0.288059264421463,
                "min": -0.3673253059387207,
                "frobenius_norm": 1.5912951231002808,
                "spectral_norm": 0.8141810297966003,
                "num_singular_values": 8,
                "alpha": 1.6393391520189873
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03130464628338814,
                "median": 0.08993899822235107,
                "std": 0.20743787288665771,
                "max": 0.3811291456222534,
                "min": -0.39700818061828613,
                "frobenius_norm": 1.6782934665679932,
                "spectral_norm": 0.9372596740722656,
                "num_singular_values": 8,
                "alpha": 1.1758491156513218
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.010388805530965328,
                "median": -0.031625114381313324,
                "std": 0.23416854441165924,
                "max": 0.48252570629119873,
                "min": -0.373636931180954,
                "frobenius_norm": 1.87519109249115,
                "spectral_norm": 1.1672803163528442,
                "num_singular_values": 8,
                "alpha": 1.2444399091640779
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.035654954612255096,
                "median": 0.018147755414247513,
                "std": 0.19218428432941437,
                "max": 0.40644556283950806,
                "min": -0.26838988065719604,
                "frobenius_norm": 1.5637099742889404,
                "spectral_norm": 0.8402896523475647,
                "num_singular_values": 8,
                "alpha": 1.2176819454430106
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.0001_batch_size_64_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "scores": {
            "smape": 0.1468300074338913,
            "mse": 1421263232.0,
            "mae": 3513.500732421875,
            "r2_score": 0.6929875612258911,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.05328747630119324,
                "median": 0.05683893710374832,
                "std": 0.16993103921413422,
                "max": 0.41234099864959717,
                "min": -0.2892206013202667,
                "frobenius_norm": 1.744920253753662,
                "spectral_norm": 0.9769110083580017,
                "num_singular_values": 8,
                "alpha": 1.4307079558301121
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04209433123469353,
                "median": 0.07841558009386063,
                "std": 0.2195831835269928,
                "max": 0.40920671820640564,
                "min": -0.36389777064323425,
                "frobenius_norm": 1.7886523008346558,
                "spectral_norm": 1.04997980594635,
                "num_singular_values": 8,
                "alpha": 1.161417273748967
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01620015688240528,
                "median": -0.017127342522144318,
                "std": 0.23380455374717712,
                "max": 0.48647552728652954,
                "min": -0.38448968529701233,
                "frobenius_norm": 1.8749210834503174,
                "spectral_norm": 1.1678589582443237,
                "num_singular_values": 8,
                "alpha": 1.3018032738052692
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.036197856068611145,
                "median": 0.014575897715985775,
                "std": 0.19371843338012695,
                "max": 0.41329020261764526,
                "min": -0.2711451053619385,
                "frobenius_norm": 1.5765708684921265,
                "spectral_norm": 0.8560178875923157,
                "num_singular_values": 8,
                "alpha": 1.2337156483699931
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.0001_batch_size_128_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 128,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.14498917758464813,
            "mse": 1188091264.0,
            "mae": 3211.933837890625,
            "r2_score": 0.743355929851532,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.07256290316581726,
                "median": 0.06077458709478378,
                "std": 0.16019780933856964,
                "max": 0.3766138553619385,
                "min": -0.27333879470825195,
                "frobenius_norm": 1.7231241464614868,
                "spectral_norm": 0.9751572608947754,
                "num_singular_values": 8,
                "alpha": 1.652821242172001
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.062310706824064255,
                "median": 0.07966233789920807,
                "std": 0.2279733568429947,
                "max": 0.46518927812576294,
                "min": -0.3411644995212555,
                "frobenius_norm": 1.8906841278076172,
                "spectral_norm": 1.2463082075119019,
                "num_singular_values": 8,
                "alpha": 1.1409061413003225
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05831555649638176,
                "median": 0.013610189780592918,
                "std": 0.23392997682094574,
                "max": 0.4703502058982849,
                "min": -0.3026360869407654,
                "frobenius_norm": 1.9287124872207642,
                "spectral_norm": 1.2753396034240723,
                "num_singular_values": 8,
                "alpha": 1.3180176533094579
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.09419871121644974,
                "median": 0.09048508107662201,
                "std": 0.1894567459821701,
                "max": 0.4715609550476074,
                "min": -0.2765870690345764,
                "frobenius_norm": 1.6926618814468384,
                "spectral_norm": 1.0235148668289185,
                "num_singular_values": 8,
                "alpha": 1.2039729475235268
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.0001_batch_size_128_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 128,
            "scaler_type": "standard",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07910385727882385,
            "mse": 592805376.0,
            "mae": 2127.87451171875,
            "r2_score": 0.871945858001709,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.012713029980659485,
                "median": 0.034804567694664,
                "std": 0.1611868441104889,
                "max": 0.2968079447746277,
                "min": -0.3136731684207916,
                "frobenius_norm": 1.5842065811157227,
                "spectral_norm": 0.8125740885734558,
                "num_singular_values": 8,
                "alpha": 1.6753290062690076
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.00714518316090107,
                "median": 0.04952477663755417,
                "std": 0.21789567172527313,
                "max": 0.3613796830177307,
                "min": -0.4451783001422882,
                "frobenius_norm": 1.7441023588180542,
                "spectral_norm": 1.0135245323181152,
                "num_singular_values": 8,
                "alpha": 1.1957464123409274
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01110360398888588,
                "median": -0.02459654211997986,
                "std": 0.2306993305683136,
                "max": 0.46945810317993164,
                "min": -0.3438793122768402,
                "frobenius_norm": 1.847731113433838,
                "spectral_norm": 1.1619668006896973,
                "num_singular_values": 8,
                "alpha": 1.2434880176770107
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.030035901814699173,
                "median": 0.014010222628712654,
                "std": 0.19283053278923035,
                "max": 0.39751511812210083,
                "min": -0.27885136008262634,
                "frobenius_norm": 1.5612461566925049,
                "spectral_norm": 0.8360580801963806,
                "num_singular_values": 8,
                "alpha": 1.2362921530432607
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.0001_batch_size_128_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 128,
            "scaler_type": "robust",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07893816381692886,
            "mse": 641900032.0,
            "mae": 2129.164794921875,
            "r2_score": 0.8613407611846924,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.018580717965960503,
                "median": 0.03667673468589783,
                "std": 0.16140057146549225,
                "max": 0.2905999720096588,
                "min": -0.3447137176990509,
                "frobenius_norm": 1.5918407440185547,
                "spectral_norm": 0.8195871710777283,
                "num_singular_values": 8,
                "alpha": 1.6328253752559467
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03060932271182537,
                "median": 0.09076860547065735,
                "std": 0.20739293098449707,
                "max": 0.3599160611629486,
                "min": -0.39824241399765015,
                "frobenius_norm": 1.6771167516708374,
                "spectral_norm": 0.936559796333313,
                "num_singular_values": 8,
                "alpha": 1.19816529776833
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.009348554536700249,
                "median": -0.03296935185790062,
                "std": 0.2337818741798401,
                "max": 0.4813184440135956,
                "min": -0.3843245804309845,
                "frobenius_norm": 1.871749758720398,
                "spectral_norm": 1.1665266752243042,
                "num_singular_values": 8,
                "alpha": 1.2411060817511996
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03270389139652252,
                "median": 0.019791431725025177,
                "std": 0.19203048944473267,
                "max": 0.40154582262039185,
                "min": -0.2720835506916046,
                "frobenius_norm": 1.5583633184432983,
                "spectral_norm": 0.8369383215904236,
                "num_singular_values": 8,
                "alpha": 1.2209246835305754
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.0001_batch_size_128_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 128,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "scores": {
            "smape": 0.15093937516212463,
            "mse": 1453644928.0,
            "mae": 3590.329833984375,
            "r2_score": 0.6859926581382751,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.05411325767636299,
                "median": 0.06250713765621185,
                "std": 0.168959379196167,
                "max": 0.41011205315589905,
                "min": -0.3038181662559509,
                "frobenius_norm": 1.7382892370224,
                "spectral_norm": 0.9842244982719421,
                "num_singular_values": 8,
                "alpha": 1.408433721991661
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04345704987645149,
                "median": 0.07529932260513306,
                "std": 0.21962715685367584,
                "max": 0.41386574506759644,
                "min": -0.3566930592060089,
                "frobenius_norm": 1.7910819053649902,
                "spectral_norm": 1.0626072883605957,
                "num_singular_values": 8,
                "alpha": 1.2027938933755122
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.014990108087658882,
                "median": -0.010250971652567387,
                "std": 0.23378115892410278,
                "max": 0.4841761589050293,
                "min": -0.37916240096092224,
                "frobenius_norm": 1.8740900754928589,
                "spectral_norm": 1.1608384847640991,
                "num_singular_values": 8,
                "alpha": 1.2964054987984086
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03145246207714081,
                "median": 0.015643542632460594,
                "std": 0.19333378970623016,
                "max": 0.39610788226127625,
                "min": -0.27840811014175415,
                "frobenius_norm": 1.5670039653778076,
                "spectral_norm": 0.83493971824646,
                "num_singular_values": 8,
                "alpha": 1.2147855463103292
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.0001_batch_size_256_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 256,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.13943804800510406,
            "mse": 1136710144.0,
            "mae": 3111.006591796875,
            "r2_score": 0.7544549703598022,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.07340860366821289,
                "median": 0.06438729166984558,
                "std": 0.1599624902009964,
                "max": 0.3769572377204895,
                "min": -0.2692932188510895,
                "frobenius_norm": 1.7244634628295898,
                "spectral_norm": 0.9794562458992004,
                "num_singular_values": 8,
                "alpha": 1.6412128500372585
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0604536272585392,
                "median": 0.0801205262541771,
                "std": 0.228010892868042,
                "max": 0.4664897322654724,
                "min": -0.3362979292869568,
                "frobenius_norm": 1.8871116638183594,
                "spectral_norm": 1.2502497434616089,
                "num_singular_values": 8,
                "alpha": 1.140457005965059
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05905378609895706,
                "median": 0.01777784526348114,
                "std": 0.23478761315345764,
                "max": 0.4740975499153137,
                "min": -0.3102370798587799,
                "frobenius_norm": 1.9368027448654175,
                "spectral_norm": 1.2816708087921143,
                "num_singular_values": 8,
                "alpha": 1.3157388411112285
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.09450696408748627,
                "median": 0.09371358901262283,
                "std": 0.18909300863742828,
                "max": 0.4728679358959198,
                "min": -0.28105735778808594,
                "frobenius_norm": 1.6911578178405762,
                "spectral_norm": 1.0169970989227295,
                "num_singular_values": 8,
                "alpha": 1.1886535011370947
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.0001_batch_size_256_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 256,
            "scaler_type": "standard",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07911398261785507,
            "mse": 593931712.0,
            "mae": 2128.487060546875,
            "r2_score": 0.8717025518417358,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.012255688197910786,
                "median": 0.034785009920597076,
                "std": 0.16184784471988678,
                "max": 0.2928709387779236,
                "min": -0.3231204152107239,
                "frobenius_norm": 1.5903185606002808,
                "spectral_norm": 0.8172277808189392,
                "num_singular_values": 8,
                "alpha": 1.6714627449978414
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.007048856467008591,
                "median": 0.055268071591854095,
                "std": 0.2177661806344986,
                "max": 0.36196810007095337,
                "min": -0.4439634680747986,
                "frobenius_norm": 1.7430418729782104,
                "spectral_norm": 1.0137736797332764,
                "num_singular_values": 8,
                "alpha": 1.1661061024038053
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0109975915402174,
                "median": -0.020133106037974358,
                "std": 0.23068328201770782,
                "max": 0.4689127802848816,
                "min": -0.3592281937599182,
                "frobenius_norm": 1.8475621938705444,
                "spectral_norm": 1.164260745048523,
                "num_singular_values": 8,
                "alpha": 1.2594177866810268
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.030285753309726715,
                "median": 0.012334407307207584,
                "std": 0.1925799697637558,
                "max": 0.39194151759147644,
                "min": -0.2748226523399353,
                "frobenius_norm": 1.5595747232437134,
                "spectral_norm": 0.8341635465621948,
                "num_singular_values": 8,
                "alpha": 1.2458135748464556
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.0001_batch_size_256_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 256,
            "scaler_type": "robust",
            "total_params": 320
        },
        "scores": {
            "smape": 0.07892455905675888,
            "mse": 643160768.0,
            "mae": 2129.556396484375,
            "r2_score": 0.8610684275627136,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.017806822434067726,
                "median": 0.03679686039686203,
                "std": 0.16157127916812897,
                "max": 0.28837573528289795,
                "min": -0.3376254141330719,
                "frobenius_norm": 1.5926539897918701,
                "spectral_norm": 0.8206741213798523,
                "num_singular_values": 8,
                "alpha": 1.6260223588397036
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02932775393128395,
                "median": 0.09289313852787018,
                "std": 0.20800358057022095,
                "max": 0.3607783913612366,
                "min": -0.39588025212287903,
                "frobenius_norm": 1.6804876327514648,
                "spectral_norm": 0.9407561421394348,
                "num_singular_values": 8,
                "alpha": 1.2078643507729323
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.009282762184739113,
                "median": -0.031402722001075745,
                "std": 0.23386135697364807,
                "max": 0.4807436168193817,
                "min": -0.37705305218696594,
                "frobenius_norm": 1.8723641633987427,
                "spectral_norm": 1.1671161651611328,
                "num_singular_values": 8,
                "alpha": 1.2397855730754945
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03268157318234444,
                "median": 0.01666947454214096,
                "std": 0.1918112337589264,
                "max": 0.39693376421928406,
                "min": -0.2713729441165924,
                "frobenius_norm": 1.5566041469573975,
                "spectral_norm": 0.8349224925041199,
                "num_singular_values": 8,
                "alpha": 1.2402115728108045
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_0.0001_batch_size_256_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 256,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "scores": {
            "smape": 0.15108667314052582,
            "mse": 1437203840.0,
            "mae": 3588.4326171875,
            "r2_score": 0.6895442008972168,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.05093926563858986,
                "median": 0.057907767593860626,
                "std": 0.17054446041584015,
                "max": 0.41353148221969604,
                "min": -0.3078767657279968,
                "frobenius_norm": 1.7439326047897339,
                "spectral_norm": 0.9836206436157227,
                "num_singular_values": 8,
                "alpha": 1.443634157078071
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04212399572134018,
                "median": 0.07653570175170898,
                "std": 0.22020433843135834,
                "max": 0.4010508358478546,
                "min": -0.3669185936450958,
                "frobenius_norm": 1.7935775518417358,
                "spectral_norm": 1.0573168992996216,
                "num_singular_values": 8,
                "alpha": 1.183065985214129
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.016427889466285706,
                "median": -0.007826244458556175,
                "std": 0.23320171236991882,
                "max": 0.48295074701309204,
                "min": -0.3981838524341583,
                "frobenius_norm": 1.870237112045288,
                "spectral_norm": 1.1606950759887695,
                "num_singular_values": 8,
                "alpha": 1.3128596284522678
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03161996230483055,
                "median": 0.013566572219133377,
                "std": 0.19274744391441345,
                "max": 0.38839229941368103,
                "min": -0.279965877532959,
                "frobenius_norm": 1.5625905990600586,
                "spectral_norm": 0.8291873931884766,
                "num_singular_values": 8,
                "alpha": 1.2143260899273594
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_5e-05_batch_size_16_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.7050068974494934,
            "mse": 4007761920.0,
            "mae": 9102.1103515625,
            "r2_score": 0.1342681646347046,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.03634326159954071,
                "median": 0.029909620061516762,
                "std": 0.15899233520030975,
                "max": 0.3340179920196533,
                "min": -0.2770825922489166,
                "frobenius_norm": 1.5979804992675781,
                "spectral_norm": 0.8546921610832214,
                "num_singular_values": 8,
                "alpha": 1.666213487045044
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03899349272251129,
                "median": 0.07691699266433716,
                "std": 0.2200596183538437,
                "max": 0.4044882655143738,
                "min": -0.32004696130752563,
                "frobenius_norm": 1.7879011631011963,
                "spectral_norm": 1.1109429597854614,
                "num_singular_values": 8,
                "alpha": 1.1320696206432765
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02957789972424507,
                "median": 0.004810751415789127,
                "std": 0.22426950931549072,
                "max": 0.4036995470523834,
                "min": -0.30519065260887146,
                "frobenius_norm": 1.8096925020217896,
                "spectral_norm": 1.1599780321121216,
                "num_singular_values": 8,
                "alpha": 1.316936475218728
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05135402828454971,
                "median": 0.03811580315232277,
                "std": 0.19437400996685028,
                "max": 0.3969898521900177,
                "min": -0.2641189396381378,
                "frobenius_norm": 1.60834801197052,
                "spectral_norm": 0.8899668455123901,
                "num_singular_values": 8,
                "alpha": 1.2446969807979835
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_5e-05_batch_size_16_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 320
        },
        "scores": {
            "smape": 0.08023963123559952,
            "mse": 595870912.0,
            "mae": 2154.237060546875,
            "r2_score": 0.8712836503982544,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.00855789054185152,
                "median": 0.0332803912460804,
                "std": 0.15486840903759003,
                "max": 0.2924421429634094,
                "min": -0.28278234601020813,
                "frobenius_norm": 1.5197093486785889,
                "spectral_norm": 0.8233758807182312,
                "num_singular_values": 8,
                "alpha": 1.5222132733630467
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.010629495605826378,
                "median": 0.046587198972702026,
                "std": 0.21104784309864044,
                "max": 0.35559895634651184,
                "min": -0.37546804547309875,
                "frobenius_norm": 1.6905227899551392,
                "spectral_norm": 0.9791273474693298,
                "num_singular_values": 8,
                "alpha": 1.1243476703366182
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.012045287527143955,
                "median": -0.01066778413951397,
                "std": 0.22299960255622864,
                "max": 0.4001467823982239,
                "min": -0.31056278944015503,
                "frobenius_norm": 1.7865973711013794,
                "spectral_norm": 1.1570621728897095,
                "num_singular_values": 8,
                "alpha": 1.2753436443249533
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.021452082321047783,
                "median": 0.011012254282832146,
                "std": 0.19251182675361633,
                "max": 0.35917961597442627,
                "min": -0.29384753108024597,
                "frobenius_norm": 1.5496269464492798,
                "spectral_norm": 0.8045281171798706,
                "num_singular_values": 8,
                "alpha": 1.1864583235204509
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_5e-05_batch_size_16_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 320
        },
        "scores": {
            "smape": 0.08027476072311401,
            "mse": 623534912.0,
            "mae": 2145.124755859375,
            "r2_score": 0.8653078675270081,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.009708943776786327,
                "median": 0.03324762359261513,
                "std": 0.15503479540348053,
                "max": 0.2904563844203949,
                "min": -0.3108351528644562,
                "frobenius_norm": 1.5220001935958862,
                "spectral_norm": 0.8225891590118408,
                "num_singular_values": 8,
                "alpha": 1.506162311232914
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.021909743547439575,
                "median": 0.061674587428569794,
                "std": 0.20591223239898682,
                "max": 0.3549700081348419,
                "min": -0.3509860932826996,
                "frobenius_norm": 1.6565966606140137,
                "spectral_norm": 0.952736496925354,
                "num_singular_values": 8,
                "alpha": 1.1648914963337729
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.011146300472319126,
                "median": -0.014476098120212555,
                "std": 0.22534705698490143,
                "max": 0.40188273787498474,
                "min": -0.33138108253479004,
                "frobenius_norm": 1.8049805164337158,
                "spectral_norm": 1.1619688272476196,
                "num_singular_values": 8,
                "alpha": 1.278425354837131
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02319973334670067,
                "median": 0.016823098063468933,
                "std": 0.19212929904460907,
                "max": 0.36181414127349854,
                "min": -0.2932310104370117,
                "frobenius_norm": 1.5481994152069092,
                "spectral_norm": 0.8060543537139893,
                "num_singular_values": 8,
                "alpha": 1.1770901587358211
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_5e-05_batch_size_16_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "scores": {
            "smape": 0.1799613982439041,
            "mse": 1420663040.0,
            "mae": 3908.731689453125,
            "r2_score": 0.6931172013282776,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.024361515417695045,
                "median": 0.032367266714572906,
                "std": 0.15991774201393127,
                "max": 0.3212810158729553,
                "min": -0.299307256937027,
                "frobenius_norm": 1.5849443674087524,
                "spectral_norm": 0.8545036315917969,
                "num_singular_values": 8,
                "alpha": 1.451353784926789
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.027895191684365273,
                "median": 0.06551037728786469,
                "std": 0.2146759033203125,
                "max": 0.3833300471305847,
                "min": -0.3281196653842926,
                "frobenius_norm": 1.7318453788757324,
                "spectral_norm": 0.9823379516601562,
                "num_singular_values": 8,
                "alpha": 1.1873375828759725
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.016790200024843216,
                "median": -0.008213276043534279,
                "std": 0.22598952054977417,
                "max": 0.41204822063446045,
                "min": -0.3200106918811798,
                "frobenius_norm": 1.8128989934921265,
                "spectral_norm": 1.1456395387649536,
                "num_singular_values": 8,
                "alpha": 1.2853313553137884
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.023393629118800163,
                "median": 0.011069407686591148,
                "std": 0.19286853075027466,
                "max": 0.368878573179245,
                "min": -0.29419800639152527,
                "frobenius_norm": 1.5542566776275635,
                "spectral_norm": 0.813014030456543,
                "num_singular_values": 8,
                "alpha": 1.1869976746177753
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_5e-05_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.63036048412323,
            "mse": 3750976768.0,
            "mae": 8479.466796875,
            "r2_score": 0.18973731994628906,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.042020153254270554,
                "median": 0.033878207206726074,
                "std": 0.159382626414299,
                "max": 0.34147119522094727,
                "min": -0.27194222807884216,
                "frobenius_norm": 1.6149852275848389,
                "spectral_norm": 0.8583467602729797,
                "num_singular_values": 8,
                "alpha": 1.679970062810817
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04677142947912216,
                "median": 0.08172742277383804,
                "std": 0.2208462506532669,
                "max": 0.4195996820926666,
                "min": -0.31254076957702637,
                "frobenius_norm": 1.8059569597244263,
                "spectral_norm": 1.1465046405792236,
                "num_singular_values": 8,
                "alpha": 1.0996275906911492
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.034228965640068054,
                "median": 0.004351082257926464,
                "std": 0.22601179778575897,
                "max": 0.41314035654067993,
                "min": -0.3050355315208435,
                "frobenius_norm": 1.8287123441696167,
                "spectral_norm": 1.1704463958740234,
                "num_singular_values": 8,
                "alpha": 1.3099771249680836
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.057219456881284714,
                "median": 0.04613418132066727,
                "std": 0.19445860385894775,
                "max": 0.4043603241443634,
                "min": -0.2613316774368286,
                "frobenius_norm": 1.6216181516647339,
                "spectral_norm": 0.9141302704811096,
                "num_singular_values": 8,
                "alpha": 1.2695669242640655
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_5e-05_batch_size_32_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 320
        },
        "scores": {
            "smape": 0.08019799739122391,
            "mse": 596487936.0,
            "mae": 2154.26220703125,
            "r2_score": 0.8711503744125366,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.008705814369022846,
                "median": 0.03554551303386688,
                "std": 0.15501442551612854,
                "max": 0.2911493480205536,
                "min": -0.28720715641975403,
                "frobenius_norm": 1.5212184190750122,
                "spectral_norm": 0.8242996335029602,
                "num_singular_values": 8,
                "alpha": 1.5349515659458794
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01054166816174984,
                "median": 0.04573449492454529,
                "std": 0.2114182710647583,
                "max": 0.35632243752479553,
                "min": -0.37945228815078735,
                "frobenius_norm": 1.693447470664978,
                "spectral_norm": 0.9783772230148315,
                "num_singular_values": 8,
                "alpha": 1.1139759751569234
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.011613203212618828,
                "median": -0.01203112117946148,
                "std": 0.22330895066261292,
                "max": 0.40139642357826233,
                "min": -0.31060636043548584,
                "frobenius_norm": 1.7888855934143066,
                "spectral_norm": 1.1581953763961792,
                "num_singular_values": 8,
                "alpha": 1.2686453420850248
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022710610181093216,
                "median": 0.010968794114887714,
                "std": 0.19240355491638184,
                "max": 0.3583010733127594,
                "min": -0.29117080569267273,
                "frobenius_norm": 1.5499141216278076,
                "spectral_norm": 0.8039231300354004,
                "num_singular_values": 8,
                "alpha": 1.1870712977222975
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_5e-05_batch_size_32_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 320
        },
        "scores": {
            "smape": 0.08020564913749695,
            "mse": 625436864.0,
            "mae": 2145.31689453125,
            "r2_score": 0.8648970127105713,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.01075790449976921,
                "median": 0.032430507242679596,
                "std": 0.15504314005374908,
                "max": 0.28887835144996643,
                "min": -0.3162507712841034,
                "frobenius_norm": 1.5227588415145874,
                "spectral_norm": 0.8220421075820923,
                "num_singular_values": 8,
                "alpha": 1.5246773232206645
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022387390956282616,
                "median": 0.062093742191791534,
                "std": 0.20556533336639404,
                "max": 0.3556475341320038,
                "min": -0.3557926118373871,
                "frobenius_norm": 1.6542463302612305,
                "spectral_norm": 0.947270393371582,
                "num_singular_values": 8,
                "alpha": 1.170686776219581
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.010553422383964062,
                "median": -0.01628163270652294,
                "std": 0.22593151032924652,
                "max": 0.4038499891757965,
                "min": -0.33387291431427,
                "frobenius_norm": 1.8094228506088257,
                "spectral_norm": 1.162436842918396,
                "num_singular_values": 8,
                "alpha": 1.2801406647935236
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02488739788532257,
                "median": 0.017693357542157173,
                "std": 0.19201058149337769,
                "max": 0.3626331686973572,
                "min": -0.29051023721694946,
                "frobenius_norm": 1.548933982849121,
                "spectral_norm": 0.8069581389427185,
                "num_singular_values": 8,
                "alpha": 1.1771956032715125
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_5e-05_batch_size_32_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "scores": {
            "smape": 0.1789868026971817,
            "mse": 1421022848.0,
            "mae": 3899.36865234375,
            "r2_score": 0.6930394768714905,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.02678159438073635,
                "median": 0.032070085406303406,
                "std": 0.16017259657382965,
                "max": 0.33026471734046936,
                "min": -0.2901543378829956,
                "frobenius_norm": 1.5911507606506348,
                "spectral_norm": 0.8561177253723145,
                "num_singular_values": 8,
                "alpha": 1.447929123607846
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.028740596026182175,
                "median": 0.06634069979190826,
                "std": 0.21500149369239807,
                "max": 0.3775407373905182,
                "min": -0.3333498239517212,
                "frobenius_norm": 1.73531174659729,
                "spectral_norm": 0.977827787399292,
                "num_singular_values": 8,
                "alpha": 1.1841874471424054
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.016439860686659813,
                "median": -0.009541647508740425,
                "std": 0.22606529295444489,
                "max": 0.41205617785453796,
                "min": -0.3150649964809418,
                "frobenius_norm": 1.8132981061935425,
                "spectral_norm": 1.14633309841156,
                "num_singular_values": 8,
                "alpha": 1.2872546039598172
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.024276483803987503,
                "median": 0.011100291274487972,
                "std": 0.19280682504177094,
                "max": 0.36851903796195984,
                "min": -0.2913176119327545,
                "frobenius_norm": 1.5546332597732544,
                "spectral_norm": 0.8130915760993958,
                "num_singular_values": 8,
                "alpha": 1.1924086487375836
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_5e-05_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.5385313034057617,
            "mse": 3375527680.0,
            "mae": 7650.02099609375,
            "r2_score": 0.27083951234817505,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.04947836324572563,
                "median": 0.04146464169025421,
                "std": 0.16000403463840485,
                "max": 0.35107460618019104,
                "min": -0.2703064978122711,
                "frobenius_norm": 1.6409578323364258,
                "spectral_norm": 0.8693821430206299,
                "num_singular_values": 8,
                "alpha": 1.6747991858895792
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05244295671582222,
                "median": 0.08291135728359222,
                "std": 0.2218613624572754,
                "max": 0.42809244990348816,
                "min": -0.3106430172920227,
                "frobenius_norm": 1.8238022327423096,
                "spectral_norm": 1.1774650812149048,
                "num_singular_values": 8,
                "alpha": 1.1069795652601109
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03914227336645126,
                "median": 0.004137047566473484,
                "std": 0.22770321369171143,
                "max": 0.4216838479042053,
                "min": -0.30444273352622986,
                "frobenius_norm": 1.8483439683914185,
                "spectral_norm": 1.1871024370193481,
                "num_singular_values": 8,
                "alpha": 1.3057339067499465
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06624561548233032,
                "median": 0.05360231548547745,
                "std": 0.1945178508758545,
                "max": 0.40572473406791687,
                "min": -0.26220083236694336,
                "frobenius_norm": 1.6439108848571777,
                "spectral_norm": 0.9522961974143982,
                "num_singular_values": 8,
                "alpha": 1.2713456714492655
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_5e-05_batch_size_64_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 64,
            "scaler_type": "standard",
            "total_params": 320
        },
        "scores": {
            "smape": 0.08017507940530777,
            "mse": 596747968.0,
            "mae": 2154.13525390625,
            "r2_score": 0.8710942268371582,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.008585002273321152,
                "median": 0.035988785326480865,
                "std": 0.15510618686676025,
                "max": 0.2923533022403717,
                "min": -0.28795796632766724,
                "frobenius_norm": 1.522050142288208,
                "spectral_norm": 0.8220118284225464,
                "num_singular_values": 8,
                "alpha": 1.5320987708430143
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.00973888672888279,
                "median": 0.04088681936264038,
                "std": 0.21096603572368622,
                "max": 0.3571091294288635,
                "min": -0.38311561942100525,
                "frobenius_norm": 1.6895256042480469,
                "spectral_norm": 0.9730048775672913,
                "num_singular_values": 8,
                "alpha": 1.0932060729463884
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.011676982045173645,
                "median": -0.012262720614671707,
                "std": 0.22347040474414825,
                "max": 0.4024326503276825,
                "min": -0.30961376428604126,
                "frobenius_norm": 1.790202260017395,
                "spectral_norm": 1.15862238407135,
                "num_singular_values": 8,
                "alpha": 1.2660976386181435
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.023118680343031883,
                "median": 0.0106160007417202,
                "std": 0.19250139594078064,
                "max": 0.3610017001628876,
                "min": -0.29059121012687683,
                "frobenius_norm": 1.5510773658752441,
                "spectral_norm": 0.8076675534248352,
                "num_singular_values": 8,
                "alpha": 1.1906491781202584
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_5e-05_batch_size_64_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 64,
            "scaler_type": "robust",
            "total_params": 320
        },
        "scores": {
            "smape": 0.08018144965171814,
            "mse": 626343232.0,
            "mae": 2145.55224609375,
            "r2_score": 0.8647012710571289,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.0109836021438241,
                "median": 0.03156277909874916,
                "std": 0.15512843430042267,
                "max": 0.28979775309562683,
                "min": -0.3179427683353424,
                "frobenius_norm": 1.5237469673156738,
                "spectral_norm": 0.8208464980125427,
                "num_singular_values": 8,
                "alpha": 1.5316871225423978
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022579127922654152,
                "median": 0.06170812249183655,
                "std": 0.20515963435173035,
                "max": 0.3563513159751892,
                "min": -0.36155959963798523,
                "frobenius_norm": 1.6511871814727783,
                "spectral_norm": 0.9451553821563721,
                "num_singular_values": 8,
                "alpha": 1.173655785586238
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.010424153879284859,
                "median": -0.016830336302518845,
                "std": 0.2260887622833252,
                "max": 0.4048593044281006,
                "min": -0.3346998691558838,
                "frobenius_norm": 1.8106316328048706,
                "spectral_norm": 1.162092924118042,
                "num_singular_values": 8,
                "alpha": 1.2757607532831015
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.025033418089151382,
                "median": 0.018066320568323135,
                "std": 0.19204455614089966,
                "max": 0.3640519380569458,
                "min": -0.2888895571231842,
                "frobenius_norm": 1.549354076385498,
                "spectral_norm": 0.8089473247528076,
                "num_singular_values": 8,
                "alpha": 1.180319134139865
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_5e-05_batch_size_64_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 64,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "scores": {
            "smape": 0.17880992591381073,
            "mse": 1421211136.0,
            "mae": 3897.23046875,
            "r2_score": 0.6929987668991089,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.025485126301646233,
                "median": 0.032944291830062866,
                "std": 0.16033530235290527,
                "max": 0.33176010847091675,
                "min": -0.3018311560153961,
                "frobenius_norm": 1.5906798839569092,
                "spectral_norm": 0.8567445874214172,
                "num_singular_values": 8,
                "alpha": 1.4529649254783235
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.029174964874982834,
                "median": 0.0668589174747467,
                "std": 0.21529915928840637,
                "max": 0.39122819900512695,
                "min": -0.33145755529403687,
                "frobenius_norm": 1.7381352186203003,
                "spectral_norm": 0.9866334199905396,
                "num_singular_values": 8,
                "alpha": 1.1883010585702818
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01662355288863182,
                "median": -0.009175695478916168,
                "std": 0.22655309736728668,
                "max": 0.41242554783821106,
                "min": -0.32552263140678406,
                "frobenius_norm": 1.8172972202301025,
                "spectral_norm": 1.1461067199707031,
                "num_singular_values": 8,
                "alpha": 1.2969090726803176
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.024746501818299294,
                "median": 0.010767708532512188,
                "std": 0.19284585118293762,
                "max": 0.36700358986854553,
                "min": -0.29016101360321045,
                "frobenius_norm": 1.5554171800613403,
                "spectral_norm": 0.81354820728302,
                "num_singular_values": 8,
                "alpha": 1.1850455962850193
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_5e-05_batch_size_128_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 128,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.5111832022666931,
            "mse": 3231850496.0,
            "mae": 7373.4150390625,
            "r2_score": 0.3018757104873657,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.051777392625808716,
                "median": 0.04430735856294632,
                "std": 0.16022132337093353,
                "max": 0.3538684546947479,
                "min": -0.27077269554138184,
                "frobenius_norm": 1.6497788429260254,
                "spectral_norm": 0.8748775720596313,
                "num_singular_values": 8,
                "alpha": 1.669276129723599
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.051963791251182556,
                "median": 0.08257080614566803,
                "std": 0.22332994639873505,
                "max": 0.43135109543800354,
                "min": -0.3117055594921112,
                "frobenius_norm": 1.8343652486801147,
                "spectral_norm": 1.1896275281906128,
                "num_singular_values": 8,
                "alpha": 1.1027565356108318
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04060109704732895,
                "median": 0.004012268967926502,
                "std": 0.2287505716085434,
                "max": 0.4233112633228302,
                "min": -0.30457910895347595,
                "frobenius_norm": 1.858606219291687,
                "spectral_norm": 1.1918506622314453,
                "num_singular_values": 8,
                "alpha": 1.307125423025799
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06940744072198868,
                "median": 0.05317911505699158,
                "std": 0.1942262202501297,
                "max": 0.4019295573234558,
                "min": -0.2620994746685028,
                "frobenius_norm": 1.6500416994094849,
                "spectral_norm": 0.9619178175926208,
                "num_singular_values": 8,
                "alpha": 1.2660143888782445
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_5e-05_batch_size_128_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 128,
            "scaler_type": "standard",
            "total_params": 320
        },
        "scores": {
            "smape": 0.08018818497657776,
            "mse": 597007744.0,
            "mae": 2155.16259765625,
            "r2_score": 0.8710380792617798,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.009086762554943562,
                "median": 0.036671556532382965,
                "std": 0.15508803725242615,
                "max": 0.2936861217021942,
                "min": -0.28791344165802,
                "frobenius_norm": 1.522152304649353,
                "spectral_norm": 0.8222230076789856,
                "num_singular_values": 8,
                "alpha": 1.5409136465272875
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.011221109889447689,
                "median": 0.05278998613357544,
                "std": 0.21087795495986938,
                "max": 0.35538846254348755,
                "min": -0.38393357396125793,
                "frobenius_norm": 1.6894102096557617,
                "spectral_norm": 0.9745357632637024,
                "num_singular_values": 8,
                "alpha": 1.072300932345142
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0108938068151474,
                "median": -0.012176483869552612,
                "std": 0.2236870974302292,
                "max": 0.4024620056152344,
                "min": -0.3104419708251953,
                "frobenius_norm": 1.7916176319122314,
                "spectral_norm": 1.1583410501480103,
                "num_singular_values": 8,
                "alpha": 1.2591968113240255
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02255578711628914,
                "median": 0.011723959818482399,
                "std": 0.19241556525230408,
                "max": 0.35877975821495056,
                "min": -0.29197052121162415,
                "frobenius_norm": 1.5498648881912231,
                "spectral_norm": 0.8045341372489929,
                "num_singular_values": 8,
                "alpha": 1.184519448771892
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_5e-05_batch_size_128_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 128,
            "scaler_type": "robust",
            "total_params": 320
        },
        "scores": {
            "smape": 0.08018360286951065,
            "mse": 626933952.0,
            "mae": 2146.60302734375,
            "r2_score": 0.86457359790802,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.011758782900869846,
                "median": 0.031833305954933167,
                "std": 0.15522010624408722,
                "max": 0.29130974411964417,
                "min": -0.319963276386261,
                "frobenius_norm": 1.525197982788086,
                "spectral_norm": 0.8202536702156067,
                "num_singular_values": 8,
                "alpha": 1.5324239985055421
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.023428363725543022,
                "median": 0.06339849531650543,
                "std": 0.20480090379714966,
                "max": 0.3547455072402954,
                "min": -0.36097410321235657,
                "frobenius_norm": 1.649092674255371,
                "spectral_norm": 0.942950427532196,
                "num_singular_values": 8,
                "alpha": 1.1689252345946657
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.010118367150425911,
                "median": -0.0169038325548172,
                "std": 0.2261057049036026,
                "max": 0.4050021171569824,
                "min": -0.3337785005569458,
                "frobenius_norm": 1.810655951499939,
                "spectral_norm": 1.1604962348937988,
                "num_singular_values": 8,
                "alpha": 1.275560255225691
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.024665702134370804,
                "median": 0.019908614456653595,
                "std": 0.1918652206659317,
                "max": 0.3623686730861664,
                "min": -0.2891431450843811,
                "frobenius_norm": 1.547553539276123,
                "spectral_norm": 0.8057743906974792,
                "num_singular_values": 8,
                "alpha": 1.1686862474225024
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_5e-05_batch_size_128_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 128,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "scores": {
            "smape": 0.17898139357566833,
            "mse": 1425227776.0,
            "mae": 3901.489013671875,
            "r2_score": 0.6921311616897583,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.027936413884162903,
                "median": 0.032427169382572174,
                "std": 0.16031228005886078,
                "max": 0.33666151762008667,
                "min": -0.2877863049507141,
                "frobenius_norm": 1.5944044589996338,
                "spectral_norm": 0.8577485084533691,
                "num_singular_values": 8,
                "alpha": 1.4482581751228538
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.029382597655057907,
                "median": 0.06866612285375595,
                "std": 0.21509917080402374,
                "max": 0.38179048895835876,
                "min": -0.3290794789791107,
                "frobenius_norm": 1.7367738485336304,
                "spectral_norm": 0.9804598093032837,
                "num_singular_values": 8,
                "alpha": 1.1946929383302762
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.015590762719511986,
                "median": -0.009023793041706085,
                "std": 0.2265203595161438,
                "max": 0.4120705723762512,
                "min": -0.318403035402298,
                "frobenius_norm": 1.8164499998092651,
                "spectral_norm": 1.1489357948303223,
                "num_singular_values": 8,
                "alpha": 1.2808296151057788
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.023833923041820526,
                "median": 0.011809500865638256,
                "std": 0.19281134009361267,
                "max": 0.3670998215675354,
                "min": -0.2919146418571472,
                "frobenius_norm": 1.5542306900024414,
                "spectral_norm": 0.8119618892669678,
                "num_singular_values": 8,
                "alpha": 1.1886790400493723
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_5e-05_batch_size_256_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 256,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.49807387590408325,
            "mse": 3185797888.0,
            "mae": 7254.775390625,
            "r2_score": 0.3118237853050232,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.05229966714978218,
                "median": 0.04575416445732117,
                "std": 0.16037960350513458,
                "max": 0.3551620841026306,
                "min": -0.27422115206718445,
                "frobenius_norm": 1.6528339385986328,
                "spectral_norm": 0.8765328526496887,
                "num_singular_values": 8,
                "alpha": 1.6651731535011947
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05303250253200531,
                "median": 0.08240300416946411,
                "std": 0.22351957857608795,
                "max": 0.43366506695747375,
                "min": -0.31173717975616455,
                "frobenius_norm": 1.8377978801727295,
                "spectral_norm": 1.1966532468795776,
                "num_singular_values": 8,
                "alpha": 1.1122306809285532
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0415458157658577,
                "median": 0.003564419923350215,
                "std": 0.22896435856819153,
                "max": 0.42417970299720764,
                "min": -0.30385780334472656,
                "frobenius_norm": 1.861624836921692,
                "spectral_norm": 1.192352056503296,
                "num_singular_values": 8,
                "alpha": 1.3032849105498943
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07027575373649597,
                "median": 0.05392100661993027,
                "std": 0.19428059458732605,
                "max": 0.4032842814922333,
                "min": -0.26265060901641846,
                "frobenius_norm": 1.6528013944625854,
                "spectral_norm": 0.9663160443305969,
                "num_singular_values": 8,
                "alpha": 1.265588436938303
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_5e-05_batch_size_256_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 256,
            "scaler_type": "standard",
            "total_params": 320
        },
        "scores": {
            "smape": 0.08017706871032715,
            "mse": 596838720.0,
            "mae": 2154.736328125,
            "r2_score": 0.8710746169090271,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.008898184634745121,
                "median": 0.036119259893894196,
                "std": 0.1553620547056198,
                "max": 0.2923533320426941,
                "min": -0.28911980986595154,
                "frobenius_norm": 1.5247255563735962,
                "spectral_norm": 0.8239414095878601,
                "num_singular_values": 8,
                "alpha": 1.535052656110948
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.010136913508176804,
                "median": 0.04152235761284828,
                "std": 0.21138623356819153,
                "max": 0.3555667996406555,
                "min": -0.3846760392189026,
                "frobenius_norm": 1.6930330991744995,
                "spectral_norm": 0.9724178910255432,
                "num_singular_values": 8,
                "alpha": 1.0898108763359082
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.011292509734630585,
                "median": -0.011204206384718418,
                "std": 0.223585307598114,
                "max": 0.4023986756801605,
                "min": -0.30996939539909363,
                "frobenius_norm": 1.7909623384475708,
                "spectral_norm": 1.155948519706726,
                "num_singular_values": 8,
                "alpha": 1.265084512129368
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02213614620268345,
                "median": 0.009662332013249397,
                "std": 0.1923152059316635,
                "max": 0.35815611481666565,
                "min": -0.29088419675827026,
                "frobenius_norm": 1.5486798286437988,
                "spectral_norm": 0.8053816556930542,
                "num_singular_values": 8,
                "alpha": 1.1972197067558903
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_5e-05_batch_size_256_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 256,
            "scaler_type": "robust",
            "total_params": 320
        },
        "scores": {
            "smape": 0.08018684387207031,
            "mse": 627199680.0,
            "mae": 2146.76123046875,
            "r2_score": 0.8645162582397461,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.011549554765224457,
                "median": 0.03252696245908737,
                "std": 0.15510985255241394,
                "max": 0.2898979187011719,
                "min": -0.31901463866233826,
                "frobenius_norm": 1.5239671468734741,
                "spectral_norm": 0.8208913803100586,
                "num_singular_values": 8,
                "alpha": 1.5257205664783808
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02311214618384838,
                "median": 0.062296874821186066,
                "std": 0.20469914376735687,
                "max": 0.35456937551498413,
                "min": -0.3594018816947937,
                "frobenius_norm": 1.647998332977295,
                "spectral_norm": 0.9375102519989014,
                "num_singular_values": 8,
                "alpha": 1.1707123593944413
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.010170078836381435,
                "median": -0.015541737899184227,
                "std": 0.2260279804468155,
                "max": 0.4043534994125366,
                "min": -0.3343532085418701,
                "frobenius_norm": 1.8100533485412598,
                "spectral_norm": 1.1607898473739624,
                "num_singular_values": 8,
                "alpha": 1.2701867542285143
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.023605575785040855,
                "median": 0.015945881605148315,
                "std": 0.19172020256519318,
                "max": 0.3586178421974182,
                "min": -0.29020678997039795,
                "frobenius_norm": 1.5453436374664307,
                "spectral_norm": 0.8042000532150269,
                "num_singular_values": 8,
                "alpha": 1.1870443544159597
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_learning_rate_5e-05_batch_size_256_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 256,
            "scaler_type": "minmax",
            "total_params": 320
        },
        "scores": {
            "smape": 0.1788526326417923,
            "mse": 1420813824.0,
            "mae": 3897.72119140625,
            "r2_score": 0.6930846571922302,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.027106529101729393,
                "median": 0.03199491649866104,
                "std": 0.160498708486557,
                "max": 0.3373412787914276,
                "min": -0.28920406103134155,
                "frobenius_norm": 1.5948296785354614,
                "spectral_norm": 0.8575118184089661,
                "num_singular_values": 8,
                "alpha": 1.4606397019491233
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.028827743604779243,
                "median": 0.0674801766872406,
                "std": 0.21471700072288513,
                "max": 0.382610946893692,
                "min": -0.32406458258628845,
                "frobenius_norm": 1.733148455619812,
                "spectral_norm": 0.9746359586715698,
                "num_singular_values": 8,
                "alpha": 1.1852369439478438
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.015964005142450333,
                "median": -0.008609890937805176,
                "std": 0.2260591685771942,
                "max": 0.41222459077835083,
                "min": -0.3118302524089813,
                "frobenius_norm": 1.8129771947860718,
                "spectral_norm": 1.1451085805892944,
                "num_singular_values": 8,
                "alpha": 1.2764763214844235
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02370653674006462,
                "median": 0.00978610198944807,
                "std": 0.1927241086959839,
                "max": 0.3687385022640228,
                "min": -0.29106196761131287,
                "frobenius_norm": 1.5534133911132812,
                "spectral_norm": 0.8148459792137146,
                "num_singular_values": 8,
                "alpha": 1.2021469547946433
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.01_batch_size_16_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.081525519490242,
            "mse": 487203136.0,
            "mae": 1999.239013671875,
            "r2_score": 0.8947573900222778,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": -0.003929073456674814,
                "median": -0.012469304725527763,
                "std": 0.22087138891220093,
                "max": 0.8346973061561584,
                "min": -0.7112547755241394,
                "frobenius_norm": 3.0609681606292725,
                "spectral_norm": 1.749468207359314,
                "num_singular_values": 12,
                "alpha": 1.289643087084137
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.01705852895975113,
                "median": -0.01696613058447838,
                "std": 0.32982146739959717,
                "max": 1.2603486776351929,
                "min": -2.8512768745422363,
                "frobenius_norm": 5.284196853637695,
                "spectral_norm": 4.345911502838135,
                "num_singular_values": 16,
                "alpha": 1.1869194040376168
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.015611570328474045,
                "median": -0.025587892159819603,
                "std": 0.1787693202495575,
                "max": 0.511624813079834,
                "min": -0.33214300870895386,
                "frobenius_norm": 2.871195077896118,
                "spectral_norm": 1.5729398727416992,
                "num_singular_values": 16,
                "alpha": 1.2277514453797072
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.07034137845039368,
                "median": 0.06290408968925476,
                "std": 0.14548936486244202,
                "max": 0.395524799823761,
                "min": -0.25155743956565857,
                "frobenius_norm": 1.828312873840332,
                "spectral_norm": 1.1328084468841553,
                "num_singular_values": 8,
                "alpha": 1.6476875039933998
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.01_batch_size_16_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07071933150291443,
            "mse": 410710592.0,
            "mae": 1952.4842529296875,
            "r2_score": 0.9112808704376221,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.12160288542509079,
                "median": 0.12677988409996033,
                "std": 0.3367125391960144,
                "max": 1.181929349899292,
                "min": -0.8004282712936401,
                "frobenius_norm": 4.960566520690918,
                "spectral_norm": 2.7987494468688965,
                "num_singular_values": 12,
                "alpha": 1.443975850181727
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.03683691471815109,
                "median": -0.050855230540037155,
                "std": 0.42536845803260803,
                "max": 1.348629117012024,
                "min": -1.223362684249878,
                "frobenius_norm": 6.8313679695129395,
                "spectral_norm": 3.9792234897613525,
                "num_singular_values": 16,
                "alpha": 1.2123452024317716
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.04941406473517418,
                "median": -0.07334351539611816,
                "std": 0.2980838119983673,
                "max": 1.175183892250061,
                "min": -0.9598768353462219,
                "frobenius_norm": 4.834428787231445,
                "spectral_norm": 2.52097749710083,
                "num_singular_values": 16,
                "alpha": 1.1487559039652269
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.01237895991653204,
                "median": 0.037391237914562225,
                "std": 0.181487038731575,
                "max": 0.4115138351917267,
                "min": -0.47573959827423096,
                "frobenius_norm": 2.0580623149871826,
                "spectral_norm": 1.433281660079956,
                "num_singular_values": 8,
                "alpha": 1.4936263255376743
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.01_batch_size_16_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07226555049419403,
            "mse": 519588096.0,
            "mae": 2083.888916015625,
            "r2_score": 0.8877618312835693,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.1612979620695114,
                "median": 0.10483002662658691,
                "std": 0.3709830045700073,
                "max": 1.8339565992355347,
                "min": -0.6621067523956299,
                "frobenius_norm": 5.605347633361816,
                "spectral_norm": 3.607774019241333,
                "num_singular_values": 12,
                "alpha": 1.3588219706950815
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.08438360691070557,
                "median": -0.011742588132619858,
                "std": 0.5022874474525452,
                "max": 1.0880941152572632,
                "min": -2.1658356189727783,
                "frobenius_norm": 8.149221420288086,
                "spectral_norm": 5.249898910522461,
                "num_singular_values": 16,
                "alpha": 1.1353257308407483
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.08426230400800705,
                "median": -0.10840705037117004,
                "std": 0.31112778186798096,
                "max": 1.392909049987793,
                "min": -0.9143329858779907,
                "frobenius_norm": 5.157379627227783,
                "spectral_norm": 2.8434510231018066,
                "num_singular_values": 16,
                "alpha": 1.2105153109590947
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.01777387410402298,
                "median": 0.011877944692969322,
                "std": 0.19086390733718872,
                "max": 0.4134431779384613,
                "min": -0.7868478298187256,
                "frobenius_norm": 2.1687214374542236,
                "spectral_norm": 1.4212241172790527,
                "num_singular_values": 8,
                "alpha": 1.4790406581671298
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.01_batch_size_16_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07365702837705612,
            "mse": 445630464.0,
            "mae": 2061.490966796875,
            "r2_score": 0.9037376642227173,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.051883310079574585,
                "median": 0.011383096687495708,
                "std": 0.2731992304325104,
                "max": 1.0710493326187134,
                "min": -0.9743006825447083,
                "frobenius_norm": 3.853219747543335,
                "spectral_norm": 2.7324206829071045,
                "num_singular_values": 12,
                "alpha": 1.286528966860755
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.09885765612125397,
                "median": -0.08680630475282669,
                "std": 0.30404600501060486,
                "max": 1.0997787714004517,
                "min": -1.5323160886764526,
                "frobenius_norm": 5.115418434143066,
                "spectral_norm": 3.259281873703003,
                "num_singular_values": 16,
                "alpha": 1.2652447158784679
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.08476550877094269,
                "median": -0.07771976292133331,
                "std": 0.34921324253082275,
                "max": 1.3409487009048462,
                "min": -3.171863555908203,
                "frobenius_norm": 5.749659538269043,
                "spectral_norm": 3.955577850341797,
                "num_singular_values": 16,
                "alpha": 1.0850357317653312
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.09249910712242126,
                "median": 0.0511215403676033,
                "std": 0.34844839572906494,
                "max": 1.9531915187835693,
                "min": -0.36837509274482727,
                "frobenius_norm": 4.078782081604004,
                "spectral_norm": 3.8416025638580322,
                "num_singular_values": 8,
                "alpha": 1.5055775910023628
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.01_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.08154130727052689,
            "mse": 477269888.0,
            "mae": 2037.6456298828125,
            "r2_score": 0.8969031572341919,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": -0.020693108439445496,
                "median": -0.00499858008697629,
                "std": 0.253413587808609,
                "max": 0.6516200304031372,
                "min": -1.0516804456710815,
                "frobenius_norm": 3.5230891704559326,
                "spectral_norm": 2.158278226852417,
                "num_singular_values": 12,
                "alpha": 1.3707896717176284
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.028982676565647125,
                "median": 0.030232802033424377,
                "std": 0.3335520327091217,
                "max": 2.4689996242523193,
                "min": -2.089970588684082,
                "frobenius_norm": 5.3569416999816895,
                "spectral_norm": 3.9200639724731445,
                "num_singular_values": 16,
                "alpha": 1.2162242707057191
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.024400249123573303,
                "median": -0.011430399492383003,
                "std": 0.2504933476448059,
                "max": 0.4671679437160492,
                "min": -1.6777573823928833,
                "frobenius_norm": 4.026863098144531,
                "spectral_norm": 2.95426344871521,
                "num_singular_values": 16,
                "alpha": 1.0985394338191348
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.07333255559206009,
                "median": 0.06838199496269226,
                "std": 0.14584054052829742,
                "max": 0.3757795989513397,
                "min": -0.2508554458618164,
                "frobenius_norm": 1.8468438386917114,
                "spectral_norm": 1.1788755655288696,
                "num_singular_values": 8,
                "alpha": 1.7799118595680588
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.01_batch_size_32_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07135041803121567,
            "mse": 412291424.0,
            "mae": 1967.29541015625,
            "r2_score": 0.9109393358230591,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.10676350444555283,
                "median": 0.10869579017162323,
                "std": 0.3214893937110901,
                "max": 0.9126797914505005,
                "min": -1.823492407798767,
                "frobenius_norm": 4.693905353546143,
                "spectral_norm": 3.0648386478424072,
                "num_singular_values": 12,
                "alpha": 1.3967634107969096
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.015560261905193329,
                "median": 0.028342531993985176,
                "std": 0.48971205949783325,
                "max": 2.2579784393310547,
                "min": -1.8667259216308594,
                "frobenius_norm": 7.8393473625183105,
                "spectral_norm": 5.034571647644043,
                "num_singular_values": 16,
                "alpha": 1.1569029364334806
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.04729603976011276,
                "median": -0.0794336348772049,
                "std": 0.2823454737663269,
                "max": 1.278557538986206,
                "min": -1.3952873945236206,
                "frobenius_norm": 4.580470085144043,
                "spectral_norm": 2.4345786571502686,
                "num_singular_values": 16,
                "alpha": 1.113851277982994
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.04395707696676254,
                "median": 0.03487883508205414,
                "std": 0.1679125875234604,
                "max": 0.4973854422569275,
                "min": -0.3889806568622589,
                "frobenius_norm": 1.9637306928634644,
                "spectral_norm": 1.1845017671585083,
                "num_singular_values": 8,
                "alpha": 1.6661724945322487
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.01_batch_size_32_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 888
        },
        "scores": {
            "smape": 0.072940394282341,
            "mse": 533140896.0,
            "mae": 2144.66650390625,
            "r2_score": 0.8848342299461365,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.12571074068546295,
                "median": 0.09462086111307144,
                "std": 0.48455721139907837,
                "max": 1.8833271265029907,
                "min": -2.382356882095337,
                "frobenius_norm": 6.936496734619141,
                "spectral_norm": 4.806924819946289,
                "num_singular_values": 12,
                "alpha": 1.325682400071635
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.08494523167610168,
                "median": -0.021484341472387314,
                "std": 0.5682832598686218,
                "max": 1.7537150382995605,
                "min": -2.0426857471466064,
                "frobenius_norm": 9.193549156188965,
                "spectral_norm": 4.7276763916015625,
                "num_singular_values": 16,
                "alpha": 1.1855619334595124
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.08905406296253204,
                "median": -0.08436445891857147,
                "std": 0.26830506324768066,
                "max": 0.9475418329238892,
                "min": -1.031657099723816,
                "frobenius_norm": 4.523170471191406,
                "spectral_norm": 2.7354884147644043,
                "num_singular_values": 16,
                "alpha": 1.1788287595347677
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.030093103647232056,
                "median": 0.040221527218818665,
                "std": 0.17920328676700592,
                "max": 0.4269758462905884,
                "min": -0.45173704624176025,
                "frobenius_norm": 2.0558416843414307,
                "spectral_norm": 1.4931666851043701,
                "num_singular_values": 8,
                "alpha": 1.6079631062682074
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.01_batch_size_32_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07628647983074188,
            "mse": 514585376.0,
            "mae": 2128.50537109375,
            "r2_score": 0.8888424634933472,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.0700760930776596,
                "median": 0.05082235485315323,
                "std": 0.39750343561172485,
                "max": 1.42682945728302,
                "min": -3.1701598167419434,
                "frobenius_norm": 5.5929036140441895,
                "spectral_norm": 4.253091812133789,
                "num_singular_values": 12,
                "alpha": 1.3287945399106262
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.03513985499739647,
                "median": -0.05227915197610855,
                "std": 0.3352428078651428,
                "max": 1.0515799522399902,
                "min": -1.4351108074188232,
                "frobenius_norm": 5.393270492553711,
                "spectral_norm": 3.1940767765045166,
                "num_singular_values": 16,
                "alpha": 1.323027524630175
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.09404800832271576,
                "median": -0.08549247682094574,
                "std": 0.25197646021842957,
                "max": 1.2765527963638306,
                "min": -1.4786161184310913,
                "frobenius_norm": 4.303291320800781,
                "spectral_norm": 2.525995969772339,
                "num_singular_values": 16,
                "alpha": 1.141770249118678
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.04949786514043808,
                "median": 0.06966999173164368,
                "std": 0.15728163719177246,
                "max": 0.40209606289863586,
                "min": -0.34202560782432556,
                "frobenius_norm": 1.8654775619506836,
                "spectral_norm": 1.0632551908493042,
                "num_singular_values": 8,
                "alpha": 1.5472774209920974
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.01_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.11122256517410278,
            "mse": 510642336.0,
            "mae": 2516.202880859375,
            "r2_score": 0.8896942138671875,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": -0.05211092159152031,
                "median": -0.033139150589704514,
                "std": 0.2647538185119629,
                "max": 0.5733895897865295,
                "min": -1.2119863033294678,
                "frobenius_norm": 3.7389230728149414,
                "spectral_norm": 2.4021105766296387,
                "num_singular_values": 12,
                "alpha": 1.410164564552333
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.044104963541030884,
                "median": 0.06427022814750671,
                "std": 0.39413705468177795,
                "max": 3.5744781494140625,
                "min": -3.3692729473114014,
                "frobenius_norm": 6.345553874969482,
                "spectral_norm": 5.305898189544678,
                "num_singular_values": 16,
                "alpha": 1.222227911850177
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.03350479155778885,
                "median": -0.019655417650938034,
                "std": 0.19541716575622559,
                "max": 0.4006863534450531,
                "min": -1.018807291984558,
                "frobenius_norm": 3.172297477722168,
                "spectral_norm": 1.650647759437561,
                "num_singular_values": 16,
                "alpha": 1.1489666806964693
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.06458437442779541,
                "median": 0.053809214383363724,
                "std": 0.14931344985961914,
                "max": 0.3656345307826996,
                "min": -0.3076230585575104,
                "frobenius_norm": 1.8405442237854004,
                "spectral_norm": 1.167998194694519,
                "num_singular_values": 8,
                "alpha": 1.7184257289948035
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.01_batch_size_64_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 64,
            "scaler_type": "standard",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07054920494556427,
            "mse": 495681792.0,
            "mae": 2037.47119140625,
            "r2_score": 0.8929259181022644,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.11933988332748413,
                "median": 0.09911543130874634,
                "std": 0.3376096785068512,
                "max": 1.1816009283065796,
                "min": -1.4312254190444946,
                "frobenius_norm": 4.961721420288086,
                "spectral_norm": 3.034196138381958,
                "num_singular_values": 12,
                "alpha": 1.3513289398181194
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.010670611634850502,
                "median": -0.005956186447292566,
                "std": 0.4987303912639618,
                "max": 1.7224094867706299,
                "min": -1.5595381259918213,
                "frobenius_norm": 7.981512546539307,
                "spectral_norm": 4.0215229988098145,
                "num_singular_values": 16,
                "alpha": 1.1000751423449784
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.046902161091566086,
                "median": -0.07588425278663635,
                "std": 0.32886913418769836,
                "max": 1.3284960985183716,
                "min": -1.0220078229904175,
                "frobenius_norm": 5.315149307250977,
                "spectral_norm": 2.8989417552948,
                "num_singular_values": 16,
                "alpha": 1.2515367877555819
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.036144912242889404,
                "median": 0.044458892196416855,
                "std": 0.1634202003479004,
                "max": 0.4426310956478119,
                "min": -0.4699184000492096,
                "frobenius_norm": 1.8935719728469849,
                "spectral_norm": 1.2391717433929443,
                "num_singular_values": 8,
                "alpha": 1.6145797613046367
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.01_batch_size_64_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 64,
            "scaler_type": "robust",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07243862748146057,
            "mse": 508111808.0,
            "mae": 2016.5,
            "r2_score": 0.8902408480644226,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.10414042323827744,
                "median": 0.09098516404628754,
                "std": 0.40430665016174316,
                "max": 1.984511137008667,
                "min": -1.923707127571106,
                "frobenius_norm": 5.785097122192383,
                "spectral_norm": 3.919565200805664,
                "num_singular_values": 12,
                "alpha": 1.369975577705278
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.08436305820941925,
                "median": -0.06827487796545029,
                "std": 0.5161142945289612,
                "max": 1.6990045309066772,
                "min": -2.7540810108184814,
                "frobenius_norm": 8.367420196533203,
                "spectral_norm": 5.213837146759033,
                "num_singular_values": 16,
                "alpha": 1.1260756598605137
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.07213881611824036,
                "median": -0.07765398919582367,
                "std": 0.2843867838382721,
                "max": 1.0007356405258179,
                "min": -1.2007485628128052,
                "frobenius_norm": 4.694299221038818,
                "spectral_norm": 2.424368381500244,
                "num_singular_values": 16,
                "alpha": 1.1618390934107388
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.027669545263051987,
                "median": 0.047741033136844635,
                "std": 0.18375740945339203,
                "max": 0.4741838574409485,
                "min": -0.5602513551712036,
                "frobenius_norm": 2.10241436958313,
                "spectral_norm": 1.309740662574768,
                "num_singular_values": 8,
                "alpha": 1.5532312458295754
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.01_batch_size_64_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 64,
            "scaler_type": "minmax",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07590994983911514,
            "mse": 506417760.0,
            "mae": 2125.33642578125,
            "r2_score": 0.8906067609786987,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.04870496317744255,
                "median": 0.05272699519991875,
                "std": 0.509354829788208,
                "max": 1.433069109916687,
                "min": -5.026538372039795,
                "frobenius_norm": 7.090020179748535,
                "spectral_norm": 6.051462173461914,
                "num_singular_values": 12,
                "alpha": 1.3343676534608495
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.04200597107410431,
                "median": -0.03798072040081024,
                "std": 0.3958919942378998,
                "max": 2.445230007171631,
                "min": -2.00192928314209,
                "frobenius_norm": 6.369828701019287,
                "spectral_norm": 4.6514153480529785,
                "num_singular_values": 16,
                "alpha": 1.1279001156935688
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.061981428414583206,
                "median": -0.0876961499452591,
                "std": 0.21905583143234253,
                "max": 1.2398879528045654,
                "min": -0.6373975872993469,
                "frobenius_norm": 3.6424925327301025,
                "spectral_norm": 2.0922889709472656,
                "num_singular_values": 16,
                "alpha": 1.1842644177764985
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.0365498922765255,
                "median": 0.009466048330068588,
                "std": 0.1611640602350235,
                "max": 0.49800220131874084,
                "min": -0.34537601470947266,
                "frobenius_norm": 1.8696650266647339,
                "spectral_norm": 1.0108038187026978,
                "num_singular_values": 8,
                "alpha": 1.522884370544832
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.01_batch_size_128_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 128,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.08325055241584778,
            "mse": 450349120.0,
            "mae": 1962.2672119140625,
            "r2_score": 0.9027183651924133,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": -0.013044576160609722,
                "median": -0.013853712007403374,
                "std": 0.24656088650226593,
                "max": 0.5419120788574219,
                "min": -1.0741136074066162,
                "frobenius_norm": 3.4212257862091064,
                "spectral_norm": 1.8299156427383423,
                "num_singular_values": 12,
                "alpha": 1.2530215736795483
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.007981959730386734,
                "median": 0.0328475758433342,
                "std": 0.353007048368454,
                "max": 0.7193071246147156,
                "min": -3.4091532230377197,
                "frobenius_norm": 5.649556636810303,
                "spectral_norm": 4.318943023681641,
                "num_singular_values": 16,
                "alpha": 1.1681709846311368
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.015888342633843422,
                "median": -0.036188118159770966,
                "std": 0.18155241012573242,
                "max": 0.4308597147464752,
                "min": -0.543950617313385,
                "frobenius_norm": 2.915940999984741,
                "spectral_norm": 1.5576562881469727,
                "num_singular_values": 16,
                "alpha": 1.0829045544005251
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.07396115362644196,
                "median": 0.08586911857128143,
                "std": 0.1452450007200241,
                "max": 0.3854467272758484,
                "min": -0.23856951296329498,
                "frobenius_norm": 1.8440430164337158,
                "spectral_norm": 1.201949119567871,
                "num_singular_values": 8,
                "alpha": 1.6430775081027817
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.01_batch_size_128_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 128,
            "scaler_type": "standard",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07119116187095642,
            "mse": 399006016.0,
            "mae": 1947.62158203125,
            "r2_score": 0.9138091802597046,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.1093888059258461,
                "median": 0.09174028038978577,
                "std": 0.3456823229789734,
                "max": 1.2239969968795776,
                "min": -2.0786828994750977,
                "frobenius_norm": 5.024016380310059,
                "spectral_norm": 3.252519130706787,
                "num_singular_values": 12,
                "alpha": 1.35287267766515
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.02181951515376568,
                "median": -0.028400219976902008,
                "std": 0.5130926966667175,
                "max": 1.7343343496322632,
                "min": -1.9120211601257324,
                "frobenius_norm": 8.216902732849121,
                "spectral_norm": 3.8030426502227783,
                "num_singular_values": 16,
                "alpha": 1.1339591789495733
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.040510520339012146,
                "median": -0.05690324679017067,
                "std": 0.3483266830444336,
                "max": 1.543137788772583,
                "min": -1.026794195175171,
                "frobenius_norm": 5.610791206359863,
                "spectral_norm": 3.383268356323242,
                "num_singular_values": 16,
                "alpha": 1.18885673172992
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": -0.01962076500058174,
                "median": -0.00340673653408885,
                "std": 0.227596253156662,
                "max": 0.48234283924102783,
                "min": -0.7853758931159973,
                "frobenius_norm": 2.5845084190368652,
                "spectral_norm": 2.024840831756592,
                "num_singular_values": 8,
                "alpha": 1.4645912332389188
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.01_batch_size_128_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 128,
            "scaler_type": "robust",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07285180687904358,
            "mse": 466944640.0,
            "mae": 1972.937744140625,
            "r2_score": 0.8991335034370422,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.12440267950296402,
                "median": 0.07538868486881256,
                "std": 0.4730757474899292,
                "max": 2.2616379261016846,
                "min": -2.9593944549560547,
                "frobenius_norm": 6.777987957000732,
                "spectral_norm": 4.892289161682129,
                "num_singular_values": 12,
                "alpha": 1.2314315534747686
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.04999489337205887,
                "median": -0.05124169960618019,
                "std": 0.5976713299751282,
                "max": 2.629791259765625,
                "min": -2.5736114978790283,
                "frobenius_norm": 9.596139907836914,
                "spectral_norm": 5.619150161743164,
                "num_singular_values": 16,
                "alpha": 1.2609893664145038
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.12108807265758514,
                "median": -0.14088061451911926,
                "std": 0.2840118408203125,
                "max": 0.8465558290481567,
                "min": -1.3626528978347778,
                "frobenius_norm": 4.939960956573486,
                "spectral_norm": 3.1424360275268555,
                "num_singular_values": 16,
                "alpha": 1.2677874069972006
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.058009810745716095,
                "median": 0.055222682654857635,
                "std": 0.1744428426027298,
                "max": 0.5399484634399414,
                "min": -0.29910174012184143,
                "frobenius_norm": 2.079859733581543,
                "spectral_norm": 1.502084493637085,
                "num_singular_values": 8,
                "alpha": 1.4816436156271677
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.01_batch_size_128_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 128,
            "scaler_type": "minmax",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07439860701560974,
            "mse": 492007008.0,
            "mae": 2141.292724609375,
            "r2_score": 0.8937197327613831,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.0900007113814354,
                "median": 0.07924617826938629,
                "std": 0.414740651845932,
                "max": 2.1097970008850098,
                "min": -2.8767642974853516,
                "frobenius_norm": 5.880570411682129,
                "spectral_norm": 4.496881008148193,
                "num_singular_values": 12,
                "alpha": 1.3103929302909267
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.12521366775035858,
                "median": -0.08889637887477875,
                "std": 0.5280992388725281,
                "max": 1.9486572742462158,
                "min": -3.127443313598633,
                "frobenius_norm": 8.68384838104248,
                "spectral_norm": 4.945339202880859,
                "num_singular_values": 16,
                "alpha": 1.2610186837002613
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.04716167226433754,
                "median": -0.0685637891292572,
                "std": 0.29976895451545715,
                "max": 1.758641004562378,
                "min": -0.699555516242981,
                "frobenius_norm": 4.85529899597168,
                "spectral_norm": 2.7730484008789062,
                "num_singular_values": 16,
                "alpha": 1.2030302303146654
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.04359809681773186,
                "median": 0.032032422721385956,
                "std": 0.17500075697898865,
                "max": 0.5711472034454346,
                "min": -0.4854572117328644,
                "frobenius_norm": 2.0404253005981445,
                "spectral_norm": 1.2001627683639526,
                "num_singular_values": 8,
                "alpha": 1.4490191537428452
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.01_batch_size_256_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 256,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.08025910705327988,
            "mse": 467676992.0,
            "mae": 2010.2705078125,
            "r2_score": 0.8989753127098083,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": -0.028488265350461006,
                "median": -0.025037242099642754,
                "std": 0.2403651624917984,
                "max": 0.5333042144775391,
                "min": -0.933228611946106,
                "frobenius_norm": 3.3539085388183594,
                "spectral_norm": 1.918894648551941,
                "num_singular_values": 12,
                "alpha": 1.1979357792800758
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.006829056888818741,
                "median": 0.042674172669649124,
                "std": 0.42274653911590576,
                "max": 0.8427678346633911,
                "min": -3.5779123306274414,
                "frobenius_norm": 6.764827251434326,
                "spectral_norm": 5.938051223754883,
                "num_singular_values": 16,
                "alpha": 1.1010879816069148
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.020215753465890884,
                "median": -0.02286725491285324,
                "std": 0.1814691424369812,
                "max": 0.42876556515693665,
                "min": -0.5268072485923767,
                "frobenius_norm": 2.9214670658111572,
                "spectral_norm": 1.5085461139678955,
                "num_singular_values": 16,
                "alpha": 1.181766480713708
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.0807383805513382,
                "median": 0.08667220175266266,
                "std": 0.1576199233531952,
                "max": 0.500042736530304,
                "min": -0.25620824098587036,
                "frobenius_norm": 2.003603935241699,
                "spectral_norm": 1.3145314455032349,
                "num_singular_values": 8,
                "alpha": 1.6416640593039293
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.01_batch_size_256_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 256,
            "scaler_type": "standard",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07368358969688416,
            "mse": 532194528.0,
            "mae": 2161.458984375,
            "r2_score": 0.8850386142730713,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.09733297675848007,
                "median": 0.06106171756982803,
                "std": 0.3795468807220459,
                "max": 1.2155054807662964,
                "min": -1.7454107999801636,
                "frobenius_norm": 5.4293341636657715,
                "spectral_norm": 3.101864814758301,
                "num_singular_values": 12,
                "alpha": 1.292917991097208
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.0343882255256176,
                "median": -0.05113961547613144,
                "std": 0.5033692717552185,
                "max": 1.6832493543624878,
                "min": -1.6955310106277466,
                "frobenius_norm": 8.072680473327637,
                "spectral_norm": 4.119678974151611,
                "num_singular_values": 16,
                "alpha": 1.1665364368025455
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.09337027370929718,
                "median": -0.08500412106513977,
                "std": 0.3283681571483612,
                "max": 0.9082310199737549,
                "min": -1.3706154823303223,
                "frobenius_norm": 5.462158679962158,
                "spectral_norm": 3.0936498641967773,
                "num_singular_values": 16,
                "alpha": 1.1990710388330832
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.02955477498471737,
                "median": 0.021755561232566833,
                "std": 0.22096757590770721,
                "max": 0.5221009850502014,
                "min": -0.611663281917572,
                "frobenius_norm": 2.5222249031066895,
                "spectral_norm": 1.5602854490280151,
                "num_singular_values": 8,
                "alpha": 1.4449089368220618
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.01_batch_size_256_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 256,
            "scaler_type": "robust",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07258278131484985,
            "mse": 510012896.0,
            "mae": 2160.415283203125,
            "r2_score": 0.8898301720619202,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.10335952788591385,
                "median": 0.08074275404214859,
                "std": 0.3912445306777954,
                "max": 1.5178511142730713,
                "min": -2.0411834716796875,
                "frobenius_norm": 5.607231616973877,
                "spectral_norm": 3.569788932800293,
                "num_singular_values": 12,
                "alpha": 1.3154959391250818
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.04202857241034508,
                "median": -0.001615534769371152,
                "std": 0.5241617560386658,
                "max": 2.173955202102661,
                "min": -2.4863479137420654,
                "frobenius_norm": 8.413504600524902,
                "spectral_norm": 4.31165075302124,
                "num_singular_values": 16,
                "alpha": 1.3086646510474442
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.11599253118038177,
                "median": -0.0987059623003006,
                "std": 0.3067428171634674,
                "max": 0.9424163699150085,
                "min": -1.5240733623504639,
                "frobenius_norm": 5.247058868408203,
                "spectral_norm": 2.9760007858276367,
                "num_singular_values": 16,
                "alpha": 1.1460280391896107
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.010311455465853214,
                "median": 0.002202793722972274,
                "std": 0.17322206497192383,
                "max": 0.48666802048683167,
                "min": -0.3614772856235504,
                "frobenius_norm": 1.9632530212402344,
                "spectral_norm": 1.0924488306045532,
                "num_singular_values": 8,
                "alpha": 1.6717252547398858
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.01_batch_size_256_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 256,
            "scaler_type": "minmax",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07749442756175995,
            "mse": 405225344.0,
            "mae": 2064.45703125,
            "r2_score": 0.9124657511711121,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.03679114207625389,
                "median": 0.0360286720097065,
                "std": 0.40588459372520447,
                "max": 1.4784725904464722,
                "min": -2.4723551273345947,
                "frobenius_norm": 5.647160053253174,
                "spectral_norm": 4.683048725128174,
                "num_singular_values": 12,
                "alpha": 1.306952848884563
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.040900759398937225,
                "median": -0.050512008368968964,
                "std": 0.39736858010292053,
                "max": 1.8523727655410767,
                "min": -2.0025007724761963,
                "frobenius_norm": 6.3914875984191895,
                "spectral_norm": 4.093475341796875,
                "num_singular_values": 16,
                "alpha": 1.1366348019925874
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.08599505573511124,
                "median": -0.07354514300823212,
                "std": 0.2492591142654419,
                "max": 0.8440079092979431,
                "min": -0.9356820583343506,
                "frobenius_norm": 4.218822956085205,
                "spectral_norm": 2.3498494625091553,
                "num_singular_values": 16,
                "alpha": 1.1574231894263525
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.012850415892899036,
                "median": 0.02482389658689499,
                "std": 0.18673236668109894,
                "max": 0.5110421180725098,
                "min": -0.6860175132751465,
                "frobenius_norm": 2.1176321506500244,
                "spectral_norm": 1.3734253644943237,
                "num_singular_values": 8,
                "alpha": 1.4881598354649452
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.005_batch_size_16_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.0813741609454155,
            "mse": 487351776.0,
            "mae": 2018.4449462890625,
            "r2_score": 0.8947253227233887,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.016521992161870003,
                "median": -0.0018285239348188043,
                "std": 0.20197032392024994,
                "max": 0.6187797784805298,
                "min": -0.669899046421051,
                "frobenius_norm": 2.8079311847686768,
                "spectral_norm": 1.5117019414901733,
                "num_singular_values": 12,
                "alpha": 1.389911861564315
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.05730412155389786,
                "median": 0.04761822521686554,
                "std": 0.27694782614707947,
                "max": 2.703155040740967,
                "min": -1.452391266822815,
                "frobenius_norm": 4.525026798248291,
                "spectral_norm": 3.225360155105591,
                "num_singular_values": 16,
                "alpha": 1.158282963978491
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.009597991593182087,
                "median": -0.010186037980020046,
                "std": 0.18600501120090485,
                "max": 0.6883394718170166,
                "min": -0.45619654655456543,
                "frobenius_norm": 2.980039596557617,
                "spectral_norm": 1.6077266931533813,
                "num_singular_values": 16,
                "alpha": 1.3538139766781625
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.05198192223906517,
                "median": 0.03687702491879463,
                "std": 0.14887785911560059,
                "max": 0.4011182487010956,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.7840802669525146,
                "spectral_norm": 1.054147481918335,
                "num_singular_values": 8,
                "alpha": 1.5495826548917289
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.005_batch_size_16_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07089053839445114,
            "mse": 335706784.0,
            "mae": 1866.2650146484375,
            "r2_score": 0.9274827241897583,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.0867646113038063,
                "median": 0.05563746765255928,
                "std": 0.3366016447544098,
                "max": 1.1067490577697754,
                "min": -1.7138744592666626,
                "frobenius_norm": 4.81654691696167,
                "spectral_norm": 2.8269073963165283,
                "num_singular_values": 12,
                "alpha": 1.330512897930647
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.025043083354830742,
                "median": 0.06681516766548157,
                "std": 0.42022526264190674,
                "max": 1.1467022895812988,
                "min": -1.2630908489227295,
                "frobenius_norm": 6.735533237457275,
                "spectral_norm": 3.7263362407684326,
                "num_singular_values": 16,
                "alpha": 1.152389452371932
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.021188601851463318,
                "median": -0.04910844564437866,
                "std": 0.2741885781288147,
                "max": 1.036301851272583,
                "min": -1.3379533290863037,
                "frobenius_norm": 4.400096893310547,
                "spectral_norm": 2.3151490688323975,
                "num_singular_values": 16,
                "alpha": 1.089664220687487
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.024752076715230942,
                "median": 0.03845139220356941,
                "std": 0.16282007098197937,
                "max": 0.31322529911994934,
                "min": -0.6982902884483337,
                "frobenius_norm": 1.8632631301879883,
                "spectral_norm": 0.9724465012550354,
                "num_singular_values": 8,
                "alpha": 1.7101965120341034
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.005_batch_size_16_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07201042026281357,
            "mse": 349575200.0,
            "mae": 1855.7098388671875,
            "r2_score": 0.9244869351387024,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.09775988012552261,
                "median": 0.05549075827002525,
                "std": 0.33608052134513855,
                "max": 1.1570638418197632,
                "min": -1.016711711883545,
                "frobenius_norm": 4.849883079528809,
                "spectral_norm": 2.7854292392730713,
                "num_singular_values": 12,
                "alpha": 1.2610299765937316
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.02852027863264084,
                "median": 0.025098131969571114,
                "std": 0.3559306263923645,
                "max": 1.1309864521026611,
                "min": -0.956325352191925,
                "frobenius_norm": 5.713143348693848,
                "spectral_norm": 3.169616937637329,
                "num_singular_values": 16,
                "alpha": 1.1125908418695585
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.04194460064172745,
                "median": -0.04976557195186615,
                "std": 0.20647075772285461,
                "max": 0.780418336391449,
                "min": -0.5283973217010498,
                "frobenius_norm": 3.37101149559021,
                "spectral_norm": 1.602739930152893,
                "num_singular_values": 16,
                "alpha": 1.206680763641499
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.011181239038705826,
                "median": 0.01941111870110035,
                "std": 0.15864895284175873,
                "max": 0.4394153356552124,
                "min": -0.43078532814979553,
                "frobenius_norm": 1.7993601560592651,
                "spectral_norm": 1.062619924545288,
                "num_singular_values": 8,
                "alpha": 1.62715548936689
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.005_batch_size_16_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07551970332860947,
            "mse": 511753536.0,
            "mae": 2171.054931640625,
            "r2_score": 0.889454185962677,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.07352393120527267,
                "median": 0.0566820465028286,
                "std": 0.27040234208106995,
                "max": 0.9862972497940063,
                "min": -1.2952226400375366,
                "frobenius_norm": 3.882841110229492,
                "spectral_norm": 2.5108842849731445,
                "num_singular_values": 12,
                "alpha": 1.3618672274246701
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.04570232331752777,
                "median": -0.023486163467168808,
                "std": 0.30327895283699036,
                "max": 1.3091486692428589,
                "min": -1.565950870513916,
                "frobenius_norm": 4.90725040435791,
                "spectral_norm": 3.2221357822418213,
                "num_singular_values": 16,
                "alpha": 1.1038633988427051
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.03132341802120209,
                "median": -0.05773138999938965,
                "std": 0.19270707666873932,
                "max": 1.0580772161483765,
                "min": -0.6518309712409973,
                "frobenius_norm": 3.123779296875,
                "spectral_norm": 1.7175039052963257,
                "num_singular_values": 16,
                "alpha": 1.2622363759714617
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.029417257755994797,
                "median": 0.028705287724733353,
                "std": 0.14146806299686432,
                "max": 0.33737048506736755,
                "min": -0.3269655406475067,
                "frobenius_norm": 1.6347657442092896,
                "spectral_norm": 0.8643036484718323,
                "num_singular_values": 8,
                "alpha": 1.5108350806346484
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.08287082612514496,
            "mse": 454153696.0,
            "mae": 1984.2152099609375,
            "r2_score": 0.9018965363502502,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.001193240866996348,
                "median": -0.011154258623719215,
                "std": 0.23033516108989716,
                "max": 0.5271029472351074,
                "min": -0.9422513842582703,
                "frobenius_norm": 3.1916604042053223,
                "spectral_norm": 1.7250691652297974,
                "num_singular_values": 12,
                "alpha": 1.2720102492940515
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.03656623512506485,
                "median": 0.056978218257427216,
                "std": 0.3444451093673706,
                "max": 1.580121397972107,
                "min": -3.480208158493042,
                "frobenius_norm": 5.542089462280273,
                "spectral_norm": 4.018539905548096,
                "num_singular_values": 16,
                "alpha": 1.14794099321216
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.01752123236656189,
                "median": 0.011532215401530266,
                "std": 0.215850368142128,
                "max": 1.6313296556472778,
                "min": -0.5766800045967102,
                "frobenius_norm": 3.4649651050567627,
                "spectral_norm": 1.9729615449905396,
                "num_singular_values": 16,
                "alpha": 1.1984455630447313
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.053944945335388184,
                "median": 0.05723244696855545,
                "std": 0.15269069373607635,
                "max": 0.3467891216278076,
                "min": -0.2864703834056854,
                "frobenius_norm": 1.8321399688720703,
                "spectral_norm": 1.0924627780914307,
                "num_singular_values": 8,
                "alpha": 1.5020222120360345
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.005_batch_size_32_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07144179195165634,
            "mse": 434863712.0,
            "mae": 2000.0015869140625,
            "r2_score": 0.906063437461853,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.057898055762052536,
                "median": 0.04071943834424019,
                "std": 0.27275753021240234,
                "max": 0.7572854161262512,
                "min": -0.8535029888153076,
                "frobenius_norm": 3.8636484146118164,
                "spectral_norm": 2.0533368587493896,
                "num_singular_values": 12,
                "alpha": 1.4056688417695171
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.019490819424390793,
                "median": 0.04817533865571022,
                "std": 0.39063939452171326,
                "max": 1.1545392274856567,
                "min": -1.5174599885940552,
                "frobenius_norm": 6.258005142211914,
                "spectral_norm": 2.891906499862671,
                "num_singular_values": 16,
                "alpha": 1.1386312297757875
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.010365169495344162,
                "median": -0.0253429152071476,
                "std": 0.2989371418952942,
                "max": 1.3441236019134521,
                "min": -0.9129133224487305,
                "frobenius_norm": 4.785868167877197,
                "spectral_norm": 2.3962302207946777,
                "num_singular_values": 16,
                "alpha": 1.150823932393541
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.030167926102876663,
                "median": 0.019898101687431335,
                "std": 0.1842842698097229,
                "max": 0.5393838286399841,
                "min": -0.4447460472583771,
                "frobenius_norm": 2.1126906871795654,
                "spectral_norm": 1.2679641246795654,
                "num_singular_values": 8,
                "alpha": 1.620912688922677
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.005_batch_size_32_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07338958233594894,
            "mse": 409869216.0,
            "mae": 1944.0186767578125,
            "r2_score": 0.9114626049995422,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.07386567443609238,
                "median": 0.06453431397676468,
                "std": 0.3327217698097229,
                "max": 1.3894840478897095,
                "min": -1.5182493925094604,
                "frobenius_norm": 4.722573280334473,
                "spectral_norm": 3.101099729537964,
                "num_singular_values": 12,
                "alpha": 1.2419592358545988
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.04257625341415405,
                "median": 0.040634144097566605,
                "std": 0.38714560866355896,
                "max": 1.5423048734664917,
                "min": -1.4372310638427734,
                "frobenius_norm": 6.231675624847412,
                "spectral_norm": 3.412534713745117,
                "num_singular_values": 16,
                "alpha": 1.2216057353938572
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.019491104409098625,
                "median": -0.043542392551898956,
                "std": 0.24492603540420532,
                "max": 0.9918152689933777,
                "min": -0.8853932619094849,
                "frobenius_norm": 3.9312057495117188,
                "spectral_norm": 2.2012104988098145,
                "num_singular_values": 16,
                "alpha": 1.1025501280880095
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.04029181972146034,
                "median": 0.04176490008831024,
                "std": 0.16340146958827972,
                "max": 0.5688058733940125,
                "min": -0.3259500563144684,
                "frobenius_norm": 1.9040493965148926,
                "spectral_norm": 1.1249111890792847,
                "num_singular_values": 8,
                "alpha": 1.663182952896595
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.005_batch_size_32_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07629625499248505,
            "mse": 480523904.0,
            "mae": 2076.830322265625,
            "r2_score": 0.8962001800537109,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.0425565280020237,
                "median": 0.022658856585621834,
                "std": 0.3284989893436432,
                "max": 0.9278727173805237,
                "min": -2.4401392936706543,
                "frobenius_norm": 4.589852333068848,
                "spectral_norm": 3.459016799926758,
                "num_singular_values": 12,
                "alpha": 1.2652678026024387
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.01711253449320793,
                "median": 0.025305241346359253,
                "std": 0.3386940658092499,
                "max": 1.0310847759246826,
                "min": -1.50040864944458,
                "frobenius_norm": 5.4260172843933105,
                "spectral_norm": 3.3869383335113525,
                "num_singular_values": 16,
                "alpha": 1.2002409082518593
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.03279578313231468,
                "median": -0.0583329014480114,
                "std": 0.23115497827529907,
                "max": 0.9650729894638062,
                "min": -1.0585461854934692,
                "frobenius_norm": 3.735518217086792,
                "spectral_norm": 2.136183500289917,
                "num_singular_values": 16,
                "alpha": 1.2143279974721777
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.032208748161792755,
                "median": 0.026005491614341736,
                "std": 0.1673751026391983,
                "max": 0.5132383108139038,
                "min": -0.39223530888557434,
                "frobenius_norm": 1.9283759593963623,
                "spectral_norm": 1.294836163520813,
                "num_singular_values": 8,
                "alpha": 1.5980606205302053
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.10418546944856644,
            "mse": 475521344.0,
            "mae": 2342.882080078125,
            "r2_score": 0.8972808122634888,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.012050837278366089,
                "median": -0.005627340637147427,
                "std": 0.19885002076625824,
                "max": 0.4812161922454834,
                "min": -0.6365014314651489,
                "frobenius_norm": 2.760401725769043,
                "spectral_norm": 1.2797017097473145,
                "num_singular_values": 12,
                "alpha": 1.264386593145859
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0435306541621685,
                "median": 0.05848965048789978,
                "std": 0.2751692533493042,
                "max": 1.0375770330429077,
                "min": -2.3634297847747803,
                "frobenius_norm": 4.45745849609375,
                "spectral_norm": 3.000270128250122,
                "num_singular_values": 16,
                "alpha": 1.1721420854095232
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.022797150537371635,
                "median": 0.020931560546159744,
                "std": 0.21116943657398224,
                "max": 0.6266652345657349,
                "min": -0.7823167443275452,
                "frobenius_norm": 3.3983428478240967,
                "spectral_norm": 2.431015968322754,
                "num_singular_values": 16,
                "alpha": 1.1717330242341677
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.05935394763946533,
                "median": 0.05361205339431763,
                "std": 0.1553354263305664,
                "max": 0.4714326858520508,
                "min": -0.35244399309158325,
                "frobenius_norm": 1.8813437223434448,
                "spectral_norm": 1.0734870433807373,
                "num_singular_values": 8,
                "alpha": 1.6873573016763768
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.005_batch_size_64_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 64,
            "scaler_type": "standard",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07218307256698608,
            "mse": 398768544.0,
            "mae": 1957.783447265625,
            "r2_score": 0.9138604998588562,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.061074793338775635,
                "median": 0.026572149246931076,
                "std": 0.268980473279953,
                "max": 0.7995339632034302,
                "min": -0.6898077130317688,
                "frobenius_norm": 3.8219735622406006,
                "spectral_norm": 2.1275713443756104,
                "num_singular_values": 12,
                "alpha": 1.4852897578727526
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.022594090551137924,
                "median": -0.00038436890463344753,
                "std": 0.376250684261322,
                "max": 1.1211309432983398,
                "min": -1.2455376386642456,
                "frobenius_norm": 6.030855655670166,
                "spectral_norm": 3.38081955909729,
                "num_singular_values": 16,
                "alpha": 1.1703933969957503
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.011650259606540203,
                "median": -0.03603242337703705,
                "std": 0.28208282589912415,
                "max": 1.1053026914596558,
                "min": -1.009246826171875,
                "frobenius_norm": 4.517172813415527,
                "spectral_norm": 2.533667802810669,
                "num_singular_values": 16,
                "alpha": 1.2030481330115659
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.02159155160188675,
                "median": 0.02368462085723877,
                "std": 0.1798662692308426,
                "max": 0.6440182328224182,
                "min": -0.5992338061332703,
                "frobenius_norm": 2.0495641231536865,
                "spectral_norm": 1.358145833015442,
                "num_singular_values": 8,
                "alpha": 1.6927352190439895
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.005_batch_size_64_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 64,
            "scaler_type": "robust",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07260239869356155,
            "mse": 398139744.0,
            "mae": 1886.26171875,
            "r2_score": 0.9139963388442993,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.06280484050512314,
                "median": 0.06860765069723129,
                "std": 0.30103906989097595,
                "max": 1.7248592376708984,
                "min": -1.3158516883850098,
                "frobenius_norm": 4.261131763458252,
                "spectral_norm": 2.8610641956329346,
                "num_singular_values": 12,
                "alpha": 1.3701728420000543
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.026971623301506042,
                "median": 0.043185897171497345,
                "std": 0.4117495119571686,
                "max": 1.563551425933838,
                "min": -1.8535492420196533,
                "frobenius_norm": 6.602111339569092,
                "spectral_norm": 4.16147518157959,
                "num_singular_values": 16,
                "alpha": 1.1620816264799578
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.002862324006855488,
                "median": -0.0015304225962609053,
                "std": 0.3041817545890808,
                "max": 1.7685387134552002,
                "min": -0.9348931908607483,
                "frobenius_norm": 4.867123603820801,
                "spectral_norm": 2.9439947605133057,
                "num_singular_values": 16,
                "alpha": 1.1427516103448694
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.035421378910541534,
                "median": 0.06066156551241875,
                "std": 0.16832806169986725,
                "max": 0.45772868394851685,
                "min": -0.5072364211082458,
                "frobenius_norm": 1.9461225271224976,
                "spectral_norm": 1.222452163696289,
                "num_singular_values": 8,
                "alpha": 1.8746359767736267
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.005_batch_size_64_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 64,
            "scaler_type": "minmax",
            "total_params": 888
        },
        "scores": {
            "smape": 0.0766211599111557,
            "mse": 503406976.0,
            "mae": 2194.957275390625,
            "r2_score": 0.8912571668624878,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.06147948279976845,
                "median": 0.030325844883918762,
                "std": 0.4073852002620697,
                "max": 1.3918746709823608,
                "min": -3.0122063159942627,
                "frobenius_norm": 5.708812713623047,
                "spectral_norm": 4.492165565490723,
                "num_singular_values": 12,
                "alpha": 1.3399482661336055
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.004800716415047646,
                "median": -0.013469738885760307,
                "std": 0.3931601047515869,
                "max": 2.0144877433776855,
                "min": -1.3006998300552368,
                "frobenius_norm": 6.291030406951904,
                "spectral_norm": 4.37710428237915,
                "num_singular_values": 16,
                "alpha": 1.2556162057315898
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.03608058765530586,
                "median": -0.03851094841957092,
                "std": 0.22168391942977905,
                "max": 0.7231758832931519,
                "min": -1.3437687158584595,
                "frobenius_norm": 3.5936145782470703,
                "spectral_norm": 2.0647997856140137,
                "num_singular_values": 16,
                "alpha": 1.148810981735587
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.030096296221017838,
                "median": 0.011718831956386566,
                "std": 0.1480742245912552,
                "max": 0.33889132738113403,
                "min": -0.24783895909786224,
                "frobenius_norm": 1.709522008895874,
                "spectral_norm": 0.9767917990684509,
                "num_singular_values": 8,
                "alpha": 1.506967810030873
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.005_batch_size_128_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 128,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07908439636230469,
            "mse": 430102400.0,
            "mae": 1903.00927734375,
            "r2_score": 0.9070919752120972,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.00754041550680995,
                "median": -0.021236877888441086,
                "std": 0.21170997619628906,
                "max": 0.5475698113441467,
                "min": -0.6181754469871521,
                "frobenius_norm": 2.935399293899536,
                "spectral_norm": 1.522911787033081,
                "num_singular_values": 12,
                "alpha": 1.290594220464656
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.05807160586118698,
                "median": 0.058143019676208496,
                "std": 0.3202683925628662,
                "max": 1.5816385746002197,
                "min": -2.7969353199005127,
                "frobenius_norm": 5.207849979400635,
                "spectral_norm": 3.7836062908172607,
                "num_singular_values": 16,
                "alpha": 1.1912475090637167
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.024491049349308014,
                "median": 0.012838372029364109,
                "std": 0.20171159505844116,
                "max": 0.684325098991394,
                "min": -0.6200190186500549,
                "frobenius_norm": 3.251087188720703,
                "spectral_norm": 1.9041712284088135,
                "num_singular_values": 16,
                "alpha": 1.0738780622155413
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.06299223005771637,
                "median": 0.05915810912847519,
                "std": 0.1609288603067398,
                "max": 0.5896368026733398,
                "min": -0.24976566433906555,
                "frobenius_norm": 1.9552143812179565,
                "spectral_norm": 1.1363465785980225,
                "num_singular_values": 8,
                "alpha": 1.6736741394348544
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.005_batch_size_128_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 128,
            "scaler_type": "standard",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07120538502931595,
            "mse": 434367392.0,
            "mae": 2006.7386474609375,
            "r2_score": 0.906170666217804,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.0855991318821907,
                "median": 0.08348427712917328,
                "std": 0.30451035499572754,
                "max": 0.8516368269920349,
                "min": -1.6850115060806274,
                "frobenius_norm": 4.382957935333252,
                "spectral_norm": 2.7481892108917236,
                "num_singular_values": 12,
                "alpha": 1.3138658972465094
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.02757156640291214,
                "median": 0.015184594318270683,
                "std": 0.39463382959365845,
                "max": 1.5880764722824097,
                "min": -1.1200432777404785,
                "frobenius_norm": 6.329533100128174,
                "spectral_norm": 3.005126714706421,
                "num_singular_values": 16,
                "alpha": 1.1364657227301258
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.02144310250878334,
                "median": -0.03590165078639984,
                "std": 0.3028026223182678,
                "max": 0.8952144384384155,
                "min": -0.9927627444267273,
                "frobenius_norm": 4.8569746017456055,
                "spectral_norm": 2.797295570373535,
                "num_singular_values": 16,
                "alpha": 1.2378393943924848
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.020375795662403107,
                "median": 0.050213221460580826,
                "std": 0.19473779201507568,
                "max": 0.39639365673065186,
                "min": -0.753072202205658,
                "frobenius_norm": 2.2152340412139893,
                "spectral_norm": 1.4725816249847412,
                "num_singular_values": 8,
                "alpha": 1.449247239648686
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.005_batch_size_128_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 128,
            "scaler_type": "robust",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07118646800518036,
            "mse": 416837760.0,
            "mae": 1926.703369140625,
            "r2_score": 0.9099572896957397,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.06958949565887451,
                "median": 0.06882550567388535,
                "std": 0.31325846910476685,
                "max": 1.26907479763031,
                "min": -1.2182079553604126,
                "frobenius_norm": 4.446450233459473,
                "spectral_norm": 2.823002576828003,
                "num_singular_values": 12,
                "alpha": 1.2234009365450582
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.04129519313573837,
                "median": 0.04214858263731003,
                "std": 0.37880414724349976,
                "max": 1.2172795534133911,
                "min": -1.5522209405899048,
                "frobenius_norm": 6.096774101257324,
                "spectral_norm": 3.1011250019073486,
                "num_singular_values": 16,
                "alpha": 1.212674564567965
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.029651418328285217,
                "median": -0.02833639457821846,
                "std": 0.31690290570259094,
                "max": 1.054770588874817,
                "min": -1.6909751892089844,
                "frobenius_norm": 5.092593193054199,
                "spectral_norm": 2.69675874710083,
                "num_singular_values": 16,
                "alpha": 1.12829768336849
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": -0.007593873888254166,
                "median": 0.004287742543965578,
                "std": 0.21779951453208923,
                "max": 0.49128299951553345,
                "min": -0.9889974594116211,
                "frobenius_norm": 2.4656174182891846,
                "spectral_norm": 1.4449783563613892,
                "num_singular_values": 8,
                "alpha": 1.6219244058910331
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.005_batch_size_128_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 128,
            "scaler_type": "minmax",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07582701742649078,
            "mse": 412659200.0,
            "mae": 2086.19091796875,
            "r2_score": 0.9108599424362183,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.06531692296266556,
                "median": 0.05791550874710083,
                "std": 0.346025675535202,
                "max": 1.1431993246078491,
                "min": -2.6120247840881348,
                "frobenius_norm": 4.879345417022705,
                "spectral_norm": 3.7912027835845947,
                "num_singular_values": 12,
                "alpha": 1.219156569898611
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.02592722699046135,
                "median": -0.03048020415008068,
                "std": 0.37053486704826355,
                "max": 1.857978343963623,
                "min": -1.6929901838302612,
                "frobenius_norm": 5.943053722381592,
                "spectral_norm": 4.070316314697266,
                "num_singular_values": 16,
                "alpha": 1.2155014212159878
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.03969043493270874,
                "median": -0.022551782429218292,
                "std": 0.26987186074256897,
                "max": 1.3213669061660767,
                "min": -1.0279968976974487,
                "frobenius_norm": 4.36439847946167,
                "spectral_norm": 2.499450922012329,
                "num_singular_values": 16,
                "alpha": 1.1824917217506368
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.022786349058151245,
                "median": 0.015265924856066704,
                "std": 0.16619037091732025,
                "max": 0.42004773020744324,
                "min": -0.41002777218818665,
                "frobenius_norm": 1.8978204727172852,
                "spectral_norm": 1.070340871810913,
                "num_singular_values": 8,
                "alpha": 1.4298369885764477
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.005_batch_size_256_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 256,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.08705467730760574,
            "mse": 518711904.0,
            "mae": 2182.768798828125,
            "r2_score": 0.8879510760307312,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": -0.013316035270690918,
                "median": -0.01648474484682083,
                "std": 0.2220199853181839,
                "max": 0.4569648802280426,
                "min": -0.7129456996917725,
                "frobenius_norm": 3.0819272994995117,
                "spectral_norm": 1.6323890686035156,
                "num_singular_values": 12,
                "alpha": 1.267606520426845
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.07117565721273422,
                "median": 0.08939708769321442,
                "std": 0.35609883069992065,
                "max": 2.8226704597473145,
                "min": -3.4361908435821533,
                "frobenius_norm": 5.810277462005615,
                "spectral_norm": 4.705009937286377,
                "num_singular_values": 16,
                "alpha": 1.1492061804088303
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.012311508879065514,
                "median": 0.0048342300578951836,
                "std": 0.18062104284763336,
                "max": 0.41809919476509094,
                "min": -0.916873037815094,
                "frobenius_norm": 2.8966424465179443,
                "spectral_norm": 1.5652192831039429,
                "num_singular_values": 16,
                "alpha": 1.202275331524366
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.06760773062705994,
                "median": 0.06433965265750885,
                "std": 0.15885110199451447,
                "max": 0.6108372211456299,
                "min": -0.25995680689811707,
                "frobenius_norm": 1.953195571899414,
                "spectral_norm": 1.1910324096679688,
                "num_singular_values": 8,
                "alpha": 1.6489033165209714
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.005_batch_size_256_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 256,
            "scaler_type": "standard",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07211875915527344,
            "mse": 410878624.0,
            "mae": 1939.478515625,
            "r2_score": 0.9112445712089539,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.024570539593696594,
                "median": 0.009201738983392715,
                "std": 0.3236428499221802,
                "max": 1.252427339553833,
                "min": -1.5484049320220947,
                "frobenius_norm": 4.497431755065918,
                "spectral_norm": 2.798776388168335,
                "num_singular_values": 12,
                "alpha": 1.3238001488034508
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.003198588266968727,
                "median": -0.028635643422603607,
                "std": 0.4380755126476288,
                "max": 1.83061945438385,
                "min": -1.9403682947158813,
                "frobenius_norm": 7.009395122528076,
                "spectral_norm": 3.7214808464050293,
                "num_singular_values": 16,
                "alpha": 1.2366621889048215
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.00925010722130537,
                "median": -0.033461250364780426,
                "std": 0.2717720568180084,
                "max": 1.0435795783996582,
                "min": -1.0391840934753418,
                "frobenius_norm": 4.3508710861206055,
                "spectral_norm": 2.535853624343872,
                "num_singular_values": 16,
                "alpha": 1.1419353738644118
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.03184910863637924,
                "median": 0.028203606605529785,
                "std": 0.14986760914325714,
                "max": 0.44762909412384033,
                "min": -0.26930609345436096,
                "frobenius_norm": 1.7334235906600952,
                "spectral_norm": 0.9665473699569702,
                "num_singular_values": 8,
                "alpha": 1.7265263787077798
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.005_batch_size_256_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 256,
            "scaler_type": "robust",
            "total_params": 888
        },
        "scores": {
            "smape": 0.0718851238489151,
            "mse": 547774720.0,
            "mae": 2051.6875,
            "r2_score": 0.8816730976104736,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.03350403532385826,
                "median": 0.011959603056311607,
                "std": 0.3433568477630615,
                "max": 1.3179081678390503,
                "min": -1.2138417959213257,
                "frobenius_norm": 4.780288219451904,
                "spectral_norm": 3.1588525772094727,
                "num_singular_values": 12,
                "alpha": 1.20557944742489
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.012323036789894104,
                "median": 0.006183295976370573,
                "std": 0.4051254987716675,
                "max": 1.3895375728607178,
                "min": -1.5715986490249634,
                "frobenius_norm": 6.4850053787231445,
                "spectral_norm": 3.5855209827423096,
                "num_singular_values": 16,
                "alpha": 1.270402106193832
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.02756623737514019,
                "median": -0.02414216473698616,
                "std": 0.2572140693664551,
                "max": 1.0254656076431274,
                "min": -0.9818575978279114,
                "frobenius_norm": 4.138992786407471,
                "spectral_norm": 2.0708346366882324,
                "num_singular_values": 16,
                "alpha": 1.2003589569964854
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.04735643044114113,
                "median": 0.03869698941707611,
                "std": 0.17237341403961182,
                "max": 0.7372006773948669,
                "min": -0.6414586305618286,
                "frobenius_norm": 2.0224411487579346,
                "spectral_norm": 1.276335597038269,
                "num_singular_values": 8,
                "alpha": 1.634225227508426
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.005_batch_size_256_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 256,
            "scaler_type": "minmax",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07435453683137894,
            "mse": 448033472.0,
            "mae": 2072.082275390625,
            "r2_score": 0.9032186269760132,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.04549695551395416,
                "median": 0.029263999313116074,
                "std": 0.3433138132095337,
                "max": 1.3106341361999512,
                "min": -1.9541643857955933,
                "frobenius_norm": 4.798686504364014,
                "spectral_norm": 3.5491244792938232,
                "num_singular_values": 12,
                "alpha": 1.2565890912556072
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.026614543050527573,
                "median": -0.01533535122871399,
                "std": 0.3870468735694885,
                "max": 1.329102635383606,
                "min": -1.9516561031341553,
                "frobenius_norm": 6.20737361907959,
                "spectral_norm": 3.655510663986206,
                "num_singular_values": 16,
                "alpha": 1.1234200138017774
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.03457137942314148,
                "median": -0.03800920769572258,
                "std": 0.2408243864774704,
                "max": 0.8306938409805298,
                "min": -1.8100110292434692,
                "frobenius_norm": 3.892690896987915,
                "spectral_norm": 2.406552314758301,
                "num_singular_values": 16,
                "alpha": 1.1942968632040172
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.04075155034661293,
                "median": 0.042902328073978424,
                "std": 0.14036916196346283,
                "max": 0.42242130637168884,
                "min": -0.24156999588012695,
                "frobenius_norm": 1.653667688369751,
                "spectral_norm": 0.9321343898773193,
                "num_singular_values": 8,
                "alpha": 1.576130551097222
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.001_batch_size_16_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.08599813282489777,
            "mse": 486528096.0,
            "mae": 2042.6351318359375,
            "r2_score": 0.8949032425880432,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.04017074778676033,
                "median": 0.04338638484477997,
                "std": 0.17240886390209198,
                "max": 0.39443719387054443,
                "min": -0.324552059173584,
                "frobenius_norm": 2.452955961227417,
                "spectral_norm": 1.1378768682479858,
                "num_singular_values": 12,
                "alpha": 1.2926040322749701
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0714699998497963,
                "median": 0.057152263820171356,
                "std": 0.17514018714427948,
                "max": 0.5368643999099731,
                "min": -0.2693294286727905,
                "frobenius_norm": 3.026582956314087,
                "spectral_norm": 1.9484853744506836,
                "num_singular_values": 16,
                "alpha": 1.1044816285174015
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0372588112950325,
                "median": 0.02388290874660015,
                "std": 0.18029513955116272,
                "max": 0.5436131358146667,
                "min": -0.28978973627090454,
                "frobenius_norm": 2.945675849914551,
                "spectral_norm": 2.0008933544158936,
                "num_singular_values": 16,
                "alpha": 1.0776665633510567
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.042976152151823044,
                "median": 0.04506896063685417,
                "std": 0.15426354110240936,
                "max": 0.34669750928878784,
                "min": -0.2454124242067337,
                "frobenius_norm": 1.8117550611495972,
                "spectral_norm": 1.0502948760986328,
                "num_singular_values": 8,
                "alpha": 1.724654631321734
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.001_batch_size_16_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07374145835638046,
            "mse": 447801056.0,
            "mae": 2000.4520263671875,
            "r2_score": 0.9032688140869141,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.03563207760453224,
                "median": 0.028939034789800644,
                "std": 0.2299467921257019,
                "max": 0.9964609146118164,
                "min": -0.6128491163253784,
                "frobenius_norm": 3.2242634296417236,
                "spectral_norm": 1.7721202373504639,
                "num_singular_values": 12,
                "alpha": 1.2801929692801401
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.03860805928707123,
                "median": 0.05296921730041504,
                "std": 0.2529345154762268,
                "max": 0.827091634273529,
                "min": -0.7949733734130859,
                "frobenius_norm": 4.0938262939453125,
                "spectral_norm": 2.187026262283325,
                "num_singular_values": 16,
                "alpha": 1.1437392248733216
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.004155993927270174,
                "median": -0.019742945209145546,
                "std": 0.2198973447084427,
                "max": 0.7351924777030945,
                "min": -0.7796577215194702,
                "frobenius_norm": 3.5189857482910156,
                "spectral_norm": 1.9735851287841797,
                "num_singular_values": 16,
                "alpha": 1.0967138256361657
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.03217293694615364,
                "median": 0.0254441536962986,
                "std": 0.1596495360136032,
                "max": 0.5470711588859558,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.8425397872924805,
                "spectral_norm": 1.112520694732666,
                "num_singular_values": 8,
                "alpha": 1.568939262955336
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.001_batch_size_16_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07253345102071762,
            "mse": 445532544.0,
            "mae": 1962.6754150390625,
            "r2_score": 0.9037588238716125,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.04633847996592522,
                "median": 0.038249991834163666,
                "std": 0.2280941903591156,
                "max": 0.7794556021690369,
                "min": -0.582396388053894,
                "frobenius_norm": 3.225127935409546,
                "spectral_norm": 1.8021647930145264,
                "num_singular_values": 12,
                "alpha": 1.332883784263979
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.030594410374760628,
                "median": 0.053475260734558105,
                "std": 0.22240720689296722,
                "max": 0.5372653603553772,
                "min": -0.7099955081939697,
                "frobenius_norm": 3.5920262336730957,
                "spectral_norm": 1.9086887836456299,
                "num_singular_values": 16,
                "alpha": 1.1645642355939567
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.013569415546953678,
                "median": 0.02115284465253353,
                "std": 0.21463562548160553,
                "max": 0.6957355737686157,
                "min": -0.5857106447219849,
                "frobenius_norm": 3.441026210784912,
                "spectral_norm": 1.9155519008636475,
                "num_singular_values": 16,
                "alpha": 1.2498785398933911
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.02805328741669655,
                "median": 0.015065936371684074,
                "std": 0.1871308833360672,
                "max": 0.5142266750335693,
                "min": -0.6717933416366577,
                "frobenius_norm": 2.1408021450042725,
                "spectral_norm": 1.250117301940918,
                "num_singular_values": 8,
                "alpha": 1.868269008531831
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.001_batch_size_16_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07757239788770676,
            "mse": 489029056.0,
            "mae": 2202.684814453125,
            "r2_score": 0.8943629860877991,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.05616554990410805,
                "median": 0.05958516150712967,
                "std": 0.19819442927837372,
                "max": 0.5603131055831909,
                "min": -0.5615766048431396,
                "frobenius_norm": 2.8544061183929443,
                "spectral_norm": 1.7062549591064453,
                "num_singular_values": 12,
                "alpha": 1.2223228961321333
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.01805843412876129,
                "median": 0.0010548817226663232,
                "std": 0.1863405406475067,
                "max": 0.5089861154556274,
                "min": -0.528965950012207,
                "frobenius_norm": 2.9954166412353516,
                "spectral_norm": 1.7521564960479736,
                "num_singular_values": 16,
                "alpha": 1.2140032062062556
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.01636912301182747,
                "median": -0.01294918917119503,
                "std": 0.18270130455493927,
                "max": 0.484528511762619,
                "min": -0.6263853907585144,
                "frobenius_norm": 2.9349300861358643,
                "spectral_norm": 1.7533364295959473,
                "num_singular_values": 16,
                "alpha": 1.1740437201175953
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.01575876772403717,
                "median": 0.028260402381420135,
                "std": 0.14664039015769958,
                "max": 0.4108269214630127,
                "min": -0.2590811550617218,
                "frobenius_norm": 1.6685991287231445,
                "spectral_norm": 0.8728064298629761,
                "num_singular_values": 8,
                "alpha": 1.8262238393730565
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.08417957276105881,
            "mse": 503341760.0,
            "mae": 2081.082275390625,
            "r2_score": 0.8912712335586548,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.04012884572148323,
                "median": 0.040403179824352264,
                "std": 0.17423513531684875,
                "max": 0.40761569142341614,
                "min": -0.31453076004981995,
                "frobenius_norm": 2.477477550506592,
                "spectral_norm": 1.1136733293533325,
                "num_singular_values": 12,
                "alpha": 1.2885694752374737
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.06753513962030411,
                "median": 0.054865818470716476,
                "std": 0.18075262010097504,
                "max": 0.5404564738273621,
                "min": -0.26524242758750916,
                "frobenius_norm": 3.0873160362243652,
                "spectral_norm": 2.0571610927581787,
                "num_singular_values": 16,
                "alpha": 1.189519592318073
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.030054815113544464,
                "median": -0.0028525670059025288,
                "std": 0.18087999522686005,
                "max": 0.5395806431770325,
                "min": -0.2839585840702057,
                "frobenius_norm": 2.9337589740753174,
                "spectral_norm": 2.017273426055908,
                "num_singular_values": 16,
                "alpha": 1.1201258357993993
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.043918922543525696,
                "median": 0.05104082077741623,
                "std": 0.152028426527977,
                "max": 0.36722618341445923,
                "min": -0.22865867614746094,
                "frobenius_norm": 1.7903391122817993,
                "spectral_norm": 1.0585910081863403,
                "num_singular_values": 8,
                "alpha": 1.7370133752798218
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.001_batch_size_32_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07397406548261642,
            "mse": 458724864.0,
            "mae": 2050.783935546875,
            "r2_score": 0.9009091258049011,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.030292971059679985,
                "median": 0.0283633042126894,
                "std": 0.23091474175453186,
                "max": 0.679248571395874,
                "min": -0.5942745804786682,
                "frobenius_norm": 3.2270641326904297,
                "spectral_norm": 1.8759053945541382,
                "num_singular_values": 12,
                "alpha": 1.3023149374453027
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.03193829208612442,
                "median": 0.045452363789081573,
                "std": 0.2606823444366455,
                "max": 0.8229995965957642,
                "min": -0.6562013626098633,
                "frobenius_norm": 4.2021050453186035,
                "spectral_norm": 2.3883116245269775,
                "num_singular_values": 16,
                "alpha": 1.1433130563016025
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0005306694656610489,
                "median": -0.006624925881624222,
                "std": 0.22538025677204132,
                "max": 0.7659746408462524,
                "min": -0.861974835395813,
                "frobenius_norm": 3.6060938835144043,
                "spectral_norm": 2.0584805011749268,
                "num_singular_values": 16,
                "alpha": 1.1182671921156102
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.034777529537677765,
                "median": 0.03502697870135307,
                "std": 0.16729742288589478,
                "max": 0.5359379649162292,
                "min": -0.28866636753082275,
                "frobenius_norm": 1.933218002319336,
                "spectral_norm": 1.191741704940796,
                "num_singular_values": 8,
                "alpha": 1.674240017913728
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.001_batch_size_32_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07316025346517563,
            "mse": 486480800.0,
            "mae": 2037.9947509765625,
            "r2_score": 0.8949134349822998,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.05275663360953331,
                "median": 0.036983706057071686,
                "std": 0.2452925145626068,
                "max": 0.9947212934494019,
                "min": -0.5882083177566528,
                "frobenius_norm": 3.4765963554382324,
                "spectral_norm": 1.823481559753418,
                "num_singular_values": 12,
                "alpha": 1.2620096316713498
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.042009882628917694,
                "median": 0.06195445358753204,
                "std": 0.23844441771507263,
                "max": 0.6843342781066895,
                "min": -0.7309260368347168,
                "frobenius_norm": 3.8738696575164795,
                "spectral_norm": 1.941219449043274,
                "num_singular_values": 16,
                "alpha": 1.147881311683046
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.01614760234951973,
                "median": 0.008551188744604588,
                "std": 0.21560505032539368,
                "max": 0.7016367316246033,
                "min": -0.5732454657554626,
                "frobenius_norm": 3.4593420028686523,
                "spectral_norm": 2.134861946105957,
                "num_singular_values": 16,
                "alpha": 1.1986935039792685
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.03856319934129715,
                "median": 0.042935311794281006,
                "std": 0.1731768399477005,
                "max": 0.5191881656646729,
                "min": -0.27007821202278137,
                "frobenius_norm": 2.0072617530822754,
                "spectral_norm": 1.217857837677002,
                "num_singular_values": 8,
                "alpha": 1.6404275828855521
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.001_batch_size_32_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07820385694503784,
            "mse": 509790304.0,
            "mae": 2236.515869140625,
            "r2_score": 0.8898782730102539,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.05926257371902466,
                "median": 0.058695584535598755,
                "std": 0.20198741555213928,
                "max": 0.5777905583381653,
                "min": -0.48614025115966797,
                "frobenius_norm": 2.916796922683716,
                "spectral_norm": 1.6878741979599,
                "num_singular_values": 12,
                "alpha": 1.1904577301362325
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.021012531593441963,
                "median": 0.013072879984974861,
                "std": 0.2015509158372879,
                "max": 0.7738027572631836,
                "min": -0.5718328356742859,
                "frobenius_norm": 3.2422924041748047,
                "spectral_norm": 1.9269139766693115,
                "num_singular_values": 16,
                "alpha": 1.2081802588925237
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.011173752136528492,
                "median": -0.016101758927106857,
                "std": 0.1821712702512741,
                "max": 0.48816928267478943,
                "min": -0.5448938608169556,
                "frobenius_norm": 2.920217990875244,
                "spectral_norm": 1.747331976890564,
                "num_singular_values": 16,
                "alpha": 1.1844218426006827
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.01938544400036335,
                "median": 0.03945712372660637,
                "std": 0.14601241052150726,
                "max": 0.3850612938404083,
                "min": -0.2541155219078064,
                "frobenius_norm": 1.6664373874664307,
                "spectral_norm": 0.8807852268218994,
                "num_singular_values": 8,
                "alpha": 1.8807354343963383
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.08250337094068527,
            "mse": 480987040.0,
            "mae": 2041.6031494140625,
            "r2_score": 0.8961001634597778,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.03945334255695343,
                "median": 0.039360709488391876,
                "std": 0.1740546077489853,
                "max": 0.40757209062576294,
                "min": -0.31826862692832947,
                "frobenius_norm": 2.472954034805298,
                "spectral_norm": 1.1284798383712769,
                "num_singular_values": 12,
                "alpha": 1.2835940024369603
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.057496681809425354,
                "median": 0.04733272269368172,
                "std": 0.17908470332622528,
                "max": 0.5836142301559448,
                "min": -0.37411683797836304,
                "frobenius_norm": 3.0094122886657715,
                "spectral_norm": 1.8852348327636719,
                "num_singular_values": 16,
                "alpha": 1.170548826838163
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.03479676693677902,
                "median": 0.024258499965071678,
                "std": 0.1829962283372879,
                "max": 0.6212426424026489,
                "min": -0.3048640191555023,
                "frobenius_norm": 2.9804024696350098,
                "spectral_norm": 2.0491552352905273,
                "num_singular_values": 16,
                "alpha": 1.15822324375215
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.04525917395949364,
                "median": 0.04512747377157211,
                "std": 0.154257133603096,
                "max": 0.3458530008792877,
                "min": -0.23488710820674896,
                "frobenius_norm": 1.8187874555587769,
                "spectral_norm": 1.0778841972351074,
                "num_singular_values": 8,
                "alpha": 1.7087736348885876
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.001_batch_size_64_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "standard",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07271098345518112,
            "mse": 497420640.0,
            "mae": 2077.7421875,
            "r2_score": 0.8925502896308899,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.04316888377070427,
                "median": 0.034469686448574066,
                "std": 0.24545231461524963,
                "max": 1.0491111278533936,
                "min": -0.6442885398864746,
                "frobenius_norm": 3.4532876014709473,
                "spectral_norm": 1.9173939228057861,
                "num_singular_values": 12,
                "alpha": 1.2581232663593838
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.015337418764829636,
                "median": 0.03053666651248932,
                "std": 0.2928626239299774,
                "max": 0.72823166847229,
                "min": -0.727908194065094,
                "frobenius_norm": 4.69222354888916,
                "spectral_norm": 2.5147757530212402,
                "num_singular_values": 16,
                "alpha": 1.1936058742110225
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.030918624252080917,
                "median": 0.014578564092516899,
                "std": 0.23288770020008087,
                "max": 0.7832830548286438,
                "min": -0.536240816116333,
                "frobenius_norm": 3.7588982582092285,
                "spectral_norm": 2.3053126335144043,
                "num_singular_values": 16,
                "alpha": 1.1682725303912722
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.03447306156158447,
                "median": 0.024149194359779358,
                "std": 0.17271672189235687,
                "max": 0.5432719588279724,
                "min": -0.26434755325317383,
                "frobenius_norm": 1.9926090240478516,
                "spectral_norm": 1.1419322490692139,
                "num_singular_values": 8,
                "alpha": 1.6724937518887284
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.001_batch_size_64_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "robust",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07283450663089752,
            "mse": 410400512.0,
            "mae": 1944.5504150390625,
            "r2_score": 0.9113478660583496,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.045353759080171585,
                "median": 0.0403008833527565,
                "std": 0.25067779421806335,
                "max": 0.9441944360733032,
                "min": -0.640493631362915,
                "frobenius_norm": 3.52988600730896,
                "spectral_norm": 1.8614766597747803,
                "num_singular_values": 12,
                "alpha": 1.27344262952496
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.01838613674044609,
                "median": 0.023336706683039665,
                "std": 0.25229692459106445,
                "max": 0.6609398722648621,
                "min": -0.8017626404762268,
                "frobenius_norm": 4.047455787658691,
                "spectral_norm": 2.1835274696350098,
                "num_singular_values": 16,
                "alpha": 1.1804618206255668
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.04338493198156357,
                "median": 0.046216122806072235,
                "std": 0.2349526584148407,
                "max": 0.814304530620575,
                "min": -0.5712383985519409,
                "frobenius_norm": 3.8227946758270264,
                "spectral_norm": 2.211866617202759,
                "num_singular_values": 16,
                "alpha": 1.225718176381151
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.030791498720645905,
                "median": 0.03452766314148903,
                "std": 0.18546853959560394,
                "max": 0.4789082705974579,
                "min": -0.7438744902610779,
                "frobenius_norm": 2.127058267593384,
                "spectral_norm": 1.3088274002075195,
                "num_singular_values": 8,
                "alpha": 1.7024984740773634
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.001_batch_size_64_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "minmax",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07736082375049591,
            "mse": 490554592.0,
            "mae": 2195.281494140625,
            "r2_score": 0.8940334320068359,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.04762272909283638,
                "median": 0.03355634957551956,
                "std": 0.21140846610069275,
                "max": 0.6703770756721497,
                "min": -0.9118677377700806,
                "frobenius_norm": 3.002765417098999,
                "spectral_norm": 1.7069075107574463,
                "num_singular_values": 12,
                "alpha": 1.2771426298872801
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.023493541404604912,
                "median": 0.02481921948492527,
                "std": 0.19993668794631958,
                "max": 0.680351197719574,
                "min": -0.4655080735683441,
                "frobenius_norm": 3.220996141433716,
                "spectral_norm": 1.9491074085235596,
                "num_singular_values": 16,
                "alpha": 1.0884618246358353
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.015157121233642101,
                "median": -0.02627767249941826,
                "std": 0.18407583236694336,
                "max": 0.44600793719291687,
                "min": -0.5918899774551392,
                "frobenius_norm": 2.955181121826172,
                "spectral_norm": 1.7397422790527344,
                "num_singular_values": 16,
                "alpha": 1.1210974757690002
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.019226131960749626,
                "median": 0.024163903668522835,
                "std": 0.1436663419008255,
                "max": 0.3504399061203003,
                "min": -0.2658322751522064,
                "frobenius_norm": 1.6398892402648926,
                "spectral_norm": 0.8711735010147095,
                "num_singular_values": 8,
                "alpha": 1.842473845940872
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.001_batch_size_128_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 128,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.08097314089536667,
            "mse": 489739488.0,
            "mae": 2008.07861328125,
            "r2_score": 0.8942095041275024,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.03880281373858452,
                "median": 0.04074421897530556,
                "std": 0.17528767883777618,
                "max": 0.41342639923095703,
                "min": -0.3638803958892822,
                "frobenius_norm": 2.487656354904175,
                "spectral_norm": 1.162514567375183,
                "num_singular_values": 12,
                "alpha": 1.2774709501155521
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.07044587284326553,
                "median": 0.06271623820066452,
                "std": 0.18124400079250336,
                "max": 0.5479856729507446,
                "min": -0.37680089473724365,
                "frobenius_norm": 3.1112494468688965,
                "spectral_norm": 2.0648887157440186,
                "num_singular_values": 16,
                "alpha": 1.132619649274685
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.03496066853404045,
                "median": 0.02842598780989647,
                "std": 0.18134242296218872,
                "max": 0.4861434996128082,
                "min": -0.46939361095428467,
                "frobenius_norm": 2.954906940460205,
                "spectral_norm": 1.9499387741088867,
                "num_singular_values": 16,
                "alpha": 1.1219203573042398
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.045860256999731064,
                "median": 0.03803279623389244,
                "std": 0.1552073210477829,
                "max": 0.35361969470977783,
                "min": -0.22533026337623596,
                "frobenius_norm": 1.8310205936431885,
                "spectral_norm": 1.086888074874878,
                "num_singular_values": 8,
                "alpha": 1.7009107829838568
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.001_batch_size_128_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 128,
            "scaler_type": "standard",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07383040338754654,
            "mse": 447989024.0,
            "mae": 2029.78564453125,
            "r2_score": 0.903228223323822,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.041207101196050644,
                "median": 0.027730297297239304,
                "std": 0.2483615279197693,
                "max": 1.1467217206954956,
                "min": -0.7023488879203796,
                "frobenius_norm": 3.4884440898895264,
                "spectral_norm": 1.9258869886398315,
                "num_singular_values": 12,
                "alpha": 1.2671354814532485
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.034751273691654205,
                "median": 0.0455121174454689,
                "std": 0.29740849137306213,
                "max": 0.7939973473548889,
                "min": -0.8191387057304382,
                "frobenius_norm": 4.790910720825195,
                "spectral_norm": 2.6485915184020996,
                "num_singular_values": 16,
                "alpha": 1.1169822529098106
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.004502052441239357,
                "median": -0.004960466641932726,
                "std": 0.2368992120027542,
                "max": 0.944571852684021,
                "min": -0.5489916205406189,
                "frobenius_norm": 3.791071653366089,
                "spectral_norm": 2.314056634902954,
                "num_singular_values": 16,
                "alpha": 1.2789373424697914
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.025736156851053238,
                "median": 0.020846989005804062,
                "std": 0.1605597883462906,
                "max": 0.546701967716217,
                "min": -0.24578969180583954,
                "frobenius_norm": 1.839714527130127,
                "spectral_norm": 1.1501342058181763,
                "num_singular_values": 8,
                "alpha": 1.6416085816178343
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.001_batch_size_128_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 128,
            "scaler_type": "robust",
            "total_params": 888
        },
        "scores": {
            "smape": 0.0733155906200409,
            "mse": 415048448.0,
            "mae": 1977.06689453125,
            "r2_score": 0.9103438258171082,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.053638312965631485,
                "median": 0.03473025932908058,
                "std": 0.252938449382782,
                "max": 0.7325796484947205,
                "min": -0.7771244049072266,
                "frobenius_norm": 3.582756519317627,
                "spectral_norm": 2.051603317260742,
                "num_singular_values": 12,
                "alpha": 1.2217869051035195
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.045043133199214935,
                "median": 0.06419718265533447,
                "std": 0.25427842140197754,
                "max": 0.7597249746322632,
                "min": -0.7546766996383667,
                "frobenius_norm": 4.13179349899292,
                "spectral_norm": 2.2641987800598145,
                "num_singular_values": 16,
                "alpha": 1.113167495879612
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.020358629524707794,
                "median": 0.01841406151652336,
                "std": 0.2261737436056137,
                "max": 0.8638126850128174,
                "min": -0.8457088470458984,
                "frobenius_norm": 3.633410692214966,
                "spectral_norm": 2.114793300628662,
                "num_singular_values": 16,
                "alpha": 1.1649457397840073
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.022669780999422073,
                "median": 0.02426396682858467,
                "std": 0.1803034096956253,
                "max": 0.5901132822036743,
                "min": -0.6447938084602356,
                "frobenius_norm": 2.0559606552124023,
                "spectral_norm": 1.2840275764465332,
                "num_singular_values": 8,
                "alpha": 1.6072887271409555
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.001_batch_size_128_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 128,
            "scaler_type": "minmax",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07735060155391693,
            "mse": 495950688.0,
            "mae": 2201.1796875,
            "r2_score": 0.8928678035736084,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.060665637254714966,
                "median": 0.05154164880514145,
                "std": 0.2152765542268753,
                "max": 0.7237520217895508,
                "min": -0.6561256647109985,
                "frobenius_norm": 3.099139928817749,
                "spectral_norm": 1.7853113412857056,
                "num_singular_values": 12,
                "alpha": 1.2089495573121354
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.022523202002048492,
                "median": 0.029940439388155937,
                "std": 0.1998600959777832,
                "max": 0.602201521396637,
                "min": -0.5505801439285278,
                "frobenius_norm": 3.218003511428833,
                "spectral_norm": 2.0014710426330566,
                "num_singular_values": 16,
                "alpha": 1.1419513602982392
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.015195959247648716,
                "median": -0.016463082283735275,
                "std": 0.18481436371803284,
                "max": 0.43205514550209045,
                "min": -0.5356197953224182,
                "frobenius_norm": 2.967008590698242,
                "spectral_norm": 1.7709044218063354,
                "num_singular_values": 16,
                "alpha": 1.20757434145924
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.012353189289569855,
                "median": 0.00966989528387785,
                "std": 0.1455123871564865,
                "max": 0.34678277373313904,
                "min": -0.25694388151168823,
                "frobenius_norm": 1.6522064208984375,
                "spectral_norm": 0.8814172744750977,
                "num_singular_values": 8,
                "alpha": 1.7127799556643333
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.001_batch_size_256_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 256,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.08103159070014954,
            "mse": 495555712.0,
            "mae": 2025.6956787109375,
            "r2_score": 0.8929531574249268,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.03681834042072296,
                "median": 0.040081098675727844,
                "std": 0.17606042325496674,
                "max": 0.4060845673084259,
                "min": -0.3411109447479248,
                "frobenius_norm": 2.492338180541992,
                "spectral_norm": 1.155198574066162,
                "num_singular_values": 12,
                "alpha": 1.272620055047951
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.06442736089229584,
                "median": 0.06437181681394577,
                "std": 0.18099583685398102,
                "max": 0.5090928077697754,
                "min": -0.4392680525779724,
                "frobenius_norm": 3.073931932449341,
                "spectral_norm": 1.84830641746521,
                "num_singular_values": 16,
                "alpha": 1.202557997887685
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.041293926537036896,
                "median": 0.0453743040561676,
                "std": 0.18752728402614594,
                "max": 0.6024846434593201,
                "min": -0.6503326296806335,
                "frobenius_norm": 3.072319269180298,
                "spectral_norm": 2.0764975547790527,
                "num_singular_values": 16,
                "alpha": 1.179260082960972
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.04703063890337944,
                "median": 0.04447052255272865,
                "std": 0.15452347695827484,
                "max": 0.34407496452331543,
                "min": -0.22721204161643982,
                "frobenius_norm": 1.82741379737854,
                "spectral_norm": 1.076371669769287,
                "num_singular_values": 8,
                "alpha": 1.760423577345406
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.001_batch_size_256_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 256,
            "scaler_type": "standard",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07368233054876328,
            "mse": 452211264.0,
            "mae": 2031.146240234375,
            "r2_score": 0.902316153049469,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.03964856639504433,
                "median": 0.03042871691286564,
                "std": 0.24185936152935028,
                "max": 1.089773178100586,
                "min": -0.6393440365791321,
                "frobenius_norm": 3.396034002304077,
                "spectral_norm": 1.8571900129318237,
                "num_singular_values": 12,
                "alpha": 1.2253184193867646
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.029603179544210434,
                "median": 0.04557172209024429,
                "std": 0.29310348629951477,
                "max": 0.7122554183006287,
                "min": -0.8250557780265808,
                "frobenius_norm": 4.71351432800293,
                "spectral_norm": 2.574112892150879,
                "num_singular_values": 16,
                "alpha": 1.1995959853490266
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.02408793941140175,
                "median": 0.02164587378501892,
                "std": 0.24743309617042542,
                "max": 0.8473103642463684,
                "min": -0.6222608089447021,
                "frobenius_norm": 3.9776453971862793,
                "spectral_norm": 2.465715169906616,
                "num_singular_values": 16,
                "alpha": 1.1326154947842453
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.02684149704873562,
                "median": 0.01273813471198082,
                "std": 0.16618458926677704,
                "max": 0.5050854682922363,
                "min": -0.2516061067581177,
                "frobenius_norm": 1.90453040599823,
                "spectral_norm": 1.1822484731674194,
                "num_singular_values": 8,
                "alpha": 1.6885137580316316
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.001_batch_size_256_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 256,
            "scaler_type": "robust",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07306499034166336,
            "mse": 424602080.0,
            "mae": 1979.86181640625,
            "r2_score": 0.908280074596405,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.05221330747008324,
                "median": 0.02958022989332676,
                "std": 0.26012805104255676,
                "max": 0.7873260378837585,
                "min": -0.669736921787262,
                "frobenius_norm": 3.676332712173462,
                "spectral_norm": 2.104797124862671,
                "num_singular_values": 12,
                "alpha": 1.2790593764015603
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.026796981692314148,
                "median": 0.04463408142328262,
                "std": 0.2748808264732361,
                "max": 0.7813496589660645,
                "min": -0.8604867458343506,
                "frobenius_norm": 4.418941974639893,
                "spectral_norm": 2.4558818340301514,
                "num_singular_values": 16,
                "alpha": 1.1335574532804025
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.04128831624984741,
                "median": 0.036008525639772415,
                "std": 0.23920664191246033,
                "max": 0.8125057220458984,
                "min": -0.6128081679344177,
                "frobenius_norm": 3.8839004039764404,
                "spectral_norm": 2.1974940299987793,
                "num_singular_values": 16,
                "alpha": 1.0806622811818205
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.014420188032090664,
                "median": 0.00654218764975667,
                "std": 0.18738257884979248,
                "max": 0.5794569253921509,
                "min": -0.7076964974403381,
                "frobenius_norm": 2.1262600421905518,
                "spectral_norm": 1.3122637271881104,
                "num_singular_values": 8,
                "alpha": 1.5272848537664379
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.001_batch_size_256_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 256,
            "scaler_type": "minmax",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07636947184801102,
            "mse": 500119808.0,
            "mae": 2176.204833984375,
            "r2_score": 0.891967236995697,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.05601160600781441,
                "median": 0.05228554457426071,
                "std": 0.2170870155096054,
                "max": 0.8188046216964722,
                "min": -0.6061964631080627,
                "frobenius_norm": 3.106557846069336,
                "spectral_norm": 1.7958792448043823,
                "num_singular_values": 12,
                "alpha": 1.189494646305908
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.018449943512678146,
                "median": 0.013747015967965126,
                "std": 0.21753138303756714,
                "max": 0.7521485686302185,
                "min": -0.6927586793899536,
                "frobenius_norm": 3.4929983615875244,
                "spectral_norm": 2.2933571338653564,
                "num_singular_values": 16,
                "alpha": 1.1703853737261931
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.0006461814045906067,
                "median": -0.014093716628849506,
                "std": 0.20830394327640533,
                "max": 0.7779402136802673,
                "min": -0.6215611100196838,
                "frobenius_norm": 3.3328793048858643,
                "spectral_norm": 2.212799549102783,
                "num_singular_values": 16,
                "alpha": 1.189840499694954
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.014347412623465061,
                "median": 0.027873750776052475,
                "std": 0.14551714062690735,
                "max": 0.35560372471809387,
                "min": -0.26627206802368164,
                "frobenius_norm": 1.6543214321136475,
                "spectral_norm": 0.8500970602035522,
                "num_singular_values": 8,
                "alpha": 1.864602924066351
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.0005_batch_size_16_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.08564334362745285,
            "mse": 497664704.0,
            "mae": 2065.21435546875,
            "r2_score": 0.8924975395202637,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.04486893489956856,
                "median": 0.052869416773319244,
                "std": 0.16901527345180511,
                "max": 0.38090941309928894,
                "min": -0.30938786268234253,
                "frobenius_norm": 2.423064708709717,
                "spectral_norm": 1.0929020643234253,
                "num_singular_values": 12,
                "alpha": 1.2752824150881588
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.06082000583410263,
                "median": 0.05180138349533081,
                "std": 0.1668774038553238,
                "max": 0.516556441783905,
                "min": -0.26210883259773254,
                "frobenius_norm": 2.8418424129486084,
                "spectral_norm": 1.8607232570648193,
                "num_singular_values": 16,
                "alpha": 1.2104001466020509
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.020867034792900085,
                "median": -0.0053940704092383385,
                "std": 0.16543808579444885,
                "max": 0.4802088737487793,
                "min": -0.28302666544914246,
                "frobenius_norm": 2.667982339859009,
                "spectral_norm": 1.5954047441482544,
                "num_singular_values": 16,
                "alpha": 1.1535303692697025
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.03393755853176117,
                "median": 0.03296133130788803,
                "std": 0.15104970335960388,
                "max": 0.3534546196460724,
                "min": -0.23338739573955536,
                "frobenius_norm": 1.7515350580215454,
                "spectral_norm": 0.9911055564880371,
                "num_singular_values": 8,
                "alpha": 1.76133960131378
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.0005_batch_size_16_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07447173446416855,
            "mse": 462592128.0,
            "mae": 2057.60107421875,
            "r2_score": 0.9000737071037292,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.029071496799588203,
                "median": 0.023615386337041855,
                "std": 0.21065084636211395,
                "max": 0.6168994903564453,
                "min": -0.4001445174217224,
                "frobenius_norm": 2.9465293884277344,
                "spectral_norm": 1.6239759922027588,
                "num_singular_values": 12,
                "alpha": 1.371289086184095
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.036682695150375366,
                "median": 0.04988706856966019,
                "std": 0.2205643206834793,
                "max": 0.6185904741287231,
                "min": -0.5955598950386047,
                "frobenius_norm": 3.577502727508545,
                "spectral_norm": 2.0580174922943115,
                "num_singular_values": 16,
                "alpha": 1.138770136975517
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.007918518967926502,
                "median": 0.004983055870980024,
                "std": 0.20021550357341766,
                "max": 0.587702214717865,
                "min": -0.5661090016365051,
                "frobenius_norm": 3.2059524059295654,
                "spectral_norm": 1.8905391693115234,
                "num_singular_values": 16,
                "alpha": 1.1690796851314573
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.028347909450531006,
                "median": 0.04479058086872101,
                "std": 0.15661264955997467,
                "max": 0.5101674199104309,
                "min": -0.2747909724712372,
                "frobenius_norm": 1.8006620407104492,
                "spectral_norm": 0.9925076365470886,
                "num_singular_values": 8,
                "alpha": 1.6684353947137964
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.0005_batch_size_16_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07286103069782257,
            "mse": 485881408.0,
            "mae": 2041.051025390625,
            "r2_score": 0.895042896270752,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.03716094419360161,
                "median": 0.04121757298707962,
                "std": 0.21739540994167328,
                "max": 0.6908726692199707,
                "min": -0.48306241631507874,
                "frobenius_norm": 3.056011199951172,
                "spectral_norm": 1.572218894958496,
                "num_singular_values": 12,
                "alpha": 1.3417541199137546
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.02569248154759407,
                "median": 0.02688405103981495,
                "std": 0.20352894067764282,
                "max": 0.5439273118972778,
                "min": -0.4821825623512268,
                "frobenius_norm": 3.2823069095611572,
                "spectral_norm": 1.9158989191055298,
                "num_singular_values": 16,
                "alpha": 1.2059177583061222
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.02742857113480568,
                "median": 0.04617968946695328,
                "std": 0.19405274093151093,
                "max": 0.5878552198410034,
                "min": -0.5197412371635437,
                "frobenius_norm": 3.1357059478759766,
                "spectral_norm": 1.8923487663269043,
                "num_singular_values": 16,
                "alpha": 1.1449506704118848
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.03565719723701477,
                "median": 0.03672470152378082,
                "std": 0.16359320282936096,
                "max": 0.4844852089881897,
                "min": -0.45179519057273865,
                "frobenius_norm": 1.8943004608154297,
                "spectral_norm": 1.080626130104065,
                "num_singular_values": 8,
                "alpha": 1.7116451029229993
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.0005_batch_size_16_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07868815213441849,
            "mse": 498640640.0,
            "mae": 2211.529052734375,
            "r2_score": 0.8922867774963379,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.05702871084213257,
                "median": 0.05622938275337219,
                "std": 0.19122493267059326,
                "max": 0.5418919324874878,
                "min": -0.4261566996574402,
                "frobenius_norm": 2.765012741088867,
                "spectral_norm": 1.5793991088867188,
                "num_singular_values": 12,
                "alpha": 1.1788912657962323
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.020616941154003143,
                "median": 0.019567474722862244,
                "std": 0.1900186836719513,
                "max": 0.4324503540992737,
                "min": -0.6674138903617859,
                "frobenius_norm": 3.0581419467926025,
                "spectral_norm": 1.765458345413208,
                "num_singular_values": 16,
                "alpha": 1.1163600436172763
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.008141680620610714,
                "median": -0.010415658354759216,
                "std": 0.17319777607917786,
                "max": 0.535881757736206,
                "min": -0.5503812432289124,
                "frobenius_norm": 2.774224281311035,
                "spectral_norm": 1.6171529293060303,
                "num_singular_values": 16,
                "alpha": 1.1308375447561918
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.013615728355944157,
                "median": 0.0269794724881649,
                "std": 0.1466580629348755,
                "max": 0.3942669630050659,
                "min": -0.27422770857810974,
                "frobenius_norm": 1.666382074356079,
                "spectral_norm": 0.8783631920814514,
                "num_singular_values": 8,
                "alpha": 1.8351239640539039
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.0005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.0848459005355835,
            "mse": 500581056.0,
            "mae": 2093.262939453125,
            "r2_score": 0.8918675780296326,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.044944390654563904,
                "median": 0.05326882004737854,
                "std": 0.1701819747686386,
                "max": 0.3794958293437958,
                "min": -0.3164544999599457,
                "frobenius_norm": 2.438960075378418,
                "spectral_norm": 1.1411794424057007,
                "num_singular_values": 12,
                "alpha": 1.286738514971351
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.06165856495499611,
                "median": 0.0518372505903244,
                "std": 0.16861553490161896,
                "max": 0.495637983083725,
                "min": -0.2948192358016968,
                "frobenius_norm": 2.8725674152374268,
                "spectral_norm": 1.8560250997543335,
                "num_singular_values": 16,
                "alpha": 1.1229449071003381
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.03760373964905739,
                "median": 0.038507457822561264,
                "std": 0.17771142721176147,
                "max": 0.4985377788543701,
                "min": -0.2900792956352234,
                "frobenius_norm": 2.906341314315796,
                "spectral_norm": 1.9480080604553223,
                "num_singular_values": 16,
                "alpha": 1.134899467343136
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.041033267974853516,
                "median": 0.04370635002851486,
                "std": 0.15532097220420837,
                "max": 0.34625279903411865,
                "min": -0.23471415042877197,
                "frobenius_norm": 1.8175441026687622,
                "spectral_norm": 1.0585507154464722,
                "num_singular_values": 8,
                "alpha": 1.7275509979318164
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.0005_batch_size_32_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07450076192617416,
            "mse": 464870208.0,
            "mae": 2058.93408203125,
            "r2_score": 0.8995816111564636,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.0314953587949276,
                "median": 0.022243911400437355,
                "std": 0.21314074099063873,
                "max": 0.629777729511261,
                "min": -0.529615044593811,
                "frobenius_norm": 2.985434055328369,
                "spectral_norm": 1.704859733581543,
                "num_singular_values": 12,
                "alpha": 1.2129849731144322
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.031188903376460075,
                "median": 0.04377823323011398,
                "std": 0.22781682014465332,
                "max": 0.5738039016723633,
                "min": -0.6806607246398926,
                "frobenius_norm": 3.6790695190429688,
                "spectral_norm": 2.124401807785034,
                "num_singular_values": 16,
                "alpha": 1.1855085044244313
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.008885249495506287,
                "median": 0.015603233128786087,
                "std": 0.19775865972042084,
                "max": 0.6132397055625916,
                "min": -0.4714418649673462,
                "frobenius_norm": 3.167330503463745,
                "spectral_norm": 1.9136743545532227,
                "num_singular_values": 16,
                "alpha": 1.2083431085954415
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.026390204206109047,
                "median": 0.01741790398955345,
                "std": 0.1560199111700058,
                "max": 0.4570850431919098,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.7902368307113647,
                "spectral_norm": 0.9384961724281311,
                "num_singular_values": 8,
                "alpha": 1.856737123715119
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.0005_batch_size_32_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07316938787698746,
            "mse": 468097088.0,
            "mae": 2055.036376953125,
            "r2_score": 0.8988845944404602,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.04461797699332237,
                "median": 0.04528695344924927,
                "std": 0.2239905446767807,
                "max": 0.7993483543395996,
                "min": -0.515855073928833,
                "frobenius_norm": 3.1646811962127686,
                "spectral_norm": 1.6865184307098389,
                "num_singular_values": 12,
                "alpha": 1.276415285698561
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.03260750323534012,
                "median": 0.04257243126630783,
                "std": 0.20750977098941803,
                "max": 0.5779412984848022,
                "min": -0.5426074862480164,
                "frobenius_norm": 3.3608973026275635,
                "spectral_norm": 1.8737738132476807,
                "num_singular_values": 16,
                "alpha": 1.1251675865402546
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.02715977281332016,
                "median": 0.03751291707158089,
                "std": 0.19643664360046387,
                "max": 0.6213241219520569,
                "min": -0.5453251004219055,
                "frobenius_norm": 3.1728854179382324,
                "spectral_norm": 1.8759934902191162,
                "num_singular_values": 16,
                "alpha": 1.1296313359782042
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.04035795480012894,
                "median": 0.0360284224152565,
                "std": 0.1677977442741394,
                "max": 0.5253576040267944,
                "min": -0.3848477602005005,
                "frobenius_norm": 1.952552318572998,
                "spectral_norm": 1.1485744714736938,
                "num_singular_values": 8,
                "alpha": 1.681165237852714
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.0005_batch_size_32_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07898655533790588,
            "mse": 467772864.0,
            "mae": 2209.099365234375,
            "r2_score": 0.8989546298980713,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.062457989901304245,
                "median": 0.07360818982124329,
                "std": 0.1879013627767563,
                "max": 0.5114348530769348,
                "min": -0.41063451766967773,
                "frobenius_norm": 2.7437057495117188,
                "spectral_norm": 1.5187894105911255,
                "num_singular_values": 12,
                "alpha": 1.2474653103966853
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.024434350430965424,
                "median": 0.008007552474737167,
                "std": 0.18357887864112854,
                "max": 0.53061443567276,
                "min": -0.4385591149330139,
                "frobenius_norm": 2.963165521621704,
                "spectral_norm": 1.7921875715255737,
                "num_singular_values": 16,
                "alpha": 1.1065158308083252
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.00611701188609004,
                "median": -0.011897217482328415,
                "std": 0.1773836314678192,
                "max": 0.4736589789390564,
                "min": -0.5350612998008728,
                "frobenius_norm": 2.839825391769409,
                "spectral_norm": 1.6601662635803223,
                "num_singular_values": 16,
                "alpha": 1.1487811528674792
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.017043955624103546,
                "median": 0.025614213198423386,
                "std": 0.149360790848732,
                "max": 0.39399856328964233,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.7007910013198853,
                "spectral_norm": 0.8886407613754272,
                "num_singular_values": 8,
                "alpha": 1.8987249751693902
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.0005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.08148495852947235,
            "mse": 494606976.0,
            "mae": 2055.677001953125,
            "r2_score": 0.8931580781936646,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.046334266662597656,
                "median": 0.05355644226074219,
                "std": 0.1702709048986435,
                "max": 0.3902720808982849,
                "min": -0.31379759311676025,
                "frobenius_norm": 2.4451375007629395,
                "spectral_norm": 1.1480722427368164,
                "num_singular_values": 12,
                "alpha": 1.277592400606503
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.06379774212837219,
                "median": 0.05850718915462494,
                "std": 0.17261116206645966,
                "max": 0.5371763706207275,
                "min": -0.29853543639183044,
                "frobenius_norm": 2.944380760192871,
                "spectral_norm": 1.909238338470459,
                "num_singular_values": 16,
                "alpha": 1.1051007111408055
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.03755262494087219,
                "median": 0.033533453941345215,
                "std": 0.1788664013147354,
                "max": 0.5340924859046936,
                "min": -0.28738316893577576,
                "frobenius_norm": 2.924255132675171,
                "spectral_norm": 1.9701745510101318,
                "num_singular_values": 16,
                "alpha": 1.1412552092984862
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.04037634655833244,
                "median": 0.03866177424788475,
                "std": 0.15497227013111115,
                "max": 0.35035884380340576,
                "min": -0.23562656342983246,
                "frobenius_norm": 1.8118422031402588,
                "spectral_norm": 1.0582830905914307,
                "num_singular_values": 8,
                "alpha": 1.7289540926752456
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.0005_batch_size_64_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "standard",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07438284903764725,
            "mse": 467013216.0,
            "mae": 2059.0791015625,
            "r2_score": 0.8991187214851379,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.0323542021214962,
                "median": 0.023768747225403786,
                "std": 0.21938270330429077,
                "max": 0.6427653431892395,
                "min": -0.5929877758026123,
                "frobenius_norm": 3.0727365016937256,
                "spectral_norm": 1.7251118421554565,
                "num_singular_values": 12,
                "alpha": 1.2594056691121438
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.04163859039545059,
                "median": 0.059330835938453674,
                "std": 0.23666445910930634,
                "max": 0.6884292960166931,
                "min": -0.7097088694572449,
                "frobenius_norm": 3.8447916507720947,
                "spectral_norm": 2.2062277793884277,
                "num_singular_values": 16,
                "alpha": 1.141720051594774
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.01570935733616352,
                "median": 0.007930304855108261,
                "std": 0.20346276462078094,
                "max": 0.6560375094413757,
                "min": -0.5868819355964661,
                "frobenius_norm": 3.2650933265686035,
                "spectral_norm": 1.996156096458435,
                "num_singular_values": 16,
                "alpha": 1.1452984206259549
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.022274252027273178,
                "median": 0.015585317276418209,
                "std": 0.15556533634662628,
                "max": 0.4838067293167114,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.7779706716537476,
                "spectral_norm": 0.9813368320465088,
                "num_singular_values": 8,
                "alpha": 1.667886640127182
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.0005_batch_size_64_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "robust",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07320583611726761,
            "mse": 501708096.0,
            "mae": 2078.351318359375,
            "r2_score": 0.8916241526603699,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.04151487722992897,
                "median": 0.032925594598054886,
                "std": 0.22554990649223328,
                "max": 0.7437214255332947,
                "min": -0.5788533091545105,
                "frobenius_norm": 3.1778106689453125,
                "spectral_norm": 1.6916712522506714,
                "num_singular_values": 12,
                "alpha": 1.2704532131592905
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.03311149775981903,
                "median": 0.03724158555269241,
                "std": 0.2180800586938858,
                "max": 0.553193986415863,
                "min": -0.6076434254646301,
                "frobenius_norm": 3.529270887374878,
                "spectral_norm": 2.0698626041412354,
                "num_singular_values": 16,
                "alpha": 1.1946278492994356
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.03221110999584198,
                "median": 0.040311165153980255,
                "std": 0.19420306384563446,
                "max": 0.6482110619544983,
                "min": -0.45104220509529114,
                "frobenius_norm": 3.149700164794922,
                "spectral_norm": 1.8967945575714111,
                "num_singular_values": 16,
                "alpha": 1.1523837853479657
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.035545967519283295,
                "median": 0.034313734620809555,
                "std": 0.1628819704055786,
                "max": 0.46020692586898804,
                "min": -0.2516006529331207,
                "frobenius_norm": 1.8861703872680664,
                "spectral_norm": 1.1223697662353516,
                "num_singular_values": 8,
                "alpha": 1.7669025339107223
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.0005_batch_size_64_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "minmax",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07823291420936584,
            "mse": 474033792.0,
            "mae": 2197.508056640625,
            "r2_score": 0.8976022005081177,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.05686339735984802,
                "median": 0.0626474991440773,
                "std": 0.18937411904335022,
                "max": 0.535468339920044,
                "min": -0.4060803949832916,
                "frobenius_norm": 2.7397871017456055,
                "spectral_norm": 1.5282565355300903,
                "num_singular_values": 12,
                "alpha": 1.2079404538017642
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.02584158442914486,
                "median": 0.026317261159420013,
                "std": 0.1898069679737091,
                "max": 0.47692379355430603,
                "min": -0.6128503084182739,
                "frobenius_norm": 3.0649282932281494,
                "spectral_norm": 1.8740875720977783,
                "num_singular_values": 16,
                "alpha": 1.171706146452695
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.005576631054282188,
                "median": -0.011693950742483139,
                "std": 0.1772734373807907,
                "max": 0.4686329662799835,
                "min": -0.5602096319198608,
                "frobenius_norm": 2.837778091430664,
                "spectral_norm": 1.6535842418670654,
                "num_singular_values": 16,
                "alpha": 1.175071232801923
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.01470951922237873,
                "median": 0.02987373247742653,
                "std": 0.14755879342556,
                "max": 0.37088486552238464,
                "min": -0.2564578950405121,
                "frobenius_norm": 1.6777114868164062,
                "spectral_norm": 0.8898655772209167,
                "num_singular_values": 8,
                "alpha": 1.8040830992811592
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.0005_batch_size_128_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 128,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.08221692591905594,
            "mse": 488072288.0,
            "mae": 2053.26513671875,
            "r2_score": 0.8945696353912354,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.04701641574501991,
                "median": 0.05109094828367233,
                "std": 0.1717492640018463,
                "max": 0.3952263593673706,
                "min": -0.29188424348831177,
                "frobenius_norm": 2.4673879146575928,
                "spectral_norm": 1.139709234237671,
                "num_singular_values": 12,
                "alpha": 1.2775072114084476
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.06412429362535477,
                "median": 0.060348473489284515,
                "std": 0.1721431314945221,
                "max": 0.48637470602989197,
                "min": -0.3021397888660431,
                "frobenius_norm": 2.939177989959717,
                "spectral_norm": 1.8794344663619995,
                "num_singular_values": 16,
                "alpha": 1.1251965912550455
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.037859268486499786,
                "median": 0.03814295306801796,
                "std": 0.18025551736354828,
                "max": 0.4988628923892975,
                "min": -0.3757949471473694,
                "frobenius_norm": 2.947014570236206,
                "spectral_norm": 1.9943053722381592,
                "num_singular_values": 16,
                "alpha": 1.082642014352652
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.03951301798224449,
                "median": 0.03739510476589203,
                "std": 0.15505367517471313,
                "max": 0.3499605357646942,
                "min": -0.23420768976211548,
                "frobenius_norm": 1.8102965354919434,
                "spectral_norm": 1.0513168573379517,
                "num_singular_values": 8,
                "alpha": 1.7278193217875701
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.0005_batch_size_128_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 128,
            "scaler_type": "standard",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07383067905902863,
            "mse": 447932288.0,
            "mae": 2030.094970703125,
            "r2_score": 0.903240442276001,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.02773996628820896,
                "median": 0.021287458017468452,
                "std": 0.2240958958864212,
                "max": 0.6407561898231506,
                "min": -0.47810882329940796,
                "frobenius_norm": 3.1288633346557617,
                "spectral_norm": 1.7002519369125366,
                "num_singular_values": 12,
                "alpha": 1.278786317744366
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.035258013755083084,
                "median": 0.035521894693374634,
                "std": 0.2431824803352356,
                "max": 0.6850380897521973,
                "min": -0.6728337407112122,
                "frobenius_norm": 3.9316020011901855,
                "spectral_norm": 2.2717783451080322,
                "num_singular_values": 16,
                "alpha": 1.149918391663935
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0008254437707364559,
                "median": -0.015502048656344414,
                "std": 0.20392011106014252,
                "max": 0.6440276503562927,
                "min": -0.6326706409454346,
                "frobenius_norm": 3.2627484798431396,
                "spectral_norm": 1.8949118852615356,
                "num_singular_values": 16,
                "alpha": 1.1578072748830888
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.023773975670337677,
                "median": 0.03865891695022583,
                "std": 0.15190429985523224,
                "max": 0.4353186786174774,
                "min": -0.24323056638240814,
                "frobenius_norm": 1.7395215034484863,
                "spectral_norm": 1.0343655347824097,
                "num_singular_values": 8,
                "alpha": 1.7359127825508809
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.0005_batch_size_128_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 128,
            "scaler_type": "robust",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07334378361701965,
            "mse": 469138976.0,
            "mae": 2039.47509765625,
            "r2_score": 0.8986595273017883,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.04752683639526367,
                "median": 0.05178341269493103,
                "std": 0.2299342304468155,
                "max": 0.6675328612327576,
                "min": -0.5382012128829956,
                "frobenius_norm": 3.253410816192627,
                "spectral_norm": 1.8463798761367798,
                "num_singular_values": 12,
                "alpha": 1.230371711323416
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0411459319293499,
                "median": 0.05951819568872452,
                "std": 0.22246135771274567,
                "max": 0.5865870714187622,
                "min": -0.5932793021202087,
                "frobenius_norm": 3.6197519302368164,
                "spectral_norm": 2.0471415519714355,
                "num_singular_values": 16,
                "alpha": 1.1250872510678127
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.012219907715916634,
                "median": 0.015216386877000332,
                "std": 0.19762197136878967,
                "max": 0.6230344772338867,
                "min": -0.44205838441848755,
                "frobenius_norm": 3.1679909229278564,
                "spectral_norm": 1.917828917503357,
                "num_singular_values": 16,
                "alpha": 1.1887614723175606
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.026431672275066376,
                "median": 0.02136077731847763,
                "std": 0.15842705965042114,
                "max": 0.4591560363769531,
                "min": -0.26740485429763794,
                "frobenius_norm": 1.8171719312667847,
                "spectral_norm": 1.0656083822250366,
                "num_singular_values": 8,
                "alpha": 1.7167697813159182
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.0005_batch_size_128_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 128,
            "scaler_type": "minmax",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07817889750003815,
            "mse": 484619168.0,
            "mae": 2201.8447265625,
            "r2_score": 0.8953155875205994,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.057787101715803146,
                "median": 0.05827309191226959,
                "std": 0.19250881671905518,
                "max": 0.5675657391548157,
                "min": -0.4622969329357147,
                "frobenius_norm": 2.7850685119628906,
                "spectral_norm": 1.5551338195800781,
                "num_singular_values": 12,
                "alpha": 1.2179904056126507
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.025914054363965988,
                "median": 0.022087831050157547,
                "std": 0.19535419344902039,
                "max": 0.5134321451187134,
                "min": -0.5342832207679749,
                "frobenius_norm": 3.153047561645508,
                "spectral_norm": 2.0922961235046387,
                "num_singular_values": 16,
                "alpha": 1.216297811918497
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.00755919236689806,
                "median": -0.014929894357919693,
                "std": 0.17442211508750916,
                "max": 0.4513309895992279,
                "min": -0.4918120205402374,
                "frobenius_norm": 2.7933733463287354,
                "spectral_norm": 1.603481411933899,
                "num_singular_values": 16,
                "alpha": 1.190101105263367
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.012527723796665668,
                "median": 0.013062428683042526,
                "std": 0.1468634009361267,
                "max": 0.35745471715927124,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.6676039695739746,
                "spectral_norm": 0.8621038794517517,
                "num_singular_values": 8,
                "alpha": 1.756356997024482
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.0005_batch_size_256_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 256,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.08195620775222778,
            "mse": 493900448.0,
            "mae": 2062.109375,
            "r2_score": 0.8933107256889343,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.04253135994076729,
                "median": 0.04932092875242233,
                "std": 0.17208634316921234,
                "max": 0.3906353712081909,
                "min": -0.3164612948894501,
                "frobenius_norm": 2.4562458992004395,
                "spectral_norm": 1.1409871578216553,
                "num_singular_values": 12,
                "alpha": 1.2601472671624494
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.06441593170166016,
                "median": 0.06979067623615265,
                "std": 0.1706221103668213,
                "max": 0.49663880467414856,
                "min": -0.3077496290206909,
                "frobenius_norm": 2.91802978515625,
                "spectral_norm": 1.866234302520752,
                "num_singular_values": 16,
                "alpha": 1.099688003597067
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.04094389081001282,
                "median": 0.039873797446489334,
                "std": 0.17560701072216034,
                "max": 0.4970027208328247,
                "min": -0.3554824888706207,
                "frobenius_norm": 2.8850722312927246,
                "spectral_norm": 1.893880009651184,
                "num_singular_values": 16,
                "alpha": 1.1333514617834632
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.04085454344749451,
                "median": 0.03913606330752373,
                "std": 0.1554865837097168,
                "max": 0.34614884853363037,
                "min": -0.23013556003570557,
                "frobenius_norm": 1.8188408613204956,
                "spectral_norm": 1.0502707958221436,
                "num_singular_values": 8,
                "alpha": 1.7790320313987693
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.0005_batch_size_256_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 256,
            "scaler_type": "standard",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07354126870632172,
            "mse": 455799008.0,
            "mae": 2015.746337890625,
            "r2_score": 0.9015411138534546,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.0366264283657074,
                "median": 0.036222442984580994,
                "std": 0.22083744406700134,
                "max": 0.6748489737510681,
                "min": -0.4905875027179718,
                "frobenius_norm": 3.101813793182373,
                "spectral_norm": 1.688116192817688,
                "num_singular_values": 12,
                "alpha": 1.2854618251757
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.025251425802707672,
                "median": 0.019459277391433716,
                "std": 0.24711963534355164,
                "max": 0.7340969443321228,
                "min": -0.6674123406410217,
                "frobenius_norm": 3.9745028018951416,
                "spectral_norm": 2.290274143218994,
                "num_singular_values": 16,
                "alpha": 1.1946916131130265
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.019026167690753937,
                "median": 0.0011816741898655891,
                "std": 0.2071516066789627,
                "max": 0.644875168800354,
                "min": -0.5383516550064087,
                "frobenius_norm": 3.328376531600952,
                "spectral_norm": 2.061959981918335,
                "num_singular_values": 16,
                "alpha": 1.1850242930402137
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.03022199310362339,
                "median": 0.03349807485938072,
                "std": 0.15765056014060974,
                "max": 0.5195499062538147,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.81609046459198,
                "spectral_norm": 1.0408222675323486,
                "num_singular_values": 8,
                "alpha": 1.7446683729783836
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.0005_batch_size_256_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 256,
            "scaler_type": "robust",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07264533638954163,
            "mse": 470846304.0,
            "mae": 2030.6610107421875,
            "r2_score": 0.8982906937599182,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.04858449101448059,
                "median": 0.03732778877019882,
                "std": 0.22469466924667358,
                "max": 0.7051124572753906,
                "min": -0.5087873935699463,
                "frobenius_norm": 3.185411214828491,
                "spectral_norm": 1.69671630859375,
                "num_singular_values": 12,
                "alpha": 1.2679972574671772
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.043157074600458145,
                "median": 0.06299866735935211,
                "std": 0.22690358757972717,
                "max": 0.6189751625061035,
                "min": -0.5611278414726257,
                "frobenius_norm": 3.6955418586730957,
                "spectral_norm": 2.119473457336426,
                "num_singular_values": 16,
                "alpha": 1.1664474103799605
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.030579116195440292,
                "median": 0.03425242751836777,
                "std": 0.2083059400320053,
                "max": 0.6021842360496521,
                "min": -0.5100812911987305,
                "frobenius_norm": 3.3686153888702393,
                "spectral_norm": 2.001762866973877,
                "num_singular_values": 16,
                "alpha": 1.2348030785039479
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.03127220273017883,
                "median": 0.016404565423727036,
                "std": 0.16707810759544373,
                "max": 0.5426707863807678,
                "min": -0.30408066511154175,
                "frobenius_norm": 1.9230989217758179,
                "spectral_norm": 1.058370590209961,
                "num_singular_values": 8,
                "alpha": 1.619964392172907
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.0005_batch_size_256_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 256,
            "scaler_type": "minmax",
            "total_params": 888
        },
        "scores": {
            "smape": 0.0772569552063942,
            "mse": 493301888.0,
            "mae": 2173.1533203125,
            "r2_score": 0.8934400081634521,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.0605725534260273,
                "median": 0.073455810546875,
                "std": 0.20547345280647278,
                "max": 0.5749823451042175,
                "min": -0.49696600437164307,
                "frobenius_norm": 2.968259811401367,
                "spectral_norm": 1.7348719835281372,
                "num_singular_values": 12,
                "alpha": 1.1837698957686877
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.02551412209868431,
                "median": 0.02847675047814846,
                "std": 0.2006813883781433,
                "max": 0.6486949920654297,
                "min": -0.5667998790740967,
                "frobenius_norm": 3.236748695373535,
                "spectral_norm": 2.1281073093414307,
                "num_singular_values": 16,
                "alpha": 1.1560787545151288
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0017984823789447546,
                "median": -0.015367135405540466,
                "std": 0.17179620265960693,
                "max": 0.4748748242855072,
                "min": -0.4445893168449402,
                "frobenius_norm": 2.748889923095703,
                "spectral_norm": 1.5244102478027344,
                "num_singular_values": 16,
                "alpha": 1.1193947028047089
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.01788770966231823,
                "median": 0.024255890399217606,
                "std": 0.15214180946350098,
                "max": 0.3626021146774292,
                "min": -0.38833704590797424,
                "frobenius_norm": 1.7331442832946777,
                "spectral_norm": 0.8646587133407593,
                "num_singular_values": 8,
                "alpha": 1.7323961540153536
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.0001_batch_size_16_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.20205597579479218,
            "mse": 854250496.0,
            "mae": 3590.19970703125,
            "r2_score": 0.8154700994491577,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.04563739523291588,
                "median": 0.047924675047397614,
                "std": 0.16569888591766357,
                "max": 0.3626464307308197,
                "min": -0.2847929894924164,
                "frobenius_norm": 2.381484270095825,
                "spectral_norm": 1.1632294654846191,
                "num_singular_values": 12,
                "alpha": 1.2692617033218712
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.044816143810749054,
                "median": 0.036350686103105545,
                "std": 0.1522337794303894,
                "max": 0.34053993225097656,
                "min": -0.2587888240814209,
                "frobenius_norm": 2.539094924926758,
                "spectral_norm": 1.4059414863586426,
                "num_singular_values": 16,
                "alpha": 1.2054479111543117
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.011184151284396648,
                "median": -0.010920322500169277,
                "std": 0.1557978391647339,
                "max": 0.3261839747428894,
                "min": -0.28074344992637634,
                "frobenius_norm": 2.4991800785064697,
                "spectral_norm": 1.2851425409317017,
                "num_singular_values": 16,
                "alpha": 1.1738075601673454
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.026021389290690422,
                "median": 0.03841050714254379,
                "std": 0.15044339001178741,
                "max": 0.3258223235607147,
                "min": -0.23874320089817047,
                "frobenius_norm": 1.72734534740448,
                "spectral_norm": 0.9558378458023071,
                "num_singular_values": 8,
                "alpha": 1.7254110920489034
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.0001_batch_size_16_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07855668663978577,
            "mse": 406166432.0,
            "mae": 1980.206787109375,
            "r2_score": 0.9122624397277832,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.012611781246960163,
                "median": 0.02082783728837967,
                "std": 0.16870729625225067,
                "max": 0.3457101583480835,
                "min": -0.3023422062397003,
                "frobenius_norm": 2.3441996574401855,
                "spectral_norm": 1.05558180809021,
                "num_singular_values": 12,
                "alpha": 1.282115189119945
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.006949321366846561,
                "median": 0.00080155860632658,
                "std": 0.14721965789794922,
                "max": 0.30521833896636963,
                "min": -0.31015053391456604,
                "frobenius_norm": 2.358137369155884,
                "spectral_norm": 1.1569390296936035,
                "num_singular_values": 16,
                "alpha": 1.1424839977642367
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.012674633413553238,
                "median": -0.02814103290438652,
                "std": 0.14991474151611328,
                "max": 0.39007675647735596,
                "min": -0.31880608201026917,
                "frobenius_norm": 2.407193183898926,
                "spectral_norm": 1.0824828147888184,
                "num_singular_values": 16,
                "alpha": 1.1864536308076223
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.002926015295088291,
                "median": -0.012362810783088207,
                "std": 0.14284372329711914,
                "max": 0.34243613481521606,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.6164313554763794,
                "spectral_norm": 0.868350625038147,
                "num_singular_values": 8,
                "alpha": 1.6637844646624411
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.0001_batch_size_16_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 888
        },
        "scores": {
            "smape": 0.0781526267528534,
            "mse": 403525056.0,
            "mae": 1961.02490234375,
            "r2_score": 0.912833034992218,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.0162774957716465,
                "median": 0.026301968842744827,
                "std": 0.17073385417461395,
                "max": 0.36572012305259705,
                "min": -0.33229246735572815,
                "frobenius_norm": 2.3764851093292236,
                "spectral_norm": 1.0915148258209229,
                "num_singular_values": 12,
                "alpha": 1.2754025612358781
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.013196935877203941,
                "median": 0.0011097125243395567,
                "std": 0.14874587953090668,
                "max": 0.31964409351348877,
                "min": -0.31177014112472534,
                "frobenius_norm": 2.389282464981079,
                "spectral_norm": 1.1558499336242676,
                "num_singular_values": 16,
                "alpha": 1.1518074696885876
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.005135779269039631,
                "median": -0.014213785529136658,
                "std": 0.15035898983478546,
                "max": 0.36779239773750305,
                "min": -0.316272497177124,
                "frobenius_norm": 2.40714693069458,
                "spectral_norm": 1.1248997449874878,
                "num_singular_values": 16,
                "alpha": 1.22514646697509
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.0073708947747945786,
                "median": -0.001604743767529726,
                "std": 0.14707036316394806,
                "max": 0.28188467025756836,
                "min": -0.25021687150001526,
                "frobenius_norm": 1.6659996509552002,
                "spectral_norm": 0.8706973791122437,
                "num_singular_values": 8,
                "alpha": 1.6940414671545383
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.0001_batch_size_16_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 888
        },
        "scores": {
            "smape": 0.11817624419927597,
            "mse": 385771616.0,
            "mae": 2455.487548828125,
            "r2_score": 0.9166679978370667,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.041281167417764664,
                "median": 0.03779793158173561,
                "std": 0.17180153727531433,
                "max": 0.379434734582901,
                "min": -0.2682656943798065,
                "frobenius_norm": 2.448309898376465,
                "spectral_norm": 1.242724895477295,
                "num_singular_values": 12,
                "alpha": 1.2216366508544891
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.02971493825316429,
                "median": 0.037663739174604416,
                "std": 0.15227991342544556,
                "max": 0.3518529236316681,
                "min": -0.2548096179962158,
                "frobenius_norm": 2.4824323654174805,
                "spectral_norm": 1.2426828145980835,
                "num_singular_values": 16,
                "alpha": 1.1797656548511788
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.009877650067210197,
                "median": -0.03041166067123413,
                "std": 0.15144866704940796,
                "max": 0.41269662976264954,
                "min": -0.30734869837760925,
                "frobenius_norm": 2.4283270835876465,
                "spectral_norm": 1.1377224922180176,
                "num_singular_values": 16,
                "alpha": 1.1847405010639507
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.003935366868972778,
                "median": -0.004747351631522179,
                "std": 0.14454008638858795,
                "max": 0.3664794862270355,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.6358903646469116,
                "spectral_norm": 0.8735783696174622,
                "num_singular_values": 8,
                "alpha": 1.7180348550348623
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.0001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.1495596021413803,
            "mse": 713868800.0,
            "mae": 3044.33056640625,
            "r2_score": 0.8457944989204407,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.04723946750164032,
                "median": 0.05330487713217735,
                "std": 0.16588446497917175,
                "max": 0.36304983496665955,
                "min": -0.28750279545783997,
                "frobenius_norm": 2.3899476528167725,
                "spectral_norm": 1.173569917678833,
                "num_singular_values": 12,
                "alpha": 1.2719602548631916
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.04871634766459465,
                "median": 0.03753159940242767,
                "std": 0.15271349251270294,
                "max": 0.3377911150455475,
                "min": -0.25687137246131897,
                "frobenius_norm": 2.564730167388916,
                "spectral_norm": 1.447204828262329,
                "num_singular_values": 16,
                "alpha": 1.2155943439599526
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.013154960237443447,
                "median": -0.008322794921696186,
                "std": 0.1567240208387375,
                "max": 0.3281557261943817,
                "min": -0.28081291913986206,
                "frobenius_norm": 2.51640248298645,
                "spectral_norm": 1.32015860080719,
                "num_singular_values": 16,
                "alpha": 1.1551342568366236
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.02844844199717045,
                "median": 0.03151360899209976,
                "std": 0.15030893683433533,
                "max": 0.3375137448310852,
                "min": -0.23680950701236725,
                "frobenius_norm": 1.7307419776916504,
                "spectral_norm": 0.9608255624771118,
                "num_singular_values": 8,
                "alpha": 1.7596013724171706
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.0001_batch_size_32_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07840908318758011,
            "mse": 402510560.0,
            "mae": 1975.0709228515625,
            "r2_score": 0.9130522012710571,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.013214308768510818,
                "median": 0.021849490702152252,
                "std": 0.17105546593666077,
                "max": 0.35916295647621155,
                "min": -0.3179835081100464,
                "frobenius_norm": 2.3772759437561035,
                "spectral_norm": 1.0678460597991943,
                "num_singular_values": 12,
                "alpha": 1.2849133679081643
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.009267200715839863,
                "median": 0.0027536337729543447,
                "std": 0.1490952968597412,
                "max": 0.3157784044742584,
                "min": -0.3233287036418915,
                "frobenius_norm": 2.3901283740997314,
                "spectral_norm": 1.197454810142517,
                "num_singular_values": 16,
                "alpha": 1.1782654840186997
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.011402883566915989,
                "median": -0.026064135134220123,
                "std": 0.15160657465457916,
                "max": 0.4007427394390106,
                "min": -0.3197100758552551,
                "frobenius_norm": 2.4325568675994873,
                "spectral_norm": 1.111755132675171,
                "num_singular_values": 16,
                "alpha": 1.1986230295856477
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.005642798729240894,
                "median": -0.008632891811430454,
                "std": 0.14416953921318054,
                "max": 0.34939447045326233,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.6323411464691162,
                "spectral_norm": 0.8819891810417175,
                "num_singular_values": 8,
                "alpha": 1.6886871198492313
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.0001_batch_size_32_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07763294875621796,
            "mse": 412600768.0,
            "mae": 1978.0758056640625,
            "r2_score": 0.9108725786209106,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.017236048355698586,
                "median": 0.030772525817155838,
                "std": 0.1731507033109665,
                "max": 0.38197025656700134,
                "min": -0.34647947549819946,
                "frobenius_norm": 2.411104202270508,
                "spectral_norm": 1.1043177843093872,
                "num_singular_values": 12,
                "alpha": 1.2807671430184489
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.017081625759601593,
                "median": 0.007904940284788609,
                "std": 0.15066343545913696,
                "max": 0.3296535611152649,
                "min": -0.33675289154052734,
                "frobenius_norm": 2.426058769226074,
                "spectral_norm": 1.1920547485351562,
                "num_singular_values": 16,
                "alpha": 1.1237467943670514
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.001312904991209507,
                "median": -0.007577676326036453,
                "std": 0.1520695984363556,
                "max": 0.3866415321826935,
                "min": -0.32369163632392883,
                "frobenius_norm": 2.433204174041748,
                "spectral_norm": 1.1549253463745117,
                "num_singular_values": 16,
                "alpha": 1.2281892086129789
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.01325672585517168,
                "median": 0.001489217160269618,
                "std": 0.1483466923236847,
                "max": 0.32544809579849243,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.6850394010543823,
                "spectral_norm": 0.8822913765907288,
                "num_singular_values": 8,
                "alpha": 1.7042944540449758
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.0001_batch_size_32_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 888
        },
        "scores": {
            "smape": 0.11451387405395508,
            "mse": 390034624.0,
            "mae": 2424.3701171875,
            "r2_score": 0.9157471656799316,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.04225705936551094,
                "median": 0.03957681730389595,
                "std": 0.17210201919078827,
                "max": 0.37968945503234863,
                "min": -0.27275481820106506,
                "frobenius_norm": 2.45554780960083,
                "spectral_norm": 1.258452296257019,
                "num_singular_values": 12,
                "alpha": 1.2173232530980305
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.03234769403934479,
                "median": 0.041590724140405655,
                "std": 0.15238440036773682,
                "max": 0.35170355439186096,
                "min": -0.2544458508491516,
                "frobenius_norm": 2.492478609085083,
                "spectral_norm": 1.2582364082336426,
                "num_singular_values": 16,
                "alpha": 1.1782144534479784
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.009203864261507988,
                "median": -0.02918231673538685,
                "std": 0.15222959220409393,
                "max": 0.4147172272205353,
                "min": -0.30676034092903137,
                "frobenius_norm": 2.4401211738586426,
                "spectral_norm": 1.155838966369629,
                "num_singular_values": 16,
                "alpha": 1.1695083128612063
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.005642357282340527,
                "median": -0.003596838563680649,
                "std": 0.1448730230331421,
                "max": 0.3681850731372833,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.640293836593628,
                "spectral_norm": 0.8755670785903931,
                "num_singular_values": 8,
                "alpha": 1.746253587411226
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.0001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.09591913223266602,
            "mse": 537524352.0,
            "mae": 2303.052734375,
            "r2_score": 0.8838873505592346,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.051055267453193665,
                "median": 0.058113232254981995,
                "std": 0.16577790677547455,
                "max": 0.36552301049232483,
                "min": -0.28563612699508667,
                "frobenius_norm": 2.4035556316375732,
                "spectral_norm": 1.1861379146575928,
                "num_singular_values": 12,
                "alpha": 1.2756167845454494
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0527203306555748,
                "median": 0.04318871349096298,
                "std": 0.15394164621829987,
                "max": 0.3376568555831909,
                "min": -0.2604925334453583,
                "frobenius_norm": 2.603503465652466,
                "spectral_norm": 1.5122672319412231,
                "num_singular_values": 16,
                "alpha": 1.203361474320202
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.013382237404584885,
                "median": -0.00967794843018055,
                "std": 0.1574707329273224,
                "max": 0.32931751012802124,
                "min": -0.2791227400302887,
                "frobenius_norm": 2.5286130905151367,
                "spectral_norm": 1.3319437503814697,
                "num_singular_values": 16,
                "alpha": 1.1376666440221892
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.02785641700029373,
                "median": 0.030962053686380386,
                "std": 0.15013718605041504,
                "max": 0.3441253900527954,
                "min": -0.23520345985889435,
                "frobenius_norm": 1.7275984287261963,
                "spectral_norm": 0.9555882811546326,
                "num_singular_values": 8,
                "alpha": 1.7847542523946913
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.0001_batch_size_64_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "standard",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07836391031742096,
            "mse": 401101600.0,
            "mae": 1975.070068359375,
            "r2_score": 0.9133565425872803,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.013226356357336044,
                "median": 0.020938623696565628,
                "std": 0.17226848006248474,
                "max": 0.3615838587284088,
                "min": -0.3213947117328644,
                "frobenius_norm": 2.394047498703003,
                "spectral_norm": 1.085683822631836,
                "num_singular_values": 12,
                "alpha": 1.2839095455941039
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.009843184612691402,
                "median": 0.003407055279240012,
                "std": 0.14994080364704132,
                "max": 0.3209149241447449,
                "min": -0.3359566926956177,
                "frobenius_norm": 2.4042165279388428,
                "spectral_norm": 1.2180670499801636,
                "num_singular_values": 16,
                "alpha": 1.1493625560311491
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.01105986163020134,
                "median": -0.030286744236946106,
                "std": 0.152531236410141,
                "max": 0.402040958404541,
                "min": -0.32308274507522583,
                "frobenius_norm": 2.446906805038452,
                "spectral_norm": 1.1254305839538574,
                "num_singular_values": 16,
                "alpha": 1.2161022698940769
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.005889631807804108,
                "median": -0.009369302541017532,
                "std": 0.14438261091709137,
                "max": 0.3483584225177765,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.6348612308502197,
                "spectral_norm": 0.8893437385559082,
                "num_singular_values": 8,
                "alpha": 1.6986203941555802
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.0001_batch_size_64_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "robust",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07716710865497589,
            "mse": 423273920.0,
            "mae": 1984.329833984375,
            "r2_score": 0.9085670113563538,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.01688261143863201,
                "median": 0.02079758420586586,
                "std": 0.17440295219421387,
                "max": 0.38726311922073364,
                "min": -0.34758150577545166,
                "frobenius_norm": 2.427894353866577,
                "spectral_norm": 1.130972146987915,
                "num_singular_values": 12,
                "alpha": 1.2914920058584773
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.019638698548078537,
                "median": 0.01500927098095417,
                "std": 0.15211357176303864,
                "max": 0.33442747592926025,
                "min": -0.33085891604423523,
                "frobenius_norm": 2.454017162322998,
                "spectral_norm": 1.2278573513031006,
                "num_singular_values": 16,
                "alpha": 1.1374482397788759
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.00018482888117432594,
                "median": -0.0008233672706410289,
                "std": 0.15382152795791626,
                "max": 0.3888940215110779,
                "min": -0.3264153003692627,
                "frobenius_norm": 2.461146354675293,
                "spectral_norm": 1.1875873804092407,
                "num_singular_values": 16,
                "alpha": 1.1873430890349115
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.013356296345591545,
                "median": -0.0011425931006669998,
                "std": 0.14996419847011566,
                "max": 0.3188444674015045,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.703366994857788,
                "spectral_norm": 0.8862814903259277,
                "num_singular_values": 8,
                "alpha": 1.7076925082069687
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.0001_batch_size_64_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "minmax",
            "total_params": 888
        },
        "scores": {
            "smape": 0.11413300037384033,
            "mse": 392505888.0,
            "mae": 2424.856201171875,
            "r2_score": 0.9152133464813232,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.04270058870315552,
                "median": 0.03990423306822777,
                "std": 0.17224569618701935,
                "max": 0.3804871141910553,
                "min": -0.27284982800483704,
                "frobenius_norm": 2.4589526653289795,
                "spectral_norm": 1.2631771564483643,
                "num_singular_values": 12,
                "alpha": 1.2178107657908703
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.033106010407209396,
                "median": 0.04056696593761444,
                "std": 0.1524701565504074,
                "max": 0.3510896563529968,
                "min": -0.25423464179039,
                "frobenius_norm": 2.4963669776916504,
                "spectral_norm": 1.2613157033920288,
                "num_singular_values": 16,
                "alpha": 1.1806971678051446
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.009235636331140995,
                "median": -0.034074507653713226,
                "std": 0.15234485268592834,
                "max": 0.4105631709098816,
                "min": -0.30670255422592163,
                "frobenius_norm": 2.44199275970459,
                "spectral_norm": 1.1503465175628662,
                "num_singular_values": 16,
                "alpha": 1.1739804737525823
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.005268314387649298,
                "median": -0.002274898812174797,
                "std": 0.1448669731616974,
                "max": 0.3676239252090454,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.640066146850586,
                "spectral_norm": 0.8762381672859192,
                "num_singular_values": 8,
                "alpha": 1.7358964931149243
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.0001_batch_size_128_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 128,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.08569655567407608,
            "mse": 522642432.0,
            "mae": 2134.4052734375,
            "r2_score": 0.8871020078659058,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.0515686459839344,
                "median": 0.05875229090452194,
                "std": 0.16662436723709106,
                "max": 0.36671698093414307,
                "min": -0.2835816442966461,
                "frobenius_norm": 2.416861057281494,
                "spectral_norm": 1.2111910581588745,
                "num_singular_values": 12,
                "alpha": 1.273423731175983
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.053233664482831955,
                "median": 0.041746899485588074,
                "std": 0.15422645211219788,
                "max": 0.3399192690849304,
                "min": -0.2610904574394226,
                "frobenius_norm": 2.610483169555664,
                "spectral_norm": 1.5213316679000854,
                "num_singular_values": 16,
                "alpha": 1.198818433402553
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.013462679460644722,
                "median": -0.00948668085038662,
                "std": 0.15779179334640503,
                "max": 0.3301277756690979,
                "min": -0.2793017625808716,
                "frobenius_norm": 2.5338408946990967,
                "spectral_norm": 1.3379545211791992,
                "num_singular_values": 16,
                "alpha": 1.1210275227403423
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.027663670480251312,
                "median": 0.02493925765156746,
                "std": 0.1501939445734024,
                "max": 0.34355494379997253,
                "min": -0.23491820693016052,
                "frobenius_norm": 1.7278333902359009,
                "spectral_norm": 0.954946756362915,
                "num_singular_values": 8,
                "alpha": 1.7852094918804475
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.0001_batch_size_128_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 128,
            "scaler_type": "standard",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07828860729932785,
            "mse": 400301472.0,
            "mae": 1972.5384521484375,
            "r2_score": 0.9135293960571289,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.013411263935267925,
                "median": 0.01865762285888195,
                "std": 0.17334558069705963,
                "max": 0.37049663066864014,
                "min": -0.3212203085422516,
                "frobenius_norm": 2.4091248512268066,
                "spectral_norm": 1.0916043519973755,
                "num_singular_values": 12,
                "alpha": 1.2794093754229094
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.010098416358232498,
                "median": 0.0025585805997252464,
                "std": 0.1509609967470169,
                "max": 0.3243090510368347,
                "min": -0.3455578684806824,
                "frobenius_norm": 2.420774221420288,
                "spectral_norm": 1.239251971244812,
                "num_singular_values": 16,
                "alpha": 1.1316501627464217
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.010377490893006325,
                "median": -0.03070107474923134,
                "std": 0.1533190906047821,
                "max": 0.4088054299354553,
                "min": -0.3312179744243622,
                "frobenius_norm": 2.4587185382843018,
                "spectral_norm": 1.140142560005188,
                "num_singular_values": 16,
                "alpha": 1.2217646445083599
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.00672447495162487,
                "median": -0.008375898003578186,
                "std": 0.14409853518009186,
                "max": 0.35358384251594543,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.6320629119873047,
                "spectral_norm": 0.8789665699005127,
                "num_singular_values": 8,
                "alpha": 1.7086872089865035
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.0001_batch_size_128_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 128,
            "scaler_type": "robust",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07709053158760071,
            "mse": 406946720.0,
            "mae": 1966.2640380859375,
            "r2_score": 0.9120938777923584,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.018627164885401726,
                "median": 0.023849036544561386,
                "std": 0.17499978840351105,
                "max": 0.38898202776908875,
                "min": -0.3456529676914215,
                "frobenius_norm": 2.438565969467163,
                "spectral_norm": 1.1346657276153564,
                "num_singular_values": 12,
                "alpha": 1.3043045119359027
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.021597392857074738,
                "median": 0.01670749858021736,
                "std": 0.15280476212501526,
                "max": 0.33562013506889343,
                "min": -0.33278971910476685,
                "frobenius_norm": 2.4691760540008545,
                "spectral_norm": 1.2432352304458618,
                "num_singular_values": 16,
                "alpha": 1.1878720537737781
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.0015096038114279509,
                "median": -0.0009047818602994084,
                "std": 0.15451852977275848,
                "max": 0.393414705991745,
                "min": -0.33037713170051575,
                "frobenius_norm": 2.472414493560791,
                "spectral_norm": 1.218105435371399,
                "num_singular_values": 16,
                "alpha": 1.1741984479051664
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.01157696545124054,
                "median": 0.0020198810379952192,
                "std": 0.14872896671295166,
                "max": 0.2975994050502777,
                "min": -0.24309052526950836,
                "frobenius_norm": 1.687766194343567,
                "spectral_norm": 0.8690439462661743,
                "num_singular_values": 8,
                "alpha": 1.6950843467177765
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.0001_batch_size_128_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 128,
            "scaler_type": "minmax",
            "total_params": 888
        },
        "scores": {
            "smape": 0.11247075349092484,
            "mse": 390523968.0,
            "mae": 2397.3994140625,
            "r2_score": 0.9156414270401001,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.043985143303871155,
                "median": 0.04087185859680176,
                "std": 0.1726946383714676,
                "max": 0.38247954845428467,
                "min": -0.2775404155254364,
                "frobenius_norm": 2.4693241119384766,
                "spectral_norm": 1.281104564666748,
                "num_singular_values": 12,
                "alpha": 1.2148365095081997
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.03354142606258392,
                "median": 0.040852468460798264,
                "std": 0.15265406668186188,
                "max": 0.3547841012477875,
                "min": -0.2528843879699707,
                "frobenius_norm": 2.5007283687591553,
                "spectral_norm": 1.2845652103424072,
                "num_singular_values": 16,
                "alpha": 1.1653671332046356
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.008968373760581017,
                "median": -0.023120535537600517,
                "std": 0.15193946659564972,
                "max": 0.41244760155677795,
                "min": -0.3066745698451996,
                "frobenius_norm": 2.43526291847229,
                "spectral_norm": 1.151694655418396,
                "num_singular_values": 16,
                "alpha": 1.1746499179663659
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.004939940758049488,
                "median": -0.00360106467269361,
                "std": 0.14452536404132843,
                "max": 0.36826446652412415,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.6360727548599243,
                "spectral_norm": 0.875896155834198,
                "num_singular_values": 8,
                "alpha": 1.722947170213366
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.0001_batch_size_256_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 256,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.08411195129156113,
            "mse": 525158336.0,
            "mae": 2105.669921875,
            "r2_score": 0.8865585327148438,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.05083372816443443,
                "median": 0.0528329573571682,
                "std": 0.166579008102417,
                "max": 0.3674434423446655,
                "min": -0.28752601146698,
                "frobenius_norm": 2.413268804550171,
                "spectral_norm": 1.1950098276138306,
                "num_singular_values": 12,
                "alpha": 1.2744024295809728
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.055081628262996674,
                "median": 0.04972425103187561,
                "std": 0.15328349173069,
                "max": 0.3413325548171997,
                "min": -0.26069730520248413,
                "frobenius_norm": 2.6060760021209717,
                "spectral_norm": 1.5272785425186157,
                "num_singular_values": 16,
                "alpha": 1.1974592719514703
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.01691684126853943,
                "median": -0.00628703273832798,
                "std": 0.15847857296466827,
                "max": 0.32960861921310425,
                "min": -0.2821101248264313,
                "frobenius_norm": 2.550062656402588,
                "spectral_norm": 1.3799060583114624,
                "num_singular_values": 16,
                "alpha": 1.091911685986382
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.02770635485649109,
                "median": 0.023262493312358856,
                "std": 0.1499439924955368,
                "max": 0.34555646777153015,
                "min": -0.2352769523859024,
                "frobenius_norm": 1.725139856338501,
                "spectral_norm": 0.9549430012702942,
                "num_singular_values": 8,
                "alpha": 1.7873853976076624
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.0001_batch_size_256_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 256,
            "scaler_type": "standard",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07830710709095001,
            "mse": 398575136.0,
            "mae": 1971.994384765625,
            "r2_score": 0.9139022827148438,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.013783023692667484,
                "median": 0.018406083807349205,
                "std": 0.173478901386261,
                "max": 0.37104499340057373,
                "min": -0.32520362734794617,
                "frobenius_norm": 2.4113688468933105,
                "spectral_norm": 1.0918173789978027,
                "num_singular_values": 12,
                "alpha": 1.2803919662030545
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.01061946526169777,
                "median": 0.006742637604475021,
                "std": 0.15132300555706024,
                "max": 0.32566699385643005,
                "min": -0.34907811880111694,
                "frobenius_norm": 2.4271228313446045,
                "spectral_norm": 1.2388498783111572,
                "num_singular_values": 16,
                "alpha": 1.113632603478186
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.01051638089120388,
                "median": -0.028929833322763443,
                "std": 0.1534927636384964,
                "max": 0.4068310558795929,
                "min": -0.33465009927749634,
                "frobenius_norm": 2.461641788482666,
                "spectral_norm": 1.1449315547943115,
                "num_singular_values": 16,
                "alpha": 1.1808082987146367
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.0056630708277225494,
                "median": -0.011333784088492393,
                "std": 0.1434689164161682,
                "max": 0.35376042127609253,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.62442946434021,
                "spectral_norm": 0.8675440549850464,
                "num_singular_values": 8,
                "alpha": 1.6918699928454215
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.0001_batch_size_256_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 256,
            "scaler_type": "robust",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07702954858541489,
            "mse": 406635776.0,
            "mae": 1963.843994140625,
            "r2_score": 0.9121610522270203,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.018761759623885155,
                "median": 0.023615948855876923,
                "std": 0.17573797702789307,
                "max": 0.3900497853755951,
                "min": -0.3455541431903839,
                "frobenius_norm": 2.44893479347229,
                "spectral_norm": 1.1431961059570312,
                "num_singular_values": 12,
                "alpha": 1.273277544886335
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.02130787819623947,
                "median": 0.013810464181005955,
                "std": 0.1529611349105835,
                "max": 0.3327238857746124,
                "min": -0.3306739330291748,
                "frobenius_norm": 2.4710099697113037,
                "spectral_norm": 1.2567310333251953,
                "num_singular_values": 16,
                "alpha": 1.1339367905148785
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 8.641369640827179e-05,
                "median": 0.000550604541786015,
                "std": 0.15497319400310516,
                "max": 0.39580270648002625,
                "min": -0.3305593430995941,
                "frobenius_norm": 2.4795713424682617,
                "spectral_norm": 1.2137234210968018,
                "num_singular_values": 16,
                "alpha": 1.1561638678725932
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.011625535786151886,
                "median": -0.002521858550608158,
                "std": 0.14865246415138245,
                "max": 0.2982701361179352,
                "min": -0.24492692947387695,
                "frobenius_norm": 1.686945915222168,
                "spectral_norm": 0.8719324469566345,
                "num_singular_values": 8,
                "alpha": 1.6875044903252334
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_0.0001_batch_size_256_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 256,
            "scaler_type": "minmax",
            "total_params": 888
        },
        "scores": {
            "smape": 0.11210291087627411,
            "mse": 398872608.0,
            "mae": 2418.14697265625,
            "r2_score": 0.9138380289077759,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.04412379860877991,
                "median": 0.0399097315967083,
                "std": 0.17243874073028564,
                "max": 0.382271409034729,
                "min": -0.27387991547584534,
                "frobenius_norm": 2.4663636684417725,
                "spectral_norm": 1.276517629623413,
                "num_singular_values": 12,
                "alpha": 1.2150203268892337
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.03327242285013199,
                "median": 0.04260290414094925,
                "std": 0.15230657160282135,
                "max": 0.3547976613044739,
                "min": -0.253043532371521,
                "frobenius_norm": 2.4943761825561523,
                "spectral_norm": 1.2765036821365356,
                "num_singular_values": 16,
                "alpha": 1.1780456570142943
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.007953441701829433,
                "median": -0.025463920086622238,
                "std": 0.15277405083179474,
                "max": 0.4138559103012085,
                "min": -0.3063369393348694,
                "frobenius_norm": 2.447695016860962,
                "spectral_norm": 1.1673376560211182,
                "num_singular_values": 16,
                "alpha": 1.1622287121343933
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.00561425369232893,
                "median": -0.0028586285188794136,
                "std": 0.14436392486095428,
                "max": 0.3706812262535095,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.6345258951187134,
                "spectral_norm": 0.8784462213516235,
                "num_singular_values": 8,
                "alpha": 1.7061518604139867
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_5e-05_batch_size_16_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.6794470548629761,
            "mse": 3058960640.0,
            "mae": 8687.931640625,
            "r2_score": 0.33922237157821655,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.025575382634997368,
                "median": 0.028050342574715614,
                "std": 0.16462571918964386,
                "max": 0.33800697326660156,
                "min": -0.2887150049209595,
                "frobenius_norm": 2.3084843158721924,
                "spectral_norm": 1.0696319341659546,
                "num_singular_values": 12,
                "alpha": 1.261300256638329
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.02474777027964592,
                "median": 0.01276850700378418,
                "std": 0.14816969633102417,
                "max": 0.3075798749923706,
                "min": -0.25771018862724304,
                "frobenius_norm": 2.403555154800415,
                "spectral_norm": 1.1651723384857178,
                "num_singular_values": 16,
                "alpha": 1.1777511954059952
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.00013535097241401672,
                "median": -0.024974433705210686,
                "std": 0.14971420168876648,
                "max": 0.30198314785957336,
                "min": -0.27834588289260864,
                "frobenius_norm": 2.395428419113159,
                "spectral_norm": 1.0590522289276123,
                "num_singular_values": 16,
                "alpha": 1.1510356406267785
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.01005636528134346,
                "median": 0.00358914234675467,
                "std": 0.14748798310756683,
                "max": 0.29549703001976013,
                "min": -0.23878329992294312,
                "frobenius_norm": 1.6725103855133057,
                "spectral_norm": 0.8997176885604858,
                "num_singular_values": 8,
                "alpha": 1.6504132873807031
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_5e-05_batch_size_16_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07935939729213715,
            "mse": 414984544.0,
            "mae": 1999.291748046875,
            "r2_score": 0.9103575944900513,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.010859827511012554,
                "median": 0.008062603883445263,
                "std": 0.16308104991912842,
                "max": 0.3090546727180481,
                "min": -0.29032379388809204,
                "frobenius_norm": 2.2647221088409424,
                "spectral_norm": 1.0249440670013428,
                "num_singular_values": 12,
                "alpha": 1.253752071376677
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0018353175837546587,
                "median": -0.006155029870569706,
                "std": 0.14378595352172852,
                "max": 0.2768721878528595,
                "min": -0.26774951815605164,
                "frobenius_norm": 2.30076265335083,
                "spectral_norm": 1.0559669733047485,
                "num_singular_values": 16,
                "alpha": 1.1445208818365773
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.01484270952641964,
                "median": -0.031193748116493225,
                "std": 0.1461876779794693,
                "max": 0.2917121946811676,
                "min": -0.28260496258735657,
                "frobenius_norm": 2.3510279655456543,
                "spectral_norm": 1.0500400066375732,
                "num_singular_values": 16,
                "alpha": 1.0840923469019066
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": -0.005904064513742924,
                "median": -0.025965269654989243,
                "std": 0.1416952759027481,
                "max": 0.2694670557975769,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.604490041732788,
                "spectral_norm": 0.8669365048408508,
                "num_singular_values": 8,
                "alpha": 1.5422861495314577
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_5e-05_batch_size_16_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07966212183237076,
            "mse": 422221024.0,
            "mae": 1990.5498046875,
            "r2_score": 0.9087944626808167,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.011763243936002254,
                "median": 0.013573447242379189,
                "std": 0.16405412554740906,
                "max": 0.316679984331131,
                "min": -0.2834630310535431,
                "frobenius_norm": 2.2790367603302,
                "spectral_norm": 1.0297911167144775,
                "num_singular_values": 12,
                "alpha": 1.250322854212607
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.004495950415730476,
                "median": -0.005741066299378872,
                "std": 0.1448163092136383,
                "max": 0.27685967087745667,
                "min": -0.27056580781936646,
                "frobenius_norm": 2.3181772232055664,
                "spectral_norm": 1.0429106950759888,
                "num_singular_values": 16,
                "alpha": 1.179266955394474
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.013511428609490395,
                "median": -0.03151288256049156,
                "std": 0.14621186256408691,
                "max": 0.29623740911483765,
                "min": -0.2790205478668213,
                "frobenius_norm": 2.3493573665618896,
                "spectral_norm": 1.047815203666687,
                "num_singular_values": 16,
                "alpha": 1.1623946125069513
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": -0.005858433432877064,
                "median": -0.022360699251294136,
                "std": 0.14191719889640808,
                "max": 0.2537151873111725,
                "min": -0.2662659287452698,
                "frobenius_norm": 1.6069772243499756,
                "spectral_norm": 0.8669741749763489,
                "num_singular_values": 8,
                "alpha": 1.515840000002715
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_5e-05_batch_size_16_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 888
        },
        "scores": {
            "smape": 0.15831010043621063,
            "mse": 595863168.0,
            "mae": 3143.76123046875,
            "r2_score": 0.8712853193283081,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.021116266027092934,
                "median": 0.027219023555517197,
                "std": 0.16467562317848206,
                "max": 0.3320979177951813,
                "min": -0.27043136954307556,
                "frobenius_norm": 2.3004956245422363,
                "spectral_norm": 1.0722521543502808,
                "num_singular_values": 12,
                "alpha": 1.2300607862618196
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.015971632674336433,
                "median": 0.010586949065327644,
                "std": 0.1460426300764084,
                "max": 0.2826624810695648,
                "min": -0.2542392909526825,
                "frobenius_norm": 2.350614070892334,
                "spectral_norm": 1.0518453121185303,
                "num_singular_values": 16,
                "alpha": 1.1347203037342966
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.01114295981824398,
                "median": -0.032016295939683914,
                "std": 0.147320955991745,
                "max": 0.32812970876693726,
                "min": -0.2993925213813782,
                "frobenius_norm": 2.363868236541748,
                "spectral_norm": 1.063483715057373,
                "num_singular_values": 16,
                "alpha": 1.226863922976709
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": -0.004112351220101118,
                "median": -0.01920904405415058,
                "std": 0.1427982598543167,
                "max": 0.29422444105148315,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.616247534751892,
                "spectral_norm": 0.8653594255447388,
                "num_singular_values": 8,
                "alpha": 1.5778575386131228
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_5e-05_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.5276784896850586,
            "mse": 2237253632.0,
            "mae": 6978.47509765625,
            "r2_score": 0.5167223215103149,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.030219251289963722,
                "median": 0.03224955499172211,
                "std": 0.1652388870716095,
                "max": 0.34704381227493286,
                "min": -0.2814294993877411,
                "frobenius_norm": 2.3275914192199707,
                "spectral_norm": 1.10027015209198,
                "num_singular_values": 12,
                "alpha": 1.2686280515205968
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.03211064636707306,
                "median": 0.022298380732536316,
                "std": 0.14945010840892792,
                "max": 0.3208853304386139,
                "min": -0.25857919454574585,
                "frobenius_norm": 2.445773124694824,
                "spectral_norm": 1.242874264717102,
                "num_singular_values": 16,
                "alpha": 1.1923966018478707
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.004031265154480934,
                "median": -0.020620940253138542,
                "std": 0.15173262357711792,
                "max": 0.31182166934013367,
                "min": -0.2773084342479706,
                "frobenius_norm": 2.4285786151885986,
                "spectral_norm": 1.1425889730453491,
                "num_singular_values": 16,
                "alpha": 1.1618071093257645
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.017073694616556168,
                "median": 0.007512172684073448,
                "std": 0.1494469791650772,
                "max": 0.32313966751098633,
                "min": -0.23628486692905426,
                "frobenius_norm": 1.7017980813980103,
                "spectral_norm": 0.9296437501907349,
                "num_singular_values": 8,
                "alpha": 1.6984172944326228
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_5e-05_batch_size_32_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07930772751569748,
            "mse": 413016288.0,
            "mae": 1997.7822265625,
            "r2_score": 0.9107828140258789,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.011207248084247112,
                "median": 0.005119042471051216,
                "std": 0.16369809210300446,
                "max": 0.3142808675765991,
                "min": -0.29081013798713684,
                "frobenius_norm": 2.2735769748687744,
                "spectral_norm": 1.0280107259750366,
                "num_singular_values": 12,
                "alpha": 1.25790809024519
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.002391916001215577,
                "median": -0.004140048287808895,
                "std": 0.14425405859947205,
                "max": 0.2770334780216217,
                "min": -0.27282190322875977,
                "frobenius_norm": 2.308382272720337,
                "spectral_norm": 1.0682494640350342,
                "num_singular_values": 16,
                "alpha": 1.1498175435030809
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.014725536108016968,
                "median": -0.031900666654109955,
                "std": 0.14661061763763428,
                "max": 0.302886039018631,
                "min": -0.2880138158798218,
                "frobenius_norm": 2.357572078704834,
                "spectral_norm": 1.059702754020691,
                "num_singular_values": 16,
                "alpha": 1.0648252411064796
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": -0.004726603627204895,
                "median": -0.0268266499042511,
                "std": 0.1419396698474884,
                "max": 0.27084654569625854,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.606754183769226,
                "spectral_norm": 0.869268000125885,
                "num_singular_values": 8,
                "alpha": 1.5503786666900545
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_5e-05_batch_size_32_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07958821207284927,
            "mse": 419821536.0,
            "mae": 1987.4825439453125,
            "r2_score": 0.9093127846717834,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.01231945026665926,
                "median": 0.011337434872984886,
                "std": 0.16470447182655334,
                "max": 0.3252537250518799,
                "min": -0.2886342704296112,
                "frobenius_norm": 2.2885870933532715,
                "spectral_norm": 1.0329844951629639,
                "num_singular_values": 12,
                "alpha": 1.2567594400359736
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.005706976633518934,
                "median": -0.0034613055177032948,
                "std": 0.1453392207622528,
                "max": 0.27664992213249207,
                "min": -0.2781709134578705,
                "frobenius_norm": 2.3272194862365723,
                "spectral_norm": 1.0506844520568848,
                "num_singular_values": 16,
                "alpha": 1.1855718381971325
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.012725629843771458,
                "median": -0.03193032741546631,
                "std": 0.14641544222831726,
                "max": 0.30418723821640015,
                "min": -0.2826460301876068,
                "frobenius_norm": 2.3514788150787354,
                "spectral_norm": 1.0496231317520142,
                "num_singular_values": 16,
                "alpha": 1.1801083712855662
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": -0.004074521828442812,
                "median": -0.020444506779313087,
                "std": 0.14256423711776733,
                "max": 0.2580813467502594,
                "min": -0.2705439031124115,
                "frobenius_norm": 1.613588809967041,
                "spectral_norm": 0.8690143823623657,
                "num_singular_values": 8,
                "alpha": 1.5376025462320309
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_5e-05_batch_size_32_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 888
        },
        "scores": {
            "smape": 0.15699966251850128,
            "mse": 584281344.0,
            "mae": 3116.0517578125,
            "r2_score": 0.8737871646881104,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.021589526906609535,
                "median": 0.02737457863986492,
                "std": 0.16477207839488983,
                "max": 0.3330126404762268,
                "min": -0.26795655488967896,
                "frobenius_norm": 2.302664041519165,
                "spectral_norm": 1.0750209093093872,
                "num_singular_values": 12,
                "alpha": 1.2266835226700268
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.01641104742884636,
                "median": 0.01046594325453043,
                "std": 0.14618465304374695,
                "max": 0.28321778774261475,
                "min": -0.25338366627693176,
                "frobenius_norm": 2.353646993637085,
                "spectral_norm": 1.0558949708938599,
                "num_singular_values": 16,
                "alpha": 1.146710921662552
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.011102527379989624,
                "median": -0.032376065850257874,
                "std": 0.1475135236978531,
                "max": 0.3314718008041382,
                "min": -0.29971301555633545,
                "frobenius_norm": 2.366891860961914,
                "spectral_norm": 1.0644782781600952,
                "num_singular_values": 16,
                "alpha": 1.2290890600602193
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": -0.0029214941896498203,
                "median": -0.015793723985552788,
                "std": 0.14297142624855042,
                "max": 0.29458850622177124,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.6178746223449707,
                "spectral_norm": 0.86617511510849,
                "num_singular_values": 8,
                "alpha": 1.59199802933691
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_5e-05_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.4049648344516754,
            "mse": 1618794496.0,
            "mae": 5419.09326171875,
            "r2_score": 0.6503180861473083,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.03931125998497009,
                "median": 0.042729102075099945,
                "std": 0.16593444347381592,
                "max": 0.3572581708431244,
                "min": -0.2826992869377136,
                "frobenius_norm": 2.3628976345062256,
                "spectral_norm": 1.1482114791870117,
                "num_singular_values": 12,
                "alpha": 1.2634754618921895
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.03802024573087692,
                "median": 0.026528477668762207,
                "std": 0.15084651112556458,
                "max": 0.32995063066482544,
                "min": -0.2591154873371124,
                "frobenius_norm": 2.4890265464782715,
                "spectral_norm": 1.3117400407791138,
                "num_singular_values": 16,
                "alpha": 1.2075190914529836
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.006042894907295704,
                "median": -0.016911983489990234,
                "std": 0.1532273143529892,
                "max": 0.3232666850090027,
                "min": -0.2773602306842804,
                "frobenius_norm": 2.453542709350586,
                "spectral_norm": 1.1942397356033325,
                "num_singular_values": 16,
                "alpha": 1.1589534266078503
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.02105872705578804,
                "median": 0.013736583292484283,
                "std": 0.1508481353521347,
                "max": 0.32676059007644653,
                "min": -0.23538507521152496,
                "frobenius_norm": 1.723201870918274,
                "spectral_norm": 0.9567274451255798,
                "num_singular_values": 8,
                "alpha": 1.6972437043941038
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_5e-05_batch_size_64_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 64,
            "scaler_type": "standard",
            "total_params": 888
        },
        "scores": {
            "smape": 0.0792909488081932,
            "mse": 412284832.0,
            "mae": 1997.3861083984375,
            "r2_score": 0.9109407663345337,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.011350465007126331,
                "median": 0.0072274403646588326,
                "std": 0.1640261709690094,
                "max": 0.3175238072872162,
                "min": -0.2894441783428192,
                "frobenius_norm": 2.2782483100891113,
                "spectral_norm": 1.0314639806747437,
                "num_singular_values": 12,
                "alpha": 1.2582712625325332
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.002390604931861162,
                "median": -0.003894797060638666,
                "std": 0.14445018768310547,
                "max": 0.2776985168457031,
                "min": -0.279531329870224,
                "frobenius_norm": 2.3115196228027344,
                "spectral_norm": 1.0761200189590454,
                "num_singular_values": 16,
                "alpha": 1.1492861759357518
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.014642929658293724,
                "median": -0.03215113654732704,
                "std": 0.14682072401046753,
                "max": 0.30534428358078003,
                "min": -0.2901088297367096,
                "frobenius_norm": 2.360785722732544,
                "spectral_norm": 1.0645807981491089,
                "num_singular_values": 16,
                "alpha": 1.111123790562019
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": -0.00448578828945756,
                "median": -0.026855818927288055,
                "std": 0.14210331439971924,
                "max": 0.2704165577888489,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.6085163354873657,
                "spectral_norm": 0.8705853223800659,
                "num_singular_values": 8,
                "alpha": 1.5549219719778617
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_5e-05_batch_size_64_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 64,
            "scaler_type": "robust",
            "total_params": 888
        },
        "scores": {
            "smape": 0.0795678049325943,
            "mse": 418907904.0,
            "mae": 1987.1544189453125,
            "r2_score": 0.9095101356506348,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.012082657776772976,
                "median": 0.006535614375025034,
                "std": 0.16496703028678894,
                "max": 0.32953283190727234,
                "min": -0.2898677587509155,
                "frobenius_norm": 2.291973114013672,
                "spectral_norm": 1.0385572910308838,
                "num_singular_values": 12,
                "alpha": 1.2470535996115664
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.005431571044027805,
                "median": -0.004660686012357473,
                "std": 0.14558233320713043,
                "max": 0.27708473801612854,
                "min": -0.28387898206710815,
                "frobenius_norm": 2.3309381008148193,
                "spectral_norm": 1.0559505224227905,
                "num_singular_values": 16,
                "alpha": 1.1782642412495936
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.011439702473580837,
                "median": -0.022577714174985886,
                "std": 0.1464693695306778,
                "max": 0.3067675232887268,
                "min": -0.2840258777141571,
                "frobenius_norm": 2.35064697265625,
                "spectral_norm": 1.0519262552261353,
                "num_singular_values": 16,
                "alpha": 1.199611638729208
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": -0.003113814629614353,
                "median": -0.015126166865229607,
                "std": 0.14417026937007904,
                "max": 0.260146826505661,
                "min": -0.28524598479270935,
                "frobenius_norm": 1.6314808130264282,
                "spectral_norm": 0.8693999648094177,
                "num_singular_values": 8,
                "alpha": 1.5789416341119635
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_5e-05_batch_size_64_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 64,
            "scaler_type": "minmax",
            "total_params": 888
        },
        "scores": {
            "smape": 0.15696007013320923,
            "mse": 583389056.0,
            "mae": 3115.3095703125,
            "r2_score": 0.873979926109314,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.02191231958568096,
                "median": 0.02756541222333908,
                "std": 0.16482141613960266,
                "max": 0.33382511138916016,
                "min": -0.2682894766330719,
                "frobenius_norm": 2.303926944732666,
                "spectral_norm": 1.077566146850586,
                "num_singular_values": 12,
                "alpha": 1.2283911013902467
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.016900036484003067,
                "median": 0.01179198082536459,
                "std": 0.1462177336215973,
                "max": 0.283464252948761,
                "min": -0.2533959448337555,
                "frobenius_norm": 2.355058431625366,
                "spectral_norm": 1.0566105842590332,
                "num_singular_values": 16,
                "alpha": 1.1475076655099885
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.01094679906964302,
                "median": -0.032583169639110565,
                "std": 0.14755092561244965,
                "max": 0.3316669166088104,
                "min": -0.29934608936309814,
                "frobenius_norm": 2.3673031330108643,
                "spectral_norm": 1.066517949104309,
                "num_singular_values": 16,
                "alpha": 1.2290918941132705
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": -0.0031710248440504074,
                "median": -0.016623277217149734,
                "std": 0.14298343658447266,
                "max": 0.29481443762779236,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.6180708408355713,
                "spectral_norm": 0.8669252395629883,
                "num_singular_values": 8,
                "alpha": 1.5880717748240814
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_5e-05_batch_size_128_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 128,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.3674783408641815,
            "mse": 1474854912.0,
            "mae": 5109.5322265625,
            "r2_score": 0.6814110279083252,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.040396176278591156,
                "median": 0.043842606246471405,
                "std": 0.16610562801361084,
                "max": 0.35870233178138733,
                "min": -0.2829473316669464,
                "frobenius_norm": 2.36871337890625,
                "spectral_norm": 1.1566267013549805,
                "num_singular_values": 12,
                "alpha": 1.2642638305860832
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.039410144090652466,
                "median": 0.02756849303841591,
                "std": 0.15091224014759064,
                "max": 0.32962167263031006,
                "min": -0.2598702609539032,
                "frobenius_norm": 2.495572090148926,
                "spectral_norm": 1.32277512550354,
                "num_singular_values": 16,
                "alpha": 1.2072714797463273
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.006833252497017384,
                "median": -0.016549941152334213,
                "std": 0.1535344272851944,
                "max": 0.32410097122192383,
                "min": -0.27720949053764343,
                "frobenius_norm": 2.458982467651367,
                "spectral_norm": 1.2078804969787598,
                "num_singular_values": 16,
                "alpha": 1.1592771096803518
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.022484464570879936,
                "median": 0.020424798130989075,
                "std": 0.15096057951450348,
                "max": 0.3234208822250366,
                "min": -0.23485763370990753,
                "frobenius_norm": 1.7267643213272095,
                "spectral_norm": 0.9602192044258118,
                "num_singular_values": 8,
                "alpha": 1.704518510614578
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_5e-05_batch_size_128_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 128,
            "scaler_type": "standard",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07927249372005463,
            "mse": 411196672.0,
            "mae": 1996.5753173828125,
            "r2_score": 0.9111758470535278,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.011021825484931469,
                "median": 0.008182620629668236,
                "std": 0.1644650548696518,
                "max": 0.31984665989875793,
                "min": -0.2953961193561554,
                "frobenius_norm": 2.284006357192993,
                "spectral_norm": 1.0367027521133423,
                "num_singular_values": 12,
                "alpha": 1.2526646051401626
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0023539194371551275,
                "median": -0.004597313702106476,
                "std": 0.14475487172603607,
                "max": 0.2771351933479309,
                "min": -0.28479674458503723,
                "frobenius_norm": 2.3163840770721436,
                "spectral_norm": 1.083353877067566,
                "num_singular_values": 16,
                "alpha": 1.1326298978793412
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.014721192419528961,
                "median": -0.03281885385513306,
                "std": 0.14698518812656403,
                "max": 0.3093276619911194,
                "min": -0.2919490933418274,
                "frobenius_norm": 2.3635287284851074,
                "spectral_norm": 1.0683263540267944,
                "num_singular_values": 16,
                "alpha": 1.1333102935226493
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": -0.004115723073482513,
                "median": -0.02623106725513935,
                "std": 0.14194242656230927,
                "max": 0.2711966335773468,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.6065701246261597,
                "spectral_norm": 0.86750727891922,
                "num_singular_values": 8,
                "alpha": 1.5537572387695766
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_5e-05_batch_size_128_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 128,
            "scaler_type": "robust",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07950957119464874,
            "mse": 418466176.0,
            "mae": 1986.3095703125,
            "r2_score": 0.9096055626869202,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.012318556196987629,
                "median": 0.004999441094696522,
                "std": 0.16540171205997467,
                "max": 0.33239462971687317,
                "min": -0.2902534604072571,
                "frobenius_norm": 2.298220634460449,
                "spectral_norm": 1.041653037071228,
                "num_singular_values": 12,
                "alpha": 1.2440809960065013
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.005903880577534437,
                "median": -0.005067503545433283,
                "std": 0.14587834477424622,
                "max": 0.2770179808139801,
                "min": -0.2848786413669586,
                "frobenius_norm": 2.3359644412994385,
                "spectral_norm": 1.0616642236709595,
                "num_singular_values": 16,
                "alpha": 1.1699594026689981
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.011104083620011806,
                "median": -0.022168956696987152,
                "std": 0.14647544920444489,
                "max": 0.30916479229927063,
                "min": -0.28505223989486694,
                "frobenius_norm": 2.3503317832946777,
                "spectral_norm": 1.0524799823760986,
                "num_singular_values": 16,
                "alpha": 1.2010001589167059
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": -0.002737266942858696,
                "median": -0.010710181668400764,
                "std": 0.14444591104984283,
                "max": 0.25670507550239563,
                "min": -0.2820485532283783,
                "frobenius_norm": 1.6345123052597046,
                "spectral_norm": 0.8667884469032288,
                "num_singular_values": 8,
                "alpha": 1.6056442349703877
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_5e-05_batch_size_128_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 128,
            "scaler_type": "minmax",
            "total_params": 888
        },
        "scores": {
            "smape": 0.1566155105829239,
            "mse": 579995968.0,
            "mae": 3104.81298828125,
            "r2_score": 0.8747128844261169,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.022453755140304565,
                "median": 0.02775798738002777,
                "std": 0.16494309902191162,
                "max": 0.3339674770832062,
                "min": -0.2677461802959442,
                "frobenius_norm": 2.306598424911499,
                "spectral_norm": 1.0796433687210083,
                "num_singular_values": 12,
                "alpha": 1.2253418498732864
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.017196349799633026,
                "median": 0.011397580616176128,
                "std": 0.1463555097579956,
                "max": 0.2834934592247009,
                "min": -0.25309017300605774,
                "frobenius_norm": 2.3577969074249268,
                "spectral_norm": 1.061181664466858,
                "num_singular_values": 16,
                "alpha": 1.1415564153859497
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.01089329831302166,
                "median": -0.03242357075214386,
                "std": 0.147800013422966,
                "max": 0.33307358622550964,
                "min": -0.29972371459007263,
                "frobenius_norm": 2.3712143898010254,
                "spectral_norm": 1.0673303604125977,
                "num_singular_values": 16,
                "alpha": 1.2311845773504912
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": -0.0030273431912064552,
                "median": -0.018477439880371094,
                "std": 0.1427830159664154,
                "max": 0.29500287771224976,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.6157684326171875,
                "spectral_norm": 0.8654254078865051,
                "num_singular_values": 8,
                "alpha": 1.5846029909423431
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_5e-05_batch_size_256_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 256,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.3574717044830322,
            "mse": 1430797056.0,
            "mae": 5043.3232421875,
            "r2_score": 0.6909281015396118,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.04030555114150047,
                "median": 0.042394205927848816,
                "std": 0.16618497669696808,
                "max": 0.35910600423812866,
                "min": -0.28189390897750854,
                "frobenius_norm": 2.369485378265381,
                "spectral_norm": 1.1621366739273071,
                "num_singular_values": 12,
                "alpha": 1.2630736965457043
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0404970683157444,
                "median": 0.03251209482550621,
                "std": 0.15067045390605927,
                "max": 0.33141079545021057,
                "min": -0.25965616106987,
                "frobenius_norm": 2.4962868690490723,
                "spectral_norm": 1.3241803646087646,
                "num_singular_values": 16,
                "alpha": 1.2019676774766732
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.007865597493946552,
                "median": -0.016413463279604912,
                "std": 0.15392164885997772,
                "max": 0.32476410269737244,
                "min": -0.28051507472991943,
                "frobenius_norm": 2.4659597873687744,
                "spectral_norm": 1.2260079383850098,
                "num_singular_values": 16,
                "alpha": 1.1497712976490193
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.022722655907273293,
                "median": 0.02082885429263115,
                "std": 0.15079806745052338,
                "max": 0.3206942677497864,
                "min": -0.23759260773658752,
                "frobenius_norm": 1.725345253944397,
                "spectral_norm": 0.957063615322113,
                "num_singular_values": 8,
                "alpha": 1.7040415293947735
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_5e-05_batch_size_256_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 256,
            "scaler_type": "standard",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07927127927541733,
            "mse": 409939616.0,
            "mae": 1995.8687744140625,
            "r2_score": 0.9114474058151245,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.011178780347108841,
                "median": 0.009119221940636635,
                "std": 0.1645229458808899,
                "max": 0.3213510513305664,
                "min": -0.2918024957180023,
                "frobenius_norm": 2.2849531173706055,
                "spectral_norm": 1.036340355873108,
                "num_singular_values": 12,
                "alpha": 1.2522318207658572
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.00269185658544302,
                "median": -0.005319111980497837,
                "std": 0.14481791853904724,
                "max": 0.2793314754962921,
                "min": -0.2852013409137726,
                "frobenius_norm": 2.3174870014190674,
                "spectral_norm": 1.084067702293396,
                "num_singular_values": 16,
                "alpha": 1.1364976202651051
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.014670426025986671,
                "median": -0.032828062772750854,
                "std": 0.14714355766773224,
                "max": 0.3101016581058502,
                "min": -0.2929355204105377,
                "frobenius_norm": 2.36596941947937,
                "spectral_norm": 1.0688124895095825,
                "num_singular_values": 16,
                "alpha": 1.1332101162024635
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": -0.004214150365442038,
                "median": -0.025956502184271812,
                "std": 0.141961008310318,
                "max": 0.27161818742752075,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.606812834739685,
                "spectral_norm": 0.8710569739341736,
                "num_singular_values": 8,
                "alpha": 1.5542350430951144
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_5e-05_batch_size_256_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 256,
            "scaler_type": "robust",
            "total_params": 888
        },
        "scores": {
            "smape": 0.07950425893068314,
            "mse": 417267040.0,
            "mae": 1985.1490478515625,
            "r2_score": 0.9098645448684692,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.01267694029957056,
                "median": 0.00448868703097105,
                "std": 0.16529494524002075,
                "max": 0.3329907953739166,
                "min": -0.2911742329597473,
                "frobenius_norm": 2.2971198558807373,
                "spectral_norm": 1.0416322946548462,
                "num_singular_values": 12,
                "alpha": 1.248851960145815
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.006190509535372257,
                "median": -0.006116475909948349,
                "std": 0.14592543244361877,
                "max": 0.27758514881134033,
                "min": -0.2863765060901642,
                "frobenius_norm": 2.336906909942627,
                "spectral_norm": 1.061112642288208,
                "num_singular_values": 16,
                "alpha": 1.1721703507128436
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.010411559604108334,
                "median": -0.02114160731434822,
                "std": 0.14669936895370483,
                "max": 0.3093545138835907,
                "min": -0.28596270084381104,
                "frobenius_norm": 2.3530938625335693,
                "spectral_norm": 1.053171157836914,
                "num_singular_values": 16,
                "alpha": 1.197649888708417
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": -0.002532736863940954,
                "median": -0.011035297997295856,
                "std": 0.14490000903606415,
                "max": 0.25597280263900757,
                "min": -0.283168226480484,
                "frobenius_norm": 1.6396068334579468,
                "spectral_norm": 0.8691465854644775,
                "num_singular_values": 8,
                "alpha": 1.6019585600667283
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_learning_rate_5e-05_batch_size_256_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 256,
            "scaler_type": "minmax",
            "total_params": 888
        },
        "scores": {
            "smape": 0.15699204802513123,
            "mse": 578908032.0,
            "mae": 3108.919677734375,
            "r2_score": 0.8749479055404663,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.02288953773677349,
                "median": 0.02816515788435936,
                "std": 0.16492924094200134,
                "max": 0.3337959945201874,
                "min": -0.2681471109390259,
                "frobenius_norm": 2.3072304725646973,
                "spectral_norm": 1.0782673358917236,
                "num_singular_values": 12,
                "alpha": 1.2272291678020226
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.017139732837677002,
                "median": 0.011599486693739891,
                "std": 0.14638939499855042,
                "max": 0.28354182839393616,
                "min": -0.2534751892089844,
                "frobenius_norm": 2.358229875564575,
                "spectral_norm": 1.0592758655548096,
                "num_singular_values": 16,
                "alpha": 1.138723489698993
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.01069564651697874,
                "median": -0.032804667949676514,
                "std": 0.1478853076696396,
                "max": 0.3316900432109833,
                "min": -0.29939568042755127,
                "frobenius_norm": 2.372345209121704,
                "spectral_norm": 1.0673338174819946,
                "num_singular_values": 16,
                "alpha": 1.23312329436679
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": -0.0030370200984179974,
                "median": -0.01867114007472992,
                "std": 0.1427667737007141,
                "max": 0.2952626049518585,
                "min": -0.24210038781166077,
                "frobenius_norm": 1.6155869960784912,
                "spectral_norm": 0.8681567907333374,
                "num_singular_values": 8,
                "alpha": 1.5784112826835912
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.01_batch_size_16_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.08179239183664322,
            "mse": 490991936.0,
            "mae": 2015.4248046875,
            "r2_score": 0.8939389586448669,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": -0.040043529123067856,
                "median": -0.06093791872262955,
                "std": 0.20149895548820496,
                "max": 0.5389658808708191,
                "min": -0.6521763205528259,
                "frobenius_norm": 4.0257720947265625,
                "spectral_norm": 2.1158628463745117,
                "num_singular_values": 12,
                "alpha": 1.7733589933111997
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.020002756267786026,
                "median": -0.030973955988883972,
                "std": 0.24824850261211395,
                "max": 1.359041452407837,
                "min": -3.1386358737945557,
                "frobenius_norm": 7.969698429107666,
                "spectral_norm": 5.6684699058532715,
                "num_singular_values": 32,
                "alpha": 1.1151797874889686
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.008326290175318718,
                "median": -0.014327245764434338,
                "std": 0.13076385855674744,
                "max": 0.5656095147132874,
                "min": -0.5482724905014038,
                "frobenius_norm": 4.192917346954346,
                "spectral_norm": 1.7378453016281128,
                "num_singular_values": 32,
                "alpha": 1.1202022229790456
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.039665959775447845,
                "median": 0.04304950684309006,
                "std": 0.1137276142835617,
                "max": 0.28801700472831726,
                "min": -0.3026789724826813,
                "frobenius_norm": 1.9271438121795654,
                "spectral_norm": 1.2257236242294312,
                "num_singular_values": 8,
                "alpha": 1.8033933551734573
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.01_batch_size_16_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.06811293214559555,
            "mse": 344994752.0,
            "mae": 1787.5235595703125,
            "r2_score": 0.9254763722419739,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.11353733390569687,
                "median": 0.10971861332654953,
                "std": 0.2775827646255493,
                "max": 0.8290508985519409,
                "min": -1.1872888803482056,
                "frobenius_norm": 5.876911163330078,
                "spectral_norm": 2.9764106273651123,
                "num_singular_values": 12,
                "alpha": 1.6140527052521056
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.03387007862329483,
                "median": -0.025178274139761925,
                "std": 0.31120607256889343,
                "max": 1.1949843168258667,
                "min": -1.297446846961975,
                "frobenius_norm": 10.017400741577148,
                "spectral_norm": 3.994107961654663,
                "num_singular_values": 32,
                "alpha": 1.1760791673065176
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.014564278535544872,
                "median": -0.02484162524342537,
                "std": 0.25137919187545776,
                "max": 1.011608600616455,
                "min": -1.2857656478881836,
                "frobenius_norm": 8.057623863220215,
                "spectral_norm": 4.107666492462158,
                "num_singular_values": 32,
                "alpha": 1.1560314636403493
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.023510944098234177,
                "median": 0.017019739374518394,
                "std": 0.15428680181503296,
                "max": 0.43770256638526917,
                "min": -0.77702796459198,
                "frobenius_norm": 2.4970858097076416,
                "spectral_norm": 1.414089322090149,
                "num_singular_values": 8,
                "alpha": 2.334500718909016
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.01_batch_size_16_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.06940949708223343,
            "mse": 361264576.0,
            "mae": 1795.88818359375,
            "r2_score": 0.9219619035720825,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.08427473902702332,
                "median": 0.09359797835350037,
                "std": 0.3249436020851135,
                "max": 1.737733244895935,
                "min": -2.0829737186431885,
                "frobenius_norm": 6.578235626220703,
                "spectral_norm": 3.8569090366363525,
                "num_singular_values": 12,
                "alpha": 1.501720210119223
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.10024615377187729,
                "median": -0.08002347499132156,
                "std": 0.3392826020717621,
                "max": 1.256484031677246,
                "min": -1.6579731702804565,
                "frobenius_norm": 11.321035385131836,
                "spectral_norm": 5.324425220489502,
                "num_singular_values": 32,
                "alpha": 1.0962759659842056
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.043836552649736404,
                "median": -0.05431229621171951,
                "std": 0.30731579661369324,
                "max": 2.6132657527923584,
                "min": -1.124403476715088,
                "frobenius_norm": 9.933649063110352,
                "spectral_norm": 5.541915416717529,
                "num_singular_values": 32,
                "alpha": 1.116936074331679
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.010067906230688095,
                "median": 0.011702235788106918,
                "std": 0.15321749448776245,
                "max": 0.5907199382781982,
                "min": -0.7734765410423279,
                "frobenius_norm": 2.4567668437957764,
                "spectral_norm": 1.493226170539856,
                "num_singular_values": 8,
                "alpha": 1.8668478862679956
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.01_batch_size_16_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07279523462057114,
            "mse": 456802912.0,
            "mae": 2016.0810546875,
            "r2_score": 0.9013242721557617,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.09136391431093216,
                "median": 0.08951634168624878,
                "std": 0.24256253242492676,
                "max": 1.9757975339889526,
                "min": -0.7015657424926758,
                "frobenius_norm": 5.079235553741455,
                "spectral_norm": 2.6230058670043945,
                "num_singular_values": 12,
                "alpha": 1.7227803096981193
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.11207101494073868,
                "median": -0.09312616288661957,
                "std": 0.26047489047050476,
                "max": 0.9407638907432556,
                "min": -2.143216848373413,
                "frobenius_norm": 9.073965072631836,
                "spectral_norm": 4.874340057373047,
                "num_singular_values": 32,
                "alpha": 1.2203845189139353
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.05629721283912659,
                "median": -0.05078539624810219,
                "std": 0.26360777020454407,
                "max": 1.7686657905578613,
                "min": -2.3833096027374268,
                "frobenius_norm": 8.625672340393066,
                "spectral_norm": 5.958559513092041,
                "num_singular_values": 32,
                "alpha": 1.1501707452438414
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": -0.03950755298137665,
                "median": -0.03955335542559624,
                "std": 0.1154361441731453,
                "max": 0.3151441514492035,
                "min": -0.3477933406829834,
                "frobenius_norm": 1.9521540403366089,
                "spectral_norm": 1.1189793348312378,
                "num_singular_values": 8,
                "alpha": 1.8981803887031128
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.01_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.08184140175580978,
            "mse": 463446176.0,
            "mae": 2017.9351806640625,
            "r2_score": 0.8998892307281494,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": -0.05635039508342743,
                "median": -0.05241890996694565,
                "std": 0.22235950827598572,
                "max": 0.5485271215438843,
                "min": -0.9974191188812256,
                "frobenius_norm": 4.495079517364502,
                "spectral_norm": 2.2911863327026367,
                "num_singular_values": 12,
                "alpha": 1.658972556828605
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.0419444665312767,
                "median": -0.03882591053843498,
                "std": 0.2570546567440033,
                "max": 1.7388516664505005,
                "min": -2.7293012142181396,
                "frobenius_norm": 8.3345365524292,
                "spectral_norm": 4.927490234375,
                "num_singular_values": 32,
                "alpha": 1.167102909657196
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.019043099135160446,
                "median": -0.013848675414919853,
                "std": 0.14710691571235657,
                "max": 0.5514049530029297,
                "min": -0.7096067070960999,
                "frobenius_norm": 4.746699810028076,
                "spectral_norm": 2.2377984523773193,
                "num_singular_values": 32,
                "alpha": 1.1911792539928914
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.07687647640705109,
                "median": 0.08042934536933899,
                "std": 0.13761605322360992,
                "max": 0.7416019439697266,
                "min": -0.22166772186756134,
                "frobenius_norm": 2.5221283435821533,
                "spectral_norm": 1.9080644845962524,
                "num_singular_values": 8,
                "alpha": 1.7064913730614204
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.01_batch_size_32_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.06823775917291641,
            "mse": 377967136.0,
            "mae": 1876.01904296875,
            "r2_score": 0.9183539152145386,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.07155825942754745,
                "median": 0.09096886217594147,
                "std": 0.2970827519893646,
                "max": 0.9261306524276733,
                "min": -1.3366050720214844,
                "frobenius_norm": 5.988108158111572,
                "spectral_norm": 2.8332207202911377,
                "num_singular_values": 12,
                "alpha": 1.6868730525001012
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.03660314530134201,
                "median": -0.030989402905106544,
                "std": 0.3387381434440613,
                "max": 1.5153610706329346,
                "min": -1.5550764799118042,
                "frobenius_norm": 10.90272045135498,
                "spectral_norm": 4.907546520233154,
                "num_singular_values": 32,
                "alpha": 1.1157530241927391
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.02475571259856224,
                "median": -0.039639607071876526,
                "std": 0.2378247082233429,
                "max": 1.4648425579071045,
                "min": -1.1174291372299194,
                "frobenius_norm": 7.651509761810303,
                "spectral_norm": 3.18705415725708,
                "num_singular_values": 32,
                "alpha": 1.1547681905941434
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.03994106128811836,
                "median": 0.04289976507425308,
                "std": 0.14820659160614014,
                "max": 0.5216168165206909,
                "min": -0.597895085811615,
                "frobenius_norm": 2.4559078216552734,
                "spectral_norm": 1.5965569019317627,
                "num_singular_values": 8,
                "alpha": 1.8607627423302193
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.01_batch_size_32_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07065626978874207,
            "mse": 467487552.0,
            "mae": 2069.389404296875,
            "r2_score": 0.899016261100769,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.08192195743322372,
                "median": 0.08296524733304977,
                "std": 0.36166712641716003,
                "max": 1.9072872400283813,
                "min": -1.8859009742736816,
                "frobenius_norm": 7.2667388916015625,
                "spectral_norm": 4.282625198364258,
                "num_singular_values": 12,
                "alpha": 1.5069518948405285
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.07911917567253113,
                "median": -0.057679079473018646,
                "std": 0.38045555353164673,
                "max": 1.664875864982605,
                "min": -1.924160122871399,
                "frobenius_norm": 12.43504810333252,
                "spectral_norm": 5.3059000968933105,
                "num_singular_values": 32,
                "alpha": 1.1292710327978768
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.06544839590787888,
                "median": -0.056692253798246384,
                "std": 0.3019293248653412,
                "max": 1.0950323343276978,
                "min": -1.6030606031417847,
                "frobenius_norm": 9.886126518249512,
                "spectral_norm": 4.245429515838623,
                "num_singular_values": 32,
                "alpha": 1.163725239585345
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.008607203140854836,
                "median": 0.03199559077620506,
                "std": 0.16386562585830688,
                "max": 0.4382508397102356,
                "min": -0.5849785804748535,
                "frobenius_norm": 2.6254642009735107,
                "spectral_norm": 1.8991570472717285,
                "num_singular_values": 8,
                "alpha": 1.7469809483151888
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.01_batch_size_32_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07289908826351166,
            "mse": 482732064.0,
            "mae": 2045.0509033203125,
            "r2_score": 0.8957232236862183,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.06164347007870674,
                "median": 0.057572659105062485,
                "std": 0.2763567864894867,
                "max": 0.9546729922294617,
                "min": -1.7307542562484741,
                "frobenius_norm": 5.5485520362854,
                "spectral_norm": 3.5856571197509766,
                "num_singular_values": 12,
                "alpha": 1.4883495075828421
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.08006317913532257,
                "median": -0.07093147933483124,
                "std": 0.2831954061985016,
                "max": 2.0422160625457764,
                "min": -1.6889127492904663,
                "frobenius_norm": 9.417451858520508,
                "spectral_norm": 5.192986488342285,
                "num_singular_values": 32,
                "alpha": 1.1294181892051829
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.043141767382621765,
                "median": -0.03883485496044159,
                "std": 0.18871724605560303,
                "max": 1.2899558544158936,
                "min": -1.8412710428237915,
                "frobenius_norm": 6.194741249084473,
                "spectral_norm": 3.047215461730957,
                "num_singular_values": 32,
                "alpha": 1.1409538330286497
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.0018736571073532104,
                "median": 0.007844644598662853,
                "std": 0.12877079844474792,
                "max": 0.4261187016963959,
                "min": -0.34836843609809875,
                "frobenius_norm": 2.0605509281158447,
                "spectral_norm": 1.1464163064956665,
                "num_singular_values": 8,
                "alpha": 1.8134476806872541
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.01_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.0887976884841919,
            "mse": 482747296.0,
            "mae": 2151.308349609375,
            "r2_score": 0.8957199454307556,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": -0.05611996725201607,
                "median": -0.05526347458362579,
                "std": 0.2623607814311981,
                "max": 0.672494649887085,
                "min": -1.200486183166504,
                "frobenius_norm": 5.25750207901001,
                "spectral_norm": 3.0493409633636475,
                "num_singular_values": 12,
                "alpha": 1.5909975413457302
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.032510384917259216,
                "median": -0.03368615359067917,
                "std": 0.23909462988376617,
                "max": 1.0399670600891113,
                "min": -3.398979902267456,
                "frobenius_norm": 7.721432209014893,
                "spectral_norm": 5.0972747802734375,
                "num_singular_values": 32,
                "alpha": 1.093353772555483
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.0052176876924932,
                "median": -0.006407890934497118,
                "std": 0.14627580344676971,
                "max": 0.6932487487792969,
                "min": -0.9483208656311035,
                "frobenius_norm": 4.683802604675293,
                "spectral_norm": 2.0378212928771973,
                "num_singular_values": 32,
                "alpha": 1.148509270609095
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.06423664838075638,
                "median": 0.07516773045063019,
                "std": 0.11641990393400192,
                "max": 0.30736157298088074,
                "min": -0.26323202252388,
                "frobenius_norm": 2.127454996109009,
                "spectral_norm": 1.410955548286438,
                "num_singular_values": 8,
                "alpha": 1.7909512645846402
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.01_batch_size_64_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 64,
            "scaler_type": "standard",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07026644051074982,
            "mse": 423243424.0,
            "mae": 1908.1630859375,
            "r2_score": 0.908573567867279,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.0753062292933464,
                "median": 0.07787013798952103,
                "std": 0.27057889103889465,
                "max": 0.9959324598312378,
                "min": -1.2188317775726318,
                "frobenius_norm": 5.503766059875488,
                "spectral_norm": 2.6239285469055176,
                "num_singular_values": 12,
                "alpha": 1.6973835035816254
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.009358197450637817,
                "median": -0.017093241214752197,
                "std": 0.3269154727458954,
                "max": 1.2655444145202637,
                "min": -1.4992579221725464,
                "frobenius_norm": 10.465580940246582,
                "spectral_norm": 5.029411315917969,
                "num_singular_values": 32,
                "alpha": 1.145312590089405
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.034519847482442856,
                "median": -0.02900129184126854,
                "std": 0.25476375222206116,
                "max": 0.9761112928390503,
                "min": -1.6123356819152832,
                "frobenius_norm": 8.226937294006348,
                "spectral_norm": 3.751619577407837,
                "num_singular_values": 32,
                "alpha": 1.1217992392437315
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.045527681708335876,
                "median": 0.04397689923644066,
                "std": 0.1606501042842865,
                "max": 0.612743079662323,
                "min": -0.5105583667755127,
                "frobenius_norm": 2.6716275215148926,
                "spectral_norm": 1.4706977605819702,
                "num_singular_values": 8,
                "alpha": 1.9449193118666617
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.01_batch_size_64_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 64,
            "scaler_type": "robust",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.06991526484489441,
            "mse": 424410336.0,
            "mae": 1984.995361328125,
            "r2_score": 0.9083214998245239,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.05399955436587334,
                "median": 0.07102039456367493,
                "std": 0.3280242085456848,
                "max": 0.993863582611084,
                "min": -1.5720090866088867,
                "frobenius_norm": 6.514451503753662,
                "spectral_norm": 3.606184482574463,
                "num_singular_values": 12,
                "alpha": 1.715658850326641
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.10414901375770569,
                "median": -0.08387622237205505,
                "std": 0.40556779503822327,
                "max": 1.5116456747055054,
                "min": -1.7361633777618408,
                "frobenius_norm": 13.399263381958008,
                "spectral_norm": 6.026092529296875,
                "num_singular_values": 32,
                "alpha": 1.133742772771222
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.03281547874212265,
                "median": -0.03335510939359665,
                "std": 0.2722339332103729,
                "max": 1.822985053062439,
                "min": -1.0955138206481934,
                "frobenius_norm": 8.774547576904297,
                "spectral_norm": 3.441188335418701,
                "num_singular_values": 32,
                "alpha": 1.140201307311302
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.030068133026361465,
                "median": 0.03138982504606247,
                "std": 0.15467554330825806,
                "max": 0.5841493606567383,
                "min": -0.49793165922164917,
                "frobenius_norm": 2.5211358070373535,
                "spectral_norm": 1.663840651512146,
                "num_singular_values": 8,
                "alpha": 1.8122164527896385
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.01_batch_size_64_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 64,
            "scaler_type": "minmax",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07049783319234848,
            "mse": 401277088.0,
            "mae": 1978.4468994140625,
            "r2_score": 0.9133186340332031,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.06847181916236877,
                "median": 0.0583077073097229,
                "std": 0.35525500774383545,
                "max": 1.3775405883789062,
                "min": -2.1339633464813232,
                "frobenius_norm": 7.089675426483154,
                "spectral_norm": 4.679956912994385,
                "num_singular_values": 12,
                "alpha": 1.5615141719190484
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.06269276142120361,
                "median": -0.06843486428260803,
                "std": 0.3099212050437927,
                "max": 1.6316457986831665,
                "min": -1.9312108755111694,
                "frobenius_norm": 10.118353843688965,
                "spectral_norm": 5.617269992828369,
                "num_singular_values": 32,
                "alpha": 1.11591479517432
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.03098740614950657,
                "median": -0.024400189518928528,
                "std": 0.19420234858989716,
                "max": 0.9392985105514526,
                "min": -2.4961726665496826,
                "frobenius_norm": 6.293088912963867,
                "spectral_norm": 3.724303960800171,
                "num_singular_values": 32,
                "alpha": 1.1424231390680795
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.03907044231891632,
                "median": 0.03625745326280594,
                "std": 0.12360827624797821,
                "max": 0.5439679026603699,
                "min": -0.36867785453796387,
                "frobenius_norm": 2.074176788330078,
                "spectral_norm": 1.3409686088562012,
                "num_singular_values": 8,
                "alpha": 1.7450242961469478
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.01_batch_size_128_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 128,
            "scaler_type": "identity",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.08112604171037674,
            "mse": 456213248.0,
            "mae": 1919.822509765625,
            "r2_score": 0.9014516472816467,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": -0.026121431961655617,
                "median": -0.03538312017917633,
                "std": 0.22797493636608124,
                "max": 0.5415129065513611,
                "min": -1.4887439012527466,
                "frobenius_norm": 4.496607780456543,
                "spectral_norm": 2.2971181869506836,
                "num_singular_values": 12,
                "alpha": 1.6098486953476925
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.024615777656435966,
                "median": -0.03820051997900009,
                "std": 0.16453242301940918,
                "max": 0.7617771625518799,
                "min": -0.7323224544525146,
                "frobenius_norm": 5.323636054992676,
                "spectral_norm": 2.479249954223633,
                "num_singular_values": 32,
                "alpha": 1.1333648211087128
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.0025056449230760336,
                "median": -0.005801587365567684,
                "std": 0.13773632049560547,
                "max": 0.7986592650413513,
                "min": -0.5288452506065369,
                "frobenius_norm": 4.408291339874268,
                "spectral_norm": 1.7521685361862183,
                "num_singular_values": 32,
                "alpha": 1.1157761431578959
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.06652751564979553,
                "median": 0.07185151427984238,
                "std": 0.11750902980566025,
                "max": 0.3025719225406647,
                "min": -0.21572259068489075,
                "frobenius_norm": 2.160550117492676,
                "spectral_norm": 1.4003570079803467,
                "num_singular_values": 8,
                "alpha": 1.8291704509202185
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.01_batch_size_128_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 128,
            "scaler_type": "standard",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.06841643154621124,
            "mse": 365884768.0,
            "mae": 1895.891357421875,
            "r2_score": 0.9209638237953186,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.09950574487447739,
                "median": 0.09350316226482391,
                "std": 0.2856190502643585,
                "max": 0.9582810401916504,
                "min": -1.5383760929107666,
                "frobenius_norm": 5.926903247833252,
                "spectral_norm": 3.261399507522583,
                "num_singular_values": 12,
                "alpha": 1.535840378177565
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.0312759168446064,
                "median": -0.0311199389398098,
                "std": 0.3262336552143097,
                "max": 1.558893084526062,
                "min": -1.5697039365768433,
                "frobenius_norm": 10.48734188079834,
                "spectral_norm": 4.202114582061768,
                "num_singular_values": 32,
                "alpha": 1.0976162321774703
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.04846697300672531,
                "median": -0.046423785388469696,
                "std": 0.2426082193851471,
                "max": 0.9486602544784546,
                "min": -1.6901251077651978,
                "frobenius_norm": 7.916866779327393,
                "spectral_norm": 3.4188427925109863,
                "num_singular_values": 32,
                "alpha": 1.079465245081987
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.027126556262373924,
                "median": 0.015213500708341599,
                "std": 0.1969515085220337,
                "max": 0.5768243670463562,
                "min": -0.5014677047729492,
                "frobenius_norm": 3.1809732913970947,
                "spectral_norm": 2.3655600547790527,
                "num_singular_values": 8,
                "alpha": 1.8791919926561937
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.01_batch_size_128_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 128,
            "scaler_type": "robust",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07114595174789429,
            "mse": 404435360.0,
            "mae": 1881.7169189453125,
            "r2_score": 0.912636399269104,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.026665212586522102,
                "median": 0.029363621026277542,
                "std": 0.3355008363723755,
                "max": 1.0447965860366821,
                "min": -1.6293952465057373,
                "frobenius_norm": 6.595179080963135,
                "spectral_norm": 3.7070698738098145,
                "num_singular_values": 12,
                "alpha": 1.564961251268485
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.027273137122392654,
                "median": -0.03133340924978256,
                "std": 0.40411871671676636,
                "max": 1.4737129211425781,
                "min": -1.9542804956436157,
                "frobenius_norm": 12.961215019226074,
                "spectral_norm": 5.865964412689209,
                "num_singular_values": 32,
                "alpha": 1.14420157273384
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.03818913549184799,
                "median": -0.04463330656290054,
                "std": 0.21632005274295807,
                "max": 0.9577428698539734,
                "min": -0.9325803518295288,
                "frobenius_norm": 7.029284477233887,
                "spectral_norm": 3.2312211990356445,
                "num_singular_values": 32,
                "alpha": 1.1730803588756356
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.016434937715530396,
                "median": 0.023235369473695755,
                "std": 0.13092908263206482,
                "max": 0.3497239053249359,
                "min": -0.48966071009635925,
                "frobenius_norm": 2.111304998397827,
                "spectral_norm": 1.224872350692749,
                "num_singular_values": 8,
                "alpha": 2.145338232612417
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.01_batch_size_128_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 128,
            "scaler_type": "minmax",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07246626168489456,
            "mse": 500789152.0,
            "mae": 2072.46044921875,
            "r2_score": 0.8918226361274719,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.08505088835954666,
                "median": 0.06113928556442261,
                "std": 0.3120855391025543,
                "max": 1.8202967643737793,
                "min": -2.1340746879577637,
                "frobenius_norm": 6.338637351989746,
                "spectral_norm": 3.8757705688476562,
                "num_singular_values": 12,
                "alpha": 1.5081465317866654
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.08451904356479645,
                "median": -0.06940091401338577,
                "std": 0.36624592542648315,
                "max": 1.472359538078308,
                "min": -2.271812915802002,
                "frobenius_norm": 12.027894020080566,
                "spectral_norm": 6.41367769241333,
                "num_singular_values": 32,
                "alpha": 1.0941581234823132
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.047980982810258865,
                "median": -0.05292646586894989,
                "std": 0.2821131646633148,
                "max": 4.0998735427856445,
                "min": -1.3598523139953613,
                "frobenius_norm": 9.157258033752441,
                "spectral_norm": 6.073423862457275,
                "num_singular_values": 32,
                "alpha": 1.1266283229154817
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 9.567057713866234e-05,
                "median": 0.0059712911024689674,
                "std": 0.13556170463562012,
                "max": 0.2854054868221283,
                "min": -0.5719839334487915,
                "frobenius_norm": 2.16898775100708,
                "spectral_norm": 1.2122461795806885,
                "num_singular_values": 8,
                "alpha": 2.0392606323123954
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.01_batch_size_256_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 256,
            "scaler_type": "identity",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.08028708398342133,
            "mse": 413021440.0,
            "mae": 1892.831787109375,
            "r2_score": 0.9107816815376282,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": -0.03925664350390434,
                "median": -0.04681362211704254,
                "std": 0.24322809278964996,
                "max": 0.6359691023826599,
                "min": -1.6507067680358887,
                "frobenius_norm": 4.827958106994629,
                "spectral_norm": 2.8493547439575195,
                "num_singular_values": 12,
                "alpha": 1.6148014753079827
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.03082156926393509,
                "median": -0.039366964250802994,
                "std": 0.2071870118379593,
                "max": 1.1558606624603271,
                "min": -3.134910821914673,
                "frobenius_norm": 6.702943801879883,
                "spectral_norm": 4.218256950378418,
                "num_singular_values": 32,
                "alpha": 1.206903957787533
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.000962569029070437,
                "median": -0.0019699290860444307,
                "std": 0.14135128259658813,
                "max": 0.693556547164917,
                "min": -1.0994104146957397,
                "frobenius_norm": 4.523345947265625,
                "spectral_norm": 2.000319480895996,
                "num_singular_values": 32,
                "alpha": 1.1581780879850017
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.05694938451051712,
                "median": 0.07210802286863327,
                "std": 0.13246425986289978,
                "max": 0.31075823307037354,
                "min": -0.33805784583091736,
                "frobenius_norm": 2.3069987297058105,
                "spectral_norm": 1.5641990900039673,
                "num_singular_values": 8,
                "alpha": 1.7222767852198055
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.01_batch_size_256_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 256,
            "scaler_type": "standard",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07000762969255447,
            "mse": 369830688.0,
            "mae": 1940.3687744140625,
            "r2_score": 0.9201114773750305,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.09424656629562378,
                "median": 0.07925552129745483,
                "std": 0.2771961987018585,
                "max": 0.8946493268013,
                "min": -1.0069211721420288,
                "frobenius_norm": 5.737293720245361,
                "spectral_norm": 2.66776967048645,
                "num_singular_values": 12,
                "alpha": 1.566014214294071
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.028631005436182022,
                "median": -0.023131120949983597,
                "std": 0.3333318829536438,
                "max": 1.1374108791351318,
                "min": -2.180124521255493,
                "frobenius_norm": 10.70589542388916,
                "spectral_norm": 4.822071075439453,
                "num_singular_values": 32,
                "alpha": 1.1377100355667062
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.060722384601831436,
                "median": -0.052850473672151566,
                "std": 0.2593851685523987,
                "max": 1.8181416988372803,
                "min": -1.8357888460159302,
                "frobenius_norm": 8.524735450744629,
                "spectral_norm": 4.0723466873168945,
                "num_singular_values": 32,
                "alpha": 1.117416797316282
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.03142733871936798,
                "median": 0.036381639540195465,
                "std": 0.14958137273788452,
                "max": 0.4662725627422333,
                "min": -0.6300055980682373,
                "frobenius_norm": 2.4455552101135254,
                "spectral_norm": 1.6796780824661255,
                "num_singular_values": 8,
                "alpha": 1.852443879483849
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.01_batch_size_256_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 256,
            "scaler_type": "robust",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.06862714886665344,
            "mse": 277192992.0,
            "mae": 1774.929931640625,
            "r2_score": 0.9401224851608276,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.09150606393814087,
                "median": 0.08584090322256088,
                "std": 0.3516309857368469,
                "max": 2.043076992034912,
                "min": -2.2783210277557373,
                "frobenius_norm": 7.120028495788574,
                "spectral_norm": 4.479781150817871,
                "num_singular_values": 12,
                "alpha": 1.8385610590171506
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.04483858495950699,
                "median": -0.045237597078084946,
                "std": 0.3782118558883667,
                "max": 1.6163328886032104,
                "min": -1.7888656854629517,
                "frobenius_norm": 12.187535285949707,
                "spectral_norm": 4.869974136352539,
                "num_singular_values": 32,
                "alpha": 1.0850135977481214
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.08339591324329376,
                "median": -0.06390301883220673,
                "std": 0.2856864929199219,
                "max": 1.4702800512313843,
                "min": -1.7604122161865234,
                "frobenius_norm": 9.523516654968262,
                "spectral_norm": 4.871537208557129,
                "num_singular_values": 32,
                "alpha": 1.1108409559410588
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.03784450888633728,
                "median": 0.052882321178913116,
                "std": 0.13966645300388336,
                "max": 0.355733186006546,
                "min": -0.4473983347415924,
                "frobenius_norm": 2.315246105194092,
                "spectral_norm": 1.412063717842102,
                "num_singular_values": 8,
                "alpha": 1.893746691174103
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.01_batch_size_256_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 256,
            "scaler_type": "minmax",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.0857795849442482,
            "mse": 583000640.0,
            "mae": 2416.0361328125,
            "r2_score": 0.8740638494491577,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.049133822321891785,
                "median": 0.050560325384140015,
                "std": 0.302453875541687,
                "max": 1.6472433805465698,
                "min": -1.9093607664108276,
                "frobenius_norm": 6.004558086395264,
                "spectral_norm": 3.6175875663757324,
                "num_singular_values": 12,
                "alpha": 1.537234923902338
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.07879026234149933,
                "median": -0.0676254853606224,
                "std": 0.2889321744441986,
                "max": 1.3232216835021973,
                "min": -2.970210552215576,
                "frobenius_norm": 9.583436965942383,
                "spectral_norm": 4.606072425842285,
                "num_singular_values": 32,
                "alpha": 1.1279251732940105
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.05455011501908302,
                "median": -0.056953899562358856,
                "std": 0.1852446049451828,
                "max": 1.3084262609481812,
                "min": -1.1736435890197754,
                "frobenius_norm": 6.17950439453125,
                "spectral_norm": 2.9596920013427734,
                "num_singular_values": 32,
                "alpha": 1.1223134618241148
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": -0.018243417143821716,
                "median": -0.011319623328745365,
                "std": 0.1365392953157425,
                "max": 0.36120161414146423,
                "min": -0.4113312363624573,
                "frobenius_norm": 2.20404314994812,
                "spectral_norm": 1.3837770223617554,
                "num_singular_values": 8,
                "alpha": 1.7797948810859838
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.005_batch_size_16_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.08026771992444992,
            "mse": 453574592.0,
            "mae": 1977.567626953125,
            "r2_score": 0.9020216464996338,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": -0.014132832176983356,
                "median": -0.01801462471485138,
                "std": 0.1995195597410202,
                "max": 0.4486771821975708,
                "min": -0.6717717051506042,
                "frobenius_norm": 3.919565439224243,
                "spectral_norm": 1.9478367567062378,
                "num_singular_values": 12,
                "alpha": 1.8340663961132422
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.015050732530653477,
                "median": -0.013541297987103462,
                "std": 0.18338173627853394,
                "max": 0.6643458604812622,
                "min": -1.3778949975967407,
                "frobenius_norm": 5.887946605682373,
                "spectral_norm": 3.631653070449829,
                "num_singular_values": 32,
                "alpha": 1.0519199461615791
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.00883063580840826,
                "median": 0.0040336837992072105,
                "std": 0.12128676474094391,
                "max": 0.39892539381980896,
                "min": -0.34807682037353516,
                "frobenius_norm": 3.8914499282836914,
                "spectral_norm": 1.749680995941162,
                "num_singular_values": 32,
                "alpha": 1.1528686123112823
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.05357988178730011,
                "median": 0.0662553682923317,
                "std": 0.10277199745178223,
                "max": 0.2718023359775543,
                "min": -0.16878537833690643,
                "frobenius_norm": 1.8544052839279175,
                "spectral_norm": 1.0777547359466553,
                "num_singular_values": 8,
                "alpha": 1.8075861311951988
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.005_batch_size_16_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.06992018222808838,
            "mse": 340765024.0,
            "mae": 1893.52001953125,
            "r2_score": 0.9263900518417358,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.056002479046583176,
                "median": 0.06357651203870773,
                "std": 0.24046583473682404,
                "max": 0.7628892064094543,
                "min": -0.8865558505058289,
                "frobenius_norm": 4.838251113891602,
                "spectral_norm": 2.1324517726898193,
                "num_singular_values": 12,
                "alpha": 1.7651874848555382
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.004706972278654575,
                "median": 0.004267439246177673,
                "std": 0.2556646168231964,
                "max": 1.349204659461975,
                "min": -1.6624925136566162,
                "frobenius_norm": 8.18265438079834,
                "spectral_norm": 4.148236274719238,
                "num_singular_values": 32,
                "alpha": 1.0819369730196287
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.0185525044798851,
                "median": -0.021506350487470627,
                "std": 0.19791053235530853,
                "max": 1.0932255983352661,
                "min": -0.9614338278770447,
                "frobenius_norm": 6.360902786254883,
                "spectral_norm": 2.7266712188720703,
                "num_singular_values": 32,
                "alpha": 1.0970656949644446
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.045304007828235626,
                "median": 0.047033607959747314,
                "std": 0.1356750726699829,
                "max": 0.42652517557144165,
                "min": -0.42587026953697205,
                "frobenius_norm": 2.288625478744507,
                "spectral_norm": 1.3654100894927979,
                "num_singular_values": 8,
                "alpha": 1.8454680063909064
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.005_batch_size_16_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.0696750283241272,
            "mse": 548912640.0,
            "mae": 2101.133056640625,
            "r2_score": 0.8814272880554199,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.052938420325517654,
                "median": 0.05082310363650322,
                "std": 0.2822323441505432,
                "max": 0.9657529592514038,
                "min": -1.3983784914016724,
                "frobenius_norm": 5.62705135345459,
                "spectral_norm": 3.0664310455322266,
                "num_singular_values": 12,
                "alpha": 1.6162470901922865
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.02085181511938572,
                "median": -0.01489621214568615,
                "std": 0.2922516465187073,
                "max": 0.958469808101654,
                "min": -1.5325244665145874,
                "frobenius_norm": 9.375826835632324,
                "spectral_norm": 3.824382781982422,
                "num_singular_values": 32,
                "alpha": 1.1562793024751885
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.04132216423749924,
                "median": -0.043195851147174835,
                "std": 0.23814386129379272,
                "max": 1.3204450607299805,
                "min": -1.1009557247161865,
                "frobenius_norm": 7.7344746589660645,
                "spectral_norm": 3.3029088973999023,
                "num_singular_values": 32,
                "alpha": 1.060376568710179
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.03460581228137016,
                "median": 0.048191484063863754,
                "std": 0.11904984712600708,
                "max": 0.31861358880996704,
                "min": -0.42544984817504883,
                "frobenius_norm": 1.9836405515670776,
                "spectral_norm": 1.189841389656067,
                "num_singular_values": 8,
                "alpha": 2.049117891438195
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.005_batch_size_16_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07644873112440109,
            "mse": 483674528.0,
            "mae": 2127.76513671875,
            "r2_score": 0.8955196142196655,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.055991947650909424,
                "median": 0.03800446540117264,
                "std": 0.24206605553627014,
                "max": 1.2933307886123657,
                "min": -0.7495023608207703,
                "frobenius_norm": 4.86875057220459,
                "spectral_norm": 2.956660747528076,
                "num_singular_values": 12,
                "alpha": 1.6703227708896442
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.05850161984562874,
                "median": -0.04227830469608307,
                "std": 0.23619870841503143,
                "max": 1.0152963399887085,
                "min": -1.6532241106033325,
                "frobenius_norm": 7.786742687225342,
                "spectral_norm": 3.8190813064575195,
                "num_singular_values": 32,
                "alpha": 1.070537499149358
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.033524878323078156,
                "median": -0.031238604336977005,
                "std": 0.14989210665225983,
                "max": 0.6412256956100464,
                "min": -0.8267672061920166,
                "frobenius_norm": 4.9150543212890625,
                "spectral_norm": 2.174734592437744,
                "num_singular_values": 32,
                "alpha": 1.1230618330695508
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.03425772488117218,
                "median": 0.03707519918680191,
                "std": 0.10705238580703735,
                "max": 0.3065495491027832,
                "min": -0.2523907423019409,
                "frobenius_norm": 1.7984031438827515,
                "spectral_norm": 1.0284327268600464,
                "num_singular_values": 8,
                "alpha": 2.1930447838967915
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.0815434381365776,
            "mse": 407256032.0,
            "mae": 1922.0301513671875,
            "r2_score": 0.9120270609855652,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.0027820959221571684,
                "median": 0.00015444715972989798,
                "std": 0.19589701294898987,
                "max": 0.47858208417892456,
                "min": -0.6234250664710999,
                "frobenius_norm": 3.8391687870025635,
                "spectral_norm": 1.5730637311935425,
                "num_singular_values": 12,
                "alpha": 1.7642605598684349
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.014532255008816719,
                "median": -0.011450093239545822,
                "std": 0.21902382373809814,
                "max": 1.1035352945327759,
                "min": -2.955854654312134,
                "frobenius_norm": 7.024172782897949,
                "spectral_norm": 4.899053573608398,
                "num_singular_values": 32,
                "alpha": 1.1284986144512952
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.012263644486665726,
                "median": 0.007461703382432461,
                "std": 0.15550850331783295,
                "max": 2.025800943374634,
                "min": -0.7230818271636963,
                "frobenius_norm": 4.991722106933594,
                "spectral_norm": 2.694272041320801,
                "num_singular_values": 32,
                "alpha": 1.1330210839393426
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.044875774532556534,
                "median": 0.05908648669719696,
                "std": 0.1213267520070076,
                "max": 0.2706400454044342,
                "min": -0.5064615607261658,
                "frobenius_norm": 2.069760322570801,
                "spectral_norm": 1.418550729751587,
                "num_singular_values": 8,
                "alpha": 1.9711259042913674
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.005_batch_size_32_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07046572118997574,
            "mse": 347500224.0,
            "mae": 1867.06787109375,
            "r2_score": 0.9249351620674133,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.05913400650024414,
                "median": 0.05744785815477371,
                "std": 0.25775083899497986,
                "max": 0.8129599094390869,
                "min": -0.8910397887229919,
                "frobenius_norm": 5.182085990905762,
                "spectral_norm": 2.376990795135498,
                "num_singular_values": 12,
                "alpha": 1.6355579663450488
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.017648963257670403,
                "median": -0.01201008353382349,
                "std": 0.27821066975593567,
                "max": 0.9832866191864014,
                "min": -1.8856282234191895,
                "frobenius_norm": 8.920637130737305,
                "spectral_norm": 3.857390880584717,
                "num_singular_values": 32,
                "alpha": 1.1118980943602277
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.019943995401263237,
                "median": -0.0270344540476799,
                "std": 0.21927523612976074,
                "max": 0.9635573625564575,
                "min": -1.092164158821106,
                "frobenius_norm": 7.045771598815918,
                "spectral_norm": 2.7990682125091553,
                "num_singular_values": 32,
                "alpha": 1.1112846993705985
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.017097918316721916,
                "median": 0.010551020503044128,
                "std": 0.1332913041114807,
                "max": 0.36524173617362976,
                "min": -0.3037215769290924,
                "frobenius_norm": 2.150135040283203,
                "spectral_norm": 1.2886167764663696,
                "num_singular_values": 8,
                "alpha": 1.935176228677491
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.005_batch_size_32_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.06914225220680237,
            "mse": 399900896.0,
            "mae": 1879.846435546875,
            "r2_score": 0.913615882396698,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.04631673917174339,
                "median": 0.044782333076000214,
                "std": 0.298759400844574,
                "max": 1.1477439403533936,
                "min": -1.7605233192443848,
                "frobenius_norm": 5.92440128326416,
                "spectral_norm": 3.46600341796875,
                "num_singular_values": 12,
                "alpha": 1.5037723090218478
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.0031822375021874905,
                "median": 0.008824942633509636,
                "std": 0.27072200179100037,
                "max": 0.9802190065383911,
                "min": -1.544900894165039,
                "frobenius_norm": 8.663702964782715,
                "spectral_norm": 3.4198479652404785,
                "num_singular_values": 32,
                "alpha": 1.1198245828183844
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.002208786318078637,
                "median": -0.006013392470777035,
                "std": 0.2462024986743927,
                "max": 1.1171987056732178,
                "min": -0.9151425957679749,
                "frobenius_norm": 7.8787970542907715,
                "spectral_norm": 3.2390694618225098,
                "num_singular_values": 32,
                "alpha": 1.095541445293584
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.02773451805114746,
                "median": 0.027937524020671844,
                "std": 0.1429222971200943,
                "max": 0.513588011264801,
                "min": -0.3981713652610779,
                "frobenius_norm": 2.3294148445129395,
                "spectral_norm": 1.5319563150405884,
                "num_singular_values": 8,
                "alpha": 2.1162028951447738
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.005_batch_size_32_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07123377174139023,
            "mse": 430180288.0,
            "mae": 2028.192626953125,
            "r2_score": 0.9070751070976257,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.058064088225364685,
                "median": 0.04476255923509598,
                "std": 0.3003733456134796,
                "max": 1.2138526439666748,
                "min": -2.1489357948303223,
                "frobenius_norm": 5.995057106018066,
                "spectral_norm": 3.869232654571533,
                "num_singular_values": 12,
                "alpha": 1.5270430833017181
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.041222892701625824,
                "median": -0.038626860827207565,
                "std": 0.2102435827255249,
                "max": 0.7394071817398071,
                "min": -1.4451063871383667,
                "frobenius_norm": 6.855897903442383,
                "spectral_norm": 3.488022565841675,
                "num_singular_values": 32,
                "alpha": 1.1654990216974146
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.009684831835329533,
                "median": -0.01124177873134613,
                "std": 0.15546637773513794,
                "max": 0.7478532791137695,
                "min": -0.6988458037376404,
                "frobenius_norm": 4.984567642211914,
                "spectral_norm": 2.6819732189178467,
                "num_singular_values": 32,
                "alpha": 1.1532063552720921
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.03041205368936062,
                "median": 0.02337576076388359,
                "std": 0.11585112661123276,
                "max": 0.4806189239025116,
                "min": -0.1961052119731903,
                "frobenius_norm": 1.9164217710494995,
                "spectral_norm": 1.0004665851593018,
                "num_singular_values": 8,
                "alpha": 1.9574024340352492
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.09514573216438293,
            "mse": 442752640.0,
            "mae": 2143.334716796875,
            "r2_score": 0.9043593406677246,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": -0.012941214255988598,
                "median": -0.00947373267263174,
                "std": 0.20901791751384735,
                "max": 0.5129937529563904,
                "min": -1.0276180505752563,
                "frobenius_norm": 4.103740692138672,
                "spectral_norm": 2.0934505462646484,
                "num_singular_values": 12,
                "alpha": 1.8022161253250677
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.005466893780976534,
                "median": -0.009420476853847504,
                "std": 0.17949354648590088,
                "max": 0.5298764705657959,
                "min": -1.0666033029556274,
                "frobenius_norm": 5.746457099914551,
                "spectral_norm": 3.209055185317993,
                "num_singular_values": 32,
                "alpha": 1.1327047328252695
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.010979240760207176,
                "median": 0.009858929552137852,
                "std": 0.1446407288312912,
                "max": 0.9468474984169006,
                "min": -0.9347041249275208,
                "frobenius_norm": 4.641818523406982,
                "spectral_norm": 2.151434898376465,
                "num_singular_values": 32,
                "alpha": 1.1184769315333676
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.04914453998208046,
                "median": 0.06110488623380661,
                "std": 0.11753930896520615,
                "max": 0.3677666187286377,
                "min": -0.41779401898384094,
                "frobenius_norm": 2.0383946895599365,
                "spectral_norm": 1.1438286304473877,
                "num_singular_values": 8,
                "alpha": 1.8972756132975561
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.005_batch_size_64_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 64,
            "scaler_type": "standard",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.06969234347343445,
            "mse": 342834720.0,
            "mae": 1849.7080078125,
            "r2_score": 0.9259429574012756,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.08115532994270325,
                "median": 0.06754098832607269,
                "std": 0.2563972771167755,
                "max": 0.9574207663536072,
                "min": -0.768678605556488,
                "frobenius_norm": 5.270017623901367,
                "spectral_norm": 2.606733560562134,
                "num_singular_values": 12,
                "alpha": 1.7088751560091273
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.001589773572050035,
                "median": 0.00019245845032855868,
                "std": 0.2619234025478363,
                "max": 1.2340116500854492,
                "min": -1.0406193733215332,
                "frobenius_norm": 8.38170337677002,
                "spectral_norm": 3.660060167312622,
                "num_singular_values": 32,
                "alpha": 1.145476358064141
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.02093449980020523,
                "median": -0.019714735448360443,
                "std": 0.2110772430896759,
                "max": 1.045555591583252,
                "min": -1.1544922590255737,
                "frobenius_norm": 6.78761100769043,
                "spectral_norm": 2.9465746879577637,
                "num_singular_values": 32,
                "alpha": 1.1127596582506392
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.005076428409665823,
                "median": 0.027819473296403885,
                "std": 0.1500115841627121,
                "max": 0.3411245346069336,
                "min": -0.5528131723403931,
                "frobenius_norm": 2.401559352874756,
                "spectral_norm": 1.733382225036621,
                "num_singular_values": 8,
                "alpha": 1.8904654968612173
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.005_batch_size_64_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 64,
            "scaler_type": "robust",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.06915844231843948,
            "mse": 458719616.0,
            "mae": 1907.86669921875,
            "r2_score": 0.9009102582931519,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.05929900333285332,
                "median": 0.05996794253587723,
                "std": 0.28838831186294556,
                "max": 1.2259416580200195,
                "min": -1.4686782360076904,
                "frobenius_norm": 5.76946496963501,
                "spectral_norm": 3.313016176223755,
                "num_singular_values": 12,
                "alpha": 1.607122694770248
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.002386439824476838,
                "median": 0.010001218877732754,
                "std": 0.2752174735069275,
                "max": 1.0506386756896973,
                "min": -1.2207849025726318,
                "frobenius_norm": 8.807290077209473,
                "spectral_norm": 3.8403115272521973,
                "num_singular_values": 32,
                "alpha": 1.1158727094961791
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.00036026351153850555,
                "median": -0.012129077687859535,
                "std": 0.22226040065288544,
                "max": 0.9309455752372742,
                "min": -1.096645712852478,
                "frobenius_norm": 7.112342357635498,
                "spectral_norm": 3.13478946685791,
                "num_singular_values": 32,
                "alpha": 1.0794440688218425
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.022186651825904846,
                "median": 0.03207958862185478,
                "std": 0.14016041159629822,
                "max": 0.3262404203414917,
                "min": -0.7052484750747681,
                "frobenius_norm": 2.270488977432251,
                "spectral_norm": 1.1575274467468262,
                "num_singular_values": 8,
                "alpha": 2.1080792395565777
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.005_batch_size_64_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 64,
            "scaler_type": "minmax",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.0706937313079834,
            "mse": 421871840.0,
            "mae": 1983.660400390625,
            "r2_score": 0.9088698625564575,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.051358699798583984,
                "median": 0.02998698689043522,
                "std": 0.2921258211135864,
                "max": 1.2788550853729248,
                "min": -2.6477909088134766,
                "frobenius_norm": 5.812270164489746,
                "spectral_norm": 3.6857523918151855,
                "num_singular_values": 12,
                "alpha": 1.6936948595882753
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.04366619884967804,
                "median": -0.039326369762420654,
                "std": 0.21389661729335785,
                "max": 0.6664499044418335,
                "min": -1.2862197160720825,
                "frobenius_norm": 6.985864162445068,
                "spectral_norm": 3.474756956100464,
                "num_singular_values": 32,
                "alpha": 1.1477326470356795
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.004063812550157309,
                "median": -0.010177920572459698,
                "std": 0.16312621533870697,
                "max": 0.9912936687469482,
                "min": -0.7151138782501221,
                "frobenius_norm": 5.221658229827881,
                "spectral_norm": 2.9684576988220215,
                "num_singular_values": 32,
                "alpha": 1.134824807962253
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.024244802072644234,
                "median": 0.015819747000932693,
                "std": 0.11870081722736359,
                "max": 0.5152169466018677,
                "min": -0.33718395233154297,
                "frobenius_norm": 1.9384245872497559,
                "spectral_norm": 1.0487265586853027,
                "num_singular_values": 8,
                "alpha": 2.1397182963476284
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.005_batch_size_128_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 128,
            "scaler_type": "identity",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.08300615847110748,
            "mse": 397316448.0,
            "mae": 1868.8587646484375,
            "r2_score": 0.9141741991043091,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": -0.009016032330691814,
                "median": -0.020669279620051384,
                "std": 0.21044538915157318,
                "max": 0.5845404267311096,
                "min": -0.6877620220184326,
                "frobenius_norm": 4.1276535987854,
                "spectral_norm": 1.9441403150558472,
                "num_singular_values": 12,
                "alpha": 1.750126550180147
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.011980370618402958,
                "median": -0.0167270228266716,
                "std": 0.20733915269374847,
                "max": 0.6627517938613892,
                "min": -3.374509811401367,
                "frobenius_norm": 6.6459197998046875,
                "spectral_norm": 4.332371234893799,
                "num_singular_values": 32,
                "alpha": 1.1677462751338286
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.017462190240621567,
                "median": 0.014905362389981747,
                "std": 0.13490019738674164,
                "max": 0.5019974112510681,
                "min": -0.6101343631744385,
                "frobenius_norm": 4.3528218269348145,
                "spectral_norm": 2.127614974975586,
                "num_singular_values": 32,
                "alpha": 1.126206387482843
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.05496533215045929,
                "median": 0.06319005787372589,
                "std": 0.11469180136919022,
                "max": 0.36188414692878723,
                "min": -0.2453927993774414,
                "frobenius_norm": 2.0349204540252686,
                "spectral_norm": 1.1775192022323608,
                "num_singular_values": 8,
                "alpha": 1.9750763782278855
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.005_batch_size_128_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 128,
            "scaler_type": "standard",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.0692351832985878,
            "mse": 377165088.0,
            "mae": 1894.0303955078125,
            "r2_score": 0.9185271263122559,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.07022225111722946,
                "median": 0.06570958346128464,
                "std": 0.24454352259635925,
                "max": 0.8353771567344666,
                "min": -0.8284797072410583,
                "frobenius_norm": 4.985714912414551,
                "spectral_norm": 2.4156203269958496,
                "num_singular_values": 12,
                "alpha": 1.561004942979015
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.004143418278545141,
                "median": 0.003997753374278545,
                "std": 0.2648561894893646,
                "max": 1.0917150974273682,
                "min": -1.2368820905685425,
                "frobenius_norm": 8.476435661315918,
                "spectral_norm": 3.5288727283477783,
                "num_singular_values": 32,
                "alpha": 1.1498003802946648
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.02165468968451023,
                "median": -0.021525051444768906,
                "std": 0.2297879308462143,
                "max": 0.98423832654953,
                "min": -1.294811725616455,
                "frobenius_norm": 7.385793209075928,
                "spectral_norm": 3.190701484680176,
                "num_singular_values": 32,
                "alpha": 1.1461249537326474
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.038008712232112885,
                "median": 0.03551524877548218,
                "std": 0.17677341401576996,
                "max": 0.6112131476402283,
                "min": -0.4345901310443878,
                "frobenius_norm": 2.8930153846740723,
                "spectral_norm": 2.124358654022217,
                "num_singular_values": 8,
                "alpha": 1.8866243871835982
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.005_batch_size_128_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 128,
            "scaler_type": "robust",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07098225504159927,
            "mse": 418972992.0,
            "mae": 1946.59765625,
            "r2_score": 0.9094960689544678,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.061652302742004395,
                "median": 0.058909084647893906,
                "std": 0.28655052185058594,
                "max": 1.3588117361068726,
                "min": -0.9123250246047974,
                "frobenius_norm": 5.743717670440674,
                "spectral_norm": 3.1129581928253174,
                "num_singular_values": 12,
                "alpha": 1.7212471311289068
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.009972460567951202,
                "median": 0.007449681870639324,
                "std": 0.2822337746620178,
                "max": 1.2108995914459229,
                "min": -1.145706295967102,
                "frobenius_norm": 9.037116050720215,
                "spectral_norm": 3.732780694961548,
                "num_singular_values": 32,
                "alpha": 1.0779460757315373
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.017573103308677673,
                "median": -0.019677769392728806,
                "std": 0.24471765756607056,
                "max": 1.2171545028686523,
                "min": -1.0209490060806274,
                "frobenius_norm": 7.851129531860352,
                "spectral_norm": 3.182865619659424,
                "num_singular_values": 32,
                "alpha": 1.1616336426206877
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.01618131808936596,
                "median": 0.02123473398387432,
                "std": 0.17910587787628174,
                "max": 0.6005736589431763,
                "min": -0.9872600436210632,
                "frobenius_norm": 2.8773655891418457,
                "spectral_norm": 1.7519420385360718,
                "num_singular_values": 8,
                "alpha": 2.0567931476493984
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.005_batch_size_128_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 128,
            "scaler_type": "minmax",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07027567923069,
            "mse": 387506176.0,
            "mae": 1915.294189453125,
            "r2_score": 0.9162933230400085,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.06085708737373352,
                "median": 0.04679294675588608,
                "std": 0.2973361313343048,
                "max": 1.3806334733963013,
                "min": -1.937318205833435,
                "frobenius_norm": 5.947364330291748,
                "spectral_norm": 3.9159092903137207,
                "num_singular_values": 12,
                "alpha": 1.5850327943364382
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.059623971581459045,
                "median": -0.04924570024013519,
                "std": 0.25526928901672363,
                "max": 0.8206210136413574,
                "min": -2.3963756561279297,
                "frobenius_norm": 8.388483047485352,
                "spectral_norm": 4.161869049072266,
                "num_singular_values": 32,
                "alpha": 1.118447692503134
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.0029981527477502823,
                "median": -0.014308434911072254,
                "std": 0.23571409285068512,
                "max": 2.0641908645629883,
                "min": -1.4107095003128052,
                "frobenius_norm": 7.543461322784424,
                "spectral_norm": 5.075831413269043,
                "num_singular_values": 32,
                "alpha": 1.1542376727752204
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.0062073953449726105,
                "median": -0.005642578937113285,
                "std": 0.16531184315681458,
                "max": 1.0545443296432495,
                "min": -0.33882540464401245,
                "frobenius_norm": 2.64685320854187,
                "spectral_norm": 2.027170181274414,
                "num_singular_values": 8,
                "alpha": 1.8467755070160814
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.005_batch_size_256_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 256,
            "scaler_type": "identity",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.08423075824975967,
            "mse": 444019232.0,
            "mae": 2053.5029296875,
            "r2_score": 0.9040857553482056,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": -0.010246366262435913,
                "median": -0.011669214814901352,
                "std": 0.20528268814086914,
                "max": 0.4761029779911041,
                "min": -0.8815688490867615,
                "frobenius_norm": 4.027710437774658,
                "spectral_norm": 1.9355241060256958,
                "num_singular_values": 12,
                "alpha": 1.6895140807792348
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.006872696802020073,
                "median": -0.010240902192890644,
                "std": 0.23976993560791016,
                "max": 2.1208624839782715,
                "min": -3.454955816268921,
                "frobenius_norm": 7.6757893562316895,
                "spectral_norm": 4.6735429763793945,
                "num_singular_values": 32,
                "alpha": 1.1582720449700006
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.007958047091960907,
                "median": 0.006206263788044453,
                "std": 0.14994916319847107,
                "max": 1.5339208841323853,
                "min": -0.8984202742576599,
                "frobenius_norm": 4.805126190185547,
                "spectral_norm": 2.129239082336426,
                "num_singular_values": 32,
                "alpha": 1.1345242408543261
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.05367478355765343,
                "median": 0.06109064817428589,
                "std": 0.11488978564739227,
                "max": 0.3591175377368927,
                "min": -0.24420078098773956,
                "frobenius_norm": 2.02895188331604,
                "spectral_norm": 1.101527214050293,
                "num_singular_values": 8,
                "alpha": 1.7838664349424422
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.005_batch_size_256_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 256,
            "scaler_type": "standard",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.06956225633621216,
            "mse": 370350272.0,
            "mae": 1924.3282470703125,
            "r2_score": 0.9199992418289185,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.07449626922607422,
                "median": 0.07162700593471527,
                "std": 0.2871875762939453,
                "max": 0.8759785294532776,
                "min": -1.2970026731491089,
                "frobenius_norm": 5.813960075378418,
                "spectral_norm": 2.7879841327667236,
                "num_singular_values": 12,
                "alpha": 1.557389519885147
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.0117171136662364,
                "median": 0.004058286547660828,
                "std": 0.2799729108810425,
                "max": 1.2251560688018799,
                "min": -1.7246859073638916,
                "frobenius_norm": 8.966975212097168,
                "spectral_norm": 3.9273338317871094,
                "num_singular_values": 32,
                "alpha": 1.0958016241317288
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.023553665727376938,
                "median": -0.03156525641679764,
                "std": 0.22030499577522278,
                "max": 1.1377183198928833,
                "min": -0.9005023241043091,
                "frobenius_norm": 7.08993673324585,
                "spectral_norm": 3.351907730102539,
                "num_singular_values": 32,
                "alpha": 1.2132620401038015
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.048590563237667084,
                "median": 0.04925892502069473,
                "std": 0.12362606078386307,
                "max": 0.4687006175518036,
                "min": -0.2428247183561325,
                "frobenius_norm": 2.1253182888031006,
                "spectral_norm": 1.4860676527023315,
                "num_singular_values": 8,
                "alpha": 1.769540842951209
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.005_batch_size_256_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 256,
            "scaler_type": "robust",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.06950520724058151,
            "mse": 412622400.0,
            "mae": 1861.27001953125,
            "r2_score": 0.9108678698539734,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.008410753682255745,
                "median": 0.00760679692029953,
                "std": 0.2757345736026764,
                "max": 0.8669307827949524,
                "min": -1.055853009223938,
                "frobenius_norm": 5.40578556060791,
                "spectral_norm": 2.729647636413574,
                "num_singular_values": 12,
                "alpha": 1.6585647451337522
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.008289800025522709,
                "median": -0.013792461715638638,
                "std": 0.28580090403556824,
                "max": 1.3141067028045654,
                "min": -1.2575329542160034,
                "frobenius_norm": 9.14947509765625,
                "spectral_norm": 3.924286127090454,
                "num_singular_values": 32,
                "alpha": 1.0823308626190467
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.010293234139680862,
                "median": -0.011452598497271538,
                "std": 0.23227974772453308,
                "max": 1.2031174898147583,
                "min": -1.1961637735366821,
                "frobenius_norm": 7.44024658203125,
                "spectral_norm": 3.3582231998443604,
                "num_singular_values": 32,
                "alpha": 1.1170928590760445
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.05305790156126022,
                "median": 0.04643324390053749,
                "std": 0.16684268414974213,
                "max": 0.6985637545585632,
                "min": -0.6512280702590942,
                "frobenius_norm": 2.8012168407440186,
                "spectral_norm": 2.0933618545532227,
                "num_singular_values": 8,
                "alpha": 1.7284194112045885
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.005_batch_size_256_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 256,
            "scaler_type": "minmax",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07091578096151352,
            "mse": 366975904.0,
            "mae": 1910.360595703125,
            "r2_score": 0.9207281470298767,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.052451521158218384,
                "median": 0.04244314879179001,
                "std": 0.2794451117515564,
                "max": 1.09897780418396,
                "min": -2.6778063774108887,
                "frobenius_norm": 5.571610450744629,
                "spectral_norm": 3.7067067623138428,
                "num_singular_values": 12,
                "alpha": 1.599444985777272
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.03927052766084671,
                "median": -0.03385300189256668,
                "std": 0.22572863101959229,
                "max": 0.8479704260826111,
                "min": -1.830096960067749,
                "frobenius_norm": 7.331813335418701,
                "spectral_norm": 3.277952194213867,
                "num_singular_values": 32,
                "alpha": 1.1758482082183424
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.01889156550168991,
                "median": -0.018693212419748306,
                "std": 0.20353667438030243,
                "max": 1.0278105735778809,
                "min": -1.6981806755065918,
                "frobenius_norm": 6.541168689727783,
                "spectral_norm": 3.037860631942749,
                "num_singular_values": 32,
                "alpha": 1.1297943838683293
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.020320715382695198,
                "median": 0.018024178221821785,
                "std": 0.13528504967689514,
                "max": 0.5510260462760925,
                "min": -0.4107472896575928,
                "frobenius_norm": 2.188843250274658,
                "spectral_norm": 1.2604997158050537,
                "num_singular_values": 8,
                "alpha": 1.6880699021599461
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.001_batch_size_16_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.08128216117620468,
            "mse": 455203008.0,
            "mae": 1968.1864013671875,
            "r2_score": 0.9016698598861694,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.021917851641774178,
                "median": 0.021042006090283394,
                "std": 0.17336073517799377,
                "max": 0.42043447494506836,
                "min": -0.47297921776771545,
                "frobenius_norm": 3.424205780029297,
                "spectral_norm": 1.441449522972107,
                "num_singular_values": 12,
                "alpha": 1.7546226916542007
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.025562429800629616,
                "median": 0.020228080451488495,
                "std": 0.13170333206653595,
                "max": 0.5349984169006348,
                "min": -0.3111863434314728,
                "frobenius_norm": 4.293155670166016,
                "spectral_norm": 2.5416760444641113,
                "num_singular_values": 32,
                "alpha": 1.1321126763263902
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.022929105907678604,
                "median": 0.021436374634504318,
                "std": 0.11532656103372574,
                "max": 0.35221609473228455,
                "min": -0.2710588276386261,
                "frobenius_norm": 3.7626829147338867,
                "spectral_norm": 1.8748767375946045,
                "num_singular_values": 32,
                "alpha": 1.13013355739459
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.041597411036491394,
                "median": 0.04796353355050087,
                "std": 0.10523515194654465,
                "max": 0.26009610295295715,
                "min": -0.1590246707201004,
                "frobenius_norm": 1.8105313777923584,
                "spectral_norm": 0.9838411808013916,
                "num_singular_values": 8,
                "alpha": 1.8002297236690519
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.001_batch_size_16_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07215115427970886,
            "mse": 478893920.0,
            "mae": 2030.6124267578125,
            "r2_score": 0.896552324295044,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.028826221823692322,
                "median": 0.0226513110101223,
                "std": 0.2117755264043808,
                "max": 0.6238723397254944,
                "min": -0.7938870787620544,
                "frobenius_norm": 4.188203811645508,
                "spectral_norm": 1.822426438331604,
                "num_singular_values": 12,
                "alpha": 1.688776688965758
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.021741341799497604,
                "median": 0.025802936404943466,
                "std": 0.15588945150375366,
                "max": 0.6277737617492676,
                "min": -0.5483781695365906,
                "frobenius_norm": 5.036743640899658,
                "spectral_norm": 1.9983739852905273,
                "num_singular_values": 32,
                "alpha": 1.1144239050175224
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.005693133920431137,
                "median": 0.0038895239122211933,
                "std": 0.16447287797927856,
                "max": 0.5855878591537476,
                "min": -0.5154972672462463,
                "frobenius_norm": 5.266283988952637,
                "spectral_norm": 2.590766668319702,
                "num_singular_values": 32,
                "alpha": 1.1197691553557279
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.0402585044503212,
                "median": 0.04481695964932442,
                "std": 0.1525387316942215,
                "max": 0.4497365951538086,
                "min": -0.45322513580322266,
                "frobenius_norm": 2.5241899490356445,
                "spectral_norm": 1.6747040748596191,
                "num_singular_values": 8,
                "alpha": 1.8791429992638355
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.001_batch_size_16_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07170472294092178,
            "mse": 464952544.0,
            "mae": 1974.5028076171875,
            "r2_score": 0.8995638489723206,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.029057959094643593,
                "median": 0.015480086207389832,
                "std": 0.2097577303647995,
                "max": 0.7694467902183533,
                "min": -0.7169501185417175,
                "frobenius_norm": 4.149648666381836,
                "spectral_norm": 1.8458815813064575,
                "num_singular_values": 12,
                "alpha": 1.7256060086206615
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.025125252082943916,
                "median": 0.021272189915180206,
                "std": 0.15813542902469635,
                "max": 0.5979682207107544,
                "min": -0.44050735235214233,
                "frobenius_norm": 5.123807907104492,
                "spectral_norm": 2.149493932723999,
                "num_singular_values": 32,
                "alpha": 1.1207608072928388
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.01937919110059738,
                "median": 0.019480347633361816,
                "std": 0.15288014709949493,
                "max": 0.7148850560188293,
                "min": -0.5555205345153809,
                "frobenius_norm": 4.931312084197998,
                "spectral_norm": 2.365724563598633,
                "num_singular_values": 32,
                "alpha": 1.1593427534754865
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.03956232964992523,
                "median": 0.04227125644683838,
                "std": 0.13935866951942444,
                "max": 0.36922961473464966,
                "min": -0.6019651293754578,
                "frobenius_norm": 2.3178482055664062,
                "spectral_norm": 1.376134991645813,
                "num_singular_values": 8,
                "alpha": 2.0216245649868796
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.001_batch_size_16_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07473160326480865,
            "mse": 451471872.0,
            "mae": 2075.756591796875,
            "r2_score": 0.9024758338928223,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.027647212147712708,
                "median": 0.01886896602809429,
                "std": 0.19608174264431,
                "max": 0.6238358616828918,
                "min": -0.8275313377380371,
                "frobenius_norm": 3.88040828704834,
                "spectral_norm": 1.9982149600982666,
                "num_singular_values": 12,
                "alpha": 1.7456305132247611
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.0002701748162508011,
                "median": -0.0029687918722629547,
                "std": 0.13469535112380981,
                "max": 0.41535094380378723,
                "min": -0.5509708523750305,
                "frobenius_norm": 4.310259819030762,
                "spectral_norm": 1.8440754413604736,
                "num_singular_values": 32,
                "alpha": 1.0626296585470345
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.007885366678237915,
                "median": 0.007170660421252251,
                "std": 0.12119673937559128,
                "max": 0.4902457594871521,
                "min": -0.42040133476257324,
                "frobenius_norm": 3.886495590209961,
                "spectral_norm": 1.7149670124053955,
                "num_singular_values": 32,
                "alpha": 1.1998553115487702
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.03474317491054535,
                "median": 0.02971755899488926,
                "std": 0.11243236809968948,
                "max": 0.36218464374542236,
                "min": -0.24969753623008728,
                "frobenius_norm": 1.882848858833313,
                "spectral_norm": 0.9763526320457458,
                "num_singular_values": 8,
                "alpha": 1.94000403356398
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07814911007881165,
            "mse": 431422208.0,
            "mae": 1916.570068359375,
            "r2_score": 0.9068068265914917,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.024063780903816223,
                "median": 0.023913521319627762,
                "std": 0.1741359680891037,
                "max": 0.40327364206314087,
                "min": -0.44358548521995544,
                "frobenius_norm": 3.444782018661499,
                "spectral_norm": 1.4382387399673462,
                "num_singular_values": 12,
                "alpha": 1.7445841688922825
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.023152070119976997,
                "median": 0.021092567592859268,
                "std": 0.1387755572795868,
                "max": 0.5391446948051453,
                "min": -1.1603373289108276,
                "frobenius_norm": 4.502193450927734,
                "spectral_norm": 2.5697693824768066,
                "num_singular_values": 32,
                "alpha": 1.1306268341239087
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.02432434633374214,
                "median": 0.0214313305914402,
                "std": 0.12413501739501953,
                "max": 0.4728017747402191,
                "min": -0.320994108915329,
                "frobenius_norm": 4.047863960266113,
                "spectral_norm": 2.2722251415252686,
                "num_singular_values": 32,
                "alpha": 1.1690832673946367
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.04855203628540039,
                "median": 0.05310998857021332,
                "std": 0.10940062999725342,
                "max": 0.273542195558548,
                "min": -0.1585668921470642,
                "frobenius_norm": 1.9150466918945312,
                "spectral_norm": 1.1172747611999512,
                "num_singular_values": 8,
                "alpha": 1.7048938808460081
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.001_batch_size_32_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07285477966070175,
            "mse": 433853056.0,
            "mae": 2006.955078125,
            "r2_score": 0.9062817692756653,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.037279438227415085,
                "median": 0.0271613672375679,
                "std": 0.22171545028686523,
                "max": 0.6521974205970764,
                "min": -0.8729797005653381,
                "frobenius_norm": 4.405704975128174,
                "spectral_norm": 1.9811969995498657,
                "num_singular_values": 12,
                "alpha": 1.7192139947630163
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.023537039756774902,
                "median": 0.02625027298927307,
                "std": 0.16653595864772797,
                "max": 0.6217527389526367,
                "min": -0.8081104159355164,
                "frobenius_norm": 5.382112503051758,
                "spectral_norm": 2.1830239295959473,
                "num_singular_values": 32,
                "alpha": 1.132950492453504
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.01474017184227705,
                "median": 0.01625852845609188,
                "std": 0.17216065526008606,
                "max": 0.6154752373695374,
                "min": -0.577707052230835,
                "frobenius_norm": 5.529296398162842,
                "spectral_norm": 2.5233423709869385,
                "num_singular_values": 32,
                "alpha": 1.1406000915833387
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.03556244447827339,
                "median": 0.03717920184135437,
                "std": 0.15638940036296844,
                "max": 0.4505729079246521,
                "min": -0.620498538017273,
                "frobenius_norm": 2.5661091804504395,
                "spectral_norm": 1.695414423942566,
                "num_singular_values": 8,
                "alpha": 1.957695152637797
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.001_batch_size_32_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.0716668963432312,
            "mse": 448838848.0,
            "mae": 1977.5062255859375,
            "r2_score": 0.9030446410179138,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.02615758217871189,
                "median": 0.023087643086910248,
                "std": 0.22460514307022095,
                "max": 0.7373726963996887,
                "min": -0.9476415514945984,
                "frobenius_norm": 4.43109130859375,
                "spectral_norm": 1.932513952255249,
                "num_singular_values": 12,
                "alpha": 1.6524231833391996
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.02441362477838993,
                "median": 0.023406483232975006,
                "std": 0.1697583943605423,
                "max": 0.7434784770011902,
                "min": -0.5175193548202515,
                "frobenius_norm": 5.488157749176025,
                "spectral_norm": 2.136352300643921,
                "num_singular_values": 32,
                "alpha": 1.1334099581562014
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.024523280560970306,
                "median": 0.025850364938378334,
                "std": 0.17081473767757416,
                "max": 0.7384912967681885,
                "min": -0.7377078533172607,
                "frobenius_norm": 5.522115707397461,
                "spectral_norm": 2.4304392337799072,
                "num_singular_values": 32,
                "alpha": 1.1530132833296105
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.036691829562187195,
                "median": 0.04026803374290466,
                "std": 0.14139844477176666,
                "max": 0.40961652994155884,
                "min": -0.6072615385055542,
                "frobenius_norm": 2.3373043537139893,
                "spectral_norm": 1.400059700012207,
                "num_singular_values": 8,
                "alpha": 2.054321102431877
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.001_batch_size_32_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07419626414775848,
            "mse": 465084992.0,
            "mae": 2100.745849609375,
            "r2_score": 0.8995352387428284,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.026904655620455742,
                "median": 0.012162650004029274,
                "std": 0.20054522156715393,
                "max": 0.6629931926727295,
                "min": -0.9527575373649597,
                "frobenius_norm": 3.9650754928588867,
                "spectral_norm": 1.9562405347824097,
                "num_singular_values": 12,
                "alpha": 1.913457861135278
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 1.1848518624901772e-05,
                "median": 0.008143008686602116,
                "std": 0.15066871047019958,
                "max": 0.5816981196403503,
                "min": -0.6158362627029419,
                "frobenius_norm": 4.821398735046387,
                "spectral_norm": 2.4345948696136475,
                "num_singular_values": 32,
                "alpha": 1.1591393009470095
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.0023123258724808693,
                "median": 0.006570303812623024,
                "std": 0.13736340403556824,
                "max": 0.46540123224258423,
                "min": -0.5778295993804932,
                "frobenius_norm": 4.396251678466797,
                "spectral_norm": 2.077185869216919,
                "num_singular_values": 32,
                "alpha": 1.1390159322985443
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.0369064137339592,
                "median": 0.03249291703104973,
                "std": 0.11532177776098251,
                "max": 0.37453657388687134,
                "min": -0.22298423945903778,
                "frobenius_norm": 1.9373348951339722,
                "spectral_norm": 1.0024104118347168,
                "num_singular_values": 8,
                "alpha": 1.953619904936025
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.081189826130867,
            "mse": 444956512.0,
            "mae": 1954.403564453125,
            "r2_score": 0.9038832783699036,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.022292764857411385,
                "median": 0.023677214980125427,
                "std": 0.17616017162799835,
                "max": 0.41692182421684265,
                "min": -0.5135344862937927,
                "frobenius_norm": 3.4795515537261963,
                "spectral_norm": 1.4713793992996216,
                "num_singular_values": 12,
                "alpha": 1.7656536068668365
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.022361163049936295,
                "median": 0.020640235394239426,
                "std": 0.13955925405025482,
                "max": 0.9434523582458496,
                "min": -0.6982539296150208,
                "frobenius_norm": 4.522858619689941,
                "spectral_norm": 2.4405198097229004,
                "num_singular_values": 32,
                "alpha": 1.1859389352954641
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.0275327879935503,
                "median": 0.02628653682768345,
                "std": 0.12974442541599274,
                "max": 0.441257119178772,
                "min": -1.2752354145050049,
                "frobenius_norm": 4.244275093078613,
                "spectral_norm": 2.229624032974243,
                "num_singular_values": 32,
                "alpha": 1.1728314571679677
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.05136475712060928,
                "median": 0.051636867225170135,
                "std": 0.10969430208206177,
                "max": 0.3655855357646942,
                "min": -0.17363221943378448,
                "frobenius_norm": 1.9379942417144775,
                "spectral_norm": 1.157562017440796,
                "num_singular_values": 8,
                "alpha": 1.9003480498232521
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.001_batch_size_64_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "standard",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07123032957315445,
            "mse": 394094336.0,
            "mae": 1950.93310546875,
            "r2_score": 0.9148702025413513,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.03249200060963631,
                "median": 0.028120100498199463,
                "std": 0.21654190123081207,
                "max": 0.6211687922477722,
                "min": -0.6965864896774292,
                "frobenius_norm": 4.2908406257629395,
                "spectral_norm": 1.9146641492843628,
                "num_singular_values": 12,
                "alpha": 1.670476180397635
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.020182117819786072,
                "median": 0.020732801407575607,
                "std": 0.1717892289161682,
                "max": 0.720760703086853,
                "min": -0.6110501289367676,
                "frobenius_norm": 5.535061359405518,
                "spectral_norm": 2.1321403980255127,
                "num_singular_values": 32,
                "alpha": 1.1669562542596559
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.011867835186421871,
                "median": 0.011958861723542213,
                "std": 0.17922832071781158,
                "max": 0.751413106918335,
                "min": -0.7292265892028809,
                "frobenius_norm": 5.747866153717041,
                "spectral_norm": 2.631204605102539,
                "num_singular_values": 32,
                "alpha": 1.1412143360503375
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.03091338649392128,
                "median": 0.03720814734697342,
                "std": 0.16867126524448395,
                "max": 0.42310643196105957,
                "min": -0.7702741622924805,
                "frobenius_norm": 2.7436912059783936,
                "spectral_norm": 1.8075851202011108,
                "num_singular_values": 8,
                "alpha": 1.8897005467631707
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.001_batch_size_64_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "robust",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07049718499183655,
            "mse": 437127648.0,
            "mae": 1933.3516845703125,
            "r2_score": 0.905574381351471,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.023487264290452003,
                "median": 0.007949338294565678,
                "std": 0.22584126889705658,
                "max": 0.7477118372917175,
                "min": -0.8632347583770752,
                "frobenius_norm": 4.449435710906982,
                "spectral_norm": 1.947664737701416,
                "num_singular_values": 12,
                "alpha": 1.6253580461582031
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.02437778376042843,
                "median": 0.01478185411542654,
                "std": 0.1718229055404663,
                "max": 0.7786521315574646,
                "min": -0.6788930296897888,
                "frobenius_norm": 5.553395748138428,
                "spectral_norm": 2.6138641834259033,
                "num_singular_values": 32,
                "alpha": 1.134781039368607
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.018946722149848938,
                "median": 0.0180077962577343,
                "std": 0.16325028240680695,
                "max": 0.7704800367355347,
                "min": -0.5721972584724426,
                "frobenius_norm": 5.2590742111206055,
                "spectral_norm": 2.5263843536376953,
                "num_singular_values": 32,
                "alpha": 1.1360723541484148
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.04284587875008583,
                "median": 0.048944227397441864,
                "std": 0.1483970284461975,
                "max": 0.40346628427505493,
                "min": -0.7763766050338745,
                "frobenius_norm": 2.471337080001831,
                "spectral_norm": 1.4869866371154785,
                "num_singular_values": 8,
                "alpha": 1.7918052856854731
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.001_batch_size_64_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "minmax",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07608897984027863,
            "mse": 468496416.0,
            "mae": 2119.845947265625,
            "r2_score": 0.8987983465194702,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.02101474441587925,
                "median": 0.007663201540708542,
                "std": 0.207546204328537,
                "max": 0.7481501698493958,
                "min": -0.9014835357666016,
                "frobenius_norm": 4.08785343170166,
                "spectral_norm": 2.2098336219787598,
                "num_singular_values": 12,
                "alpha": 1.7130411808024397
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.0013255247613415122,
                "median": -0.004761950112879276,
                "std": 0.14271089434623718,
                "max": 0.540261447429657,
                "min": -0.6072739958763123,
                "frobenius_norm": 4.566945552825928,
                "spectral_norm": 1.9226819276809692,
                "num_singular_values": 32,
                "alpha": 1.1277248200489147
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.0011535892263054848,
                "median": 0.003561700228601694,
                "std": 0.12476631253957748,
                "max": 0.428710401058197,
                "min": -0.5697676539421082,
                "frobenius_norm": 3.992692470550537,
                "spectral_norm": 1.8697444200515747,
                "num_singular_values": 32,
                "alpha": 1.2024067605035598
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.03839215636253357,
                "median": 0.03124726191163063,
                "std": 0.10578496009111404,
                "max": 0.28319188952445984,
                "min": -0.2084188461303711,
                "frobenius_norm": 1.800580620765686,
                "spectral_norm": 0.9470705389976501,
                "num_singular_values": 8,
                "alpha": 1.9750601555246377
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.001_batch_size_128_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 128,
            "scaler_type": "identity",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.08024322241544724,
            "mse": 410536160.0,
            "mae": 1907.8621826171875,
            "r2_score": 0.9113185405731201,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.02084413357079029,
                "median": 0.0211491696536541,
                "std": 0.17963317036628723,
                "max": 0.408590167760849,
                "min": -0.49338874220848083,
                "frobenius_norm": 3.5436956882476807,
                "spectral_norm": 1.550392985343933,
                "num_singular_values": 12,
                "alpha": 1.8266813314933517
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.021328195929527283,
                "median": 0.015047714114189148,
                "std": 0.13849836587905884,
                "max": 0.5634860396385193,
                "min": -0.42533227801322937,
                "frobenius_norm": 4.484191417694092,
                "spectral_norm": 2.6325929164886475,
                "num_singular_values": 32,
                "alpha": 1.1147926898377687
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.025634486228227615,
                "median": 0.022681578993797302,
                "std": 0.12236570566892624,
                "max": 0.4353852868080139,
                "min": -0.3662155568599701,
                "frobenius_norm": 4.000702857971191,
                "spectral_norm": 2.1246860027313232,
                "num_singular_values": 32,
                "alpha": 1.15307909272531
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.045518144965171814,
                "median": 0.0516405925154686,
                "std": 0.10904241353273392,
                "max": 0.274181991815567,
                "min": -0.16833405196666718,
                "frobenius_norm": 1.8905845880508423,
                "spectral_norm": 1.0361361503601074,
                "num_singular_values": 8,
                "alpha": 1.738875173185554
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.001_batch_size_128_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 128,
            "scaler_type": "standard",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07053474336862564,
            "mse": 383036000.0,
            "mae": 1936.260986328125,
            "r2_score": 0.9172589778900146,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.039418790489435196,
                "median": 0.02562524750828743,
                "std": 0.21999438107013702,
                "max": 0.5970376133918762,
                "min": -0.7002144455909729,
                "frobenius_norm": 4.3796491622924805,
                "spectral_norm": 1.8858146667480469,
                "num_singular_values": 12,
                "alpha": 1.6700924071312058
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.02125977724790573,
                "median": 0.022432496771216393,
                "std": 0.1804215908050537,
                "max": 0.7085831165313721,
                "min": -0.6440313458442688,
                "frobenius_norm": 5.813434600830078,
                "spectral_norm": 2.1552176475524902,
                "num_singular_values": 32,
                "alpha": 1.179517938096372
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.009563719853758812,
                "median": 0.0041557420045137405,
                "std": 0.18211668729782104,
                "max": 0.8690558075904846,
                "min": -0.6035075187683105,
                "frobenius_norm": 5.835764408111572,
                "spectral_norm": 2.582817792892456,
                "num_singular_values": 32,
                "alpha": 1.0775298757780298
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.03936001658439636,
                "median": 0.04311911389231682,
                "std": 0.1638721227645874,
                "max": 0.43123510479927063,
                "min": -0.6833027601242065,
                "frobenius_norm": 2.696523666381836,
                "spectral_norm": 1.899368405342102,
                "num_singular_values": 8,
                "alpha": 1.7529473001697256
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.001_batch_size_128_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 128,
            "scaler_type": "robust",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07094738632440567,
            "mse": 469576896.0,
            "mae": 1951.8123779296875,
            "r2_score": 0.8985649347305298,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.020168976858258247,
                "median": 0.00648967269808054,
                "std": 0.2181212604045868,
                "max": 0.6211963891983032,
                "min": -0.8215404152870178,
                "frobenius_norm": 4.292520046234131,
                "spectral_norm": 1.881762981414795,
                "num_singular_values": 12,
                "alpha": 1.6469270669609943
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.022899124771356583,
                "median": 0.02141997218132019,
                "std": 0.17311343550682068,
                "max": 0.8798524141311646,
                "min": -0.5198325514793396,
                "frobenius_norm": 5.587884426116943,
                "spectral_norm": 2.4247074127197266,
                "num_singular_values": 32,
                "alpha": 1.0946869943189719
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.016332067549228668,
                "median": 0.01446674857288599,
                "std": 0.16944245994091034,
                "max": 0.8118247985839844,
                "min": -0.6437037587165833,
                "frobenius_norm": 5.4472880363464355,
                "spectral_norm": 2.526736259460449,
                "num_singular_values": 32,
                "alpha": 1.098495069212681
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.03852366283535957,
                "median": 0.046382151544094086,
                "std": 0.1627115160226822,
                "max": 0.46406126022338867,
                "min": -0.6604858040809631,
                "frobenius_norm": 2.67535662651062,
                "spectral_norm": 1.735940933227539,
                "num_singular_values": 8,
                "alpha": 1.7359645630732423
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.001_batch_size_128_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 128,
            "scaler_type": "minmax",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07173284143209457,
            "mse": 444446368.0,
            "mae": 2052.625244140625,
            "r2_score": 0.9039934873580933,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.031184250488877296,
                "median": 0.02426101081073284,
                "std": 0.2087922990322113,
                "max": 0.7597246170043945,
                "min": -0.9890345335006714,
                "frobenius_norm": 4.13685941696167,
                "spectral_norm": 2.081916093826294,
                "num_singular_values": 12,
                "alpha": 1.6522185728670884
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.0015365532599389553,
                "median": 0.002672102302312851,
                "std": 0.15816029906272888,
                "max": 0.5382946729660034,
                "min": -0.7126591801643372,
                "frobenius_norm": 5.061368465423584,
                "spectral_norm": 2.3070695400238037,
                "num_singular_values": 32,
                "alpha": 1.151926354575089
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.011142561212182045,
                "median": 0.012845859862864017,
                "std": 0.13663604855537415,
                "max": 0.5591082572937012,
                "min": -0.4829033315181732,
                "frobenius_norm": 4.386868000030518,
                "spectral_norm": 2.4287986755371094,
                "num_singular_values": 32,
                "alpha": 1.1062287355697555
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.03250584751367569,
                "median": 0.037810247391462326,
                "std": 0.11843296885490417,
                "max": 0.31662118434906006,
                "min": -0.3396959900856018,
                "frobenius_norm": 1.9650057554244995,
                "spectral_norm": 1.1075366735458374,
                "num_singular_values": 8,
                "alpha": 1.8730955020054332
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.001_batch_size_256_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 256,
            "scaler_type": "identity",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07767892628908157,
            "mse": 449461504.0,
            "mae": 1902.9947509765625,
            "r2_score": 0.9029101133346558,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.023313501849770546,
                "median": 0.02606000378727913,
                "std": 0.1757175475358963,
                "max": 0.3845629394054413,
                "min": -0.42127126455307007,
                "frobenius_norm": 3.4735209941864014,
                "spectral_norm": 1.4690961837768555,
                "num_singular_values": 12,
                "alpha": 1.8219479893264778
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.022565452381968498,
                "median": 0.02088412269949913,
                "std": 0.14486251771450043,
                "max": 0.6159689426422119,
                "min": -1.3126965761184692,
                "frobenius_norm": 4.691504001617432,
                "spectral_norm": 2.7041492462158203,
                "num_singular_values": 32,
                "alpha": 1.077616280904118
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.02577638253569603,
                "median": 0.024944406002759933,
                "std": 0.12292073667049408,
                "max": 0.4273587167263031,
                "min": -0.3736104965209961,
                "frobenius_norm": 4.019017696380615,
                "spectral_norm": 2.10107684135437,
                "num_singular_values": 32,
                "alpha": 1.1830065837026038
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.04564535245299339,
                "median": 0.04935804009437561,
                "std": 0.10850370675325394,
                "max": 0.3474214971065521,
                "min": -0.16268259286880493,
                "frobenius_norm": 1.883421778678894,
                "spectral_norm": 1.0670756101608276,
                "num_singular_values": 8,
                "alpha": 1.8413734274639642
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.001_batch_size_256_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 256,
            "scaler_type": "standard",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07118760794401169,
            "mse": 381791136.0,
            "mae": 1915.6624755859375,
            "r2_score": 0.9175278544425964,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.032103221863508224,
                "median": 0.026148751378059387,
                "std": 0.217360720038414,
                "max": 0.5878800749778748,
                "min": -0.7532143592834473,
                "frobenius_norm": 4.305589199066162,
                "spectral_norm": 1.8339084386825562,
                "num_singular_values": 12,
                "alpha": 1.7794500303905652
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.029278378933668137,
                "median": 0.027526434510946274,
                "std": 0.17367462813854218,
                "max": 0.8193232417106628,
                "min": -0.6249284744262695,
                "frobenius_norm": 5.636007308959961,
                "spectral_norm": 2.07218074798584,
                "num_singular_values": 32,
                "alpha": 1.1388651346599383
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.010506827384233475,
                "median": 0.008552484214305878,
                "std": 0.17761310935020447,
                "max": 0.9083116054534912,
                "min": -0.71258544921875,
                "frobenius_norm": 5.6935553550720215,
                "spectral_norm": 2.6073474884033203,
                "num_singular_values": 32,
                "alpha": 1.1574750003363785
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.04965496435761452,
                "median": 0.03784015029668808,
                "std": 0.177011176943779,
                "max": 0.6676086187362671,
                "min": -0.7957095503807068,
                "frobenius_norm": 2.9415018558502197,
                "spectral_norm": 2.176318645477295,
                "num_singular_values": 8,
                "alpha": 1.8696593387974723
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.001_batch_size_256_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 256,
            "scaler_type": "robust",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07058769464492798,
            "mse": 443925024.0,
            "mae": 1976.2840576171875,
            "r2_score": 0.904106080532074,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.018456315621733665,
                "median": -0.0023748730309307575,
                "std": 0.22627492249011993,
                "max": 0.7382399439811707,
                "min": -0.8919790387153625,
                "frobenius_norm": 4.448790073394775,
                "spectral_norm": 1.98207426071167,
                "num_singular_values": 12,
                "alpha": 1.5964073744532739
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.027239233255386353,
                "median": 0.024928737431764603,
                "std": 0.17478130757808685,
                "max": 0.7813480496406555,
                "min": -0.7231511473655701,
                "frobenius_norm": 5.66051721572876,
                "spectral_norm": 2.2613587379455566,
                "num_singular_values": 32,
                "alpha": 1.084310093090355
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.017547473311424255,
                "median": 0.021353837102651596,
                "std": 0.17072658240795135,
                "max": 0.6735756993293762,
                "min": -0.6675336956977844,
                "frobenius_norm": 5.492031574249268,
                "spectral_norm": 2.6131935119628906,
                "num_singular_values": 32,
                "alpha": 1.1312245527221902
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.03872331976890564,
                "median": 0.03025663085281849,
                "std": 0.15998727083206177,
                "max": 0.43888160586357117,
                "min": -0.6932825446128845,
                "frobenius_norm": 2.633709669113159,
                "spectral_norm": 1.7456717491149902,
                "num_singular_values": 8,
                "alpha": 1.7329964723804507
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.001_batch_size_256_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 256,
            "scaler_type": "minmax",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.0735497996211052,
            "mse": 442241472.0,
            "mae": 2046.6329345703125,
            "r2_score": 0.9044697284698486,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.027316989377141,
                "median": 0.011451227590441704,
                "std": 0.20704902708530426,
                "max": 0.7509907484054565,
                "min": -0.9941539168357849,
                "frobenius_norm": 4.092475891113281,
                "spectral_norm": 2.118119955062866,
                "num_singular_values": 12,
                "alpha": 1.740026569524221
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": -0.008049157448112965,
                "median": -0.0035197632387280464,
                "std": 0.1528976410627365,
                "max": 0.5552875995635986,
                "min": -1.0188254117965698,
                "frobenius_norm": 4.899499893188477,
                "spectral_norm": 2.4630556106567383,
                "num_singular_values": 32,
                "alpha": 1.1687187434402193
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.00747832003980875,
                "median": 0.008060408756136894,
                "std": 0.12331415712833405,
                "max": 0.41026216745376587,
                "min": -0.4268913269042969,
                "frobenius_norm": 3.9533028602600098,
                "spectral_norm": 1.726100206375122,
                "num_singular_values": 32,
                "alpha": 1.154247306811287
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.03519274294376373,
                "median": 0.0292480681091547,
                "std": 0.1224060207605362,
                "max": 0.37670671939849854,
                "min": -0.2950206696987152,
                "frobenius_norm": 2.037834882736206,
                "spectral_norm": 1.1492102146148682,
                "num_singular_values": 8,
                "alpha": 1.8124851117116054
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.0005_batch_size_16_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.08409945666790009,
            "mse": 480128064.0,
            "mae": 2015.84765625,
            "r2_score": 0.8962857127189636,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.02962026558816433,
                "median": 0.030435509979724884,
                "std": 0.16949227452278137,
                "max": 0.371724009513855,
                "min": -0.366427481174469,
                "frobenius_norm": 3.3716933727264404,
                "spectral_norm": 1.4405452013015747,
                "num_singular_values": 12,
                "alpha": 1.7204411666542416
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.025792015716433525,
                "median": 0.01799546554684639,
                "std": 0.12297952175140381,
                "max": 0.48380884528160095,
                "min": -0.2859249413013458,
                "frobenius_norm": 4.020961284637451,
                "spectral_norm": 2.2750258445739746,
                "num_singular_values": 32,
                "alpha": 1.047864973363288
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.024733394384384155,
                "median": 0.02198643609881401,
                "std": 0.11275853216648102,
                "max": 0.3276694118976593,
                "min": -0.23409149050712585,
                "frobenius_norm": 3.694056987762451,
                "spectral_norm": 1.857496976852417,
                "num_singular_values": 32,
                "alpha": 1.1428738679177242
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.04363830015063286,
                "median": 0.04444732144474983,
                "std": 0.10618530958890915,
                "max": 0.26798370480537415,
                "min": -0.16303996741771698,
                "frobenius_norm": 1.8368405103683472,
                "spectral_norm": 1.0274282693862915,
                "num_singular_values": 8,
                "alpha": 1.7563847438301203
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.0005_batch_size_16_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07315098494291306,
            "mse": 459107520.0,
            "mae": 1993.268798828125,
            "r2_score": 0.9008264541625977,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.024616330862045288,
                "median": 0.005775448866188526,
                "std": 0.20514968037605286,
                "max": 0.675337553024292,
                "min": -0.6988568305969238,
                "frobenius_norm": 4.048933982849121,
                "spectral_norm": 1.8374907970428467,
                "num_singular_values": 12,
                "alpha": 1.7225911595868832
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.02427246980369091,
                "median": 0.024547968059778214,
                "std": 0.13682563602924347,
                "max": 0.4788700044155121,
                "min": -0.43789342045783997,
                "frobenius_norm": 4.446780204772949,
                "spectral_norm": 1.775206446647644,
                "num_singular_values": 32,
                "alpha": 1.1292775855562651
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.0078027257695794106,
                "median": 0.006354277953505516,
                "std": 0.14246216416358948,
                "max": 0.4629872441291809,
                "min": -0.4900253713130951,
                "frobenius_norm": 4.565621852874756,
                "spectral_norm": 2.0599887371063232,
                "num_singular_values": 32,
                "alpha": 1.133807495449425
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.03604058921337128,
                "median": 0.03706776723265648,
                "std": 0.13977006077766418,
                "max": 0.37576669454574585,
                "min": -0.3803173899650574,
                "frobenius_norm": 2.3094708919525146,
                "spectral_norm": 1.5281527042388916,
                "num_singular_values": 8,
                "alpha": 1.9295238956030212
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.0005_batch_size_16_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07163036614656448,
            "mse": 428865824.0,
            "mae": 1964.3497314453125,
            "r2_score": 0.9073590636253357,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.02184111811220646,
                "median": 0.007651899009943008,
                "std": 0.1968749761581421,
                "max": 0.6321711540222168,
                "min": -0.7282933592796326,
                "frobenius_norm": 3.8816139698028564,
                "spectral_norm": 1.7652323246002197,
                "num_singular_values": 12,
                "alpha": 1.7378888215308756
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.02230425551533699,
                "median": 0.018949678167700768,
                "std": 0.1381262093782425,
                "max": 0.5050855875015259,
                "min": -0.44944149255752563,
                "frobenius_norm": 4.477293968200684,
                "spectral_norm": 1.8170329332351685,
                "num_singular_values": 32,
                "alpha": 1.1489627592988974
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.020088139921426773,
                "median": 0.022350158542394638,
                "std": 0.13909979164600372,
                "max": 0.5421989560127258,
                "min": -0.5222054719924927,
                "frobenius_norm": 4.49737024307251,
                "spectral_norm": 2.1370816230773926,
                "num_singular_values": 32,
                "alpha": 1.1558764175113274
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.03661440312862396,
                "median": 0.040083687752485275,
                "std": 0.13472428917884827,
                "max": 0.3712936341762543,
                "min": -0.46624302864074707,
                "frobenius_norm": 2.233776807785034,
                "spectral_norm": 1.2803654670715332,
                "num_singular_values": 8,
                "alpha": 1.9517517491145826
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.0005_batch_size_16_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07601660490036011,
            "mse": 473349856.0,
            "mae": 2135.77197265625,
            "r2_score": 0.8977499008178711,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.025020448490977287,
                "median": 0.01887527108192444,
                "std": 0.18258601427078247,
                "max": 0.5916206240653992,
                "min": -0.5414392948150635,
                "frobenius_norm": 3.6113779544830322,
                "spectral_norm": 1.6912126541137695,
                "num_singular_values": 12,
                "alpha": 1.7846468519912806
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.011067761108279228,
                "median": 0.009522497653961182,
                "std": 0.11898195743560791,
                "max": 0.3298986256122589,
                "min": -0.4543628692626953,
                "frobenius_norm": 3.823859691619873,
                "spectral_norm": 1.549250841140747,
                "num_singular_values": 32,
                "alpha": 1.1406326347943614
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.00404510460793972,
                "median": 0.006944773718714714,
                "std": 0.11634485423564911,
                "max": 0.2910408079624176,
                "min": -0.5024877190589905,
                "frobenius_norm": 3.725285053253174,
                "spectral_norm": 1.689961314201355,
                "num_singular_values": 32,
                "alpha": 1.1169288138725315
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.032427139580249786,
                "median": 0.03011322021484375,
                "std": 0.10757521539926529,
                "max": 0.29141196608543396,
                "min": -0.18144969642162323,
                "frobenius_norm": 1.797701358795166,
                "spectral_norm": 0.9892830848693848,
                "num_singular_values": 8,
                "alpha": 1.94410584577698
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.0005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.08115342259407043,
            "mse": 470494944.0,
            "mae": 1990.652099609375,
            "r2_score": 0.8983666300773621,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.028901681303977966,
                "median": 0.028108883649110794,
                "std": 0.17136843502521515,
                "max": 0.3791750967502594,
                "min": -0.4125966727733612,
                "frobenius_norm": 3.405545473098755,
                "spectral_norm": 1.4508283138275146,
                "num_singular_values": 12,
                "alpha": 1.7097888409611661
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.02484956383705139,
                "median": 0.01957274228334427,
                "std": 0.12630915641784668,
                "max": 0.4713064432144165,
                "min": -0.302810937166214,
                "frobenius_norm": 4.11937141418457,
                "spectral_norm": 2.3308472633361816,
                "num_singular_values": 32,
                "alpha": 1.1627935984733675
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.024214930832386017,
                "median": 0.021266110241413116,
                "std": 0.11536223441362381,
                "max": 0.40441927313804626,
                "min": -0.26191410422325134,
                "frobenius_norm": 3.7720398902893066,
                "spectral_norm": 1.951822280883789,
                "num_singular_values": 32,
                "alpha": 1.1146731582318563
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.044697489589452744,
                "median": 0.04538416489958763,
                "std": 0.10751903057098389,
                "max": 0.2732265591621399,
                "min": -0.1632847934961319,
                "frobenius_norm": 1.8630354404449463,
                "spectral_norm": 1.0652529001235962,
                "num_singular_values": 8,
                "alpha": 1.7637227714593198
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.0005_batch_size_32_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.0731351226568222,
            "mse": 473218464.0,
            "mae": 2044.4990234375,
            "r2_score": 0.8977782726287842,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.028136512264609337,
                "median": 0.014338151551783085,
                "std": 0.20839139819145203,
                "max": 0.6069204807281494,
                "min": -0.7346466183662415,
                "frobenius_norm": 4.120674133300781,
                "spectral_norm": 1.8995673656463623,
                "num_singular_values": 12,
                "alpha": 1.6908407379032417
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.02696378529071808,
                "median": 0.029052216559648514,
                "std": 0.14666834473609924,
                "max": 0.5776010751724243,
                "min": -0.5961987376213074,
                "frobenius_norm": 4.772041320800781,
                "spectral_norm": 1.9463708400726318,
                "num_singular_values": 32,
                "alpha": 1.1152641026830006
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.011645841412246227,
                "median": 0.007469896227121353,
                "std": 0.14859667420387268,
                "max": 0.47349563241004944,
                "min": -0.5570480823516846,
                "frobenius_norm": 4.769674777984619,
                "spectral_norm": 2.1931800842285156,
                "num_singular_values": 32,
                "alpha": 1.1758728548024475
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.03199006989598274,
                "median": 0.03306727856397629,
                "std": 0.14004413783550262,
                "max": 0.3787747323513031,
                "min": -0.4756832718849182,
                "frobenius_norm": 2.2984225749969482,
                "spectral_norm": 1.5436159372329712,
                "num_singular_values": 8,
                "alpha": 1.915418496496004
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.0005_batch_size_32_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07181782275438309,
            "mse": 429806208.0,
            "mae": 1974.5589599609375,
            "r2_score": 0.9071559309959412,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.023786896839737892,
                "median": 0.01269521377980709,
                "std": 0.20503760874271393,
                "max": 0.7258507609367371,
                "min": -0.7311442494392395,
                "frobenius_norm": 4.0448479652404785,
                "spectral_norm": 1.8333098888397217,
                "num_singular_values": 12,
                "alpha": 1.7283561549187796
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.022908909246325493,
                "median": 0.020359719172120094,
                "std": 0.14239422976970673,
                "max": 0.590717613697052,
                "min": -0.4152812361717224,
                "frobenius_norm": 4.615209102630615,
                "spectral_norm": 1.8110469579696655,
                "num_singular_values": 32,
                "alpha": 1.129477247565253
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.02276870608329773,
                "median": 0.023597339168190956,
                "std": 0.14717411994934082,
                "max": 0.538970947265625,
                "min": -0.5408928394317627,
                "frobenius_norm": 4.765597820281982,
                "spectral_norm": 2.2843565940856934,
                "num_singular_values": 32,
                "alpha": 1.1243877557114828
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.03869514912366867,
                "median": 0.040970511734485626,
                "std": 0.1311177909374237,
                "max": 0.39835792779922485,
                "min": -0.5257837772369385,
                "frobenius_norm": 2.1873347759246826,
                "spectral_norm": 1.2954730987548828,
                "num_singular_values": 8,
                "alpha": 1.9577612878485549
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.0005_batch_size_32_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07649341225624084,
            "mse": 478146976.0,
            "mae": 2150.815185546875,
            "r2_score": 0.8967136740684509,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.023845909163355827,
                "median": 0.015553412027657032,
                "std": 0.18178869783878326,
                "max": 0.5618630051612854,
                "min": -0.5806781649589539,
                "frobenius_norm": 3.5928330421447754,
                "spectral_norm": 1.6466293334960938,
                "num_singular_values": 12,
                "alpha": 1.7945536437026088
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.011062942445278168,
                "median": 0.007504718378186226,
                "std": 0.1199650689959526,
                "max": 0.33693236112594604,
                "min": -0.34888964891433716,
                "frobenius_norm": 3.855170965194702,
                "spectral_norm": 1.5673987865447998,
                "num_singular_values": 32,
                "alpha": 1.1409174282554486
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.005755137652158737,
                "median": 0.00879256334155798,
                "std": 0.11883570998907089,
                "max": 0.3169839680194855,
                "min": -0.46617352962493896,
                "frobenius_norm": 3.807199716567993,
                "spectral_norm": 1.720607876777649,
                "num_singular_values": 32,
                "alpha": 1.1390171081064737
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.03514033555984497,
                "median": 0.03553026542067528,
                "std": 0.11106056720018387,
                "max": 0.3130599558353424,
                "min": -0.2769947350025177,
                "frobenius_norm": 1.8637969493865967,
                "spectral_norm": 1.0098369121551514,
                "num_singular_values": 8,
                "alpha": 1.8269919773982695
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.0005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.08020272850990295,
            "mse": 467132896.0,
            "mae": 1969.5794677734375,
            "r2_score": 0.8990928530693054,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.028075000271201134,
                "median": 0.028001269325613976,
                "std": 0.17140449583530426,
                "max": 0.3816007673740387,
                "min": -0.3740822374820709,
                "frobenius_norm": 3.4035863876342773,
                "spectral_norm": 1.4478174448013306,
                "num_singular_values": 12,
                "alpha": 1.6985173512483902
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.026866670697927475,
                "median": 0.02170555293560028,
                "std": 0.12740997970104218,
                "max": 0.4990329444408417,
                "min": -0.3069402277469635,
                "frobenius_norm": 4.166778564453125,
                "spectral_norm": 2.4078173637390137,
                "num_singular_values": 32,
                "alpha": 1.11254268487655
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.028623182326555252,
                "median": 0.025631792843341827,
                "std": 0.11614153534173965,
                "max": 0.3503424823284149,
                "min": -0.2834746241569519,
                "frobenius_norm": 3.827732801437378,
                "spectral_norm": 2.054352045059204,
                "num_singular_values": 32,
                "alpha": 1.1574648537542487
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.03924692049622536,
                "median": 0.04262576997280121,
                "std": 0.10531049966812134,
                "max": 0.25122201442718506,
                "min": -0.16353963315486908,
                "frobenius_norm": 1.798176646232605,
                "spectral_norm": 0.9488809704780579,
                "num_singular_values": 8,
                "alpha": 1.8009325102934755
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.0005_batch_size_64_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "standard",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07251469045877457,
            "mse": 466501856.0,
            "mae": 2024.2161865234375,
            "r2_score": 0.8992291688919067,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.023697907105088234,
                "median": 0.011491780169308186,
                "std": 0.20663782954216003,
                "max": 0.6086900234222412,
                "min": -0.7043181657791138,
                "frobenius_norm": 4.075799465179443,
                "spectral_norm": 1.8722580671310425,
                "num_singular_values": 12,
                "alpha": 1.6384724283880203
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.023341482505202293,
                "median": 0.025884831324219704,
                "std": 0.1502693146467209,
                "max": 0.6279278993606567,
                "min": -0.44811925292015076,
                "frobenius_norm": 4.866282939910889,
                "spectral_norm": 2.024981737136841,
                "num_singular_values": 32,
                "alpha": 1.1180738649041366
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.011820022016763687,
                "median": 0.010165279731154442,
                "std": 0.1516900658607483,
                "max": 0.46161267161369324,
                "min": -0.5130524635314941,
                "frobenius_norm": 4.868796348571777,
                "spectral_norm": 2.3118574619293213,
                "num_singular_values": 32,
                "alpha": 1.0955851782865331
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.031200800091028214,
                "median": 0.03560464456677437,
                "std": 0.1363733857870102,
                "max": 0.40449532866477966,
                "min": -0.3693298399448395,
                "frobenius_norm": 2.2383530139923096,
                "spectral_norm": 1.5171126127243042,
                "num_singular_values": 8,
                "alpha": 1.9289665800244142
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.0005_batch_size_64_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "robust",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07147996872663498,
            "mse": 437805376.0,
            "mae": 1966.9124755859375,
            "r2_score": 0.9054279923439026,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.023640526458621025,
                "median": 0.014500316232442856,
                "std": 0.20481203496456146,
                "max": 0.681917130947113,
                "min": -0.6694719195365906,
                "frobenius_norm": 4.040127277374268,
                "spectral_norm": 1.8194854259490967,
                "num_singular_values": 12,
                "alpha": 1.7230537630942266
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.02166897803544998,
                "median": 0.020301926881074905,
                "std": 0.14604461193084717,
                "max": 0.5678390860557556,
                "min": -0.4286463260650635,
                "frobenius_norm": 4.724588394165039,
                "spectral_norm": 1.829598069190979,
                "num_singular_values": 32,
                "alpha": 1.1435586651850171
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.020821547135710716,
                "median": 0.023863788694143295,
                "std": 0.14750316739082336,
                "max": 0.5296430587768555,
                "min": -0.5948430299758911,
                "frobenius_norm": 4.7668962478637695,
                "spectral_norm": 2.3967032432556152,
                "num_singular_values": 32,
                "alpha": 1.1243667744829446
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.038877446204423904,
                "median": 0.04290393739938736,
                "std": 0.1291974037885666,
                "max": 0.42146530747413635,
                "min": -0.4893797039985657,
                "frobenius_norm": 2.1587209701538086,
                "spectral_norm": 1.284531593322754,
                "num_singular_values": 8,
                "alpha": 1.9207248182315149
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.0005_batch_size_64_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "minmax",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07597187161445618,
            "mse": 465457184.0,
            "mae": 2116.269775390625,
            "r2_score": 0.8994548320770264,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.026421725749969482,
                "median": 0.013411345891654491,
                "std": 0.18494904041290283,
                "max": 0.5916458368301392,
                "min": -0.5986298322677612,
                "frobenius_norm": 3.6610424518585205,
                "spectral_norm": 1.667128324508667,
                "num_singular_values": 12,
                "alpha": 1.8083254631966512
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.011485803872346878,
                "median": 0.009061625227332115,
                "std": 0.12349431216716766,
                "max": 0.38752803206443787,
                "min": -0.4956103265285492,
                "frobenius_norm": 3.9688732624053955,
                "spectral_norm": 1.5914841890335083,
                "num_singular_values": 32,
                "alpha": 1.1384396031788966
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.006289232987910509,
                "median": 0.010008223354816437,
                "std": 0.11775356531143188,
                "max": 0.31982412934303284,
                "min": -0.4906598627567291,
                "frobenius_norm": 3.773484945297241,
                "spectral_norm": 1.8055057525634766,
                "num_singular_values": 32,
                "alpha": 1.127214646473357
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.02863278239965439,
                "median": 0.02772148698568344,
                "std": 0.11064118891954422,
                "max": 0.3065433204174042,
                "min": -0.23982685804367065,
                "frobenius_norm": 1.8285772800445557,
                "spectral_norm": 0.9900308847427368,
                "num_singular_values": 8,
                "alpha": 1.9707168651148241
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.0005_batch_size_128_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 128,
            "scaler_type": "identity",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.0794617161154747,
            "mse": 444186080.0,
            "mae": 1945.6495361328125,
            "r2_score": 0.9040496945381165,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.02738776057958603,
                "median": 0.024776654317975044,
                "std": 0.17225275933742523,
                "max": 0.38120236992836,
                "min": -0.3885962665081024,
                "frobenius_norm": 3.417850971221924,
                "spectral_norm": 1.4403119087219238,
                "num_singular_values": 12,
                "alpha": 1.7398290002772143
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.025772660970687866,
                "median": 0.022957224398851395,
                "std": 0.12951575219631195,
                "max": 0.5061580538749695,
                "min": -0.5657860636711121,
                "frobenius_norm": 4.225764751434326,
                "spectral_norm": 2.426520586013794,
                "num_singular_values": 32,
                "alpha": 1.170227784473443
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.02772618643939495,
                "median": 0.025210198014974594,
                "std": 0.11722676455974579,
                "max": 0.3516792058944702,
                "min": -0.2713356018066406,
                "frobenius_norm": 3.8547523021698,
                "spectral_norm": 2.093327283859253,
                "num_singular_values": 32,
                "alpha": 1.1723431472405188
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.039517857134342194,
                "median": 0.04357994347810745,
                "std": 0.10578905791044235,
                "max": 0.25504347681999207,
                "min": -0.16670191287994385,
                "frobenius_norm": 1.806865930557251,
                "spectral_norm": 0.9537988901138306,
                "num_singular_values": 8,
                "alpha": 1.8036154816450825
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.0005_batch_size_128_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 128,
            "scaler_type": "standard",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.0723150223493576,
            "mse": 447037952.0,
            "mae": 1995.6630859375,
            "r2_score": 0.903433620929718,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.03157944977283478,
                "median": 0.021698296070098877,
                "std": 0.20469506084918976,
                "max": 0.5579363703727722,
                "min": -0.6571127772331238,
                "frobenius_norm": 4.0586419105529785,
                "spectral_norm": 1.8817774057388306,
                "num_singular_values": 12,
                "alpha": 1.714247896141237
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.025946449488401413,
                "median": 0.025622859597206116,
                "std": 0.1493002325296402,
                "max": 0.5688076615333557,
                "min": -0.3849599063396454,
                "frobenius_norm": 4.849216938018799,
                "spectral_norm": 2.0717155933380127,
                "num_singular_values": 32,
                "alpha": 1.1428941511471091
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.013754497282207012,
                "median": 0.01268626656383276,
                "std": 0.15856142342090607,
                "max": 0.5169751048088074,
                "min": -0.5002185702323914,
                "frobenius_norm": 5.093019962310791,
                "spectral_norm": 2.552880048751831,
                "num_singular_values": 32,
                "alpha": 1.1891057556716045
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.03374149650335312,
                "median": 0.03280816972255707,
                "std": 0.14728833734989166,
                "max": 0.4333420693874359,
                "min": -0.5072279572486877,
                "frobenius_norm": 2.4176599979400635,
                "spectral_norm": 1.6510404348373413,
                "num_singular_values": 8,
                "alpha": 1.8204045676488456
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.0005_batch_size_128_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 128,
            "scaler_type": "robust",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07178153842687607,
            "mse": 444091296.0,
            "mae": 2004.71875,
            "r2_score": 0.9040701389312744,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.02437281608581543,
                "median": 0.017195604741573334,
                "std": 0.2056107223033905,
                "max": 0.6324841380119324,
                "min": -0.6683454513549805,
                "frobenius_norm": 4.057339668273926,
                "spectral_norm": 1.7658528089523315,
                "num_singular_values": 12,
                "alpha": 1.6820071178525766
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.022777866572141647,
                "median": 0.01752842590212822,
                "std": 0.14681297540664673,
                "max": 0.6051884889602661,
                "min": -0.4145832061767578,
                "frobenius_norm": 4.754222393035889,
                "spectral_norm": 1.8424935340881348,
                "num_singular_values": 32,
                "alpha": 1.1897878884201596
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.021290408447384834,
                "median": 0.02637767791748047,
                "std": 0.1474195122718811,
                "max": 0.5781511664390564,
                "min": -0.5046965479850769,
                "frobenius_norm": 4.766366481781006,
                "spectral_norm": 2.4043517112731934,
                "num_singular_values": 32,
                "alpha": 1.1489426050755214
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.03931264951825142,
                "median": 0.03974166885018349,
                "std": 0.13383309543132782,
                "max": 0.37522220611572266,
                "min": -0.5671910047531128,
                "frobenius_norm": 2.2318010330200195,
                "spectral_norm": 1.3008551597595215,
                "num_singular_values": 8,
                "alpha": 1.9180837258962882
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.0005_batch_size_128_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 128,
            "scaler_type": "minmax",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.0759226381778717,
            "mse": 471971936.0,
            "mae": 2124.0986328125,
            "r2_score": 0.8980475664138794,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.024880513548851013,
                "median": 0.015831906348466873,
                "std": 0.18661698698997498,
                "max": 0.5717422962188721,
                "min": -0.6330085396766663,
                "frobenius_norm": 3.6892895698547363,
                "spectral_norm": 1.693274736404419,
                "num_singular_values": 12,
                "alpha": 1.813027401633169
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.008116807788610458,
                "median": 0.003705628914758563,
                "std": 0.1261230856180191,
                "max": 0.41459235548973083,
                "min": -0.5036171078681946,
                "frobenius_norm": 4.044288158416748,
                "spectral_norm": 1.5508605241775513,
                "num_singular_values": 32,
                "alpha": 1.0943028195589568
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.0032515418715775013,
                "median": 0.00459049828350544,
                "std": 0.12244056165218353,
                "max": 0.3576478660106659,
                "min": -0.423422634601593,
                "frobenius_norm": 3.9194793701171875,
                "spectral_norm": 2.092280626296997,
                "num_singular_values": 32,
                "alpha": 1.1540570698798702
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.03251254931092262,
                "median": 0.031599752604961395,
                "std": 0.10862638056278229,
                "max": 0.26830533146858215,
                "min": -0.18903890252113342,
                "frobenius_norm": 1.8142021894454956,
                "spectral_norm": 0.9837089776992798,
                "num_singular_values": 8,
                "alpha": 2.009362484503786
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.0005_batch_size_256_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 256,
            "scaler_type": "identity",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07988172769546509,
            "mse": 448667040.0,
            "mae": 1950.2362060546875,
            "r2_score": 0.9030817151069641,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.02660873532295227,
                "median": 0.02675769105553627,
                "std": 0.1726102977991104,
                "max": 0.3792644143104553,
                "min": -0.41570714116096497,
                "frobenius_norm": 3.4224112033843994,
                "spectral_norm": 1.4428026676177979,
                "num_singular_values": 12,
                "alpha": 1.7415001664836645
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.025336971506476402,
                "median": 0.02429961785674095,
                "std": 0.12950114905834198,
                "max": 0.5292264223098755,
                "min": -0.4318995475769043,
                "frobenius_norm": 4.222607135772705,
                "spectral_norm": 2.4276652336120605,
                "num_singular_values": 32,
                "alpha": 1.1108624710217392
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.02567428909242153,
                "median": 0.02284017577767372,
                "std": 0.11818845570087433,
                "max": 0.3559776246547699,
                "min": -0.2903040945529938,
                "frobenius_norm": 3.8702380657196045,
                "spectral_norm": 2.098647356033325,
                "num_singular_values": 32,
                "alpha": 1.1670486719402355
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.0380660705268383,
                "median": 0.04321454465389252,
                "std": 0.10599425435066223,
                "max": 0.25494393706321716,
                "min": -0.1664561927318573,
                "frobenius_norm": 1.8019585609436035,
                "spectral_norm": 0.9453979730606079,
                "num_singular_values": 8,
                "alpha": 1.818517877946588
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.0005_batch_size_256_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 256,
            "scaler_type": "standard",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07248667627573013,
            "mse": 445759616.0,
            "mae": 2007.3753662109375,
            "r2_score": 0.9037097692489624,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.028012173250317574,
                "median": 0.014251427724957466,
                "std": 0.20525263249874115,
                "max": 0.5462018251419067,
                "min": -0.6668550372123718,
                "frobenius_norm": 4.059398651123047,
                "spectral_norm": 1.8873192071914673,
                "num_singular_values": 12,
                "alpha": 1.7043117805696824
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.02834278717637062,
                "median": 0.029595468193292618,
                "std": 0.15174461901187897,
                "max": 0.5795653462409973,
                "min": -0.43234050273895264,
                "frobenius_norm": 4.939803123474121,
                "spectral_norm": 2.0427942276000977,
                "num_singular_values": 32,
                "alpha": 1.1676573375300843
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.01752680540084839,
                "median": 0.017686210572719574,
                "std": 0.1616603583097458,
                "max": 0.5565422177314758,
                "min": -0.5288376212120056,
                "frobenius_norm": 5.203445911407471,
                "spectral_norm": 2.4807071685791016,
                "num_singular_values": 32,
                "alpha": 1.1663134381098479
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.03654772788286209,
                "median": 0.035363249480724335,
                "std": 0.15336337685585022,
                "max": 0.43769165873527527,
                "min": -0.4663807451725006,
                "frobenius_norm": 2.522528886795044,
                "spectral_norm": 1.6647284030914307,
                "num_singular_values": 8,
                "alpha": 1.8154611173324693
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.0005_batch_size_256_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 256,
            "scaler_type": "robust",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.0719243511557579,
            "mse": 427282496.0,
            "mae": 1979.1268310546875,
            "r2_score": 0.9077010750770569,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.020536387339234352,
                "median": 0.006348644383251667,
                "std": 0.20528393983840942,
                "max": 0.6380491852760315,
                "min": -0.6988865733146667,
                "frobenius_norm": 4.042806625366211,
                "spectral_norm": 1.8037222623825073,
                "num_singular_values": 12,
                "alpha": 1.6701502933490486
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.023057540878653526,
                "median": 0.021231725811958313,
                "std": 0.14619103074073792,
                "max": 0.5760263204574585,
                "min": -0.4307538866996765,
                "frobenius_norm": 4.735942363739014,
                "spectral_norm": 1.8199422359466553,
                "num_singular_values": 32,
                "alpha": 1.1568406832971794
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.01989857107400894,
                "median": 0.020754098892211914,
                "std": 0.14612922072410583,
                "max": 0.5645761489868164,
                "min": -0.512982189655304,
                "frobenius_norm": 4.719289779663086,
                "spectral_norm": 2.4343245029449463,
                "num_singular_values": 32,
                "alpha": 1.138725568862985
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.04049893468618393,
                "median": 0.0413573682308197,
                "std": 0.13934825360774994,
                "max": 0.37589892745018005,
                "min": -0.575695812702179,
                "frobenius_norm": 2.3218252658843994,
                "spectral_norm": 1.3257273435592651,
                "num_singular_values": 8,
                "alpha": 1.8174762514894165
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.0005_batch_size_256_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 256,
            "scaler_type": "minmax",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07530519366264343,
            "mse": 450685280.0,
            "mae": 2077.90185546875,
            "r2_score": 0.9026457667350769,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.024960674345493317,
                "median": 0.015263618901371956,
                "std": 0.18503974378108978,
                "max": 0.5663716197013855,
                "min": -0.6316909193992615,
                "frobenius_norm": 3.658864736557007,
                "spectral_norm": 1.6340417861938477,
                "num_singular_values": 12,
                "alpha": 1.8689490502770623
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.009138966910541058,
                "median": 0.007928367704153061,
                "std": 0.1286841630935669,
                "max": 0.34245243668556213,
                "min": -0.4578564167022705,
                "frobenius_norm": 4.128264427185059,
                "spectral_norm": 1.596954107284546,
                "num_singular_values": 32,
                "alpha": 1.1475415478587399
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.007408473175019026,
                "median": 0.009429752826690674,
                "std": 0.12193071842193604,
                "max": 0.43085983395576477,
                "min": -0.39940017461776733,
                "frobenius_norm": 3.9089787006378174,
                "spectral_norm": 1.8595272302627563,
                "num_singular_values": 32,
                "alpha": 1.0874065873310312
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.034758925437927246,
                "median": 0.028925998136401176,
                "std": 0.11570509523153305,
                "max": 0.33746638894081116,
                "min": -0.19203811883926392,
                "frobenius_norm": 1.9330127239227295,
                "spectral_norm": 1.1198954582214355,
                "num_singular_values": 8,
                "alpha": 1.8707146985725909
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.0001_batch_size_16_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.08276479691267014,
            "mse": 497564672.0,
            "mae": 2017.453857421875,
            "r2_score": 0.8925191760063171,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.030376866459846497,
                "median": 0.019013648852705956,
                "std": 0.16712723672389984,
                "max": 0.3392563760280609,
                "min": -0.3061519265174866,
                "frobenius_norm": 3.3286690711975098,
                "spectral_norm": 1.4239269495010376,
                "num_singular_values": 12,
                "alpha": 1.7256818341932774
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.015278530307114124,
                "median": 0.011178556829690933,
                "std": 0.10842416435480118,
                "max": 0.2425907701253891,
                "min": -0.19651657342910767,
                "frobenius_norm": 3.5038511753082275,
                "spectral_norm": 1.5165647268295288,
                "num_singular_values": 32,
                "alpha": 1.164232259762858
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.01710464432835579,
                "median": 0.017486652359366417,
                "std": 0.10591277480125427,
                "max": 0.24026843905448914,
                "min": -0.18936458230018616,
                "frobenius_norm": 3.433121919631958,
                "spectral_norm": 1.4389872550964355,
                "num_singular_values": 32,
                "alpha": 1.1634168128994866
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.033919643610715866,
                "median": 0.034459225833415985,
                "std": 0.1049460619688034,
                "max": 0.2445012629032135,
                "min": -0.16923880577087402,
                "frobenius_norm": 1.7646642923355103,
                "spectral_norm": 0.9111513495445251,
                "num_singular_values": 8,
                "alpha": 1.827752394352932
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.0001_batch_size_16_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07582908123731613,
            "mse": 510327040.0,
            "mae": 2106.18115234375,
            "r2_score": 0.8897623419761658,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.011832348071038723,
                "median": 0.0061413682997226715,
                "std": 0.17675843834877014,
                "max": 0.4180651307106018,
                "min": -0.35548701882362366,
                "frobenius_norm": 3.471496105194092,
                "spectral_norm": 1.4622182846069336,
                "num_singular_values": 12,
                "alpha": 1.7856278597754733
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.0135614313185215,
                "median": 0.011418422684073448,
                "std": 0.11081735789775848,
                "max": 0.2934451103210449,
                "min": -0.28313538432121277,
                "frobenius_norm": 3.57261061668396,
                "spectral_norm": 1.411458969116211,
                "num_singular_values": 32,
                "alpha": 1.1580112099346915
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.0047844694927334785,
                "median": 0.0022266036830842495,
                "std": 0.11054079979658127,
                "max": 0.29156363010406494,
                "min": -0.30003055930137634,
                "frobenius_norm": 3.5406174659729004,
                "spectral_norm": 1.4912527799606323,
                "num_singular_values": 32,
                "alpha": 1.1584778494411543
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.028030799701809883,
                "median": 0.02925507165491581,
                "std": 0.11039464175701141,
                "max": 0.29187384247779846,
                "min": -0.18415164947509766,
                "frobenius_norm": 1.8223644495010376,
                "spectral_norm": 1.0642085075378418,
                "num_singular_values": 8,
                "alpha": 1.8672003995320174
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.0001_batch_size_16_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07519512623548508,
            "mse": 547750912.0,
            "mae": 2164.86083984375,
            "r2_score": 0.8816782832145691,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.014673125930130482,
                "median": 0.006086328066885471,
                "std": 0.17347314953804016,
                "max": 0.4195999503135681,
                "min": -0.3093920648097992,
                "frobenius_norm": 3.4115045070648193,
                "spectral_norm": 1.4165507555007935,
                "num_singular_values": 12,
                "alpha": 1.7196002574901585
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.01465576607733965,
                "median": 0.01197153702378273,
                "std": 0.11041267961263657,
                "max": 0.2922283411026001,
                "min": -0.24995605647563934,
                "frobenius_norm": 3.564195394515991,
                "spectral_norm": 1.540618896484375,
                "num_singular_values": 32,
                "alpha": 1.1703845793303636
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.013671787455677986,
                "median": 0.013331351801753044,
                "std": 0.11066189408302307,
                "max": 0.2773571014404297,
                "min": -0.26798638701438904,
                "frobenius_norm": 3.568103551864624,
                "spectral_norm": 1.6591687202453613,
                "num_singular_values": 32,
                "alpha": 1.0908753915667613
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.0321350172162056,
                "median": 0.032067831605672836,
                "std": 0.10919402539730072,
                "max": 0.2720824182033539,
                "min": -0.19318458437919617,
                "frobenius_norm": 1.8211904764175415,
                "spectral_norm": 1.0038623809814453,
                "num_singular_values": 8,
                "alpha": 1.8900119959289976
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.0001_batch_size_16_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07940724492073059,
            "mse": 541776320.0,
            "mae": 2189.76953125,
            "r2_score": 0.8829688429832458,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.024637117981910706,
                "median": 0.020526904612779617,
                "std": 0.1692371815443039,
                "max": 0.38621535897254944,
                "min": -0.2875210642814636,
                "frobenius_norm": 3.3513152599334717,
                "spectral_norm": 1.4400299787521362,
                "num_singular_values": 12,
                "alpha": 1.7104219337613724
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.012064235284924507,
                "median": 0.011820022016763687,
                "std": 0.10816910117864609,
                "max": 0.26249000430107117,
                "min": -0.2424125373363495,
                "frobenius_norm": 3.4828732013702393,
                "spectral_norm": 1.4893083572387695,
                "num_singular_values": 32,
                "alpha": 1.119519486064276
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.008585702627897263,
                "median": 0.010846121236681938,
                "std": 0.10522332042455673,
                "max": 0.26220065355300903,
                "min": -0.23724918067455292,
                "frobenius_norm": 3.3783364295959473,
                "spectral_norm": 1.2882890701293945,
                "num_singular_values": 32,
                "alpha": 1.1440693330626408
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.027162086218595505,
                "median": 0.025695711374282837,
                "std": 0.1043342798948288,
                "max": 0.24466072022914886,
                "min": -0.18789033591747284,
                "frobenius_norm": 1.7249915599822998,
                "spectral_norm": 0.9175922870635986,
                "num_singular_values": 8,
                "alpha": 1.8684958758684949
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.0001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.08242587745189667,
            "mse": 498512864.0,
            "mae": 2026.1744384765625,
            "r2_score": 0.8923143744468689,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.030546383932232857,
                "median": 0.020386051386594772,
                "std": 0.1670762449502945,
                "max": 0.3423020839691162,
                "min": -0.30601373314857483,
                "frobenius_norm": 3.328282117843628,
                "spectral_norm": 1.4114136695861816,
                "num_singular_values": 12,
                "alpha": 1.7200556350374736
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.017551735043525696,
                "median": 0.012798094190657139,
                "std": 0.10936859995126724,
                "max": 0.26104143261909485,
                "min": -0.20797467231750488,
                "frobenius_norm": 3.544576644897461,
                "spectral_norm": 1.5895700454711914,
                "num_singular_values": 32,
                "alpha": 1.1451369227471366
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.01931789703667164,
                "median": 0.020463962107896805,
                "std": 0.10683567076921463,
                "max": 0.25527894496917725,
                "min": -0.19156283140182495,
                "frobenius_norm": 3.4741806983947754,
                "spectral_norm": 1.5328224897384644,
                "num_singular_values": 32,
                "alpha": 1.1421274391953034
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.033992089331150055,
                "median": 0.03405621647834778,
                "std": 0.10498224943876266,
                "max": 0.250410795211792,
                "min": -0.16919253766536713,
                "frobenius_norm": 1.76557195186615,
                "spectral_norm": 0.9121090769767761,
                "num_singular_values": 8,
                "alpha": 1.8251315093575524
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.0001_batch_size_32_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07573792338371277,
            "mse": 514921248.0,
            "mae": 2121.546630859375,
            "r2_score": 0.8887699246406555,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.01275404542684555,
                "median": 0.010005807504057884,
                "std": 0.1777348667383194,
                "max": 0.4250956177711487,
                "min": -0.36654606461524963,
                "frobenius_norm": 3.491833448410034,
                "spectral_norm": 1.452925205230713,
                "num_singular_values": 12,
                "alpha": 1.738565058581821
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.016315340995788574,
                "median": 0.016310961917042732,
                "std": 0.11218231916427612,
                "max": 0.3102778196334839,
                "min": -0.2928104102611542,
                "frobenius_norm": 3.627600908279419,
                "spectral_norm": 1.4526724815368652,
                "num_singular_values": 32,
                "alpha": 1.131267365518541
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.005708873271942139,
                "median": 0.002895789686590433,
                "std": 0.11324413120746613,
                "max": 0.2971261739730835,
                "min": -0.30806249380111694,
                "frobenius_norm": 3.6284139156341553,
                "spectral_norm": 1.644699215888977,
                "num_singular_values": 32,
                "alpha": 1.1506368338175854
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.032206617295742035,
                "median": 0.03149677440524101,
                "std": 0.11077872663736343,
                "max": 0.2903650999069214,
                "min": -0.18363401293754578,
                "frobenius_norm": 1.845847487449646,
                "spectral_norm": 1.064003825187683,
                "num_singular_values": 8,
                "alpha": 1.8589937470588425
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.0001_batch_size_32_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07538862526416779,
            "mse": 542501248.0,
            "mae": 2177.892333984375,
            "r2_score": 0.8828122615814209,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.01554509624838829,
                "median": 0.006918503902852535,
                "std": 0.17440463602542877,
                "max": 0.42161086201667786,
                "min": -0.32591965794563293,
                "frobenius_norm": 3.4311678409576416,
                "spectral_norm": 1.4383405447006226,
                "num_singular_values": 12,
                "alpha": 1.7184596053918488
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.01645548641681671,
                "median": 0.013527756556868553,
                "std": 0.11174161732196808,
                "max": 0.29269030690193176,
                "min": -0.26976442337036133,
                "frobenius_norm": 3.6142964363098145,
                "spectral_norm": 1.5752958059310913,
                "num_singular_values": 32,
                "alpha": 1.1483204950218222
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.015524588525295258,
                "median": 0.013107014819979668,
                "std": 0.11239804327487946,
                "max": 0.2819836437702179,
                "min": -0.29896923899650574,
                "frobenius_norm": 3.6308836936950684,
                "spectral_norm": 1.7388033866882324,
                "num_singular_values": 32,
                "alpha": 1.1081213399103051
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.0335991308093071,
                "median": 0.03205612301826477,
                "std": 0.1102290004491806,
                "max": 0.2910754382610321,
                "min": -0.18159903585910797,
                "frobenius_norm": 1.8437758684158325,
                "spectral_norm": 1.028051495552063,
                "num_singular_values": 8,
                "alpha": 1.9069871641600356
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.0001_batch_size_32_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07937848567962646,
            "mse": 554668928.0,
            "mae": 2203.336181640625,
            "r2_score": 0.8801838755607605,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.02466047741472721,
                "median": 0.017865628004074097,
                "std": 0.16924133896827698,
                "max": 0.3886636197566986,
                "min": -0.28729790449142456,
                "frobenius_norm": 3.35146164894104,
                "spectral_norm": 1.4347376823425293,
                "num_singular_values": 12,
                "alpha": 1.712853762109374
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.012941084802150726,
                "median": 0.012125924229621887,
                "std": 0.10828711837530136,
                "max": 0.25307366251945496,
                "min": -0.25868815183639526,
                "frobenius_norm": 3.489844799041748,
                "spectral_norm": 1.473284125328064,
                "num_singular_values": 32,
                "alpha": 1.1208175434175116
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.008693702518939972,
                "median": 0.008208435028791428,
                "std": 0.10609541833400726,
                "max": 0.2744622826576233,
                "min": -0.2719416320323944,
                "frobenius_norm": 3.406432628631592,
                "spectral_norm": 1.3234436511993408,
                "num_singular_values": 32,
                "alpha": 1.1194895672277356
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.028883446007966995,
                "median": 0.031973354518413544,
                "std": 0.1051030084490776,
                "max": 0.24515265226364136,
                "min": -0.19751335680484772,
                "frobenius_norm": 1.7439923286437988,
                "spectral_norm": 0.920835554599762,
                "num_singular_values": 8,
                "alpha": 1.8513005561055704
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.0001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.08216799795627594,
            "mse": 499925120.0,
            "mae": 2044.81640625,
            "r2_score": 0.8920092582702637,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.03018023632466793,
                "median": 0.02034911885857582,
                "std": 0.1674468070268631,
                "max": 0.3479915261268616,
                "min": -0.30587273836135864,
                "frobenius_norm": 3.3341450691223145,
                "spectral_norm": 1.4150421619415283,
                "num_singular_values": 12,
                "alpha": 1.7162353318945915
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.019631171599030495,
                "median": 0.014336790889501572,
                "std": 0.10990484803915024,
                "max": 0.2732927203178406,
                "min": -0.19484741985797882,
                "frobenius_norm": 3.5726187229156494,
                "spectral_norm": 1.6351299285888672,
                "num_singular_values": 32,
                "alpha": 1.1583085280281598
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.021576419472694397,
                "median": 0.021777700632810593,
                "std": 0.10805008560419083,
                "max": 0.2779764235019684,
                "min": -0.1908816397190094,
                "frobenius_norm": 3.5258662700653076,
                "spectral_norm": 1.6492552757263184,
                "num_singular_values": 32,
                "alpha": 1.1591699787618392
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.0340350866317749,
                "median": 0.034702178090810776,
                "std": 0.10490511357784271,
                "max": 0.2462046891450882,
                "min": -0.1710449457168579,
                "frobenius_norm": 1.7646100521087646,
                "spectral_norm": 0.9085454940795898,
                "num_singular_values": 8,
                "alpha": 1.8236359956803883
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.0001_batch_size_64_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "standard",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07586771249771118,
            "mse": 519988320.0,
            "mae": 2131.3447265625,
            "r2_score": 0.8876753449440002,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.013203383423388004,
                "median": 0.007590333465486765,
                "std": 0.17768698930740356,
                "max": 0.4288499057292938,
                "min": -0.3703106641769409,
                "frobenius_norm": 3.491539239883423,
                "spectral_norm": 1.441985011100769,
                "num_singular_values": 12,
                "alpha": 1.7271680313268056
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.017227087169885635,
                "median": 0.016335610300302505,
                "std": 0.11334206163883209,
                "max": 0.3183385729789734,
                "min": -0.307585746049881,
                "frobenius_norm": 3.6686007976531982,
                "spectral_norm": 1.523231863975525,
                "num_singular_values": 32,
                "alpha": 1.157234080580147
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.007407493889331818,
                "median": 0.0066923294216394424,
                "std": 0.11302054673433304,
                "max": 0.30094826221466064,
                "min": -0.30182498693466187,
                "frobenius_norm": 3.624417304992676,
                "spectral_norm": 1.6634894609451294,
                "num_singular_values": 32,
                "alpha": 1.1364830038502172
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.031233783811330795,
                "median": 0.0308394692838192,
                "std": 0.11084052175283432,
                "max": 0.2893272936344147,
                "min": -0.18552827835083008,
                "frobenius_norm": 1.8425145149230957,
                "spectral_norm": 1.0541913509368896,
                "num_singular_values": 8,
                "alpha": 1.854096461548298
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.0001_batch_size_64_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "robust",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.0754096731543541,
            "mse": 531632320.0,
            "mae": 2172.64111328125,
            "r2_score": 0.8851600885391235,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.014917981810867786,
                "median": 0.00815332867205143,
                "std": 0.17429447174072266,
                "max": 0.42161455750465393,
                "min": -0.3243589699268341,
                "frobenius_norm": 3.427947759628296,
                "spectral_norm": 1.4387940168380737,
                "num_singular_values": 12,
                "alpha": 1.7224800796401822
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.015296418219804764,
                "median": 0.01313626579940319,
                "std": 0.11194755882024765,
                "max": 0.2921375632286072,
                "min": -0.2853555381298065,
                "frobenius_norm": 3.6156086921691895,
                "spectral_norm": 1.5424890518188477,
                "num_singular_values": 32,
                "alpha": 1.1666171704808015
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.014508012682199478,
                "median": 0.015547733753919601,
                "std": 0.1134205237030983,
                "max": 0.2836790382862091,
                "min": -0.2998426556587219,
                "frobenius_norm": 3.6590285301208496,
                "spectral_norm": 1.7524490356445312,
                "num_singular_values": 32,
                "alpha": 1.0773237129564444
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.03636199235916138,
                "median": 0.03336792439222336,
                "std": 0.11136141419410706,
                "max": 0.2994481921195984,
                "min": -0.17529118061065674,
                "frobenius_norm": 1.874361515045166,
                "spectral_norm": 1.0882645845413208,
                "num_singular_values": 8,
                "alpha": 1.8596638769246019
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.0001_batch_size_64_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "minmax",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07954920083284378,
            "mse": 552842112.0,
            "mae": 2210.438720703125,
            "r2_score": 0.8805785179138184,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.025167519226670265,
                "median": 0.02196197584271431,
                "std": 0.16985921561717987,
                "max": 0.3915773928165436,
                "min": -0.2907019555568695,
                "frobenius_norm": 3.3648855686187744,
                "spectral_norm": 1.4491485357284546,
                "num_singular_values": 12,
                "alpha": 1.7014360000594597
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.01324324682354927,
                "median": 0.01233433187007904,
                "std": 0.10882344096899033,
                "max": 0.270364373922348,
                "min": -0.2848292887210846,
                "frobenius_norm": 3.5080413818359375,
                "spectral_norm": 1.5099761486053467,
                "num_singular_values": 32,
                "alpha": 1.1352551630552095
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.009592432528734207,
                "median": 0.011919040232896805,
                "std": 0.1054881289601326,
                "max": 0.2651291489601135,
                "min": -0.2572402358055115,
                "frobenius_norm": 3.389547824859619,
                "spectral_norm": 1.3079087734222412,
                "num_singular_values": 32,
                "alpha": 1.1425176801182853
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.02553425543010235,
                "median": 0.027154121547937393,
                "std": 0.10418207198381424,
                "max": 0.24640251696109772,
                "min": -0.20307716727256775,
                "frobenius_norm": 1.7162491083145142,
                "spectral_norm": 0.9109687209129333,
                "num_singular_values": 8,
                "alpha": 1.8930570954117234
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.0001_batch_size_128_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 128,
            "scaler_type": "identity",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.08174896240234375,
            "mse": 489952064.0,
            "mae": 2032.11669921875,
            "r2_score": 0.8941636085510254,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.029737865552306175,
                "median": 0.02068936638534069,
                "std": 0.1676831841468811,
                "max": 0.3516256511211395,
                "min": -0.30610600113868713,
                "frobenius_norm": 3.337179183959961,
                "spectral_norm": 1.4162360429763794,
                "num_singular_values": 12,
                "alpha": 1.717395625130615
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.02000374346971512,
                "median": 0.0152354147285223,
                "std": 0.11037991940975189,
                "max": 0.27527546882629395,
                "min": -0.1953428089618683,
                "frobenius_norm": 3.5896921157836914,
                "spectral_norm": 1.6543930768966675,
                "num_singular_values": 32,
                "alpha": 1.1456966845081284
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.021771445870399475,
                "median": 0.020179811865091324,
                "std": 0.10819179564714432,
                "max": 0.27427196502685547,
                "min": -0.20095089077949524,
                "frobenius_norm": 3.531538963317871,
                "spectral_norm": 1.6536531448364258,
                "num_singular_values": 32,
                "alpha": 1.1628219008422032
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.03448878601193428,
                "median": 0.03478866070508957,
                "std": 0.10503647476434708,
                "max": 0.24509845674037933,
                "min": -0.1701103299856186,
                "frobenius_norm": 1.7688603401184082,
                "spectral_norm": 0.9143006205558777,
                "num_singular_values": 8,
                "alpha": 1.8213133903747545
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.0001_batch_size_128_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 128,
            "scaler_type": "standard",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07555419951677322,
            "mse": 512010624.0,
            "mae": 2115.516845703125,
            "r2_score": 0.8893986344337463,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.014627725817263126,
                "median": 0.009468299336731434,
                "std": 0.17840874195098877,
                "max": 0.4272349774837494,
                "min": -0.3738340735435486,
                "frobenius_norm": 3.507814407348633,
                "spectral_norm": 1.460984468460083,
                "num_singular_values": 12,
                "alpha": 1.7267899562707085
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.016989540308713913,
                "median": 0.01865803264081478,
                "std": 0.11417144536972046,
                "max": 0.3260919749736786,
                "min": -0.31172725558280945,
                "frobenius_norm": 3.6937155723571777,
                "spectral_norm": 1.515144944190979,
                "num_singular_values": 32,
                "alpha": 1.0808489587510761
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.006635350175201893,
                "median": 0.005444112233817577,
                "std": 0.11493873596191406,
                "max": 0.3100813925266266,
                "min": -0.30388349294662476,
                "frobenius_norm": 3.6841635704040527,
                "spectral_norm": 1.6939278841018677,
                "num_singular_values": 32,
                "alpha": 1.185915097648666
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.026487069204449654,
                "median": 0.027388110756874084,
                "std": 0.11383994668722153,
                "max": 0.2814668118953705,
                "min": -0.22098037600517273,
                "frobenius_norm": 1.870091199874878,
                "spectral_norm": 1.1200273036956787,
                "num_singular_values": 8,
                "alpha": 1.8675628157925275
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.0001_batch_size_128_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 128,
            "scaler_type": "robust",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07530131936073303,
            "mse": 532086528.0,
            "mae": 2170.416015625,
            "r2_score": 0.8850619792938232,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.015203219838440418,
                "median": 0.009214978665113449,
                "std": 0.17406219244003296,
                "max": 0.4230877161026001,
                "min": -0.3267304599285126,
                "frobenius_norm": 3.4238944053649902,
                "spectral_norm": 1.4298439025878906,
                "num_singular_values": 12,
                "alpha": 1.7217478401073507
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.016851022839546204,
                "median": 0.013304761610925198,
                "std": 0.11315874010324478,
                "max": 0.297707200050354,
                "min": -0.29968690872192383,
                "frobenius_norm": 3.6610095500946045,
                "spectral_norm": 1.6016950607299805,
                "num_singular_values": 32,
                "alpha": 1.1550061617191552
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.014666328206658363,
                "median": 0.013914518058300018,
                "std": 0.11335036158561707,
                "max": 0.29364266991615295,
                "min": -0.31103116273880005,
                "frobenius_norm": 3.6574482917785645,
                "spectral_norm": 1.7644753456115723,
                "num_singular_values": 32,
                "alpha": 1.1323893163965753
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.03228384256362915,
                "median": 0.03101157769560814,
                "std": 0.11067603528499603,
                "max": 0.2711213231086731,
                "min": -0.19733861088752747,
                "frobenius_norm": 1.8446155786514282,
                "spectral_norm": 1.0363349914550781,
                "num_singular_values": 8,
                "alpha": 1.894368633398054
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.0001_batch_size_128_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 128,
            "scaler_type": "minmax",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07927164435386658,
            "mse": 548638208.0,
            "mae": 2205.412109375,
            "r2_score": 0.8814865946769714,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.02527235448360443,
                "median": 0.024061262607574463,
                "std": 0.16926917433738708,
                "max": 0.3926527798175812,
                "min": -0.287323534488678,
                "frobenius_norm": 3.3537511825561523,
                "spectral_norm": 1.4352827072143555,
                "num_singular_values": 12,
                "alpha": 1.7008596548597081
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.012611590325832367,
                "median": 0.01030886359512806,
                "std": 0.10896521061658859,
                "max": 0.26727670431137085,
                "min": -0.29017311334609985,
                "frobenius_norm": 3.5101637840270996,
                "spectral_norm": 1.485203504562378,
                "num_singular_values": 32,
                "alpha": 1.1458888945097547
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.009178616106510162,
                "median": 0.010938288643956184,
                "std": 0.10590744763612747,
                "max": 0.2630622982978821,
                "min": -0.2632567286491394,
                "frobenius_norm": 3.4017422199249268,
                "spectral_norm": 1.3339492082595825,
                "num_singular_values": 32,
                "alpha": 1.144960933187291
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.026788786053657532,
                "median": 0.02608325332403183,
                "std": 0.10443856567144394,
                "max": 0.24626651406288147,
                "min": -0.20053239166736603,
                "frobenius_norm": 1.7251126766204834,
                "spectral_norm": 0.9203252196311951,
                "num_singular_values": 8,
                "alpha": 1.8733368775396717
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.0001_batch_size_256_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 256,
            "scaler_type": "identity",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.08200016617774963,
            "mse": 499892352.0,
            "mae": 2049.16357421875,
            "r2_score": 0.8920163512229919,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.030002476647496223,
                "median": 0.021619684994220734,
                "std": 0.1677488386631012,
                "max": 0.35355451703071594,
                "min": -0.3059554398059845,
                "frobenius_norm": 3.339355230331421,
                "spectral_norm": 1.4145491123199463,
                "num_singular_values": 12,
                "alpha": 1.712985535407126
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.018949678167700768,
                "median": 0.013981257565319538,
                "std": 0.11062364280223846,
                "max": 0.2889176905155182,
                "min": -0.19163371622562408,
                "frobenius_norm": 3.591517925262451,
                "spectral_norm": 1.651617407798767,
                "num_singular_values": 32,
                "alpha": 1.1223825972115482
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.020742975175380707,
                "median": 0.020418722182512283,
                "std": 0.10812936723232269,
                "max": 0.28337720036506653,
                "min": -0.19440025091171265,
                "frobenius_norm": 3.5232319831848145,
                "spectral_norm": 1.633539080619812,
                "num_singular_values": 32,
                "alpha": 1.1460067905538016
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.0348803885281086,
                "median": 0.035087745636701584,
                "std": 0.10534331947565079,
                "max": 0.24888035655021667,
                "min": -0.1701359897851944,
                "frobenius_norm": 1.7754851579666138,
                "spectral_norm": 0.9250625967979431,
                "num_singular_values": 8,
                "alpha": 1.8229001918216166
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.0001_batch_size_256_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 256,
            "scaler_type": "standard",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.0755600556731224,
            "mse": 520647040.0,
            "mae": 2124.106689453125,
            "r2_score": 0.8875330686569214,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.013440416194498539,
                "median": 0.00843144953250885,
                "std": 0.17796194553375244,
                "max": 0.4258597493171692,
                "min": -0.3758071959018707,
                "frobenius_norm": 3.4972593784332275,
                "spectral_norm": 1.4565002918243408,
                "num_singular_values": 12,
                "alpha": 1.7041762258942557
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.017176762223243713,
                "median": 0.019778043031692505,
                "std": 0.11467953026294708,
                "max": 0.325161874294281,
                "min": -0.3103596270084381,
                "frobenius_norm": 3.7106807231903076,
                "spectral_norm": 1.5573021173477173,
                "num_singular_values": 32,
                "alpha": 1.1265344687438636
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.007047639228403568,
                "median": 0.005925060249865055,
                "std": 0.11604867875576019,
                "max": 0.3227085471153259,
                "min": -0.3135058283805847,
                "frobenius_norm": 3.7203993797302246,
                "spectral_norm": 1.7785218954086304,
                "num_singular_values": 32,
                "alpha": 1.1883337757870038
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.02678065188229084,
                "median": 0.028784388676285744,
                "std": 0.11459043622016907,
                "max": 0.2854141294956207,
                "min": -0.23487839102745056,
                "frobenius_norm": 1.8828520774841309,
                "spectral_norm": 1.1403504610061646,
                "num_singular_values": 8,
                "alpha": 1.901664408654569
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.0001_batch_size_256_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 256,
            "scaler_type": "robust",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.0753183662891388,
            "mse": 529846880.0,
            "mae": 2167.093505859375,
            "r2_score": 0.8855457901954651,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.015728311613202095,
                "median": 0.011013342067599297,
                "std": 0.17474114894866943,
                "max": 0.4228496551513672,
                "min": -0.32893916964530945,
                "frobenius_norm": 3.438055992126465,
                "spectral_norm": 1.4502760171890259,
                "num_singular_values": 12,
                "alpha": 1.720402859262039
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.01713215745985508,
                "median": 0.016309667378664017,
                "std": 0.11271438747644424,
                "max": 0.29418882727622986,
                "min": -0.3010754883289337,
                "frobenius_norm": 3.648286819458008,
                "spectral_norm": 1.5864733457565308,
                "num_singular_values": 32,
                "alpha": 1.141396448506181
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.016207575798034668,
                "median": 0.014477765187621117,
                "std": 0.11427002400159836,
                "max": 0.29313182830810547,
                "min": -0.3141590654850006,
                "frobenius_norm": 3.6932384967803955,
                "spectral_norm": 1.840263843536377,
                "num_singular_values": 32,
                "alpha": 1.1223916374327603
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.03335469961166382,
                "median": 0.030427690595388412,
                "std": 0.11065052449703217,
                "max": 0.2892976999282837,
                "min": -0.18741312623023987,
                "frobenius_norm": 1.8490957021713257,
                "spectral_norm": 1.0337878465652466,
                "num_singular_values": 8,
                "alpha": 1.9192868349121552
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_0.0001_batch_size_256_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 0.0001,
            "batch_size": 256,
            "scaler_type": "minmax",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.0794559121131897,
            "mse": 555459008.0,
            "mae": 2218.404296875,
            "r2_score": 0.8800132274627686,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.02397139184176922,
                "median": 0.018006864935159683,
                "std": 0.16982990503311157,
                "max": 0.39381927251815796,
                "min": -0.2921386957168579,
                "frobenius_norm": 3.3609609603881836,
                "spectral_norm": 1.4385043382644653,
                "num_singular_values": 12,
                "alpha": 1.7014953543884324
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.012318410910665989,
                "median": 0.009964853525161743,
                "std": 0.10879997164011002,
                "max": 0.2668500244617462,
                "min": -0.2884921729564667,
                "frobenius_norm": 3.503843069076538,
                "spectral_norm": 1.4779802560806274,
                "num_singular_values": 32,
                "alpha": 1.1438166562461949
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.008565970696508884,
                "median": 0.009613873437047005,
                "std": 0.1061415895819664,
                "max": 0.29690635204315186,
                "min": -0.2621253728866577,
                "frobenius_norm": 3.407573938369751,
                "spectral_norm": 1.362113356590271,
                "num_singular_values": 32,
                "alpha": 1.1572986465683759
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.030603766441345215,
                "median": 0.030492674559354782,
                "std": 0.10615494102239609,
                "max": 0.2476610392332077,
                "min": -0.17340749502182007,
                "frobenius_norm": 1.767653226852417,
                "spectral_norm": 0.9786660671234131,
                "num_singular_values": 8,
                "alpha": 1.8531223306109894
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_5e-05_batch_size_16_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.12099388986825943,
            "mse": 768462784.0,
            "mae": 2864.4189453125,
            "r2_score": 0.8340014219284058,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.029439019039273262,
                "median": 0.0215301513671875,
                "std": 0.16694675385951996,
                "max": 0.33185914158821106,
                "min": -0.3034195601940155,
                "frobenius_norm": 3.321948766708374,
                "spectral_norm": 1.4334571361541748,
                "num_singular_values": 12,
                "alpha": 1.7295871338824846
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.008862179704010487,
                "median": 0.004401138983666897,
                "std": 0.10741233080625534,
                "max": 0.22712945938110352,
                "min": -0.20193718373775482,
                "frobenius_norm": 3.448873519897461,
                "spectral_norm": 1.3924416303634644,
                "num_singular_values": 32,
                "alpha": 1.1461303819855966
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.012604473158717155,
                "median": 0.013253877870738506,
                "std": 0.10449808090925217,
                "max": 0.23264017701148987,
                "min": -0.1816953420639038,
                "frobenius_norm": 3.3681764602661133,
                "spectral_norm": 1.3089286088943481,
                "num_singular_values": 32,
                "alpha": 1.1794410051101547
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.03277057409286499,
                "median": 0.03270997107028961,
                "std": 0.10503552854061127,
                "max": 0.23695212602615356,
                "min": -0.1704743206501007,
                "frobenius_norm": 1.7604634761810303,
                "spectral_norm": 0.913947343826294,
                "num_singular_values": 8,
                "alpha": 1.7984491652817174
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_5e-05_batch_size_16_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.0768408253788948,
            "mse": 513065824.0,
            "mae": 2064.710205078125,
            "r2_score": 0.8891707062721252,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.006413890514522791,
                "median": -0.004373558331280947,
                "std": 0.16894757747650146,
                "max": 0.3526202142238617,
                "min": -0.3014419972896576,
                "frobenius_norm": 3.31306791305542,
                "spectral_norm": 1.4110403060913086,
                "num_singular_values": 12,
                "alpha": 1.7683866574079583
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.006245448254048824,
                "median": 0.0029810392297804356,
                "std": 0.10616301000118256,
                "max": 0.23897336423397064,
                "min": -0.22767874598503113,
                "frobenius_norm": 3.403089761734009,
                "spectral_norm": 1.2516841888427734,
                "num_singular_values": 32,
                "alpha": 1.15659539646047
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.003231543116271496,
                "median": 0.0037426496855914593,
                "std": 0.10458404570817947,
                "max": 0.24359019100666046,
                "min": -0.230525404214859,
                "frobenius_norm": 3.3482868671417236,
                "spectral_norm": 1.180577278137207,
                "num_singular_values": 32,
                "alpha": 1.1682810451902643
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.021182755008339882,
                "median": 0.020702220499515533,
                "std": 0.10447075217962265,
                "max": 0.22431254386901855,
                "min": -0.1751590222120285,
                "frobenius_norm": 1.705546498298645,
                "spectral_norm": 0.9118829965591431,
                "num_singular_values": 8,
                "alpha": 1.8793722615456037
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_5e-05_batch_size_16_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.0763004869222641,
            "mse": 533796832.0,
            "mae": 2041.5360107421875,
            "r2_score": 0.8846925497055054,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.00782793015241623,
                "median": -0.0030062953010201454,
                "std": 0.16851721704006195,
                "max": 0.3522130250930786,
                "min": -0.29427284002304077,
                "frobenius_norm": 3.3058104515075684,
                "spectral_norm": 1.4127588272094727,
                "num_singular_values": 12,
                "alpha": 1.7281889607977166
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.0071081845089793205,
                "median": 0.005843513645231724,
                "std": 0.10559103637933731,
                "max": 0.23846770823001862,
                "min": -0.2062750905752182,
                "frobenius_norm": 3.3865606784820557,
                "spectral_norm": 1.2831904888153076,
                "num_singular_values": 32,
                "alpha": 1.1700310705233128
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.007236264180392027,
                "median": 0.009292534552514553,
                "std": 0.10373472422361374,
                "max": 0.23577214777469635,
                "min": -0.20292314887046814,
                "frobenius_norm": 3.327577829360962,
                "spectral_norm": 1.2201038599014282,
                "num_singular_values": 32,
                "alpha": 1.1214071856986199
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.023631863296031952,
                "median": 0.023150790482759476,
                "std": 0.10469354689121246,
                "max": 0.23395365476608276,
                "min": -0.1962011307477951,
                "frobenius_norm": 1.717240810394287,
                "spectral_norm": 0.909464955329895,
                "num_singular_values": 8,
                "alpha": 1.8728933809575716
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_5e-05_batch_size_16_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.08333983272314072,
            "mse": 618484160.0,
            "mae": 2324.5302734375,
            "r2_score": 0.8663989305496216,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.02333880215883255,
                "median": 0.017138876020908356,
                "std": 0.16904471814632416,
                "max": 0.3472175598144531,
                "min": -0.2869325578212738,
                "frobenius_norm": 3.344008684158325,
                "spectral_norm": 1.4480116367340088,
                "num_singular_values": 12,
                "alpha": 1.717743199451264
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.01111542247235775,
                "median": 0.008945850655436516,
                "std": 0.10726121813058853,
                "max": 0.24627116322517395,
                "min": -0.1923902928829193,
                "frobenius_norm": 3.450739860534668,
                "spectral_norm": 1.4643996953964233,
                "num_singular_values": 32,
                "alpha": 1.1083448347396723
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.008577108383178711,
                "median": 0.009333103895187378,
                "std": 0.10366833209991455,
                "max": 0.243072971701622,
                "min": -0.20600014925003052,
                "frobenius_norm": 3.328721284866333,
                "spectral_norm": 1.2241687774658203,
                "num_singular_values": 32,
                "alpha": 1.1534722094116108
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.026250815019011497,
                "median": 0.025473929941654205,
                "std": 0.10397361218929291,
                "max": 0.21747441589832306,
                "min": -0.17354024946689606,
                "frobenius_norm": 1.715780258178711,
                "spectral_norm": 0.9107087254524231,
                "num_singular_values": 8,
                "alpha": 1.8268769589047347
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_5e-05_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.08721397817134857,
            "mse": 547925184.0,
            "mae": 2195.08447265625,
            "r2_score": 0.881640613079071,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.030718551948666573,
                "median": 0.022013705223798752,
                "std": 0.16665764153003693,
                "max": 0.3296543061733246,
                "min": -0.3029801547527313,
                "frobenius_norm": 3.3208231925964355,
                "spectral_norm": 1.4238653182983398,
                "num_singular_values": 12,
                "alpha": 1.7308837524861127
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.011551923118531704,
                "median": 0.007876279763877392,
                "std": 0.10778755694627762,
                "max": 0.2367967665195465,
                "min": -0.2048768252134323,
                "frobenius_norm": 3.46895432472229,
                "spectral_norm": 1.4524166584014893,
                "num_singular_values": 32,
                "alpha": 1.1518975845200639
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.01399695873260498,
                "median": 0.014589943923056126,
                "std": 0.10479892790317535,
                "max": 0.23629912734031677,
                "min": -0.1832846701145172,
                "frobenius_norm": 3.3833444118499756,
                "spectral_norm": 1.3240000009536743,
                "num_singular_values": 32,
                "alpha": 1.1707686485385451
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.03363017365336418,
                "median": 0.03351540118455887,
                "std": 0.10515962541103363,
                "max": 0.24547342956066132,
                "min": -0.16957582533359528,
                "frobenius_norm": 1.766499638557434,
                "spectral_norm": 0.9150096774101257,
                "num_singular_values": 8,
                "alpha": 1.822047662520697
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_5e-05_batch_size_32_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07662554830312729,
            "mse": 513926720.0,
            "mae": 2065.862548828125,
            "r2_score": 0.888984739780426,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.007402751594781876,
                "median": -0.002005798975005746,
                "std": 0.1696065366268158,
                "max": 0.3574213683605194,
                "min": -0.30806949734687805,
                "frobenius_norm": 3.3267600536346436,
                "spectral_norm": 1.414103388786316,
                "num_singular_values": 12,
                "alpha": 1.7491742656160425
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.00770376343280077,
                "median": 0.005365398712456226,
                "std": 0.10673561692237854,
                "max": 0.24307261407375336,
                "min": -0.2358514666557312,
                "frobenius_norm": 3.424424648284912,
                "spectral_norm": 1.2728265523910522,
                "num_singular_values": 32,
                "alpha": 1.1608176520723787
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.003733726218342781,
                "median": 0.003956878557801247,
                "std": 0.10528721660375595,
                "max": 0.2497524917125702,
                "min": -0.2393030822277069,
                "frobenius_norm": 3.3713088035583496,
                "spectral_norm": 1.2145745754241943,
                "num_singular_values": 32,
                "alpha": 1.1537576886524141
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.022861821576952934,
                "median": 0.024847565218806267,
                "std": 0.1046968474984169,
                "max": 0.22696129977703094,
                "min": -0.17300795018672943,
                "frobenius_norm": 1.714621663093567,
                "spectral_norm": 0.9220479726791382,
                "num_singular_values": 8,
                "alpha": 1.869353713220816
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_5e-05_batch_size_32_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07576088607311249,
            "mse": 536625440.0,
            "mae": 2048.69140625,
            "r2_score": 0.8840814828872681,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.008403167128562927,
                "median": -0.0007153021288104355,
                "std": 0.1690906286239624,
                "max": 0.355922132730484,
                "min": -0.29188409447669983,
                "frobenius_norm": 3.317575216293335,
                "spectral_norm": 1.4107849597930908,
                "num_singular_values": 12,
                "alpha": 1.7180180605640565
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.00898687168955803,
                "median": 0.007697463966906071,
                "std": 0.10613703727722168,
                "max": 0.24191352725028992,
                "min": -0.21578562259674072,
                "frobenius_norm": 3.408538579940796,
                "spectral_norm": 1.3202775716781616,
                "num_singular_values": 32,
                "alpha": 1.178293111598635
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.008729754015803337,
                "median": 0.010336950421333313,
                "std": 0.10454036295413971,
                "max": 0.24032564461231232,
                "min": -0.21446098387241364,
                "frobenius_norm": 3.3569350242614746,
                "spectral_norm": 1.270166039466858,
                "num_singular_values": 32,
                "alpha": 1.1149314341696153
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.025509364902973175,
                "median": 0.025227172300219536,
                "std": 0.10495927184820175,
                "max": 0.23685142397880554,
                "min": -0.18608435988426208,
                "frobenius_norm": 1.7282353639602661,
                "spectral_norm": 0.9176506996154785,
                "num_singular_values": 8,
                "alpha": 1.8728494964607356
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_5e-05_batch_size_32_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.08198804408311844,
            "mse": 600091392.0,
            "mae": 2292.52197265625,
            "r2_score": 0.8703719973564148,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.023192068561911583,
                "median": 0.01697363518178463,
                "std": 0.1690802127122879,
                "max": 0.34717172384262085,
                "min": -0.28578636050224304,
                "frobenius_norm": 3.3443055152893066,
                "spectral_norm": 1.4473072290420532,
                "num_singular_values": 12,
                "alpha": 1.721322389161302
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.011735823005437851,
                "median": 0.009264458902180195,
                "std": 0.10727714747190475,
                "max": 0.24762789905071259,
                "min": -0.19447660446166992,
                "frobenius_norm": 3.4533495903015137,
                "spectral_norm": 1.4763890504837036,
                "num_singular_values": 32,
                "alpha": 1.0970008726369769
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.009619753807783127,
                "median": 0.011419778689742088,
                "std": 0.10370445251464844,
                "max": 0.2515605092048645,
                "min": -0.20368342101573944,
                "frobenius_norm": 3.332789421081543,
                "spectral_norm": 1.2342910766601562,
                "num_singular_values": 32,
                "alpha": 1.1491961642887598
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.02715805172920227,
                "median": 0.027981869876384735,
                "std": 0.10419745743274689,
                "max": 0.22320720553398132,
                "min": -0.1730262041091919,
                "frobenius_norm": 1.7228567600250244,
                "spectral_norm": 0.9164547324180603,
                "num_singular_values": 8,
                "alpha": 1.8147707441625203
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_5e-05_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.08230285346508026,
            "mse": 501546912.0,
            "mae": 2045.027099609375,
            "r2_score": 0.8916589617729187,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.03119278885424137,
                "median": 0.020436231046915054,
                "std": 0.16687937080860138,
                "max": 0.3317621648311615,
                "min": -0.3054729700088501,
                "frobenius_norm": 3.3267910480499268,
                "spectral_norm": 1.4254785776138306,
                "num_singular_values": 12,
                "alpha": 1.7259656883325802
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.011851759627461433,
                "median": 0.00804225541651249,
                "std": 0.1079447865486145,
                "max": 0.2386474460363388,
                "min": -0.20552365481853485,
                "frobenius_norm": 3.4749908447265625,
                "spectral_norm": 1.4579918384552002,
                "num_singular_values": 32,
                "alpha": 1.1430137346278366
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.014397135935723782,
                "median": 0.015122356824576855,
                "std": 0.10502008348703384,
                "max": 0.23628902435302734,
                "min": -0.18511252105236053,
                "frobenius_norm": 3.3920748233795166,
                "spectral_norm": 1.3524441719055176,
                "num_singular_values": 32,
                "alpha": 1.1670182407102554
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.03328196704387665,
                "median": 0.03385142982006073,
                "std": 0.10484664887189865,
                "max": 0.2459772676229477,
                "min": -0.17091989517211914,
                "frobenius_norm": 1.7600369453430176,
                "spectral_norm": 0.9065914750099182,
                "num_singular_values": 8,
                "alpha": 1.829815342467105
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_5e-05_batch_size_64_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 64,
            "scaler_type": "standard",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07650542259216309,
            "mse": 512281472.0,
            "mae": 2063.699462890625,
            "r2_score": 0.8893401622772217,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.007368640508502722,
                "median": -0.003814724273979664,
                "std": 0.17021718621253967,
                "max": 0.35947608947753906,
                "min": -0.31940680742263794,
                "frobenius_norm": 3.338685989379883,
                "spectral_norm": 1.4187387228012085,
                "num_singular_values": 12,
                "alpha": 1.7530157254370362
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.008182425051927567,
                "median": 0.006890545599162579,
                "std": 0.10683520883321762,
                "max": 0.24597936868667603,
                "min": -0.24096328020095825,
                "frobenius_norm": 3.428739070892334,
                "spectral_norm": 1.2735755443572998,
                "num_singular_values": 32,
                "alpha": 1.1705193587906302
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.004233876243233681,
                "median": 0.003423453541472554,
                "std": 0.10574284195899963,
                "max": 0.24913820624351501,
                "min": -0.24345475435256958,
                "frobenius_norm": 3.3864824771881104,
                "spectral_norm": 1.2426518201828003,
                "num_singular_values": 32,
                "alpha": 1.1543812448372859
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.02261499874293804,
                "median": 0.022850535809993744,
                "std": 0.10491891950368881,
                "max": 0.2281244695186615,
                "min": -0.17381341755390167,
                "frobenius_norm": 1.717256784439087,
                "spectral_norm": 0.9251621961593628,
                "num_singular_values": 8,
                "alpha": 1.852104108236352
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_5e-05_batch_size_64_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 64,
            "scaler_type": "robust",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07565414160490036,
            "mse": 534501856.0,
            "mae": 2046.1640625,
            "r2_score": 0.8845402598381042,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.00909844134002924,
                "median": 0.0008628832874819636,
                "std": 0.16928908228874207,
                "max": 0.357652872800827,
                "min": -0.29423952102661133,
                "frobenius_norm": 3.322162628173828,
                "spectral_norm": 1.4093296527862549,
                "num_singular_values": 12,
                "alpha": 1.7159429193857871
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.009403198026120663,
                "median": 0.00842217169702053,
                "std": 0.1063554435968399,
                "max": 0.2428750991821289,
                "min": -0.2201845943927765,
                "frobenius_norm": 3.4166500568389893,
                "spectral_norm": 1.3305892944335938,
                "num_singular_values": 32,
                "alpha": 1.1743463792888993
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.009105831384658813,
                "median": 0.011123334988951683,
                "std": 0.10482973605394363,
                "max": 0.24074193835258484,
                "min": -0.2143992781639099,
                "frobenius_norm": 3.367183208465576,
                "spectral_norm": 1.288069248199463,
                "num_singular_values": 32,
                "alpha": 1.0848982506759237
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.024977907538414,
                "median": 0.025114793330430984,
                "std": 0.10509593039751053,
                "max": 0.23842968046665192,
                "min": -0.18490111827850342,
                "frobenius_norm": 1.7283741235733032,
                "spectral_norm": 0.9172868132591248,
                "num_singular_values": 8,
                "alpha": 1.8827131130521662
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_5e-05_batch_size_64_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 64,
            "scaler_type": "minmax",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.08226868510246277,
            "mse": 598739520.0,
            "mae": 2282.68359375,
            "r2_score": 0.8706640005111694,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.023659512400627136,
                "median": 0.017856808379292488,
                "std": 0.1694014072418213,
                "max": 0.348100870847702,
                "min": -0.2869429588317871,
                "frobenius_norm": 3.3517961502075195,
                "spectral_norm": 1.4575004577636719,
                "num_singular_values": 12,
                "alpha": 1.7193765373075047
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.011601686477661133,
                "median": 0.009608188644051552,
                "std": 0.10746067762374878,
                "max": 0.24715836346149445,
                "min": -0.1964281052350998,
                "frobenius_norm": 3.4587242603302,
                "spectral_norm": 1.4745972156524658,
                "num_singular_values": 32,
                "alpha": 1.120266849720481
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.009099125862121582,
                "median": 0.011798053979873657,
                "std": 0.10400387644767761,
                "max": 0.24807706475257874,
                "min": -0.2061108946800232,
                "frobenius_norm": 3.340837001800537,
                "spectral_norm": 1.2324869632720947,
                "num_singular_values": 32,
                "alpha": 1.1599799593933355
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.025560688227415085,
                "median": 0.02561117708683014,
                "std": 0.10376673191785812,
                "max": 0.22639626264572144,
                "min": -0.17371900379657745,
                "frobenius_norm": 1.7098965644836426,
                "spectral_norm": 0.9013484716415405,
                "num_singular_values": 8,
                "alpha": 1.8205672148951644
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_5e-05_batch_size_128_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 128,
            "scaler_type": "identity",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.08201184123754501,
            "mse": 493808672.0,
            "mae": 2029.794921875,
            "r2_score": 0.8933305144309998,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.030974647030234337,
                "median": 0.01952233910560608,
                "std": 0.16691790521144867,
                "max": 0.33301687240600586,
                "min": -0.3061476945877075,
                "frobenius_norm": 3.3267505168914795,
                "spectral_norm": 1.4222248792648315,
                "num_singular_values": 12,
                "alpha": 1.7252605676921822
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.01217118464410305,
                "median": 0.007849928922951221,
                "std": 0.10800528526306152,
                "max": 0.23980063199996948,
                "min": -0.20619399845600128,
                "frobenius_norm": 3.4780447483062744,
                "spectral_norm": 1.4647245407104492,
                "num_singular_values": 32,
                "alpha": 1.1465520303464738
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.014564667828381062,
                "median": 0.01503070630133152,
                "std": 0.1050742119550705,
                "max": 0.2374536693096161,
                "min": -0.18588820099830627,
                "frobenius_norm": 3.3945229053497314,
                "spectral_norm": 1.3501074314117432,
                "num_singular_values": 32,
                "alpha": 1.1643665054644408
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.03341076895594597,
                "median": 0.03404928743839264,
                "std": 0.10491181910037994,
                "max": 0.24622119963169098,
                "min": -0.1700817495584488,
                "frobenius_norm": 1.7616550922393799,
                "spectral_norm": 0.9081456661224365,
                "num_singular_values": 8,
                "alpha": 1.828735966726231
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_5e-05_batch_size_128_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 128,
            "scaler_type": "standard",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07643773406744003,
            "mse": 515668320.0,
            "mae": 2069.062744140625,
            "r2_score": 0.8886085152626038,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.008200821466743946,
                "median": -0.0018578158924356103,
                "std": 0.17021603882312775,
                "max": 0.3592047095298767,
                "min": -0.31934690475463867,
                "frobenius_norm": 3.3394083976745605,
                "spectral_norm": 1.4158365726470947,
                "num_singular_values": 12,
                "alpha": 1.7506498063663647
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.008009197190403938,
                "median": 0.005432266741991043,
                "std": 0.10699797421693802,
                "max": 0.248985156416893,
                "min": -0.24455340206623077,
                "frobenius_norm": 3.433513879776001,
                "spectral_norm": 1.2838398218154907,
                "num_singular_values": 32,
                "alpha": 1.1674722620451783
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.003987723961472511,
                "median": 0.00491071492433548,
                "std": 0.10611096024513245,
                "max": 0.2540496289730072,
                "min": -0.2463904470205307,
                "frobenius_norm": 3.3979475498199463,
                "spectral_norm": 1.265704870223999,
                "num_singular_values": 32,
                "alpha": 1.1569748501721517
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.023273106664419174,
                "median": 0.027165716513991356,
                "std": 0.10520115494728088,
                "max": 0.22956013679504395,
                "min": -0.1734638661146164,
                "frobenius_norm": 1.7239152193069458,
                "spectral_norm": 0.9369133114814758,
                "num_singular_values": 8,
                "alpha": 1.8497391073036065
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_5e-05_batch_size_128_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 128,
            "scaler_type": "robust",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07559133321046829,
            "mse": 534609280.0,
            "mae": 2048.2216796875,
            "r2_score": 0.8845170140266418,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.00932325515896082,
                "median": 0.003180708270519972,
                "std": 0.16897860169410706,
                "max": 0.3583158552646637,
                "min": -0.2926730513572693,
                "frobenius_norm": 3.3163270950317383,
                "spectral_norm": 1.4087440967559814,
                "num_singular_values": 12,
                "alpha": 1.7137269271977744
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.009518035687506199,
                "median": 0.008882874622941017,
                "std": 0.10671201348304749,
                "max": 0.2442215383052826,
                "min": -0.2246551215648651,
                "frobenius_norm": 3.4283409118652344,
                "spectral_norm": 1.3413289785385132,
                "num_singular_values": 32,
                "alpha": 1.1810826237849115
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.008876610547304153,
                "median": 0.01078360341489315,
                "std": 0.10509344935417175,
                "max": 0.24172425270080566,
                "min": -0.21859361231327057,
                "frobenius_norm": 3.374964952468872,
                "spectral_norm": 1.2996721267700195,
                "num_singular_values": 32,
                "alpha": 1.089158007664346
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.025067169219255447,
                "median": 0.026364360004663467,
                "std": 0.10513544082641602,
                "max": 0.23986056447029114,
                "min": -0.18215744197368622,
                "frobenius_norm": 1.7293198108673096,
                "spectral_norm": 0.9212555885314941,
                "num_singular_values": 8,
                "alpha": 1.8778176772832733
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_5e-05_batch_size_128_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 128,
            "scaler_type": "minmax",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.08160240948200226,
            "mse": 579866048.0,
            "mae": 2255.662109375,
            "r2_score": 0.8747409582138062,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.024570221081376076,
                "median": 0.01905784010887146,
                "std": 0.16891829669475555,
                "max": 0.3475889265537262,
                "min": -0.2855204939842224,
                "frobenius_norm": 3.344942569732666,
                "spectral_norm": 1.445748209953308,
                "num_singular_values": 12,
                "alpha": 1.7228485822884825
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.012015135027468204,
                "median": 0.008697325363755226,
                "std": 0.10720723122358322,
                "max": 0.24514929950237274,
                "min": -0.1958998143672943,
                "frobenius_norm": 3.4521095752716064,
                "spectral_norm": 1.4758645296096802,
                "num_singular_values": 32,
                "alpha": 1.0569754251479888
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.009187361225485802,
                "median": 0.011618289165198803,
                "std": 0.10378389060497284,
                "max": 0.25153282284736633,
                "min": -0.20323607325553894,
                "frobenius_norm": 3.3340721130371094,
                "spectral_norm": 1.228548526763916,
                "num_singular_values": 32,
                "alpha": 1.1532220916028457
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.026219526305794716,
                "median": 0.027136050164699554,
                "std": 0.10371802747249603,
                "max": 0.21865905821323395,
                "min": -0.17390087246894836,
                "frobenius_norm": 1.7116929292678833,
                "spectral_norm": 0.9094451665878296,
                "num_singular_values": 8,
                "alpha": 1.8405242262853316
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_5e-05_batch_size_256_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 256,
            "scaler_type": "identity",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.08176134526729584,
            "mse": 495133600.0,
            "mae": 2023.83837890625,
            "r2_score": 0.8930442929267883,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.030902452766895294,
                "median": 0.019701451063156128,
                "std": 0.16697026789188385,
                "max": 0.3334621489048004,
                "min": -0.30607855319976807,
                "frobenius_norm": 3.3275017738342285,
                "spectral_norm": 1.4213992357254028,
                "num_singular_values": 12,
                "alpha": 1.7246025804935874
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.012044480070471764,
                "median": 0.008539726957678795,
                "std": 0.10797443985939026,
                "max": 0.23863117396831512,
                "min": -0.20568042993545532,
                "frobenius_norm": 3.4766123294830322,
                "spectral_norm": 1.4582058191299438,
                "num_singular_values": 32,
                "alpha": 1.1339945646586334
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.01465131901204586,
                "median": 0.01481443177908659,
                "std": 0.10514869540929794,
                "max": 0.23788227140903473,
                "min": -0.18476350605487823,
                "frobenius_norm": 3.3972651958465576,
                "spectral_norm": 1.3566590547561646,
                "num_singular_values": 32,
                "alpha": 1.1611464850816913
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.03337240591645241,
                "median": 0.034067634493112564,
                "std": 0.10501375049352646,
                "max": 0.2463430017232895,
                "min": -0.17076626420021057,
                "frobenius_norm": 1.7630231380462646,
                "spectral_norm": 0.9096886515617371,
                "num_singular_values": 8,
                "alpha": 1.829585551113514
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_5e-05_batch_size_256_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 256,
            "scaler_type": "standard",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07646947354078293,
            "mse": 516989408.0,
            "mae": 2070.4931640625,
            "r2_score": 0.888323187828064,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.007610740605741739,
                "median": -0.0034913744311779737,
                "std": 0.17020505666732788,
                "max": 0.3599279820919037,
                "min": -0.3212810158729553,
                "frobenius_norm": 3.3386569023132324,
                "spectral_norm": 1.4148942232131958,
                "num_singular_values": 12,
                "alpha": 1.7378428425758619
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.008224289864301682,
                "median": 0.006019819527864456,
                "std": 0.10711362212896347,
                "max": 0.24897080659866333,
                "min": -0.24506156146526337,
                "frobenius_norm": 3.4377243518829346,
                "spectral_norm": 1.2888895273208618,
                "num_singular_values": 32,
                "alpha": 1.1622074796112822
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.004211874678730965,
                "median": 0.0038000186905264854,
                "std": 0.1060599684715271,
                "max": 0.25289803743362427,
                "min": -0.24687331914901733,
                "frobenius_norm": 3.3965940475463867,
                "spectral_norm": 1.2645686864852905,
                "num_singular_values": 32,
                "alpha": 1.1483525971982125
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.02291187085211277,
                "median": 0.02468702383339405,
                "std": 0.10520555078983307,
                "max": 0.22833578288555145,
                "min": -0.17378804087638855,
                "frobenius_norm": 1.7227447032928467,
                "spectral_norm": 0.9363905787467957,
                "num_singular_values": 8,
                "alpha": 1.852804852265502
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_5e-05_batch_size_256_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 256,
            "scaler_type": "robust",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.07554403692483902,
            "mse": 538039488.0,
            "mae": 2053.832763671875,
            "r2_score": 0.883776068687439,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.009382815100252628,
                "median": 0.0014737468445673585,
                "std": 0.1694028079509735,
                "max": 0.3588118255138397,
                "min": -0.2950496971607208,
                "frobenius_norm": 3.3246917724609375,
                "spectral_norm": 1.408321738243103,
                "num_singular_values": 12,
                "alpha": 1.7188184243913112
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.009800514206290245,
                "median": 0.009411324746906757,
                "std": 0.10640592128038406,
                "max": 0.2454596757888794,
                "min": -0.22547712922096252,
                "frobenius_norm": 3.4194021224975586,
                "spectral_norm": 1.3390729427337646,
                "num_singular_values": 32,
                "alpha": 1.1709936816388438
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.00948207825422287,
                "median": 0.01116954255849123,
                "std": 0.10519840568304062,
                "max": 0.2415120005607605,
                "min": -0.22027139365673065,
                "frobenius_norm": 3.3799960613250732,
                "spectral_norm": 1.3183614015579224,
                "num_singular_values": 32,
                "alpha": 1.0926109004966487
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.02582748979330063,
                "median": 0.02713148482143879,
                "std": 0.10514915734529495,
                "max": 0.24043753743171692,
                "min": -0.17728006839752197,
                "frobenius_norm": 1.7323945760726929,
                "spectral_norm": 0.9257922768592834,
                "num_singular_values": 8,
                "alpha": 1.874662404388025
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_32_learning_rate_5e-05_batch_size_256_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 32,
            "max_steps": 1000,
            "learning_rate": 5e-05,
            "batch_size": 256,
            "scaler_type": "minmax",
            "total_params": 2792
        },
        "scores": {
            "smape": 0.0818016529083252,
            "mse": 582513152.0,
            "mae": 2256.92578125,
            "r2_score": 0.874169111251831,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    32,
                    12
                ],
                "input_size": 12,
                "output_size": 32,
                "mean": 0.02390623651444912,
                "median": 0.01808146759867668,
                "std": 0.16921120882034302,
                "max": 0.34755218029022217,
                "min": -0.28792813420295715,
                "frobenius_norm": 3.348778009414673,
                "spectral_norm": 1.4514166116714478,
                "num_singular_values": 12,
                "alpha": 1.729286353034694
            },
            "mlp.1.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.011464019306004047,
                "median": 0.008171300403773785,
                "std": 0.10727498680353165,
                "max": 0.2450987696647644,
                "min": -0.19345484673976898,
                "frobenius_norm": 3.452345609664917,
                "spectral_norm": 1.4723297357559204,
                "num_singular_values": 32,
                "alpha": 1.0866130167067625
            },
            "mlp.2.weight": {
                "shape": [
                    32,
                    32
                ],
                "input_size": 32,
                "output_size": 32,
                "mean": 0.009269301779568195,
                "median": 0.01165790855884552,
                "std": 0.10413305461406708,
                "max": 0.2525709867477417,
                "min": -0.20551398396492004,
                "frobenius_norm": 3.345433235168457,
                "spectral_norm": 1.2321655750274658,
                "num_singular_values": 32,
                "alpha": 1.163118204677381
            },
            "out.weight": {
                "shape": [
                    8,
                    32
                ],
                "input_size": 32,
                "output_size": 8,
                "mean": 0.026045512408018112,
                "median": 0.026762153953313828,
                "std": 0.10349791496992111,
                "max": 0.2181866466999054,
                "min": -0.17372757196426392,
                "frobenius_norm": 1.7075971364974976,
                "spectral_norm": 0.9008610248565674,
                "num_singular_values": 8,
                "alpha": 1.8310425663216794
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.01_batch_size_16_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.08556389808654785,
            "mse": 509459808.0,
            "mae": 2120.63525390625,
            "r2_score": 0.8899496793746948,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": -0.07251113653182983,
                "median": -0.06847204267978668,
                "std": 0.21126298606395721,
                "max": 0.7520233392715454,
                "min": -1.0901310443878174,
                "frobenius_norm": 6.189947605133057,
                "spectral_norm": 3.1281003952026367,
                "num_singular_values": 12,
                "alpha": 1.9194448260501873
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.025567781180143356,
                "median": -0.02612481638789177,
                "std": 0.20685915648937225,
                "max": 3.1400773525238037,
                "min": -3.318877696990967,
                "frobenius_norm": 13.339729309082031,
                "spectral_norm": 9.151601791381836,
                "num_singular_values": 64,
                "alpha": 1.1135390021528753
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.026696735993027687,
                "median": -0.02120892144739628,
                "std": 0.11840719729661942,
                "max": 1.200592279434204,
                "min": -1.3314203023910522,
                "frobenius_norm": 7.768287181854248,
                "spectral_norm": 3.718981981277466,
                "num_singular_values": 64,
                "alpha": 1.1100367474173516
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.021386321634054184,
                "median": 0.023532863706350327,
                "std": 0.11151070892810822,
                "max": 0.4466964900493622,
                "min": -0.6211392283439636,
                "frobenius_norm": 2.5691847801208496,
                "spectral_norm": 1.7802791595458984,
                "num_singular_values": 8,
                "alpha": 1.9491473753473296
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.01_batch_size_16_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.0685311034321785,
            "mse": 339569632.0,
            "mae": 1816.4444580078125,
            "r2_score": 0.9266482591629028,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.08726373314857483,
                "median": 0.09230425953865051,
                "std": 0.25452104210853577,
                "max": 0.865990936756134,
                "min": -0.816632091999054,
                "frobenius_norm": 7.456545352935791,
                "spectral_norm": 3.6739213466644287,
                "num_singular_values": 12,
                "alpha": 1.8043795681726613
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.07795187085866928,
                "median": -0.07537932693958282,
                "std": 0.2525930106639862,
                "max": 1.333590030670166,
                "min": -1.8564907312393188,
                "frobenius_norm": 16.918254852294922,
                "spectral_norm": 7.767502307891846,
                "num_singular_values": 64,
                "alpha": 1.1247534656133755
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.07314404845237732,
                "median": -0.0750037431716919,
                "std": 0.22048206627368927,
                "max": 2.1300225257873535,
                "min": -1.42827570438385,
                "frobenius_norm": 14.86707592010498,
                "spectral_norm": 6.699919700622559,
                "num_singular_values": 64,
                "alpha": 1.1595038337938197
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.00303583568893373,
                "median": 0.0020271234679967165,
                "std": 0.16477887332439423,
                "max": 0.49465399980545044,
                "min": -0.5858345627784729,
                "frobenius_norm": 3.7291529178619385,
                "spectral_norm": 2.047898292541504,
                "num_singular_values": 8,
                "alpha": 1.9005914242119935
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.01_batch_size_16_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.06797860562801361,
            "mse": 469327296.0,
            "mae": 1932.45263671875,
            "r2_score": 0.8986188173294067,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.07505957037210464,
                "median": 0.06609049439430237,
                "std": 0.2602703869342804,
                "max": 1.0635274648666382,
                "min": -0.9560741782188416,
                "frobenius_norm": 7.506777286529541,
                "spectral_norm": 3.3516201972961426,
                "num_singular_values": 12,
                "alpha": 1.90837983482174
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.0837242603302002,
                "median": -0.0755368173122406,
                "std": 0.2609747648239136,
                "max": 1.373923897743225,
                "min": -1.4770900011062622,
                "frobenius_norm": 17.540855407714844,
                "spectral_norm": 7.773547649383545,
                "num_singular_values": 64,
                "alpha": 1.0480648492137923
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.055588316172361374,
                "median": -0.053461216390132904,
                "std": 0.22066350281238556,
                "max": 1.5262507200241089,
                "min": -1.2013264894485474,
                "frobenius_norm": 14.563682556152344,
                "spectral_norm": 5.696827411651611,
                "num_singular_values": 64,
                "alpha": 1.1203219068011991
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.013876898214221,
                "median": 0.022856801748275757,
                "std": 0.14161552488803864,
                "max": 0.47695741057395935,
                "min": -0.47318241000175476,
                "frobenius_norm": 3.219741106033325,
                "spectral_norm": 2.1935245990753174,
                "num_singular_values": 8,
                "alpha": 1.7893887296769764
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.01_batch_size_16_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.07255399972200394,
            "mse": 508225504.0,
            "mae": 2049.873291015625,
            "r2_score": 0.8902162909507751,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.035157445818185806,
                "median": 0.04071066528558731,
                "std": 0.24724078178405762,
                "max": 1.1397987604141235,
                "min": -2.043210506439209,
                "frobenius_norm": 6.920664310455322,
                "spectral_norm": 4.2310404777526855,
                "num_singular_values": 12,
                "alpha": 1.8446988205473573
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.06955400109291077,
                "median": -0.06112629547715187,
                "std": 0.20497910678386688,
                "max": 1.4659503698349,
                "min": -1.8901201486587524,
                "frobenius_norm": 13.853330612182617,
                "spectral_norm": 7.786900997161865,
                "num_singular_values": 64,
                "alpha": 1.0873560609784798
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.04415660724043846,
                "median": -0.04533619433641434,
                "std": 0.14333514869213104,
                "max": 1.3806980848312378,
                "min": -0.8476641774177551,
                "frobenius_norm": 9.598884582519531,
                "spectral_norm": 4.271536827087402,
                "num_singular_values": 64,
                "alpha": 1.1130292405446103
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": -0.012248460203409195,
                "median": -0.014688537456095219,
                "std": 0.14013536274433136,
                "max": 0.449395090341568,
                "min": -0.39637935161590576,
                "frobenius_norm": 3.182990312576294,
                "spectral_norm": 1.7071501016616821,
                "num_singular_values": 8,
                "alpha": 1.6311537730460661
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.01_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.08399243652820587,
            "mse": 488396800.0,
            "mae": 2127.120361328125,
            "r2_score": 0.8944995403289795,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": -0.0732756182551384,
                "median": -0.07299748063087463,
                "std": 0.21248823404312134,
                "max": 0.6681888699531555,
                "min": -1.7623474597930908,
                "frobenius_norm": 6.22894811630249,
                "spectral_norm": 3.1679840087890625,
                "num_singular_values": 12,
                "alpha": 1.9744042523374778
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.0034882305189967155,
                "median": -0.015026094391942024,
                "std": 0.19455572962760925,
                "max": 2.8066811561584473,
                "min": -2.4146416187286377,
                "frobenius_norm": 12.453567504882812,
                "spectral_norm": 7.858081340789795,
                "num_singular_values": 64,
                "alpha": 1.0851185615966648
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.021786104887723923,
                "median": -0.018650047481060028,
                "std": 0.10323809087276459,
                "max": 0.6545761227607727,
                "min": -0.9748408794403076,
                "frobenius_norm": 6.752755165100098,
                "spectral_norm": 3.211570978164673,
                "num_singular_values": 64,
                "alpha": 1.070734558229858
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.04006486013531685,
                "median": 0.040198735892772675,
                "std": 0.07684452831745148,
                "max": 0.2613985538482666,
                "min": -0.187614306807518,
                "frobenius_norm": 1.9609335660934448,
                "spectral_norm": 1.3367226123809814,
                "num_singular_values": 8,
                "alpha": 2.384134513164664
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.01_batch_size_32_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.06786027550697327,
            "mse": 326067392.0,
            "mae": 1843.8621826171875,
            "r2_score": 0.9295649528503418,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.07675477862358093,
                "median": 0.06298251450061798,
                "std": 0.261619508266449,
                "max": 0.8519147634506226,
                "min": -1.1718416213989258,
                "frobenius_norm": 7.5557990074157715,
                "spectral_norm": 3.4195873737335205,
                "num_singular_values": 12,
                "alpha": 2.042325117167169
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.0640484094619751,
                "median": -0.05750492215156555,
                "std": 0.23133987188339233,
                "max": 0.8905841708183289,
                "min": -2.0540740489959717,
                "frobenius_norm": 15.362710952758789,
                "spectral_norm": 7.173504829406738,
                "num_singular_values": 64,
                "alpha": 1.081438547713778
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.027672508731484413,
                "median": -0.031240932643413544,
                "std": 0.1922459751367569,
                "max": 1.217523455619812,
                "min": -1.4486947059631348,
                "frobenius_norm": 12.430554389953613,
                "spectral_norm": 4.847638130187988,
                "num_singular_values": 64,
                "alpha": 1.082096121724661
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": -0.024028252810239792,
                "median": -0.013547176495194435,
                "std": 0.12264596670866013,
                "max": 0.3407834768295288,
                "min": -0.7148454189300537,
                "frobenius_norm": 2.8279192447662354,
                "spectral_norm": 1.8524367809295654,
                "num_singular_values": 8,
                "alpha": 2.015673492296625
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.01_batch_size_32_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.06929566711187363,
            "mse": 584250752.0,
            "mae": 2059.09814453125,
            "r2_score": 0.8737937808036804,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.05959281325340271,
                "median": 0.051730237901210785,
                "std": 0.2701832056045532,
                "max": 1.4084815979003906,
                "min": -1.3531019687652588,
                "frobenius_norm": 7.667503356933594,
                "spectral_norm": 4.0211405754089355,
                "num_singular_values": 12,
                "alpha": 2.0864697273098054
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.08659379929304123,
                "median": -0.07281821221113205,
                "std": 0.25373148918151855,
                "max": 1.4828873872756958,
                "min": -2.080500602722168,
                "frobenius_norm": 17.158464431762695,
                "spectral_norm": 8.468184471130371,
                "num_singular_values": 64,
                "alpha": 1.1244775914871068
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.05353119596838951,
                "median": -0.051764409989118576,
                "std": 0.2210051417350769,
                "max": 1.225084900856018,
                "min": -1.3696541786193848,
                "frobenius_norm": 14.553333282470703,
                "spectral_norm": 5.929762840270996,
                "num_singular_values": 64,
                "alpha": 1.1158025941004277
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": -0.008279116824269295,
                "median": -0.003752979915589094,
                "std": 0.1347605586051941,
                "max": 0.597091555595398,
                "min": -0.39116308093070984,
                "frobenius_norm": 3.05503249168396,
                "spectral_norm": 1.6031619310379028,
                "num_singular_values": 8,
                "alpha": 1.836283570199123
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.01_batch_size_32_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.07237878441810608,
            "mse": 391280352.0,
            "mae": 1943.666748046875,
            "r2_score": 0.9154780507087708,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.03544526919722557,
                "median": 0.03557107225060463,
                "std": 0.253292977809906,
                "max": 1.0699056386947632,
                "min": -1.9641879796981812,
                "frobenius_norm": 7.087856769561768,
                "spectral_norm": 4.926001071929932,
                "num_singular_values": 12,
                "alpha": 2.0385696069614774
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.08067589998245239,
                "median": -0.07117012143135071,
                "std": 0.18771250545978546,
                "max": 1.1887781620025635,
                "min": -1.7373491525650024,
                "frobenius_norm": 13.076155662536621,
                "spectral_norm": 7.0320210456848145,
                "num_singular_values": 64,
                "alpha": 1.1386758372441221
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.05168775096535683,
                "median": -0.049678292125463486,
                "std": 0.19048982858657837,
                "max": 3.345803737640381,
                "min": -1.3472803831100464,
                "frobenius_norm": 12.632179260253906,
                "spectral_norm": 7.351076602935791,
                "num_singular_values": 64,
                "alpha": 1.0900189217043752
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.01243574358522892,
                "median": 0.010320987552404404,
                "std": 0.13514572381973267,
                "max": 0.6589173078536987,
                "min": -0.4640049636363983,
                "frobenius_norm": 3.070917844772339,
                "spectral_norm": 1.9568854570388794,
                "num_singular_values": 8,
                "alpha": 1.9607777391031274
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.01_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.0827064961194992,
            "mse": 470786944.0,
            "mae": 2078.651123046875,
            "r2_score": 0.8983035087585449,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": -0.0773162767291069,
                "median": -0.06845417618751526,
                "std": 0.24087446928024292,
                "max": 0.6786527633666992,
                "min": -1.6968145370483398,
                "frobenius_norm": 7.010756492614746,
                "spectral_norm": 4.151368618011475,
                "num_singular_values": 12,
                "alpha": 1.9022745712080962
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.014301520772278309,
                "median": -0.01874431222677231,
                "std": 0.16701892018318176,
                "max": 2.5470523834228516,
                "min": -2.2428336143493652,
                "frobenius_norm": 10.728326797485352,
                "spectral_norm": 4.993172645568848,
                "num_singular_values": 64,
                "alpha": 1.0950785385251656
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.015416285954415798,
                "median": -0.015188857913017273,
                "std": 0.11023188382387161,
                "max": 1.0341931581497192,
                "min": -1.7916643619537354,
                "frobenius_norm": 7.123498916625977,
                "spectral_norm": 2.8979859352111816,
                "num_singular_values": 64,
                "alpha": 1.1193459025007524
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.038826845586299896,
                "median": 0.03919192776083946,
                "std": 0.0861043781042099,
                "max": 0.308640718460083,
                "min": -0.23940087854862213,
                "frobenius_norm": 2.1372416019439697,
                "spectral_norm": 1.3085170984268188,
                "num_singular_values": 8,
                "alpha": 2.014428003342096
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.01_batch_size_64_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 64,
            "scaler_type": "standard",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.06761261820793152,
            "mse": 325862656.0,
            "mae": 1823.6229248046875,
            "r2_score": 0.9296091794967651,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.08863136172294617,
                "median": 0.07539065182209015,
                "std": 0.2522512376308441,
                "max": 0.9235408306121826,
                "min": -0.940150260925293,
                "frobenius_norm": 7.409548759460449,
                "spectral_norm": 3.518000364303589,
                "num_singular_values": 12,
                "alpha": 1.9073072075556174
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.056081049144268036,
                "median": -0.057169198989868164,
                "std": 0.27059346437454224,
                "max": 1.3270584344863892,
                "min": -2.893740653991699,
                "frobenius_norm": 17.686004638671875,
                "spectral_norm": 7.434355735778809,
                "num_singular_values": 64,
                "alpha": 1.0891765608948445
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.029384423047304153,
                "median": -0.034684665501117706,
                "std": 0.25445443391799927,
                "max": 4.699181079864502,
                "min": -1.6330599784851074,
                "frobenius_norm": 16.393310546875,
                "spectral_norm": 9.65238094329834,
                "num_singular_values": 64,
                "alpha": 1.1546721841236491
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": -0.01853884756565094,
                "median": -0.00878112856298685,
                "std": 0.09530754387378693,
                "max": 0.44518259167671204,
                "min": -0.3606286346912384,
                "frobenius_norm": 2.1969833374023438,
                "spectral_norm": 1.3898793458938599,
                "num_singular_values": 8,
                "alpha": 2.055248318118223
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.01_batch_size_64_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 64,
            "scaler_type": "robust",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.0677872747182846,
            "mse": 399182976.0,
            "mae": 1836.5908203125,
            "r2_score": 0.9137709736824036,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.039669569581747055,
                "median": 0.03626933693885803,
                "std": 0.2945961356163025,
                "max": 1.127270221710205,
                "min": -1.4037818908691406,
                "frobenius_norm": 8.237773895263672,
                "spectral_norm": 4.295548915863037,
                "num_singular_values": 12,
                "alpha": 1.853937600466506
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.0844927579164505,
                "median": -0.06466612964868546,
                "std": 0.28734666109085083,
                "max": 1.9173130989074707,
                "min": -2.0262155532836914,
                "frobenius_norm": 19.16873550415039,
                "spectral_norm": 10.112212181091309,
                "num_singular_values": 64,
                "alpha": 1.096568541495359
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.06600520014762878,
                "median": -0.057788290083408356,
                "std": 0.21609731018543243,
                "max": 1.4033325910568237,
                "min": -1.331299901008606,
                "frobenius_norm": 14.46098804473877,
                "spectral_norm": 6.9101033210754395,
                "num_singular_values": 64,
                "alpha": 1.127462578128818
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.0029248513747006655,
                "median": -0.003754951758310199,
                "std": 0.13906405866146088,
                "max": 0.4128151535987854,
                "min": -0.759365975856781,
                "frobenius_norm": 3.1473565101623535,
                "spectral_norm": 1.9641132354736328,
                "num_singular_values": 8,
                "alpha": 2.1135969720936187
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.01_batch_size_64_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 64,
            "scaler_type": "minmax",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.0696241706609726,
            "mse": 354518208.0,
            "mae": 1903.2896728515625,
            "r2_score": 0.923419177532196,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.030288226902484894,
                "median": 0.039550136774778366,
                "std": 0.3378254473209381,
                "max": 1.274512529373169,
                "min": -4.080746650695801,
                "frobenius_norm": 9.399645805358887,
                "spectral_norm": 7.170290946960449,
                "num_singular_values": 12,
                "alpha": 1.743031124732778
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.049334198236465454,
                "median": -0.04615213721990585,
                "std": 0.20861175656318665,
                "max": 1.5922956466674805,
                "min": -2.2721621990203857,
                "frobenius_norm": 13.719416618347168,
                "spectral_norm": 6.521712303161621,
                "num_singular_values": 64,
                "alpha": 1.1357828136790793
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.032227013260126114,
                "median": -0.02915715053677559,
                "std": 0.13912302255630493,
                "max": 1.3050156831741333,
                "min": -0.9973065853118896,
                "frobenius_norm": 9.13963794708252,
                "spectral_norm": 4.2299065589904785,
                "num_singular_values": 64,
                "alpha": 1.117375402258328
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": -0.006753179244697094,
                "median": -0.0020183671731501818,
                "std": 0.10521301627159119,
                "max": 0.3775937855243683,
                "min": -0.4631233811378479,
                "frobenius_norm": 2.3855977058410645,
                "spectral_norm": 1.4683648347854614,
                "num_singular_values": 8,
                "alpha": 1.889108496924358
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.01_batch_size_128_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 128,
            "scaler_type": "identity",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.08020705729722977,
            "mse": 476365952.0,
            "mae": 1979.4395751953125,
            "r2_score": 0.8970984220504761,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": -0.07102787494659424,
                "median": -0.062437549233436584,
                "std": 0.22566379606723785,
                "max": 0.8131998181343079,
                "min": -1.4617924690246582,
                "frobenius_norm": 6.556239604949951,
                "spectral_norm": 3.1720447540283203,
                "num_singular_values": 12,
                "alpha": 1.8444072599828893
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.016192726790905,
                "median": -0.022305021062493324,
                "std": 0.19423043727874756,
                "max": 3.5884931087493896,
                "min": -3.3337132930755615,
                "frobenius_norm": 12.473872184753418,
                "spectral_norm": 7.001077175140381,
                "num_singular_values": 64,
                "alpha": 1.1171746085708703
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.01609707996249199,
                "median": -0.015953687950968742,
                "std": 0.10203103721141815,
                "max": 0.7500133514404297,
                "min": -1.5547963380813599,
                "frobenius_norm": 6.610753059387207,
                "spectral_norm": 2.816851854324341,
                "num_singular_values": 64,
                "alpha": 1.128421957798329
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.040928348898887634,
                "median": 0.04105763882398605,
                "std": 0.084318608045578,
                "max": 0.24493223428726196,
                "min": -0.26559028029441833,
                "frobenius_norm": 2.120800733566284,
                "spectral_norm": 1.3248627185821533,
                "num_singular_values": 8,
                "alpha": 2.4363516352632146
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.01_batch_size_128_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 128,
            "scaler_type": "standard",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.07603015005588531,
            "mse": 536804320.0,
            "mae": 2225.29443359375,
            "r2_score": 0.8840428590774536,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.10644450038671494,
                "median": 0.11145266890525818,
                "std": 0.2719018757343292,
                "max": 1.7447525262832642,
                "min": -2.0746490955352783,
                "frobenius_norm": 8.092001914978027,
                "spectral_norm": 4.373355388641357,
                "num_singular_values": 12,
                "alpha": 1.894567552151654
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.05785131826996803,
                "median": -0.053331587463617325,
                "std": 0.26098281145095825,
                "max": 1.0353904962539673,
                "min": -2.1765425205230713,
                "frobenius_norm": 17.108339309692383,
                "spectral_norm": 7.464005947113037,
                "num_singular_values": 64,
                "alpha": 1.1139170589804481
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.031157106161117554,
                "median": -0.024362921714782715,
                "std": 0.24522940814495087,
                "max": 2.2291195392608643,
                "min": -1.7589553594589233,
                "frobenius_norm": 15.820850372314453,
                "spectral_norm": 6.938660621643066,
                "num_singular_values": 64,
                "alpha": 1.1239150766075399
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": -0.02461327239871025,
                "median": -0.024733686819672585,
                "std": 0.13733869791030884,
                "max": 0.7877752780914307,
                "min": -0.5130104422569275,
                "frobenius_norm": 3.1571311950683594,
                "spectral_norm": 2.31441330909729,
                "num_singular_values": 8,
                "alpha": 1.90557724517858
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.01_batch_size_128_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 128,
            "scaler_type": "robust",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.0685570240020752,
            "mse": 388293600.0,
            "mae": 1861.1324462890625,
            "r2_score": 0.9161232113838196,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.06469136476516724,
                "median": 0.05613935738801956,
                "std": 0.3046310544013977,
                "max": 1.6835461854934692,
                "min": -1.531363606452942,
                "frobenius_norm": 8.630441665649414,
                "spectral_norm": 4.765081882476807,
                "num_singular_values": 12,
                "alpha": 1.8468408239439094
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.08842936158180237,
                "median": -0.07943975925445557,
                "std": 0.29077163338661194,
                "max": 1.3048546314239502,
                "min": -2.009748935699463,
                "frobenius_norm": 19.450937271118164,
                "spectral_norm": 8.948105812072754,
                "num_singular_values": 64,
                "alpha": 1.079400134685443
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.04668226093053818,
                "median": -0.04348739609122276,
                "std": 0.21603383123874664,
                "max": 1.2128576040267944,
                "min": -1.0714008808135986,
                "frobenius_norm": 14.145280838012695,
                "spectral_norm": 5.683093547821045,
                "num_singular_values": 64,
                "alpha": 1.1027276953296354
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": -0.01046229898929596,
                "median": -0.0062832217663526535,
                "std": 0.13154901564121246,
                "max": 0.4337223768234253,
                "min": -0.3692649006843567,
                "frobenius_norm": 2.986013174057007,
                "spectral_norm": 1.6231043338775635,
                "num_singular_values": 8,
                "alpha": 2.1876710409432736
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.01_batch_size_128_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 128,
            "scaler_type": "minmax",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.0961865559220314,
            "mse": 385718816.0,
            "mae": 2236.22705078125,
            "r2_score": 0.9166794419288635,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.05951125919818878,
                "median": 0.06506340205669403,
                "std": 0.3165140748023987,
                "max": 1.0728849172592163,
                "min": -2.678013324737549,
                "frobenius_norm": 8.925193786621094,
                "spectral_norm": 6.175459861755371,
                "num_singular_values": 12,
                "alpha": 1.7751316229170757
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.0709807500243187,
                "median": -0.062452755868434906,
                "std": 0.24479873478412628,
                "max": 1.6358016729354858,
                "min": -2.394421339035034,
                "frobenius_norm": 16.31243133544922,
                "spectral_norm": 7.964146614074707,
                "num_singular_values": 64,
                "alpha": 1.1068486278707228
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.025551117956638336,
                "median": -0.031468406319618225,
                "std": 0.20647181570529938,
                "max": 3.3756134510040283,
                "min": -2.3992373943328857,
                "frobenius_norm": 13.314994812011719,
                "spectral_norm": 5.9841694831848145,
                "num_singular_values": 64,
                "alpha": 1.1389762915501087
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": -0.022315755486488342,
                "median": -0.025548240169882774,
                "std": 0.11490978300571442,
                "max": 0.4468814730644226,
                "min": -0.375018835067749,
                "frobenius_norm": 2.648688793182373,
                "spectral_norm": 1.664898157119751,
                "num_singular_values": 8,
                "alpha": 1.9251918082731385
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.01_batch_size_256_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 256,
            "scaler_type": "identity",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.08825647085905075,
            "mse": 474256352.0,
            "mae": 2167.1171875,
            "r2_score": 0.8975540995597839,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": -0.06283550709486008,
                "median": -0.05449211597442627,
                "std": 0.23462443053722382,
                "max": 0.6913267970085144,
                "min": -1.8486154079437256,
                "frobenius_norm": 6.73124361038208,
                "spectral_norm": 3.2043416500091553,
                "num_singular_values": 12,
                "alpha": 1.9660554184450287
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.019761506468057632,
                "median": -0.02186085842549801,
                "std": 0.22296161949634552,
                "max": 4.793823719024658,
                "min": -3.7465062141418457,
                "frobenius_norm": 14.325482368469238,
                "spectral_norm": 7.452963352203369,
                "num_singular_values": 64,
                "alpha": 1.1020255885689603
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.012741969898343086,
                "median": -0.013095559552311897,
                "std": 0.10431403666734695,
                "max": 0.6797435283660889,
                "min": -0.9243107438087463,
                "frobenius_norm": 6.725719928741455,
                "spectral_norm": 2.59683895111084,
                "num_singular_values": 64,
                "alpha": 1.104092040630407
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.03987386077642441,
                "median": 0.03957069665193558,
                "std": 0.09138786792755127,
                "max": 0.3674047887325287,
                "min": -0.5568601489067078,
                "frobenius_norm": 2.2561323642730713,
                "spectral_norm": 1.2823469638824463,
                "num_singular_values": 8,
                "alpha": 2.039380623317794
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.01_batch_size_256_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 256,
            "scaler_type": "standard",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.06802832335233688,
            "mse": 379634464.0,
            "mae": 1928.7666015625,
            "r2_score": 0.9179937243461609,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.058036383241415024,
                "median": 0.05649968236684799,
                "std": 0.27408894896507263,
                "max": 0.9278078675270081,
                "min": -1.5388587713241577,
                "frobenius_norm": 7.764186859130859,
                "spectral_norm": 3.9333767890930176,
                "num_singular_values": 12,
                "alpha": 1.904630824064773
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.05335654318332672,
                "median": -0.05457548797130585,
                "std": 0.2284485548734665,
                "max": 1.097594976425171,
                "min": -1.469393014907837,
                "frobenius_norm": 15.01419448852539,
                "spectral_norm": 5.867614269256592,
                "num_singular_values": 64,
                "alpha": 1.1534386191892239
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.024797111749649048,
                "median": -0.025445662438869476,
                "std": 0.18251028656959534,
                "max": 1.0477434396743774,
                "min": -1.5675737857818604,
                "frobenius_norm": 11.78797721862793,
                "spectral_norm": 4.627861976623535,
                "num_singular_values": 64,
                "alpha": 1.106758077969461
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.0005308385007083416,
                "median": 5.128281190991402e-05,
                "std": 0.12580738961696625,
                "max": 0.5015751123428345,
                "min": -0.5486704707145691,
                "frobenius_norm": 2.846721649169922,
                "spectral_norm": 1.5758392810821533,
                "num_singular_values": 8,
                "alpha": 2.039052200844199
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.01_batch_size_256_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 256,
            "scaler_type": "robust",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.07223055511713028,
            "mse": 599405440.0,
            "mae": 2102.8193359375,
            "r2_score": 0.8705201745033264,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.0490235798060894,
                "median": 0.04171433299779892,
                "std": 0.2633550465106964,
                "max": 1.2898085117340088,
                "min": -1.7025877237319946,
                "frobenius_norm": 7.42368221282959,
                "spectral_norm": 3.97147274017334,
                "num_singular_values": 12,
                "alpha": 2.020447364653477
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.07782436907291412,
                "median": -0.06551066040992737,
                "std": 0.2612839341163635,
                "max": 1.225903034210205,
                "min": -1.6224098205566406,
                "frobenius_norm": 17.44818115234375,
                "spectral_norm": 8.009407043457031,
                "num_singular_values": 64,
                "alpha": 1.1338849876038646
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.03798586130142212,
                "median": -0.039393868297338486,
                "std": 0.2522243559360504,
                "max": 1.62424635887146,
                "min": -1.6584124565124512,
                "frobenius_norm": 16.324398040771484,
                "spectral_norm": 7.149763107299805,
                "num_singular_values": 64,
                "alpha": 1.1028452581870323
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": -0.04350755363702774,
                "median": -0.032185524702072144,
                "std": 0.14100418984889984,
                "max": 0.37589943408966064,
                "min": -0.4825774133205414,
                "frobenius_norm": 3.3389883041381836,
                "spectral_norm": 2.2099716663360596,
                "num_singular_values": 8,
                "alpha": 1.9331946985269557
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.01_batch_size_256_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.01,
            "batch_size": 256,
            "scaler_type": "minmax",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.07261650264263153,
            "mse": 418444928.0,
            "mae": 2003.3670654296875,
            "r2_score": 0.9096101522445679,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.04810420796275139,
                "median": 0.05043323338031769,
                "std": 0.3473891615867615,
                "max": 1.653112769126892,
                "min": -3.0969042778015137,
                "frobenius_norm": 9.718992233276367,
                "spectral_norm": 7.214559078216553,
                "num_singular_values": 12,
                "alpha": 1.7089731068084022
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.08937956392765045,
                "median": -0.07262381911277771,
                "std": 0.2412586361169815,
                "max": 2.5239479541778564,
                "min": -2.9522430896759033,
                "frobenius_norm": 16.466100692749023,
                "spectral_norm": 8.489606857299805,
                "num_singular_values": 64,
                "alpha": 1.1201968026797557
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.06086015701293945,
                "median": -0.054158248007297516,
                "std": 0.2026267796754837,
                "max": 2.1253414154052734,
                "min": -1.7578301429748535,
                "frobenius_norm": 13.540434837341309,
                "spectral_norm": 6.002732753753662,
                "num_singular_values": 64,
                "alpha": 1.1070491357900372
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": -0.021183637902140617,
                "median": -0.01922018453478813,
                "std": 0.12683114409446716,
                "max": 0.5291759967803955,
                "min": -0.4142441749572754,
                "frobenius_norm": 2.9096152782440186,
                "spectral_norm": 1.9365545511245728,
                "num_singular_values": 8,
                "alpha": 1.9485639235877592
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.005_batch_size_16_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.081085205078125,
            "mse": 408740128.0,
            "mae": 1902.3067626953125,
            "r2_score": 0.9117065072059631,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": -0.037001851946115494,
                "median": -0.03871014714241028,
                "std": 0.19337843358516693,
                "max": 0.3795628249645233,
                "min": -1.048025369644165,
                "frobenius_norm": 5.456283092498779,
                "spectral_norm": 2.4045164585113525,
                "num_singular_values": 12,
                "alpha": 2.0394226572901912
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.006391333416104317,
                "median": -0.007458318490535021,
                "std": 0.14617560803890228,
                "max": 1.2832739353179932,
                "min": -2.583327531814575,
                "frobenius_norm": 9.364176750183105,
                "spectral_norm": 5.160693645477295,
                "num_singular_values": 64,
                "alpha": 1.0749344079421206
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.007622097618877888,
                "median": -0.00610257126390934,
                "std": 0.09090793877840042,
                "max": 0.5981178879737854,
                "min": -0.5265036225318909,
                "frobenius_norm": 5.838522434234619,
                "spectral_norm": 2.388838768005371,
                "num_singular_values": 64,
                "alpha": 1.1278238245684182
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.02363653853535652,
                "median": 0.025415774434804916,
                "std": 0.07930406183004379,
                "max": 0.19719402492046356,
                "min": -0.38659438490867615,
                "frobenius_norm": 1.8724541664123535,
                "spectral_norm": 1.11906099319458,
                "num_singular_values": 8,
                "alpha": 2.375245685131852
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.005_batch_size_16_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.06758623570203781,
            "mse": 352170976.0,
            "mae": 1818.703369140625,
            "r2_score": 0.9239262342453003,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.051078617572784424,
                "median": 0.05021549016237259,
                "std": 0.23655091226100922,
                "max": 0.810595691204071,
                "min": -1.177107572555542,
                "frobenius_norm": 6.706578731536865,
                "spectral_norm": 2.8866729736328125,
                "num_singular_values": 12,
                "alpha": 2.18092236767378
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.028629731386899948,
                "median": -0.02879330702126026,
                "std": 0.18970738351345062,
                "max": 0.9685218930244446,
                "min": -1.1149494647979736,
                "frobenius_norm": 12.278754234313965,
                "spectral_norm": 4.648283958435059,
                "num_singular_values": 64,
                "alpha": 1.092472805870358
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.016537394374608994,
                "median": -0.02005130611360073,
                "std": 0.15689602494239807,
                "max": 0.8606944680213928,
                "min": -0.9753186106681824,
                "frobenius_norm": 10.096970558166504,
                "spectral_norm": 4.216685771942139,
                "num_singular_values": 64,
                "alpha": 1.115700586287863
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.0007908754050731659,
                "median": 0.0017926571890711784,
                "std": 0.09115343540906906,
                "max": 0.3471798598766327,
                "min": -0.2826022207736969,
                "frobenius_norm": 2.0626444816589355,
                "spectral_norm": 1.2393330335617065,
                "num_singular_values": 8,
                "alpha": 2.5950786706358056
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.005_batch_size_16_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.06919754296541214,
            "mse": 444196832.0,
            "mae": 1936.6732177734375,
            "r2_score": 0.9040473699569702,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.03782905265688896,
                "median": 0.024953579530119896,
                "std": 0.24004866182804108,
                "max": 0.9728219509124756,
                "min": -1.0264583826065063,
                "frobenius_norm": 6.73452091217041,
                "spectral_norm": 3.347325563430786,
                "num_singular_values": 12,
                "alpha": 2.038079943101779
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.04033233970403671,
                "median": -0.03508592024445534,
                "std": 0.2073996663093567,
                "max": 0.8797441720962524,
                "min": -1.0762410163879395,
                "frobenius_norm": 13.522234916687012,
                "spectral_norm": 5.550238132476807,
                "num_singular_values": 64,
                "alpha": 1.1487252549587312
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.02567245438694954,
                "median": -0.023826776072382927,
                "std": 0.17298364639282227,
                "max": 0.8793445229530334,
                "min": -0.8249265551567078,
                "frobenius_norm": 11.19221019744873,
                "spectral_norm": 3.883335590362549,
                "num_singular_values": 64,
                "alpha": 1.1011337848762088
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.0042176698334515095,
                "median": 0.003470427356660366,
                "std": 0.10068952292203903,
                "max": 0.33438247442245483,
                "min": -0.4476083517074585,
                "frobenius_norm": 2.280341625213623,
                "spectral_norm": 1.0894684791564941,
                "num_singular_values": 8,
                "alpha": 2.2126788333295457
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.005_batch_size_16_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.07461421936750412,
            "mse": 422118368.0,
            "mae": 1969.509521484375,
            "r2_score": 0.9088166356086731,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.032382309436798096,
                "median": 0.023658132180571556,
                "std": 0.23253808915615082,
                "max": 1.022576093673706,
                "min": -1.403666377067566,
                "frobenius_norm": 6.506468772888184,
                "spectral_norm": 3.766024351119995,
                "num_singular_values": 12,
                "alpha": 1.9927015903661154
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.05114581435918808,
                "median": -0.04277458041906357,
                "std": 0.17703671753406525,
                "max": 1.2588783502578735,
                "min": -1.3482513427734375,
                "frobenius_norm": 11.793707847595215,
                "spectral_norm": 5.71744441986084,
                "num_singular_values": 64,
                "alpha": 1.1717482773023704
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.034134406596422195,
                "median": -0.03485164791345596,
                "std": 0.1373787522315979,
                "max": 0.9050026535987854,
                "min": -0.8294453024864197,
                "frobenius_norm": 9.059577941894531,
                "spectral_norm": 3.508500576019287,
                "num_singular_values": 64,
                "alpha": 1.1385554405865654
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.0048608602955937386,
                "median": 0.005636554677039385,
                "std": 0.0831780806183815,
                "max": 0.29500600695610046,
                "min": -0.23583219945430756,
                "frobenius_norm": 1.8853161334991455,
                "spectral_norm": 1.1325594186782837,
                "num_singular_values": 8,
                "alpha": 2.2248104853268638
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.08012397587299347,
            "mse": 423627648.0,
            "mae": 1918.260986328125,
            "r2_score": 0.9084905982017517,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": -0.044848501682281494,
                "median": -0.044685814529657364,
                "std": 0.2085433006286621,
                "max": 0.5823088884353638,
                "min": -1.2874352931976318,
                "frobenius_norm": 5.9114556312561035,
                "spectral_norm": 2.5396664142608643,
                "num_singular_values": 12,
                "alpha": 1.9082612973099184
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.018280083313584328,
                "median": -0.013122839853167534,
                "std": 0.19387418031692505,
                "max": 2.4320788383483887,
                "min": -2.718900680541992,
                "frobenius_norm": 12.462980270385742,
                "spectral_norm": 8.378565788269043,
                "num_singular_values": 64,
                "alpha": 1.0790799745354362
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.004590584430843592,
                "median": -0.005375333596020937,
                "std": 0.10781758278608322,
                "max": 0.9751973748207092,
                "min": -1.472585916519165,
                "frobenius_norm": 6.906577110290527,
                "spectral_norm": 2.859168767929077,
                "num_singular_values": 64,
                "alpha": 1.1679878956731111
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.03359173238277435,
                "median": 0.03403289616107941,
                "std": 0.08151416480541229,
                "max": 0.4552192986011505,
                "min": -0.3048391342163086,
                "frobenius_norm": 1.9949328899383545,
                "spectral_norm": 1.1432297229766846,
                "num_singular_values": 8,
                "alpha": 2.2836568435710114
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.005_batch_size_32_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.06844206154346466,
            "mse": 376887488.0,
            "mae": 1831.96044921875,
            "r2_score": 0.9185870885848999,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.04554322361946106,
                "median": 0.04108843952417374,
                "std": 0.23997235298156738,
                "max": 0.9276306629180908,
                "min": -0.8944663405418396,
                "frobenius_norm": 6.769016265869141,
                "spectral_norm": 2.9487192630767822,
                "num_singular_values": 12,
                "alpha": 1.847651548496517
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.027094120159745216,
                "median": -0.02678026631474495,
                "std": 0.19968928396701813,
                "max": 0.8129879236221313,
                "min": -1.223427653312683,
                "frobenius_norm": 12.897215843200684,
                "spectral_norm": 4.672351837158203,
                "num_singular_values": 64,
                "alpha": 1.13312139074002
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.009731986559927464,
                "median": -0.015995049849152565,
                "std": 0.16515783965587616,
                "max": 1.599413275718689,
                "min": -0.9380589723587036,
                "frobenius_norm": 10.5884370803833,
                "spectral_norm": 4.3189616203308105,
                "num_singular_values": 64,
                "alpha": 1.0718388863554458
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": -0.007072696462273598,
                "median": 0.0012666396796703339,
                "std": 0.10134158283472061,
                "max": 0.2663464844226837,
                "min": -0.3629301190376282,
                "frobenius_norm": 2.298676013946533,
                "spectral_norm": 1.5459133386611938,
                "num_singular_values": 8,
                "alpha": 2.4793342243610463
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.005_batch_size_32_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.06835845112800598,
            "mse": 415655648.0,
            "mae": 1893.2542724609375,
            "r2_score": 0.9102126359939575,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.04648764431476593,
                "median": 0.034954242408275604,
                "std": 0.2538392245769501,
                "max": 1.2071559429168701,
                "min": -1.1568957567214966,
                "frobenius_norm": 7.151594638824463,
                "spectral_norm": 3.7645881175994873,
                "num_singular_values": 12,
                "alpha": 1.996177069577947
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.038138166069984436,
                "median": -0.03708196431398392,
                "std": 0.2116357982158661,
                "max": 0.9411337971687317,
                "min": -1.2170075178146362,
                "frobenius_norm": 13.762862205505371,
                "spectral_norm": 5.579275131225586,
                "num_singular_values": 64,
                "alpha": 1.1265833255077482
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.021421410143375397,
                "median": -0.022013217210769653,
                "std": 0.1719103455543518,
                "max": 1.0091859102249146,
                "min": -0.8744010329246521,
                "frobenius_norm": 11.087350845336914,
                "spectral_norm": 3.8548805713653564,
                "num_singular_values": 64,
                "alpha": 1.0928825625467575
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": -0.0009618627373129129,
                "median": 0.005483107641339302,
                "std": 0.0909968763589859,
                "max": 0.2345428317785263,
                "min": -0.3986871838569641,
                "frobenius_norm": 2.0591394901275635,
                "spectral_norm": 1.1408355236053467,
                "num_singular_values": 8,
                "alpha": 2.198862473547462
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.005_batch_size_32_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.0823945552110672,
            "mse": 506095072.0,
            "mae": 2177.879150390625,
            "r2_score": 0.8906764984130859,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.021254763007164,
                "median": 0.023943763226270676,
                "std": 0.2691427767276764,
                "max": 1.0254547595977783,
                "min": -2.175750970840454,
                "frobenius_norm": 7.481925964355469,
                "spectral_norm": 4.980413913726807,
                "num_singular_values": 12,
                "alpha": 1.9127577346313953
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.05242620036005974,
                "median": -0.0406234934926033,
                "std": 0.17688393592834473,
                "max": 0.9229357838630676,
                "min": -1.366823673248291,
                "frobenius_norm": 11.80733871459961,
                "spectral_norm": 5.633680820465088,
                "num_singular_values": 64,
                "alpha": 1.1122189861458927
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.031757913529872894,
                "median": -0.02452152967453003,
                "std": 0.1676744818687439,
                "max": 1.7092617750167847,
                "min": -1.243086814880371,
                "frobenius_norm": 10.921951293945312,
                "spectral_norm": 4.586465835571289,
                "num_singular_values": 64,
                "alpha": 1.078425151916616
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.006547842640429735,
                "median": 0.012686040252447128,
                "std": 0.08020952343940735,
                "max": 0.23369137942790985,
                "min": -0.2206224948167801,
                "frobenius_norm": 1.8209718465805054,
                "spectral_norm": 0.9380960464477539,
                "num_singular_values": 8,
                "alpha": 2.396647164960151
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.08106623589992523,
            "mse": 463329472.0,
            "mae": 2010.1766357421875,
            "r2_score": 0.8999144434928894,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": -0.037930216640233994,
                "median": -0.0385027676820755,
                "std": 0.21294055879116058,
                "max": 0.5236329436302185,
                "min": -1.033024787902832,
                "frobenius_norm": 5.9940690994262695,
                "spectral_norm": 2.64095401763916,
                "num_singular_values": 12,
                "alpha": 1.836187134171062
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.0073614162392914295,
                "median": -0.00629716832190752,
                "std": 0.20365481078624725,
                "max": 2.3608686923980713,
                "min": -3.8322465419769287,
                "frobenius_norm": 13.042420387268066,
                "spectral_norm": 8.553564071655273,
                "num_singular_values": 64,
                "alpha": 1.1558560129369382
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.005915215238928795,
                "median": -0.005901011638343334,
                "std": 0.10768570005893707,
                "max": 1.2399429082870483,
                "min": -1.294775128364563,
                "frobenius_norm": 6.902275085449219,
                "spectral_norm": 2.560628652572632,
                "num_singular_values": 64,
                "alpha": 1.154989591156889
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.03428965061903,
                "median": 0.03424600884318352,
                "std": 0.08394844084978104,
                "max": 0.3273228406906128,
                "min": -0.2733164131641388,
                "frobenius_norm": 2.051886558532715,
                "spectral_norm": 1.2492091655731201,
                "num_singular_values": 8,
                "alpha": 2.348132269452316
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.005_batch_size_64_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 64,
            "scaler_type": "standard",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.06682034581899643,
            "mse": 334141344.0,
            "mae": 1787.7601318359375,
            "r2_score": 0.9278208613395691,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.03769311681389809,
                "median": 0.033409617841243744,
                "std": 0.24079573154449463,
                "max": 0.7996538281440735,
                "min": -1.9561095237731934,
                "frobenius_norm": 6.75438928604126,
                "spectral_norm": 3.352786064147949,
                "num_singular_values": 12,
                "alpha": 2.0812430172554057
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.021246522665023804,
                "median": -0.020849864929914474,
                "std": 0.1815827637910843,
                "max": 0.8043326735496521,
                "min": -1.3315943479537964,
                "frobenius_norm": 11.700578689575195,
                "spectral_norm": 4.124266624450684,
                "num_singular_values": 64,
                "alpha": 1.1128679458999144
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.006870723329484463,
                "median": -0.007959311828017235,
                "std": 0.1631597876548767,
                "max": 1.1879373788833618,
                "min": -0.8484841585159302,
                "frobenius_norm": 10.451480865478516,
                "spectral_norm": 4.004082202911377,
                "num_singular_values": 64,
                "alpha": 1.1127919137527138
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.004471753723919392,
                "median": 0.0035234750248491764,
                "std": 0.10553434491157532,
                "max": 0.3972375690937042,
                "min": -0.49905574321746826,
                "frobenius_norm": 2.3901124000549316,
                "spectral_norm": 1.432909369468689,
                "num_singular_values": 8,
                "alpha": 2.356988078210915
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.005_batch_size_64_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 64,
            "scaler_type": "robust",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.06757298856973648,
            "mse": 358192000.0,
            "mae": 1830.1317138671875,
            "r2_score": 0.9226256012916565,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.0387067012488842,
                "median": 0.028848696500062943,
                "std": 0.24922046065330505,
                "max": 1.1976475715637207,
                "min": -1.3092892169952393,
                "frobenius_norm": 6.989402770996094,
                "spectral_norm": 4.0194220542907715,
                "num_singular_values": 12,
                "alpha": 2.1035547948916506
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.04079145938158035,
                "median": -0.036719802767038345,
                "std": 0.20516547560691833,
                "max": 1.0075424909591675,
                "min": -1.2545207738876343,
                "frobenius_norm": 13.387603759765625,
                "spectral_norm": 5.242618560791016,
                "num_singular_values": 64,
                "alpha": 1.0961725671408085
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.02262086793780327,
                "median": -0.024070827290415764,
                "std": 0.19094091653823853,
                "max": 1.438659429550171,
                "min": -1.1203889846801758,
                "frobenius_norm": 12.305675506591797,
                "spectral_norm": 4.503637790679932,
                "num_singular_values": 64,
                "alpha": 1.1385932012313447
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.004436127375811338,
                "median": 0.00999366119503975,
                "std": 0.11196447908878326,
                "max": 0.2722904682159424,
                "min": -0.6796071529388428,
                "frobenius_norm": 2.535454750061035,
                "spectral_norm": 1.4047797918319702,
                "num_singular_values": 8,
                "alpha": 2.218805781815763
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.005_batch_size_64_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 64,
            "scaler_type": "minmax",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.07067357003688812,
            "mse": 389105216.0,
            "mae": 2015.8836669921875,
            "r2_score": 0.9159479141235352,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.013492736034095287,
                "median": 0.023401334881782532,
                "std": 0.2711220979690552,
                "max": 0.7929502725601196,
                "min": -2.076383113861084,
                "frobenius_norm": 7.522855281829834,
                "spectral_norm": 5.368297100067139,
                "num_singular_values": 12,
                "alpha": 2.2036729839488878
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.043858692049980164,
                "median": -0.029992254450917244,
                "std": 0.1799323707818985,
                "max": 1.3456556797027588,
                "min": -1.598233699798584,
                "frobenius_norm": 11.852834701538086,
                "spectral_norm": 5.22149658203125,
                "num_singular_values": 64,
                "alpha": 1.0905571397596237
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.01866266503930092,
                "median": -0.01842624694108963,
                "std": 0.15635286271572113,
                "max": 1.0584057569503784,
                "min": -1.0511552095413208,
                "frobenius_norm": 10.077615737915039,
                "spectral_norm": 4.126742839813232,
                "num_singular_values": 64,
                "alpha": 1.0907094220154587
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": -0.004801704082638025,
                "median": 0.0018305899575352669,
                "std": 0.10020402818918228,
                "max": 0.27338311076164246,
                "min": -0.3852217495441437,
                "frobenius_norm": 2.2699599266052246,
                "spectral_norm": 1.3799567222595215,
                "num_singular_values": 8,
                "alpha": 2.1139884889519003
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.005_batch_size_128_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 128,
            "scaler_type": "identity",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.07795512676239014,
            "mse": 439065760.0,
            "mae": 1848.0006103515625,
            "r2_score": 0.9051557779312134,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": -0.026316067203879356,
                "median": -0.021782755851745605,
                "std": 0.20998059213161469,
                "max": 0.6093464493751526,
                "min": -0.9910702705383301,
                "frobenius_norm": 5.8646745681762695,
                "spectral_norm": 2.4014155864715576,
                "num_singular_values": 12,
                "alpha": 2.0038178572680243
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.00987292267382145,
                "median": -0.006614563055336475,
                "std": 0.18674170970916748,
                "max": 0.9990895390510559,
                "min": -3.398754835128784,
                "frobenius_norm": 11.968159675598145,
                "spectral_norm": 6.155457019805908,
                "num_singular_values": 64,
                "alpha": 1.0977970650570223
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.009191079996526241,
                "median": -0.005940086208283901,
                "std": 0.12685754895210266,
                "max": 0.7604847550392151,
                "min": -2.5415537357330322,
                "frobenius_norm": 8.140164375305176,
                "spectral_norm": 4.316588878631592,
                "num_singular_values": 64,
                "alpha": 1.0971325849268654
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.039882853627204895,
                "median": 0.03524089977145195,
                "std": 0.0966944545507431,
                "max": 0.47962838411331177,
                "min": -0.4791852533817291,
                "frobenius_norm": 2.3667521476745605,
                "spectral_norm": 1.3851593732833862,
                "num_singular_values": 8,
                "alpha": 1.998088006536852
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.005_batch_size_128_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 128,
            "scaler_type": "standard",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.06857957690954208,
            "mse": 366166080.0,
            "mae": 1773.5592041015625,
            "r2_score": 0.9209030866622925,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.07023738324642181,
                "median": 0.05821490287780762,
                "std": 0.2591661214828491,
                "max": 0.9569265842437744,
                "min": -1.4782650470733643,
                "frobenius_norm": 7.441309452056885,
                "spectral_norm": 3.4312901496887207,
                "num_singular_values": 12,
                "alpha": 1.9064852040751297
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.03304537385702133,
                "median": -0.03651398420333862,
                "std": 0.2167186588048935,
                "max": 0.9511919021606445,
                "min": -1.2249361276626587,
                "frobenius_norm": 14.030309677124023,
                "spectral_norm": 5.453714847564697,
                "num_singular_values": 64,
                "alpha": 1.1081591268533495
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.015370504930615425,
                "median": -0.015618078410625458,
                "std": 0.18897712230682373,
                "max": 1.468515396118164,
                "min": -1.0378780364990234,
                "frobenius_norm": 12.134474754333496,
                "spectral_norm": 4.908239364624023,
                "num_singular_values": 64,
                "alpha": 1.1411503760723665
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.0013460787013173103,
                "median": -8.746713865548372e-05,
                "std": 0.08788347989320755,
                "max": 0.31405705213546753,
                "min": -0.4508361518383026,
                "frobenius_norm": 1.9888094663619995,
                "spectral_norm": 0.9491112232208252,
                "num_singular_values": 8,
                "alpha": 2.3179204335982044
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.005_batch_size_128_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 128,
            "scaler_type": "robust",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.06832394748926163,
            "mse": 413430304.0,
            "mae": 1884.077392578125,
            "r2_score": 0.910693347454071,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.04157442972064018,
                "median": 0.033101797103881836,
                "std": 0.26243898272514343,
                "max": 1.326459288597107,
                "min": -1.4326367378234863,
                "frobenius_norm": 7.363615989685059,
                "spectral_norm": 4.32260274887085,
                "num_singular_values": 12,
                "alpha": 2.0876170057987573
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.03946121782064438,
                "median": -0.04238317906856537,
                "std": 0.2222500592470169,
                "max": 1.0633689165115356,
                "min": -1.2124032974243164,
                "frobenius_norm": 14.446471214294434,
                "spectral_norm": 6.004805564880371,
                "num_singular_values": 64,
                "alpha": 1.0767038240749596
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.016839809715747833,
                "median": -0.016869666054844856,
                "std": 0.18795716762542725,
                "max": 1.20615816116333,
                "min": -1.0513312816619873,
                "frobenius_norm": 12.077442169189453,
                "spectral_norm": 4.433417320251465,
                "num_singular_values": 64,
                "alpha": 1.1297596449289216
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": -0.0002891740296036005,
                "median": 0.003919058479368687,
                "std": 0.09070970863103867,
                "max": 0.24343924224376678,
                "min": -0.34416913986206055,
                "frobenius_norm": 2.052536964416504,
                "spectral_norm": 1.0714099407196045,
                "num_singular_values": 8,
                "alpha": 1.9680715302689515
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.005_batch_size_128_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 128,
            "scaler_type": "minmax",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.07130143791437149,
            "mse": 418532064.0,
            "mae": 1951.479736328125,
            "r2_score": 0.9095913171768188,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.023090803995728493,
                "median": 0.023035848513245583,
                "std": 0.2777526378631592,
                "max": 0.885587751865387,
                "min": -2.5506327152252197,
                "frobenius_norm": 7.723859786987305,
                "spectral_norm": 5.51071834564209,
                "num_singular_values": 12,
                "alpha": 1.9522364336967664
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.047126635909080505,
                "median": -0.03982165455818176,
                "std": 0.1757853627204895,
                "max": 1.0959566831588745,
                "min": -1.2530022859573364,
                "frobenius_norm": 11.64754581451416,
                "spectral_norm": 5.77681827545166,
                "num_singular_values": 64,
                "alpha": 1.1024392424732614
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.02496069297194481,
                "median": -0.02751440927386284,
                "std": 0.15051931142807007,
                "max": 1.1946886777877808,
                "min": -0.9952312111854553,
                "frobenius_norm": 9.764793395996094,
                "spectral_norm": 3.8339312076568604,
                "num_singular_values": 64,
                "alpha": 1.0851991868604534
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.0017993398942053318,
                "median": 0.0024375393986701965,
                "std": 0.10467761754989624,
                "max": 0.3532088100910187,
                "min": -0.36115169525146484,
                "frobenius_norm": 2.368933916091919,
                "spectral_norm": 1.5922383069992065,
                "num_singular_values": 8,
                "alpha": 2.105299688685485
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.005_batch_size_256_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 256,
            "scaler_type": "identity",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.07944947481155396,
            "mse": 437146144.0,
            "mae": 1967.0496826171875,
            "r2_score": 0.905570387840271,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": -0.036488473415374756,
                "median": -0.03470635041594505,
                "std": 0.22059287130832672,
                "max": 0.6283062100410461,
                "min": -1.5104660987854004,
                "frobenius_norm": 6.196316242218018,
                "spectral_norm": 2.7335000038146973,
                "num_singular_values": 12,
                "alpha": 1.9584039023796422
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.008283020928502083,
                "median": -0.007760318927466869,
                "std": 0.19912736117839813,
                "max": 2.0985753536224365,
                "min": -3.3848886489868164,
                "frobenius_norm": 12.755172729492188,
                "spectral_norm": 7.567509174346924,
                "num_singular_values": 64,
                "alpha": 1.110582758358752
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.004486170597374439,
                "median": -0.00521788839250803,
                "std": 0.11429867148399353,
                "max": 1.3334612846374512,
                "min": -1.391296625137329,
                "frobenius_norm": 7.3207478523254395,
                "spectral_norm": 3.380174160003662,
                "num_singular_values": 64,
                "alpha": 1.0872588666794043
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.03388550132513046,
                "median": 0.03297046571969986,
                "std": 0.08187949657440186,
                "max": 0.24799327552318573,
                "min": -0.22735095024108887,
                "frobenius_norm": 2.0051109790802,
                "spectral_norm": 1.0925347805023193,
                "num_singular_values": 8,
                "alpha": 2.5832203269348852
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.005_batch_size_256_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 256,
            "scaler_type": "standard",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.06828124076128006,
            "mse": 403183712.0,
            "mae": 1898.9913330078125,
            "r2_score": 0.9129067659378052,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.06038182973861694,
                "median": 0.047804057598114014,
                "std": 0.2514426112174988,
                "max": 0.9527555704116821,
                "min": -1.4278216361999512,
                "frobenius_norm": 7.166286468505859,
                "spectral_norm": 3.487295389175415,
                "num_singular_values": 12,
                "alpha": 1.8619886280523832
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.02252613753080368,
                "median": -0.0226481631398201,
                "std": 0.19211140275001526,
                "max": 0.917663037776947,
                "min": -1.3040107488632202,
                "frobenius_norm": 12.379364013671875,
                "spectral_norm": 4.220152854919434,
                "num_singular_values": 64,
                "alpha": 1.0757929682455196
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.012261292897164822,
                "median": -0.016519473865628242,
                "std": 0.17095722258090973,
                "max": 1.3514997959136963,
                "min": -0.9246860146522522,
                "frobenius_norm": 10.969367027282715,
                "spectral_norm": 4.586912631988525,
                "num_singular_values": 64,
                "alpha": 1.134183043307315
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.010151177644729614,
                "median": 0.01715787872672081,
                "std": 0.1122281402349472,
                "max": 0.3200717270374298,
                "min": -0.7558394074440002,
                "frobenius_norm": 2.549799919128418,
                "spectral_norm": 1.7389225959777832,
                "num_singular_values": 8,
                "alpha": 1.9676791360612995
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.005_batch_size_256_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 256,
            "scaler_type": "robust",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.06900607794523239,
            "mse": 365057760.0,
            "mae": 1805.0992431640625,
            "r2_score": 0.9211424589157104,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.024561360478401184,
                "median": 0.025247907266020775,
                "std": 0.24725472927093506,
                "max": 1.180143117904663,
                "min": -1.3071284294128418,
                "frobenius_norm": 6.885848522186279,
                "spectral_norm": 4.0083441734313965,
                "num_singular_values": 12,
                "alpha": 1.906373133669436
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.0371624231338501,
                "median": -0.03511298447847366,
                "std": 0.21315018832683563,
                "max": 1.308474063873291,
                "min": -1.216652274131775,
                "frobenius_norm": 13.847394943237305,
                "spectral_norm": 5.194798469543457,
                "num_singular_values": 64,
                "alpha": 1.1389486252256444
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.009652108885347843,
                "median": -0.016065876930952072,
                "std": 0.1924421191215515,
                "max": 1.48993980884552,
                "min": -0.984987735748291,
                "frobenius_norm": 12.33177661895752,
                "spectral_norm": 4.818456649780273,
                "num_singular_values": 64,
                "alpha": 1.1269160824311024
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.006389171816408634,
                "median": 0.009291186928749084,
                "std": 0.08446080982685089,
                "max": 0.26621213555336,
                "min": -0.3684256672859192,
                "frobenius_norm": 1.9165902137756348,
                "spectral_norm": 0.978549599647522,
                "num_singular_values": 8,
                "alpha": 2.291675927083413
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.005_batch_size_256_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.005,
            "batch_size": 256,
            "scaler_type": "minmax",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.08322017639875412,
            "mse": 631026048.0,
            "mae": 2394.547607421875,
            "r2_score": 0.863689661026001,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.01066902931779623,
                "median": 0.02718300372362137,
                "std": 0.2698275148868561,
                "max": 1.1999006271362305,
                "min": -2.528785467147827,
                "frobenius_norm": 7.483522891998291,
                "spectral_norm": 5.125612735748291,
                "num_singular_values": 12,
                "alpha": 1.8295438762214897
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.05240827053785324,
                "median": -0.03885309398174286,
                "std": 0.19135110080242157,
                "max": 1.0907261371612549,
                "min": -1.544298768043518,
                "frobenius_norm": 12.697488784790039,
                "spectral_norm": 6.267844200134277,
                "num_singular_values": 64,
                "alpha": 1.1154490878280892
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.027842529118061066,
                "median": -0.02765565738081932,
                "std": 0.15030741691589355,
                "max": 1.2151267528533936,
                "min": -1.4900027513504028,
                "frobenius_norm": 9.78332233428955,
                "spectral_norm": 4.265295028686523,
                "num_singular_values": 64,
                "alpha": 1.131125980370362
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": -0.0109010124579072,
                "median": -0.007223258726298809,
                "std": 0.09208595007658005,
                "max": 0.3339749276638031,
                "min": -0.47454163432121277,
                "frobenius_norm": 2.0982160568237305,
                "spectral_norm": 1.3736852407455444,
                "num_singular_values": 8,
                "alpha": 2.2927047918210617
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.001_batch_size_16_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.08265950530767441,
            "mse": 437814816.0,
            "mae": 2020.649658203125,
            "r2_score": 0.9054259657859802,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.00843850802630186,
                "median": 0.007286542095243931,
                "std": 0.17402343451976776,
                "max": 0.34452641010284424,
                "min": -0.4691694974899292,
                "frobenius_norm": 4.82834529876709,
                "spectral_norm": 1.823952555656433,
                "num_singular_values": 12,
                "alpha": 2.2700196178374865
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.011457592248916626,
                "median": 0.011558684520423412,
                "std": 0.09855440258979797,
                "max": 0.6363815665245056,
                "min": -0.6426936984062195,
                "frobenius_norm": 6.349963665008545,
                "spectral_norm": 3.3790886402130127,
                "num_singular_values": 64,
                "alpha": 1.0747313432226626
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.012451892718672752,
                "median": 0.013492338359355927,
                "std": 0.08450984954833984,
                "max": 0.4359569251537323,
                "min": -0.2666170001029968,
                "frobenius_norm": 5.467024803161621,
                "spectral_norm": 2.180069923400879,
                "num_singular_values": 64,
                "alpha": 1.164033982776071
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.02521626278758049,
                "median": 0.029045652598142624,
                "std": 0.07488217949867249,
                "max": 0.18505539000034332,
                "min": -0.20132926106452942,
                "frobenius_norm": 1.7878810167312622,
                "spectral_norm": 0.9277040362358093,
                "num_singular_values": 8,
                "alpha": 2.7349152151478036
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.001_batch_size_16_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.06993471831083298,
            "mse": 391547072.0,
            "mae": 1909.298828125,
            "r2_score": 0.915420413017273,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.026351377367973328,
                "median": 0.012857362627983093,
                "std": 0.20548401772975922,
                "max": 0.6455093622207642,
                "min": -0.668134331703186,
                "frobenius_norm": 5.741174221038818,
                "spectral_norm": 2.352717161178589,
                "num_singular_values": 12,
                "alpha": 2.3386852333572485
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.009003530256450176,
                "median": 0.00757575361058116,
                "std": 0.11891287565231323,
                "max": 0.6726065278053284,
                "min": -0.4983859360218048,
                "frobenius_norm": 7.63220739364624,
                "spectral_norm": 2.7060699462890625,
                "num_singular_values": 64,
                "alpha": 1.1409227264035695
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.009405198507010937,
                "median": 0.007363069802522659,
                "std": 0.10567737370729446,
                "max": 0.6619907021522522,
                "min": -0.513237476348877,
                "frobenius_norm": 6.7900848388671875,
                "spectral_norm": 2.7281274795532227,
                "num_singular_values": 64,
                "alpha": 1.1183226059243916
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.016302134841680527,
                "median": 0.017138386145234108,
                "std": 0.08469425141811371,
                "max": 0.2735900282859802,
                "min": -0.2991126775741577,
                "frobenius_norm": 1.9515902996063232,
                "spectral_norm": 1.015559434890747,
                "num_singular_values": 8,
                "alpha": 2.8970802336322086
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.001_batch_size_16_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.06987721472978592,
            "mse": 324482496.0,
            "mae": 1851.28125,
            "r2_score": 0.9299073219299316,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.015484467148780823,
                "median": 0.012934151105582714,
                "std": 0.20573531091213226,
                "max": 0.5527867674827576,
                "min": -0.8649724721908569,
                "frobenius_norm": 5.717630386352539,
                "spectral_norm": 2.4940476417541504,
                "num_singular_values": 12,
                "alpha": 2.309461386038932
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.010615425184369087,
                "median": 0.00750931678339839,
                "std": 0.11992347985506058,
                "max": 0.6090036630630493,
                "min": -0.49475353956222534,
                "frobenius_norm": 7.705113410949707,
                "spectral_norm": 2.8446555137634277,
                "num_singular_values": 64,
                "alpha": 1.0965279094018512
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.007388005498796701,
                "median": 0.00781420897692442,
                "std": 0.10340997576713562,
                "max": 0.5220664739608765,
                "min": -0.5159146189689636,
                "frobenius_norm": 6.635107040405273,
                "spectral_norm": 2.34892201423645,
                "num_singular_values": 64,
                "alpha": 1.1375719337135743
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.010325533337891102,
                "median": 0.01743258722126484,
                "std": 0.09808376431465149,
                "max": 0.298189252614975,
                "min": -0.46999651193618774,
                "frobenius_norm": 2.2316462993621826,
                "spectral_norm": 1.4420034885406494,
                "num_singular_values": 8,
                "alpha": 2.3804172228768454
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.001_batch_size_16_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.07191828638315201,
            "mse": 406240896.0,
            "mae": 1965.5780029296875,
            "r2_score": 0.9122463464736938,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.01691226102411747,
                "median": 0.010344795882701874,
                "std": 0.200933575630188,
                "max": 0.640960693359375,
                "min": -0.8936091065406799,
                "frobenius_norm": 5.5881242752075195,
                "spectral_norm": 2.8683524131774902,
                "num_singular_values": 12,
                "alpha": 2.1351830047887943
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.005618754308670759,
                "median": -0.0053325132466852665,
                "std": 0.10247936844825745,
                "max": 0.5526057481765747,
                "min": -0.6084511280059814,
                "frobenius_norm": 6.568530559539795,
                "spectral_norm": 2.5173568725585938,
                "num_singular_values": 64,
                "alpha": 1.0976189069342108
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.0010325944749638438,
                "median": 0.0008961878484115005,
                "std": 0.09230602532625198,
                "max": 0.44796979427337646,
                "min": -0.5636544227600098,
                "frobenius_norm": 5.907954692840576,
                "spectral_norm": 2.632103443145752,
                "num_singular_values": 64,
                "alpha": 1.1066490676962133
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.014610250480473042,
                "median": 0.017243651673197746,
                "std": 0.07335293292999268,
                "max": 0.29941117763519287,
                "min": -0.18674902617931366,
                "frobenius_norm": 1.6923905611038208,
                "spectral_norm": 0.7665964961051941,
                "num_singular_values": 8,
                "alpha": 2.916175220321639
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.07582686841487885,
            "mse": 421928256.0,
            "mae": 1887.6744384765625,
            "r2_score": 0.9088577032089233,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.00891033560037613,
                "median": 0.012498365715146065,
                "std": 0.17683091759681702,
                "max": 0.3814677298069,
                "min": -0.4852031171321869,
                "frobenius_norm": 4.906699180603027,
                "spectral_norm": 1.9372793436050415,
                "num_singular_values": 12,
                "alpha": 2.218740444054241
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.011673797853291035,
                "median": 0.012825816869735718,
                "std": 0.10300082713365555,
                "max": 0.44458135962486267,
                "min": -0.8587345480918884,
                "frobenius_norm": 6.634256362915039,
                "spectral_norm": 3.6510941982269287,
                "num_singular_values": 64,
                "alpha": 1.1078712225295695
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.013247973285615444,
                "median": 0.013078225776553154,
                "std": 0.08768485486507416,
                "max": 0.3401387631893158,
                "min": -0.4495932161808014,
                "frobenius_norm": 5.675519943237305,
                "spectral_norm": 2.4886691570281982,
                "num_singular_values": 64,
                "alpha": 1.106436902437977
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.02856994979083538,
                "median": 0.03539638966321945,
                "std": 0.0757133737206459,
                "max": 0.2088174670934677,
                "min": -0.1485617607831955,
                "frobenius_norm": 1.8311100006103516,
                "spectral_norm": 0.9468495845794678,
                "num_singular_values": 8,
                "alpha": 2.731721788286805
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.001_batch_size_32_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.07024716585874557,
            "mse": 362645568.0,
            "mae": 1874.8116455078125,
            "r2_score": 0.9216635823249817,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.020610036328434944,
                "median": 0.011575212702155113,
                "std": 0.21095526218414307,
                "max": 0.622995138168335,
                "min": -1.03641939163208,
                "frobenius_norm": 5.873998165130615,
                "spectral_norm": 2.5239715576171875,
                "num_singular_values": 12,
                "alpha": 2.1742104891387726
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.007936075329780579,
                "median": 0.007426855154335499,
                "std": 0.11723632365465164,
                "max": 0.5931759476661682,
                "min": -0.6054664850234985,
                "frobenius_norm": 7.5202956199646,
                "spectral_norm": 2.556607961654663,
                "num_singular_values": 64,
                "alpha": 1.1401435763708503
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.011400563642382622,
                "median": 0.008854348212480545,
                "std": 0.11313378810882568,
                "max": 0.5669125318527222,
                "min": -0.4740225076675415,
                "frobenius_norm": 7.2772321701049805,
                "spectral_norm": 2.6560168266296387,
                "num_singular_values": 64,
                "alpha": 1.128063624983611
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.020057354122400284,
                "median": 0.022511642426252365,
                "std": 0.09390023350715637,
                "max": 0.31625425815582275,
                "min": -0.2874715328216553,
                "frobenius_norm": 2.1726505756378174,
                "spectral_norm": 1.22370445728302,
                "num_singular_values": 8,
                "alpha": 2.5756429909222813
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.001_batch_size_32_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.07019184529781342,
            "mse": 382731904.0,
            "mae": 1896.360595703125,
            "r2_score": 0.9173246622085571,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.012492389418184757,
                "median": 0.005494511686265469,
                "std": 0.20580485463142395,
                "max": 0.5705004930496216,
                "min": -0.800137460231781,
                "frobenius_norm": 5.713928699493408,
                "spectral_norm": 2.612888813018799,
                "num_singular_values": 12,
                "alpha": 2.3948345536491167
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.011459773406386375,
                "median": 0.008666018024086952,
                "std": 0.12204719334840775,
                "max": 0.6118884086608887,
                "min": -0.46231332421302795,
                "frobenius_norm": 7.8453779220581055,
                "spectral_norm": 2.9719088077545166,
                "num_singular_values": 64,
                "alpha": 1.0925296867737229
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.008918074890971184,
                "median": 0.008818946778774261,
                "std": 0.11285395920276642,
                "max": 0.5910592079162598,
                "min": -0.49497905373573303,
                "frobenius_norm": 7.2451701164245605,
                "spectral_norm": 2.7573952674865723,
                "num_singular_values": 64,
                "alpha": 1.0815742621345876
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.011435765773057938,
                "median": 0.018911268562078476,
                "std": 0.10462405532598495,
                "max": 0.3578806519508362,
                "min": -0.5993555188179016,
                "frobenius_norm": 2.381471872329712,
                "spectral_norm": 1.3757117986679077,
                "num_singular_values": 8,
                "alpha": 2.358785967720686
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.001_batch_size_32_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.07262733578681946,
            "mse": 386579008.0,
            "mae": 1971.3525390625,
            "r2_score": 0.9164935946464539,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.018955156207084656,
                "median": 0.014827636070549488,
                "std": 0.2076134979724884,
                "max": 0.6098628044128418,
                "min": -0.920240581035614,
                "frobenius_norm": 5.77748441696167,
                "spectral_norm": 3.1094937324523926,
                "num_singular_values": 12,
                "alpha": 2.214583200235804
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.00049217464402318,
                "median": 0.0007177195511758327,
                "std": 0.10370246320962906,
                "max": 0.48490771651268005,
                "min": -0.521598219871521,
                "frobenius_norm": 6.637032985687256,
                "spectral_norm": 2.374964952468872,
                "num_singular_values": 64,
                "alpha": 1.1307016885202088
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.00022477435413748026,
                "median": 0.0009048227802850306,
                "std": 0.09633858501911163,
                "max": 0.5654283761978149,
                "min": -0.8311552405357361,
                "frobenius_norm": 6.165686130523682,
                "spectral_norm": 2.3574676513671875,
                "num_singular_values": 64,
                "alpha": 1.1049776372780193
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.013844010420143604,
                "median": 0.015029409900307655,
                "std": 0.09044966101646423,
                "max": 0.4208974838256836,
                "min": -0.35418590903282166,
                "frobenius_norm": 2.0704762935638428,
                "spectral_norm": 1.3369457721710205,
                "num_singular_values": 8,
                "alpha": 2.2889700468145424
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.08927156031131744,
            "mse": 395336672.0,
            "mae": 1998.3360595703125,
            "r2_score": 0.9146018028259277,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.00609505595639348,
                "median": 0.010789219290018082,
                "std": 0.1786046326160431,
                "max": 0.40556201338768005,
                "min": -0.5553768277168274,
                "frobenius_norm": 4.952517509460449,
                "spectral_norm": 1.9560118913650513,
                "num_singular_values": 12,
                "alpha": 2.159582085905271
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.011745079420506954,
                "median": 0.01381413172930479,
                "std": 0.10920888185501099,
                "max": 0.49578016996383667,
                "min": -0.9464490413665771,
                "frobenius_norm": 7.029673099517822,
                "spectral_norm": 3.93253493309021,
                "num_singular_values": 64,
                "alpha": 1.156450755408263
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.012607064098119736,
                "median": 0.013942940160632133,
                "std": 0.0864337757229805,
                "max": 0.37101009488105774,
                "min": -0.3192877471446991,
                "frobenius_norm": 5.59029483795166,
                "spectral_norm": 2.3134472370147705,
                "num_singular_values": 64,
                "alpha": 1.1454272846467601
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.026525121182203293,
                "median": 0.03432844206690788,
                "std": 0.07705773413181305,
                "max": 0.17980220913887024,
                "min": -0.21379731595516205,
                "frobenius_norm": 1.8440272808074951,
                "spectral_norm": 0.9134587049484253,
                "num_singular_values": 8,
                "alpha": 2.7349142697365068
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.001_batch_size_64_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "standard",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.06819893419742584,
            "mse": 345518144.0,
            "mae": 1849.1759033203125,
            "r2_score": 0.925363302230835,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.01747969537973404,
                "median": 0.014520312659442425,
                "std": 0.21254278719425201,
                "max": 0.546840488910675,
                "min": -0.9358953237533569,
                "frobenius_norm": 5.910043716430664,
                "spectral_norm": 2.600933313369751,
                "num_singular_values": 12,
                "alpha": 2.1831926113445235
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.009744700975716114,
                "median": 0.005064558703452349,
                "std": 0.11841253191232681,
                "max": 0.6650489568710327,
                "min": -0.505222737789154,
                "frobenius_norm": 7.604021072387695,
                "spectral_norm": 2.597862958908081,
                "num_singular_values": 64,
                "alpha": 1.1067819030393835
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.010551166720688343,
                "median": 0.01026360597461462,
                "std": 0.11361972987651825,
                "max": 0.5302719473838806,
                "min": -0.46253010630607605,
                "frobenius_norm": 7.30294942855835,
                "spectral_norm": 2.9326672554016113,
                "num_singular_values": 64,
                "alpha": 1.123977490002547
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.017207955941557884,
                "median": 0.021912846714258194,
                "std": 0.09939668327569962,
                "max": 0.3724219799041748,
                "min": -0.27648332715034485,
                "frobenius_norm": 2.282546043395996,
                "spectral_norm": 1.474677324295044,
                "num_singular_values": 8,
                "alpha": 2.359604067585997
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.001_batch_size_64_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "robust",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.06954958289861679,
            "mse": 360213856.0,
            "mae": 1879.7032470703125,
            "r2_score": 0.9221888780593872,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.008820665068924427,
                "median": 0.012611286714673042,
                "std": 0.20684094727039337,
                "max": 0.5830506682395935,
                "min": -0.8620976805686951,
                "frobenius_norm": 5.737354278564453,
                "spectral_norm": 2.6984269618988037,
                "num_singular_values": 12,
                "alpha": 2.3272092512085285
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.010840984992682934,
                "median": 0.007868831977248192,
                "std": 0.1231674924492836,
                "max": 0.6409103274345398,
                "min": -0.5733084678649902,
                "frobenius_norm": 7.9131951332092285,
                "spectral_norm": 2.897645950317383,
                "num_singular_values": 64,
                "alpha": 1.117211377628668
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.013151919469237328,
                "median": 0.013564296066761017,
                "std": 0.11454802751541138,
                "max": 0.6216993927955627,
                "min": -0.6046568155288696,
                "frobenius_norm": 7.379237174987793,
                "spectral_norm": 2.699918508529663,
                "num_singular_values": 64,
                "alpha": 1.141923180600581
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.01276625506579876,
                "median": 0.01346982829272747,
                "std": 0.09086158871650696,
                "max": 0.26486465334892273,
                "min": -0.42345932126045227,
                "frobenius_norm": 2.0761570930480957,
                "spectral_norm": 1.1260626316070557,
                "num_singular_values": 8,
                "alpha": 2.5518234074148256
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.001_batch_size_64_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "minmax",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.07057799398899078,
            "mse": 373933504.0,
            "mae": 1910.486572265625,
            "r2_score": 0.9192252159118652,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.016344964504241943,
                "median": 0.013575812801718712,
                "std": 0.20878835022449493,
                "max": 0.7926561832427979,
                "min": -0.9717264175415039,
                "frobenius_norm": 5.8038153648376465,
                "spectral_norm": 3.233785629272461,
                "num_singular_values": 12,
                "alpha": 2.156977161788717
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.0010533835738897324,
                "median": -0.00046153090079315007,
                "std": 0.10859543830156326,
                "max": 0.6443321108818054,
                "min": -0.6167126297950745,
                "frobenius_norm": 6.950435161590576,
                "spectral_norm": 2.3641345500946045,
                "num_singular_values": 64,
                "alpha": 1.0848076440139285
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.0025015755090862513,
                "median": 0.0031456234864890575,
                "std": 0.09863002598285675,
                "max": 0.5494767427444458,
                "min": -0.5032081604003906,
                "frobenius_norm": 6.314351558685303,
                "spectral_norm": 2.391136884689331,
                "num_singular_values": 64,
                "alpha": 1.1835804993899572
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.012156233191490173,
                "median": 0.01847350224852562,
                "std": 0.08592624962329865,
                "max": 0.3717661499977112,
                "min": -0.27208536863327026,
                "frobenius_norm": 1.9636497497558594,
                "spectral_norm": 1.168365716934204,
                "num_singular_values": 8,
                "alpha": 2.6188533266023413
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.001_batch_size_128_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 128,
            "scaler_type": "identity",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.07572723925113678,
            "mse": 395909792.0,
            "mae": 1809.607421875,
            "r2_score": 0.9144780039787292,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.008120018057525158,
                "median": 0.014440885744988918,
                "std": 0.18017856776714325,
                "max": 0.3670448362827301,
                "min": -0.5350133776664734,
                "frobenius_norm": 4.9983229637146,
                "spectral_norm": 1.971474528312683,
                "num_singular_values": 12,
                "alpha": 2.1985436011045376
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.012921376153826714,
                "median": 0.015952926129102707,
                "std": 0.11097237467765808,
                "max": 0.39933979511260986,
                "min": -0.9540847539901733,
                "frobenius_norm": 7.150215148925781,
                "spectral_norm": 3.894700765609741,
                "num_singular_values": 64,
                "alpha": 1.1439218108838907
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.012872575782239437,
                "median": 0.014006889425218105,
                "std": 0.09013663232326508,
                "max": 0.3260047435760498,
                "min": -0.4870598614215851,
                "frobenius_norm": 5.827274799346924,
                "spectral_norm": 2.5105552673339844,
                "num_singular_values": 64,
                "alpha": 1.1211065883945188
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.025534745305776596,
                "median": 0.03136418014764786,
                "std": 0.08108919113874435,
                "max": 0.25358787178993225,
                "min": -0.2370115965604782,
                "frobenius_norm": 1.923660397529602,
                "spectral_norm": 0.9494909644126892,
                "num_singular_values": 8,
                "alpha": 2.484755707423254
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.001_batch_size_128_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 128,
            "scaler_type": "standard",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.06895969808101654,
            "mse": 353429952.0,
            "mae": 1855.6600341796875,
            "r2_score": 0.9236542582511902,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.025658734142780304,
                "median": 0.016775676980614662,
                "std": 0.20339734852313995,
                "max": 0.5397241711616516,
                "min": -0.8049200177192688,
                "frobenius_norm": 5.681386947631836,
                "spectral_norm": 2.398099422454834,
                "num_singular_values": 12,
                "alpha": 2.367814658232854
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.005203878507018089,
                "median": 0.003550148569047451,
                "std": 0.11502667516469955,
                "max": 0.49916785955429077,
                "min": -0.5281526446342468,
                "frobenius_norm": 7.369236946105957,
                "spectral_norm": 2.4688124656677246,
                "num_singular_values": 64,
                "alpha": 1.1378131963648785
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.009453343227505684,
                "median": 0.006904739886522293,
                "std": 0.1150943711400032,
                "max": 0.4784431755542755,
                "min": -0.5919607877731323,
                "frobenius_norm": 7.390844821929932,
                "spectral_norm": 3.0372416973114014,
                "num_singular_values": 64,
                "alpha": 1.0653866699033314
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.015710905194282532,
                "median": 0.016745038330554962,
                "std": 0.10959935188293457,
                "max": 0.3359217643737793,
                "min": -0.3881853222846985,
                "frobenius_norm": 2.505300521850586,
                "spectral_norm": 1.5055829286575317,
                "num_singular_values": 8,
                "alpha": 2.227606899057962
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.001_batch_size_128_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 128,
            "scaler_type": "robust",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.06969951093196869,
            "mse": 336111648.0,
            "mae": 1780.5782470703125,
            "r2_score": 0.927395224571228,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.011938135139644146,
                "median": 0.014323621056973934,
                "std": 0.20641645789146423,
                "max": 0.5577666759490967,
                "min": -0.8633431792259216,
                "frobenius_norm": 5.7299394607543945,
                "spectral_norm": 2.68522310256958,
                "num_singular_values": 12,
                "alpha": 2.026459107157316
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.00808825995773077,
                "median": 0.0050130076706409454,
                "std": 0.12389440089464188,
                "max": 0.5366705656051636,
                "min": -0.6563228964805603,
                "frobenius_norm": 7.946120262145996,
                "spectral_norm": 2.894163131713867,
                "num_singular_values": 64,
                "alpha": 1.1190498291996216
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.01590210571885109,
                "median": 0.01335375290364027,
                "std": 0.10979374498128891,
                "max": 0.5524812936782837,
                "min": -0.4869377315044403,
                "frobenius_norm": 7.100119590759277,
                "spectral_norm": 2.8156304359436035,
                "num_singular_values": 64,
                "alpha": 1.0619931412736765
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.013426234014332294,
                "median": 0.018199000507593155,
                "std": 0.09669103473424911,
                "max": 0.28026995062828064,
                "min": -0.4650639593601227,
                "frobenius_norm": 2.208859920501709,
                "spectral_norm": 1.046791911125183,
                "num_singular_values": 8,
                "alpha": 2.4840439386114093
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.001_batch_size_128_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 128,
            "scaler_type": "minmax",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.0701439157128334,
            "mse": 372676576.0,
            "mae": 1944.72119140625,
            "r2_score": 0.9194967150688171,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.018034011125564575,
                "median": 0.010091559961438179,
                "std": 0.20814357697963715,
                "max": 0.6421446800231934,
                "min": -1.0248541831970215,
                "frobenius_norm": 5.789854049682617,
                "spectral_norm": 3.133500814437866,
                "num_singular_values": 12,
                "alpha": 2.171540675663577
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.003075630869716406,
                "median": -0.0034340503625571728,
                "std": 0.10988269746303558,
                "max": 0.5314436554908752,
                "min": -0.6271043419837952,
                "frobenius_norm": 7.035246849060059,
                "spectral_norm": 2.560898542404175,
                "num_singular_values": 64,
                "alpha": 1.1107501114802787
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.002521174494177103,
                "median": 0.003285151906311512,
                "std": 0.10435334593057632,
                "max": 0.7243127822875977,
                "min": -0.6777589321136475,
                "frobenius_norm": 6.680563449859619,
                "spectral_norm": 2.58372163772583,
                "num_singular_values": 64,
                "alpha": 1.1378840341430696
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.005832985043525696,
                "median": 0.008709939196705818,
                "std": 0.09388095140457153,
                "max": 0.3443407714366913,
                "min": -0.4958718419075012,
                "frobenius_norm": 2.1283798217773438,
                "spectral_norm": 1.4055111408233643,
                "num_singular_values": 8,
                "alpha": 2.2433576663074994
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.001_batch_size_256_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 256,
            "scaler_type": "identity",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.07832683622837067,
            "mse": 450433984.0,
            "mae": 1909.945556640625,
            "r2_score": 0.9027000665664673,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.008524608798325062,
                "median": 0.009278216399252415,
                "std": 0.1800549477338791,
                "max": 0.38054975867271423,
                "min": -0.6334295868873596,
                "frobenius_norm": 4.995418548583984,
                "spectral_norm": 1.965798258781433,
                "num_singular_values": 12,
                "alpha": 2.1336520035196385
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.007561639882624149,
                "median": 0.00980415754020214,
                "std": 0.1091398075222969,
                "max": 0.525948703289032,
                "min": -0.8795351386070251,
                "frobenius_norm": 7.001692295074463,
                "spectral_norm": 3.7846386432647705,
                "num_singular_values": 64,
                "alpha": 1.1231222488347194
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.01361496839672327,
                "median": 0.01544148102402687,
                "std": 0.08911485970020294,
                "max": 0.31907278299331665,
                "min": -0.4566132128238678,
                "frobenius_norm": 5.769529819488525,
                "spectral_norm": 2.388368606567383,
                "num_singular_values": 64,
                "alpha": 1.1451743876455345
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.02479582652449608,
                "median": 0.03090056963264942,
                "std": 0.08322660624980927,
                "max": 0.2034459412097931,
                "min": -0.2641528248786926,
                "frobenius_norm": 1.9650059938430786,
                "spectral_norm": 0.9661465287208557,
                "num_singular_values": 8,
                "alpha": 2.44349672702901
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.001_batch_size_256_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 256,
            "scaler_type": "standard",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.0691525936126709,
            "mse": 364989920.0,
            "mae": 1893.4984130859375,
            "r2_score": 0.9211571216583252,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.02198958955705166,
                "median": 0.01091786939650774,
                "std": 0.20728638768196106,
                "max": 0.5869012475013733,
                "min": -0.940627932548523,
                "frobenius_norm": 5.776721954345703,
                "spectral_norm": 2.435602903366089,
                "num_singular_values": 12,
                "alpha": 2.385887868561346
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.007568744942545891,
                "median": 0.006112034432590008,
                "std": 0.12289868295192719,
                "max": 0.5712141990661621,
                "min": -0.5708227753639221,
                "frobenius_norm": 7.880417346954346,
                "spectral_norm": 2.768333673477173,
                "num_singular_values": 64,
                "alpha": 1.1144439833401965
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.01078515499830246,
                "median": 0.008679157122969627,
                "std": 0.1148497462272644,
                "max": 0.6803656220436096,
                "min": -0.4946485459804535,
                "frobenius_norm": 7.3827223777771,
                "spectral_norm": 3.438863515853882,
                "num_singular_values": 64,
                "alpha": 1.1086122904738842
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.015244645066559315,
                "median": 0.016282087191939354,
                "std": 0.09743952751159668,
                "max": 0.3249190151691437,
                "min": -0.38384637236595154,
                "frobenius_norm": 2.231625556945801,
                "spectral_norm": 1.1192432641983032,
                "num_singular_values": 8,
                "alpha": 2.524124694449358
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.001_batch_size_256_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 256,
            "scaler_type": "robust",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.06974411010742188,
            "mse": 379982944.0,
            "mae": 1847.19189453125,
            "r2_score": 0.9179184436798096,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.013664337806403637,
                "median": 0.011425628326833248,
                "std": 0.21179333329200745,
                "max": 0.6991813778877258,
                "min": -0.8350732326507568,
                "frobenius_norm": 5.881591796875,
                "spectral_norm": 2.8193862438201904,
                "num_singular_values": 12,
                "alpha": 2.0980301787848576
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.014236418530344963,
                "median": 0.010391024872660637,
                "std": 0.12675997614860535,
                "max": 0.6931781768798828,
                "min": -0.6557436585426331,
                "frobenius_norm": 8.163642883300781,
                "spectral_norm": 2.969339609146118,
                "num_singular_values": 64,
                "alpha": 1.1339731330605538
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.014820577576756477,
                "median": 0.011919742450118065,
                "std": 0.1106090396642685,
                "max": 0.5394339561462402,
                "min": -0.6106181740760803,
                "frobenius_norm": 7.142242431640625,
                "spectral_norm": 3.1038572788238525,
                "num_singular_values": 64,
                "alpha": 1.1424835092481191
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.009375382214784622,
                "median": 0.011713031679391861,
                "std": 0.09194722771644592,
                "max": 0.29276248812675476,
                "min": -0.587859570980072,
                "frobenius_norm": 2.091315746307373,
                "spectral_norm": 1.0064946413040161,
                "num_singular_values": 8,
                "alpha": 2.518410908635499
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.001_batch_size_256_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.001,
            "batch_size": 256,
            "scaler_type": "minmax",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.070261150598526,
            "mse": 384386656.0,
            "mae": 1924.3968505859375,
            "r2_score": 0.9169671535491943,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.0157319363206625,
                "median": 0.013944730162620544,
                "std": 0.21017462015151978,
                "max": 0.6901854276657104,
                "min": -0.9945406317710876,
                "frobenius_norm": 5.840823650360107,
                "spectral_norm": 3.162626266479492,
                "num_singular_values": 12,
                "alpha": 2.080722876214529
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": -0.005471562035381794,
                "median": -0.00429762527346611,
                "std": 0.11132355779409409,
                "max": 0.5127695798873901,
                "min": -0.6569226980209351,
                "frobenius_norm": 7.133308410644531,
                "spectral_norm": 2.820617914199829,
                "num_singular_values": 64,
                "alpha": 1.1164988361760426
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.0028675294015556574,
                "median": 0.0002871858887374401,
                "std": 0.10340799391269684,
                "max": 0.650524914264679,
                "min": -0.4638579785823822,
                "frobenius_norm": 6.620655536651611,
                "spectral_norm": 2.8457448482513428,
                "num_singular_values": 64,
                "alpha": 1.0991726080541617
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.012934626080095768,
                "median": 0.015913454815745354,
                "std": 0.0767340287566185,
                "max": 0.3258667588233948,
                "min": -0.1992093175649643,
                "frobenius_norm": 1.7607876062393188,
                "spectral_norm": 0.8160779476165771,
                "num_singular_values": 8,
                "alpha": 2.466760133172694
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.0005_batch_size_16_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "identity",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.08158587664365768,
            "mse": 428500000.0,
            "mae": 1943.3270263671875,
            "r2_score": 0.9074380993843079,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.012010750360786915,
                "median": 0.012914201244711876,
                "std": 0.17086362838745117,
                "max": 0.3328661024570465,
                "min": -0.36611026525497437,
                "frobenius_norm": 4.746796131134033,
                "spectral_norm": 1.8149524927139282,
                "num_singular_values": 12,
                "alpha": 2.166608091564563
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.015036431141197681,
                "median": 0.014713665470480919,
                "std": 0.087179034948349,
                "max": 0.3546801805496216,
                "min": -0.24903979897499084,
                "frobenius_norm": 5.661840438842773,
                "spectral_norm": 2.971946954727173,
                "num_singular_values": 64,
                "alpha": 1.1119925409059097
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.013349535875022411,
                "median": 0.01592172682285309,
                "std": 0.08022628724575043,
                "max": 0.29402610659599304,
                "min": -0.24837572872638702,
                "frobenius_norm": 5.205080509185791,
                "spectral_norm": 2.0191500186920166,
                "num_singular_values": 64,
                "alpha": 1.117904500067684
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.026807770133018494,
                "median": 0.03312922269105911,
                "std": 0.07382654398679733,
                "max": 0.18329767882823944,
                "min": -0.12852860987186432,
                "frobenius_norm": 1.7772270441055298,
                "spectral_norm": 0.9088456034660339,
                "num_singular_values": 8,
                "alpha": 2.8225766224806197
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.0005_batch_size_16_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "standard",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.07027802616357803,
            "mse": 375719360.0,
            "mae": 1872.6318359375,
            "r2_score": 0.9188394546508789,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.01585654728114605,
                "median": 0.00667149480432272,
                "std": 0.19391022622585297,
                "max": 0.5440477728843689,
                "min": -0.6000534892082214,
                "frobenius_norm": 5.391734600067139,
                "spectral_norm": 2.1761815547943115,
                "num_singular_values": 12,
                "alpha": 2.3919283298544194
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.009979423135519028,
                "median": 0.009872149676084518,
                "std": 0.10017529129981995,
                "max": 0.4721549153327942,
                "min": -0.346926748752594,
                "frobenius_norm": 6.4429521560668945,
                "spectral_norm": 2.167210817337036,
                "num_singular_values": 64,
                "alpha": 1.1104826298196269
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.010301249101758003,
                "median": 0.009204601868987083,
                "std": 0.09842310845851898,
                "max": 0.4520407021045685,
                "min": -0.3981223702430725,
                "frobenius_norm": 6.333486080169678,
                "spectral_norm": 2.178964138031006,
                "num_singular_values": 64,
                "alpha": 1.1475400744250095
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.01693922095000744,
                "median": 0.019266996532678604,
                "std": 0.09250930696725845,
                "max": 0.2807312309741974,
                "min": -0.30700257420539856,
                "frobenius_norm": 2.128049373626709,
                "spectral_norm": 1.199885606765747,
                "num_singular_values": 8,
                "alpha": 2.5205393239502545
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.0005_batch_size_16_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "robust",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.06985247135162354,
            "mse": 364513088.0,
            "mae": 1821.6904296875,
            "r2_score": 0.9212601184844971,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.012395632453262806,
                "median": 0.009068838320672512,
                "std": 0.19356907904148102,
                "max": 0.4708743095397949,
                "min": -0.6593977212905884,
                "frobenius_norm": 5.375331878662109,
                "spectral_norm": 2.1515257358551025,
                "num_singular_values": 12,
                "alpha": 2.4161931934414893
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.012330938130617142,
                "median": 0.011097919195890427,
                "std": 0.10020510107278824,
                "max": 0.46818748116493225,
                "min": -0.3595455586910248,
                "frobenius_norm": 6.461501121520996,
                "spectral_norm": 2.220726490020752,
                "num_singular_values": 64,
                "alpha": 1.1193384752235274
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.01068828348070383,
                "median": 0.007730359211564064,
                "std": 0.09603675454854965,
                "max": 0.5050663352012634,
                "min": -0.3465343713760376,
                "frobenius_norm": 6.184299945831299,
                "spectral_norm": 2.16892147064209,
                "num_singular_values": 64,
                "alpha": 1.118330577813146
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.016662437468767166,
                "median": 0.017729058861732483,
                "std": 0.08069241791963577,
                "max": 0.21517999470233917,
                "min": -0.2045966237783432,
                "frobenius_norm": 1.8643814325332642,
                "spectral_norm": 0.9279236197471619,
                "num_singular_values": 8,
                "alpha": 2.670304660149023
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.0005_batch_size_16_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 16,
            "scaler_type": "minmax",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.07369136065244675,
            "mse": 448400064.0,
            "mae": 2040.2171630859375,
            "r2_score": 0.9031394124031067,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.018344230949878693,
                "median": 0.017696063965559006,
                "std": 0.1859317272901535,
                "max": 0.4994969367980957,
                "min": -0.6610999703407288,
                "frobenius_norm": 5.177708625793457,
                "spectral_norm": 2.391850233078003,
                "num_singular_values": 12,
                "alpha": 2.098083342911688
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.0027477345429360867,
                "median": 0.00345406960695982,
                "std": 0.08749430626630783,
                "max": 0.32018500566482544,
                "min": -0.35887056589126587,
                "frobenius_norm": 5.602396488189697,
                "spectral_norm": 1.9162495136260986,
                "num_singular_values": 64,
                "alpha": 1.129575450662206
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.004830994643270969,
                "median": 0.0065170517191290855,
                "std": 0.08616864681243896,
                "max": 0.4565967321395874,
                "min": -0.4046406149864197,
                "frobenius_norm": 5.523453712463379,
                "spectral_norm": 2.1311538219451904,
                "num_singular_values": 64,
                "alpha": 1.1309758532411616
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.015133129432797432,
                "median": 0.019767437130212784,
                "std": 0.0761185809969902,
                "max": 0.28612715005874634,
                "min": -0.17832006514072418,
                "frobenius_norm": 1.7560756206512451,
                "spectral_norm": 0.9017276167869568,
                "num_singular_values": 8,
                "alpha": 2.8397570929701192
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.0005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.07544613629579544,
            "mse": 415408800.0,
            "mae": 1898.3995361328125,
            "r2_score": 0.9102659821510315,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.013032100163400173,
                "median": 0.012398398481309414,
                "std": 0.1723940223455429,
                "max": 0.33367452025413513,
                "min": -0.3829726576805115,
                "frobenius_norm": 4.791154861450195,
                "spectral_norm": 1.8531224727630615,
                "num_singular_values": 12,
                "alpha": 2.1623567377993673
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.013765192590653896,
                "median": 0.014004412107169628,
                "std": 0.09077970683574677,
                "max": 0.36588868498802185,
                "min": -0.5078301429748535,
                "frobenius_norm": 5.876314163208008,
                "spectral_norm": 3.069032907485962,
                "num_singular_values": 64,
                "alpha": 1.1342155417512036
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.015424877405166626,
                "median": 0.017532847821712494,
                "std": 0.08374752104282379,
                "max": 0.323058158159256,
                "min": -0.23886863887310028,
                "frobenius_norm": 5.449995517730713,
                "spectral_norm": 2.4826254844665527,
                "num_singular_values": 64,
                "alpha": 1.106737941012338
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.027697056531906128,
                "median": 0.035119034349918365,
                "std": 0.07603531330823898,
                "max": 0.21587863564491272,
                "min": -0.16870713233947754,
                "frobenius_norm": 1.8310734033584595,
                "spectral_norm": 0.9461997747421265,
                "num_singular_values": 8,
                "alpha": 2.746669385355262
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.0005_batch_size_32_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "standard",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.07072152197360992,
            "mse": 359733568.0,
            "mae": 1912.39013671875,
            "r2_score": 0.9222925901412964,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.013623942621052265,
                "median": -0.0007551435264758766,
                "std": 0.19703903794288635,
                "max": 0.4891701936721802,
                "min": -0.6775394082069397,
                "frobenius_norm": 5.473543167114258,
                "spectral_norm": 2.1986582279205322,
                "num_singular_values": 12,
                "alpha": 2.3995841929042214
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.0096729202196002,
                "median": 0.010660353116691113,
                "std": 0.10378793627023697,
                "max": 0.41689053177833557,
                "min": -0.47214463353157043,
                "frobenius_norm": 6.671213626861572,
                "spectral_norm": 2.310518503189087,
                "num_singular_values": 64,
                "alpha": 1.0728173550373876
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.012414767406880856,
                "median": 0.009936979971826077,
                "std": 0.10366443544626236,
                "max": 0.4478462040424347,
                "min": -0.35956859588623047,
                "frobenius_norm": 6.681931495666504,
                "spectral_norm": 2.4621870517730713,
                "num_singular_values": 64,
                "alpha": 1.1237031822701544
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.019072843715548515,
                "median": 0.020406294614076614,
                "std": 0.0965133011341095,
                "max": 0.33773118257522583,
                "min": -0.280811071395874,
                "frobenius_norm": 2.226081371307373,
                "spectral_norm": 1.3577810525894165,
                "num_singular_values": 8,
                "alpha": 2.5525051375576986
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.0005_batch_size_32_scaler_type_robust": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "robust",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.07084701955318451,
            "mse": 363065760.0,
            "mae": 1863.2269287109375,
            "r2_score": 0.9215728044509888,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.009905506856739521,
                "median": 0.008665296249091625,
                "std": 0.19485266506671906,
                "max": 0.48858845233917236,
                "min": -0.6332771182060242,
                "frobenius_norm": 5.406888484954834,
                "spectral_norm": 2.28410267829895,
                "num_singular_values": 12,
                "alpha": 2.5095665398009963
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.011275050230324268,
                "median": 0.011194344609975815,
                "std": 0.10283854603767395,
                "max": 0.47629424929618835,
                "min": -0.41527876257896423,
                "frobenius_norm": 6.6211066246032715,
                "spectral_norm": 2.1487154960632324,
                "num_singular_values": 64,
                "alpha": 1.0889799361847017
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.012200657278299332,
                "median": 0.010394955053925514,
                "std": 0.10036065429449081,
                "max": 0.4775239825248718,
                "min": -0.4107449948787689,
                "frobenius_norm": 6.470370769500732,
                "spectral_norm": 2.347229242324829,
                "num_singular_values": 64,
                "alpha": 1.0761776149712736
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.014953992329537868,
                "median": 0.016819309443235397,
                "std": 0.0881672352552414,
                "max": 0.2622889280319214,
                "min": -0.39953380823135376,
                "frobenius_norm": 2.0234885215759277,
                "spectral_norm": 1.0922901630401611,
                "num_singular_values": 8,
                "alpha": 2.3315771175732456
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.0005_batch_size_32_scaler_type_minmax": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "minmax",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.07306191325187683,
            "mse": 432992384.0,
            "mae": 2005.7236328125,
            "r2_score": 0.9064676761627197,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.01638571359217167,
                "median": 0.013591436669230461,
                "std": 0.1896204799413681,
                "max": 0.5306015610694885,
                "min": -0.6902437806129456,
                "frobenius_norm": 5.274499893188477,
                "spectral_norm": 2.5124261379241943,
                "num_singular_values": 12,
                "alpha": 2.207110787635771
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.0050979661755263805,
                "median": 0.0049127256497740746,
                "std": 0.09188437461853027,
                "max": 0.49662694334983826,
                "min": -0.4148366153240204,
                "frobenius_norm": 5.889644145965576,
                "spectral_norm": 1.8820754289627075,
                "num_singular_values": 64,
                "alpha": 1.094254989357428
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.0038228402845561504,
                "median": 0.004680932499468327,
                "std": 0.08744645118713379,
                "max": 0.406248539686203,
                "min": -0.4387739598751068,
                "frobenius_norm": 5.6019182205200195,
                "spectral_norm": 1.9587833881378174,
                "num_singular_values": 64,
                "alpha": 1.1121023435340227
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.013292942196130753,
                "median": 0.018144531175494194,
                "std": 0.08221325278282166,
                "max": 0.29861655831336975,
                "min": -0.3595622777938843,
                "frobenius_norm": 1.884433388710022,
                "spectral_norm": 0.9942284822463989,
                "num_singular_values": 8,
                "alpha": 2.549018815338634
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.0005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.07749061286449432,
            "mse": 416179648.0,
            "mae": 1889.525146484375,
            "r2_score": 0.910099446773529,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.014314938336610794,
                "median": 0.013631769455969334,
                "std": 0.17265112698078156,
                "max": 0.3570396602153778,
                "min": -0.4170229434967041,
                "frobenius_norm": 4.8010663986206055,
                "spectral_norm": 1.8738021850585938,
                "num_singular_values": 12,
                "alpha": 2.148708615962275
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.014304904267191887,
                "median": 0.015043281018733978,
                "std": 0.09188764542341232,
                "max": 0.36783185601234436,
                "min": -0.3091650605201721,
                "frobenius_norm": 5.951645374298096,
                "spectral_norm": 2.936164140701294,
                "num_singular_values": 64,
                "alpha": 1.0894357128313117
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.01453335676342249,
                "median": 0.016335032880306244,
                "std": 0.08480744808912277,
                "max": 0.6061508059501648,
                "min": -0.267192006111145,
                "frobenius_norm": 5.506798267364502,
                "spectral_norm": 2.4985435009002686,
                "num_singular_values": 64,
                "alpha": 1.1345369061204544
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.02431551367044449,
                "median": 0.03520917147397995,
                "std": 0.07770822942256927,
                "max": 0.20566891133785248,
                "min": -0.20070508122444153,
                "frobenius_norm": 1.8424072265625,
                "spectral_norm": 0.9619153738021851,
                "num_singular_values": 8,
                "alpha": 2.761332303915299
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_64_learning_rate_0.0005_batch_size_64_scaler_type_standard": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 64,
            "max_steps": 1000,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "standard",
            "total_params": 9672
        },
        "scores": {
            "smape": 0.0695924162864685,
            "mse": 349998976.0,
            "mae": 1838.332275390625,
            "r2_score": 0.9243953824043274,
            "sn_smape": 0.0828474834561348,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    64,
                    12
                ],
                "input_size": 12,
                "output_size": 64,
                "mean": 0.01695137470960617,
                "median": 0.008403011597692966,
                "std": 0.20047836005687714,
                "max": 0.5071176886558533,
                "min": -0.6785456538200378,
                "frobenius_norm": 5.575644493103027,
                "spectral_norm": 2.308830499649048,
                "num_singular_values": 12,
                "alpha": 2.3350509195670117
            },
            "mlp.1.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.011959496885538101,
                "median": 0.010788318701088428,
                "std": 0.10663466900587082,
                "max": 0.44985178112983704,
                "min": -0.3668140470981598,
                "frobenius_norm": 6.867406845092773,
                "spectral_norm": 2.3943800926208496,
                "num_singular_values": 64,
                "alpha": 1.0801534741488834
            },
            "mlp.2.weight": {
                "shape": [
                    64,
                    64
                ],
                "input_size": 64,
                "output_size": 64,
                "mean": 0.010266043245792389,
                "median": 0.008116979151964188,
                "std": 0.10457970947027206,
                "max": 0.4951602518558502,
                "min": -0.41057905554771423,
                "frobenius_norm": 6.7252726554870605,
                "spectral_norm": 2.48201322555542,
                "num_singular_values": 64,
                "alpha": 1.1212990532846594
            },
            "out.weight": {
                "shape": [
                    8,
                    64
                ],
                "input_size": 64,
                "output_size": 8,
                "mean": 0.012563527561724186,
                "median": 0.014810293912887573,
                "std": 0.09057372808456421,
                "max": 0.2716737687587738,
                "min": -0.3571039140224457,
                "frobenius_norm": 2.0690717697143555,
                "spectral_norm": 1.1418368816375732,
                "num_singular_values": 8,
                "alpha": 2.6229114220433307
            }
        }
    }
}