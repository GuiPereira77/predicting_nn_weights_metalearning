{
    "Gluonts_m1_monthly_hidden_size_8_max_steps_50_learning_rate_0.001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 50,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.7423017621040344,
            "mse": 4137029632.0,
            "mae": 9439.6640625,
            "r2_score": 0.10634458065032959,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.03157970309257507,
                "median": 0.024712810292840004,
                "std": 0.16027192771434784,
                "max": 0.3325093686580658,
                "min": -0.29003480076789856
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03891574591398239,
                "median": 0.06546647846698761,
                "std": 0.21819841861724854,
                "max": 0.3920753300189972,
                "min": -0.3257197141647339
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.029225826263427734,
                "median": -0.0007419028552249074,
                "std": 0.22331316769123077,
                "max": 0.3963049352169037,
                "min": -0.30932003259658813
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.050529345870018005,
                "median": 0.040278494358062744,
                "std": 0.19436654448509216,
                "max": 0.39272910356521606,
                "min": -0.27458009123802185
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_max_steps_50_learning_rate_0.001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 50,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.684407114982605,
            "mse": 3945809664.0,
            "mae": 8940.8115234375,
            "r2_score": 0.14765071868896484,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.03641599044203758,
                "median": 0.030588984489440918,
                "std": 0.16119910776615143,
                "max": 0.3406829237937927,
                "min": -0.2910064458847046
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03939542919397354,
                "median": 0.07043297588825226,
                "std": 0.21923358738422394,
                "max": 0.39284855127334595,
                "min": -0.3190559446811676
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03246604651212692,
                "median": 0.004891453310847282,
                "std": 0.22419720888137817,
                "max": 0.40341904759407043,
                "min": -0.3095804750919342
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.056772563606500626,
                "median": 0.048047758638858795,
                "std": 0.19528837502002716,
                "max": 0.40030184388160706,
                "min": -0.26965150237083435
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_max_steps_50_learning_rate_0.0005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 50,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.9031097888946533,
            "mse": 4613733376.0,
            "mae": 10534.541015625,
            "r2_score": 0.0033699870109558105,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.015947669744491577,
                "median": 0.012618097476661205,
                "std": 0.1579991728067398,
                "max": 0.30913469195365906,
                "min": -0.2815554141998291
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02919587679207325,
                "median": 0.06292124092578888,
                "std": 0.21297425031661987,
                "max": 0.36392325162887573,
                "min": -0.3276023268699646
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.019566215574741364,
                "median": -0.0014926332514733076,
                "std": 0.2209070473909378,
                "max": 0.3713206946849823,
                "min": -0.3072082996368408
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.029206199571490288,
                "median": 0.01692722737789154,
                "std": 0.1931629478931427,
                "max": 0.3684554696083069,
                "min": -0.29832467436790466
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_max_steps_50_learning_rate_0.0005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 50,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.8844538927078247,
            "mse": 4566347264.0,
            "mae": 10427.2314453125,
            "r2_score": 0.013606011867523193,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.018589088693261147,
                "median": 0.016836529597640038,
                "std": 0.1582978367805481,
                "max": 0.3133889138698578,
                "min": -0.28246697783470154
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.029459461569786072,
                "median": 0.06361763924360275,
                "std": 0.2136545479297638,
                "max": 0.36447739601135254,
                "min": -0.32416021823883057
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.020720481872558594,
                "median": -0.0018072482198476791,
                "std": 0.22126615047454834,
                "max": 0.3752014935016632,
                "min": -0.30709409713745117
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03240808844566345,
                "median": 0.020714960992336273,
                "std": 0.19348664581775665,
                "max": 0.37244096398353577,
                "min": -0.29701852798461914
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_max_steps_50_learning_rate_0.0001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 50,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.9590868353843689,
            "mse": 4741926400.0,
            "mae": 10835.4306640625,
            "r2_score": -0.024321436882019043,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.00592054845765233,
                "median": 0.010175094939768314,
                "std": 0.15676888823509216,
                "max": 0.2913275957107544,
                "min": -0.27839669585227966
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.022892167791724205,
                "median": 0.0606972798705101,
                "std": 0.21092352271080017,
                "max": 0.3546464145183563,
                "min": -0.33142873644828796
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.013200467452406883,
                "median": -0.000756189925596118,
                "std": 0.22105762362480164,
                "max": 0.3522285521030426,
                "min": -0.3146611154079437
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01308475062251091,
                "median": -0.0009171105921268463,
                "std": 0.19218744337558746,
                "max": 0.3499610424041748,
                "min": -0.31976065039634705
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_max_steps_50_learning_rate_0.0001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 50,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.9576137065887451,
            "mse": 4739388416.0,
            "mae": 10828.9169921875,
            "r2_score": -0.023773193359375,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.006306282710283995,
                "median": 0.01028564665466547,
                "std": 0.15681339800357819,
                "max": 0.2922185957431793,
                "min": -0.2774549722671509
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0229994747787714,
                "median": 0.06083550304174423,
                "std": 0.21102140843868256,
                "max": 0.35475462675094604,
                "min": -0.3307732939720154
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.013398682698607445,
                "median": -0.0011453796178102493,
                "std": 0.22107045352458954,
                "max": 0.35294172167778015,
                "min": -0.31444841623306274
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.013669546693563461,
                "median": -0.00023496989160776138,
                "std": 0.1922142058610916,
                "max": 0.350677490234375,
                "min": -0.319856733083725
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_max_steps_100_learning_rate_0.001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 100,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.2829950451850891,
            "mse": 2427646208.0,
            "mae": 5346.244140625,
            "r2_score": 0.47559499740600586,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06494813412427902,
                "median": 0.054691560566425323,
                "std": 0.16567175090312958,
                "max": 0.37471428513526917,
                "min": -0.2927524149417877
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.057836417108774185,
                "median": 0.08017195016145706,
                "std": 0.22887195646762848,
                "max": 0.45294904708862305,
                "min": -0.32566338777542114
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05459243059158325,
                "median": 0.003961981274187565,
                "std": 0.22941263020038605,
                "max": 0.4333634674549103,
                "min": -0.30428311228752136
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0968356803059578,
                "median": 0.10132460296154022,
                "std": 0.19398607313632965,
                "max": 0.428039014339447,
                "min": -0.25603270530700684
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_max_steps_100_learning_rate_0.001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 100,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.22623243927955627,
            "mse": 2037391488.0,
            "mae": 4698.0224609375,
            "r2_score": 0.559895396232605,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06794863194227219,
                "median": 0.059935033321380615,
                "std": 0.16590125858783722,
                "max": 0.37804633378982544,
                "min": -0.29473719000816345
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05467534810304642,
                "median": 0.07793748378753662,
                "std": 0.22932672500610352,
                "max": 0.44827038049697876,
                "min": -0.3198707103729248
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05651719868183136,
                "median": 0.00752782728523016,
                "std": 0.23020370304584503,
                "max": 0.4379962980747223,
                "min": -0.30595746636390686
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.103457972407341,
                "median": 0.11152352392673492,
                "std": 0.19404123723506927,
                "max": 0.4406024217605591,
                "min": -0.25811585783958435
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_max_steps_100_learning_rate_0.0005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 100,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.6872063875198364,
            "mse": 3956495616.0,
            "mae": 8974.6533203125,
            "r2_score": 0.1453424096107483,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.03686225786805153,
                "median": 0.029550207778811455,
                "std": 0.16032631695270538,
                "max": 0.3381619155406952,
                "min": -0.28619933128356934
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04134198650717735,
                "median": 0.07522359490394592,
                "std": 0.219950869679451,
                "max": 0.4004194736480713,
                "min": -0.32703182101249695
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.032283686101436615,
                "median": 0.0073598166927695274,
                "std": 0.22427168488502502,
                "max": 0.4046527147293091,
                "min": -0.30732616782188416
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05502310022711754,
                "median": 0.043453335762023926,
                "std": 0.19504468142986298,
                "max": 0.39968639612197876,
                "min": -0.26449137926101685
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_max_steps_100_learning_rate_0.0005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 100,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.6218982934951782,
            "mse": 3731763968.0,
            "mae": 8411.7666015625,
            "r2_score": 0.1938875913619995,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.04207159951329231,
                "median": 0.03489205986261368,
                "std": 0.16116367280483246,
                "max": 0.3457154333591461,
                "min": -0.28720492124557495
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.043471239507198334,
                "median": 0.07769966870546341,
                "std": 0.22192218899726868,
                "max": 0.405965656042099,
                "min": -0.32371941208839417
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03582660108804703,
                "median": 0.007123289164155722,
                "std": 0.22540879249572754,
                "max": 0.4125007390975952,
                "min": -0.30667844414711
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06178808957338333,
                "median": 0.05130942910909653,
                "std": 0.19559246301651,
                "max": 0.40716737508773804,
                "min": -0.2602088749408722
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_max_steps_100_learning_rate_0.0001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 100,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.9494057297706604,
            "mse": 4724684800.0,
            "mae": 10789.494140625,
            "r2_score": -0.020596981048583984,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.008572920225560665,
                "median": 0.010754893533885479,
                "std": 0.15697409212589264,
                "max": 0.2956911325454712,
                "min": -0.27385514974594116
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.024523941799998283,
                "median": 0.061313971877098083,
                "std": 0.21134082973003387,
                "max": 0.35667911171913147,
                "min": -0.3308635652065277
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.014761061407625675,
                "median": -0.001697268569841981,
                "std": 0.22096140682697296,
                "max": 0.3570335805416107,
                "min": -0.3124253749847412
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.016878454014658928,
                "median": 0.003475307486951351,
                "std": 0.1924348920583725,
                "max": 0.354585736989975,
                "min": -0.3152273893356323
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_max_steps_100_learning_rate_0.0001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 100,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.9451817274093628,
            "mse": 4716806144.0,
            "mae": 10769.83984375,
            "r2_score": -0.01889514923095703,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.009515617042779922,
                "median": 0.010310256853699684,
                "std": 0.15705373883247375,
                "max": 0.29740622639656067,
                "min": -0.27379658818244934
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02478913962841034,
                "median": 0.06161419302225113,
                "std": 0.2116430401802063,
                "max": 0.35724353790283203,
                "min": -0.33018919825553894
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.015333613380789757,
                "median": -0.001729173120111227,
                "std": 0.22085627913475037,
                "max": 0.35868045687675476,
                "min": -0.3107004463672638
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01837739907205105,
                "median": 0.004974305164068937,
                "std": 0.19251173734664917,
                "max": 0.3561546206474304,
                "min": -0.3133490979671478
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_max_steps_200_learning_rate_0.001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 200,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.08449532091617584,
            "mse": 499476160.0,
            "mae": 1991.6978759765625,
            "r2_score": 0.892106294631958,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.07231352478265762,
                "median": 0.0666508823633194,
                "std": 0.16336189210414886,
                "max": 0.3736492097377777,
                "min": -0.2960950434207916
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06133019179105759,
                "median": 0.08236056566238403,
                "std": 0.2298939824104309,
                "max": 0.45046544075012207,
                "min": -0.3256259262561798
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08090242743492126,
                "median": 0.02571212314069271,
                "std": 0.23861201107501984,
                "max": 0.563924252986908,
                "min": -0.30399090051651
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.11242853105068207,
                "median": 0.11974489688873291,
                "std": 0.19134420156478882,
                "max": 0.49926838278770447,
                "min": -0.26221340894699097
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_max_steps_200_learning_rate_0.001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 200,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.08297315239906311,
            "mse": 503511488.0,
            "mae": 1984.16650390625,
            "r2_score": 0.8912345767021179,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.07270589470863342,
                "median": 0.07021927088499069,
                "std": 0.16359400749206543,
                "max": 0.37445613741874695,
                "min": -0.2967087924480438
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.057453837245702744,
                "median": 0.08437429368495941,
                "std": 0.23012925684452057,
                "max": 0.44858163595199585,
                "min": -0.3627253770828247
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0791652575135231,
                "median": 0.030112668871879578,
                "std": 0.2392161786556244,
                "max": 0.5606826543807983,
                "min": -0.30607128143310547
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.11468861997127533,
                "median": 0.1192440316081047,
                "std": 0.19231872260570526,
                "max": 0.507710337638855,
                "min": -0.26304957270622253
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_max_steps_200_learning_rate_0.0005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 200,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.28003889322280884,
            "mse": 2247931648.0,
            "mae": 5014.0869140625,
            "r2_score": 0.5144157409667969,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06521576642990112,
                "median": 0.05602771043777466,
                "std": 0.16375549137592316,
                "max": 0.37565678358078003,
                "min": -0.287335067987442
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06331680715084076,
                "median": 0.07808166742324829,
                "std": 0.2268303781747818,
                "max": 0.45613521337509155,
                "min": -0.31554844975471497
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05333993211388588,
                "median": 0.005140185356140137,
                "std": 0.23097379505634308,
                "max": 0.4349516034126282,
                "min": -0.3044399917125702
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08977088332176208,
                "median": 0.08216384053230286,
                "std": 0.19225135445594788,
                "max": 0.43570148944854736,
                "min": -0.26034149527549744
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_max_steps_200_learning_rate_0.0005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 200,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.18227890133857727,
            "mse": 1564871168.0,
            "mae": 3917.11962890625,
            "r2_score": 0.6619662642478943,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.06604088097810745,
                "median": 0.05450580269098282,
                "std": 0.16486608982086182,
                "max": 0.3738310933113098,
                "min": -0.29331541061401367
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05741189047694206,
                "median": 0.08314672112464905,
                "std": 0.22926835715770721,
                "max": 0.4540635943412781,
                "min": -0.3238242268562317
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05863406881690025,
                "median": 0.007144362665712833,
                "std": 0.23043613135814667,
                "max": 0.444913387298584,
                "min": -0.29895707964897156
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.1035037711262703,
                "median": 0.11767889559268951,
                "std": 0.19267761707305908,
                "max": 0.45173802971839905,
                "min": -0.26021715998649597
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_max_steps_200_learning_rate_0.0001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 200,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.9171518683433533,
            "mse": 4651126272.0,
            "mae": 10615.740234375,
            "r2_score": -0.00470733642578125,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.015194066800177097,
                "median": 0.010978732258081436,
                "std": 0.15737955272197723,
                "max": 0.30540192127227783,
                "min": -0.27751314640045166
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.027463402599096298,
                "median": 0.06317105889320374,
                "std": 0.21266880631446838,
                "max": 0.3620261549949646,
                "min": -0.32871976494789124
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01848183386027813,
                "median": -0.002662369981408119,
                "std": 0.22089883685112,
                "max": 0.368415504693985,
                "min": -0.3080254793167114
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.026032892987132072,
                "median": 0.013153084553778172,
                "std": 0.19303283095359802,
                "max": 0.3652210831642151,
                "min": -0.29998305439949036
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_8_max_steps_200_learning_rate_0.0001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 200,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 320
        },
        "scores": {
            "smape": 0.8969840407371521,
            "mse": 4600865280.0,
            "mae": 10503.4443359375,
            "r2_score": 0.006149709224700928,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    12
                ],
                "input_size": 12,
                "output_size": 8,
                "mean": 0.01809992827475071,
                "median": 0.014942505396902561,
                "std": 0.15762946009635925,
                "max": 0.3100868761539459,
                "min": -0.2779616117477417
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02839340828359127,
                "median": 0.06257270276546478,
                "std": 0.2135372906923294,
                "max": 0.36447063088417053,
                "min": -0.32817086577415466
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02000114694237709,
                "median": -0.0030887224711477757,
                "std": 0.22098380327224731,
                "max": 0.3736096918582916,
                "min": -0.3062346875667572
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02995581552386284,
                "median": 0.017438964918255806,
                "std": 0.19331762194633484,
                "max": 0.3699854016304016,
                "min": -0.29466894268989563
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_max_steps_50_learning_rate_0.001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 50,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.7574468851089478,
            "mse": 3491712768.0,
            "mae": 9412.4423828125,
            "r2_score": 0.24574190378189087,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.017568789422512054,
                "median": 0.015394280664622784,
                "std": 0.16496755182743073,
                "max": 0.3353158235549927,
                "min": -0.2900935709476471
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.018274569883942604,
                "median": 0.00744206877425313,
                "std": 0.1479744166135788,
                "max": 0.29800036549568176,
                "min": -0.2645414173603058
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.0051509058102965355,
                "median": -0.026719985529780388,
                "std": 0.14880426228046417,
                "max": 0.293561726808548,
                "min": -0.28128084540367126
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.014282967895269394,
                "median": 0.0026191810611635447,
                "std": 0.14541439712047577,
                "max": 0.2822011709213257,
                "min": -0.2306060492992401
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_max_steps_50_learning_rate_0.001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 50,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.6963914632797241,
            "mse": 3138337536.0,
            "mae": 8865.654296875,
            "r2_score": 0.32207590341567993,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.020072273910045624,
                "median": 0.01671421527862549,
                "std": 0.16591517627239227,
                "max": 0.3415069580078125,
                "min": -0.2934035062789917
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.020380571484565735,
                "median": 0.007822195999324322,
                "std": 0.14873529970645905,
                "max": 0.30332961678504944,
                "min": -0.2667173445224762
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.004021890461444855,
                "median": -0.022266162559390068,
                "std": 0.14984041452407837,
                "max": 0.30026140809059143,
                "min": -0.280810683965683
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.016929877921938896,
                "median": 0.007379927672445774,
                "std": 0.14638100564479828,
                "max": 0.29153549671173096,
                "min": -0.23504969477653503
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_max_steps_50_learning_rate_0.0005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 50,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.9163761138916016,
            "mse": 4392515072.0,
            "mae": 10586.421875,
            "r2_score": 0.05115622282028198,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.010146996937692165,
                "median": 0.015129421837627888,
                "std": 0.16338399052619934,
                "max": 0.3097711205482483,
                "min": -0.28114381432533264
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.007452333811670542,
                "median": 0.0006613799487240613,
                "std": 0.1455949991941452,
                "max": 0.2697438597679138,
                "min": -0.2551443576812744
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.008067522197961807,
                "median": -0.02533402107656002,
                "std": 0.14613892138004303,
                "max": 0.2695322334766388,
                "min": -0.26628679037094116
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": -0.00034030433744192123,
                "median": -0.016286853700876236,
                "std": 0.14396412670612335,
                "max": 0.2665063738822937,
                "min": -0.2364896982908249
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_max_steps_50_learning_rate_0.0005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 50,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.9007954001426697,
            "mse": 4308105728.0,
            "mae": 10487.1767578125,
            "r2_score": 0.06938976049423218,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.01064212340861559,
                "median": 0.01314806379377842,
                "std": 0.16364005208015442,
                "max": 0.3128008544445038,
                "min": -0.2822102904319763
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.008603844791650772,
                "median": 0.0006909592193551362,
                "std": 0.14581061899662018,
                "max": 0.27403515577316284,
                "min": -0.2587989866733551
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.007852545008063316,
                "median": -0.02277686819434166,
                "std": 0.14647331833839417,
                "max": 0.2727608382701874,
                "min": -0.26920440793037415
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.0008922526612877846,
                "median": -0.013445526361465454,
                "std": 0.14428630471229553,
                "max": 0.26898080110549927,
                "min": -0.23667296767234802
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_max_steps_50_learning_rate_0.0001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 50,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.9681883454322815,
            "mse": 4756119552.0,
            "mae": 10966.37109375,
            "r2_score": -0.027387380599975586,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.007709152530878782,
                "median": 0.011037839576601982,
                "std": 0.16330179572105408,
                "max": 0.29210931062698364,
                "min": -0.28095343708992004
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.003284116741269827,
                "median": 0.003956287633627653,
                "std": 0.14389635622501373,
                "max": 0.2522182762622833,
                "min": -0.24938754737377167
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.008245011791586876,
                "median": -0.024205181747674942,
                "std": 0.1447998583316803,
                "max": 0.24928069114685059,
                "min": -0.25099095702171326
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": -0.013877206481993198,
                "median": -0.02971745654940605,
                "std": 0.14372120797634125,
                "max": 0.25066667795181274,
                "min": -0.2407037317752838
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_max_steps_50_learning_rate_0.0001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 50,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.9677618741989136,
            "mse": 4743351808.0,
            "mae": 10953.068359375,
            "r2_score": -0.02462935447692871,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.0076384712010622025,
                "median": 0.010556825436651707,
                "std": 0.16329410672187805,
                "max": 0.2926796078681946,
                "min": -0.28151968121528625
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.003265989013016224,
                "median": 0.00377819687128067,
                "std": 0.14397525787353516,
                "max": 0.2529504597187042,
                "min": -0.2501574456691742
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.008269540965557098,
                "median": -0.023564673960208893,
                "std": 0.1448419988155365,
                "max": 0.24979877471923828,
                "min": -0.25151684880256653
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": -0.013614121824502945,
                "median": -0.029086515307426453,
                "std": 0.14374475181102753,
                "max": 0.2503257095813751,
                "min": -0.24074651300907135
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_max_steps_100_learning_rate_0.001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 100,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.22282961010932922,
            "mse": 881004608.0,
            "mae": 3824.657958984375,
            "r2_score": 0.8096908330917358,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.037220317870378494,
                "median": 0.04157005250453949,
                "std": 0.1684904843568802,
                "max": 0.37011009454727173,
                "min": -0.29548484086990356
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.03970445692539215,
                "median": 0.030143598094582558,
                "std": 0.15220780670642853,
                "max": 0.33621886372566223,
                "min": -0.2652377486228943
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.00746155995875597,
                "median": -0.0157152209430933,
                "std": 0.15546542406082153,
                "max": 0.3310289978981018,
                "min": -0.28393980860710144
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.0360896922647953,
                "median": 0.04560172185301781,
                "std": 0.1503916233778,
                "max": 0.32151854038238525,
                "min": -0.22867238521575928
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_max_steps_100_learning_rate_0.001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 100,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.1264321506023407,
            "mse": 550781184.0,
            "mae": 2694.387451171875,
            "r2_score": 0.881023645401001,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.04077186435461044,
                "median": 0.05144840478897095,
                "std": 0.16972477734088898,
                "max": 0.37081557512283325,
                "min": -0.3002872169017792
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.040484774857759476,
                "median": 0.028365205973386765,
                "std": 0.15272483229637146,
                "max": 0.3362956643104553,
                "min": -0.2676451504230499
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.011328521184623241,
                "median": -0.012556832283735275,
                "std": 0.15567129850387573,
                "max": 0.3313984274864197,
                "min": -0.2782524824142456
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.039287738502025604,
                "median": 0.04485302418470383,
                "std": 0.1525145322084427,
                "max": 0.3346399664878845,
                "min": -0.23488818109035492
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_max_steps_100_learning_rate_0.0005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 100,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.6852506995201111,
            "mse": 3070536960.0,
            "mae": 8763.3212890625,
            "r2_score": 0.33672165870666504,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.02319186180830002,
                "median": 0.021298695355653763,
                "std": 0.16542619466781616,
                "max": 0.33956554532051086,
                "min": -0.29170504212379456
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.020245002582669258,
                "median": 0.009885434061288834,
                "std": 0.14878080785274506,
                "max": 0.3043515086174011,
                "min": -0.2619676887989044
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.001204722560942173,
                "median": -0.023623347282409668,
                "std": 0.14957384765148163,
                "max": 0.30316105484962463,
                "min": -0.28334298729896545
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.015628110617399216,
                "median": 0.007520526181906462,
                "std": 0.1470068097114563,
                "max": 0.29920920729637146,
                "min": -0.23475651443004608
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_max_steps_100_learning_rate_0.0005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 100,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.5918310284614563,
            "mse": 2535584768.0,
            "mae": 7776.7001953125,
            "r2_score": 0.4522787928581238,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.02841510809957981,
                "median": 0.026813929900527,
                "std": 0.16628241539001465,
                "max": 0.3471717834472656,
                "min": -0.29223209619522095
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.02513221837580204,
                "median": 0.013484345749020576,
                "std": 0.1499369889497757,
                "max": 0.3137572407722473,
                "min": -0.26517120003700256
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0007069231942296028,
                "median": -0.021298494189977646,
                "std": 0.15066805481910706,
                "max": 0.31046903133392334,
                "min": -0.2787582278251648
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.01879267208278179,
                "median": 0.012721369042992592,
                "std": 0.14854104816913605,
                "max": 0.304499089717865,
                "min": -0.235655277967453
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_max_steps_100_learning_rate_0.0001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 100,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.9616487622261047,
            "mse": 4670891008.0,
            "mae": 10880.2978515625,
            "r2_score": -0.00897681713104248,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.008367589674890041,
                "median": 0.011670470237731934,
                "std": 0.16321787238121033,
                "max": 0.2977968454360962,
                "min": -0.28215885162353516
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.003953174222260714,
                "median": 0.0019128296989947557,
                "std": 0.14426203072071075,
                "max": 0.2570855915546417,
                "min": -0.2535144090652466
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.008373256772756577,
                "median": -0.025792736560106277,
                "std": 0.14502713084220886,
                "max": 0.25440385937690735,
                "min": -0.2529546320438385
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": -0.010632053948938847,
                "median": -0.02589433826506138,
                "std": 0.14374876022338867,
                "max": 0.2525882422924042,
                "min": -0.23974370956420898
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_max_steps_100_learning_rate_0.0001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 100,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.9581038951873779,
            "mse": 4639066624.0,
            "mae": 10849.294921875,
            "r2_score": -0.002102375030517578,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.00852945726364851,
                "median": 0.01191534474492073,
                "std": 0.16320930421352386,
                "max": 0.29898595809936523,
                "min": -0.28187084197998047
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.00429938267916441,
                "median": 0.0006867516785860062,
                "std": 0.1444680094718933,
                "max": 0.25890859961509705,
                "min": -0.254287451505661
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.008451348170638084,
                "median": -0.025803042575716972,
                "std": 0.14517256617546082,
                "max": 0.25628048181533813,
                "min": -0.2547561526298523
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": -0.009746274910867214,
                "median": -0.024980071932077408,
                "std": 0.143803671002388,
                "max": 0.25314292311668396,
                "min": -0.23880508542060852
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_max_steps_200_learning_rate_0.001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 200,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.0859740749001503,
            "mse": 515921856.0,
            "mae": 2065.69873046875,
            "r2_score": 0.8885537385940552,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.042337048798799515,
                "median": 0.0430549681186676,
                "std": 0.1689382791519165,
                "max": 0.372455894947052,
                "min": -0.30115461349487305
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.04983074590563774,
                "median": 0.041790664196014404,
                "std": 0.15735359489917755,
                "max": 0.3933742344379425,
                "min": -0.26524168252944946
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.01540903840214014,
                "median": -0.008699711412191391,
                "std": 0.1616399884223938,
                "max": 0.38699421286582947,
                "min": -0.2839585840702057
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.040435969829559326,
                "median": 0.04098823666572571,
                "std": 0.15090134739875793,
                "max": 0.3618602454662323,
                "min": -0.22865867614746094
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_max_steps_200_learning_rate_0.001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 200,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.0853986069560051,
            "mse": 534892608.0,
            "mae": 2081.041015625,
            "r2_score": 0.8844558000564575,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.04276643693447113,
                "median": 0.05566815659403801,
                "std": 0.17013289034366608,
                "max": 0.37469419836997986,
                "min": -0.3041258454322815
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.05204739421606064,
                "median": 0.043727852404117584,
                "std": 0.15895234048366547,
                "max": 0.41720789670944214,
                "min": -0.269019216299057
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.021248668432235718,
                "median": 0.008775196969509125,
                "std": 0.16215665638446808,
                "max": 0.3472607135772705,
                "min": -0.2782335579395294
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.04194260016083717,
                "median": 0.04426614195108414,
                "std": 0.153450608253479,
                "max": 0.3516710102558136,
                "min": -0.23488710820674896
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_max_steps_200_learning_rate_0.0005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 200,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.14320500195026398,
            "mse": 596416320.0,
            "mae": 2923.0615234375,
            "r2_score": 0.8711658716201782,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.04361219331622124,
                "median": 0.04854944720864296,
                "std": 0.16757440567016602,
                "max": 0.3667429983615875,
                "min": -0.2944577634334564
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.04185626655817032,
                "median": 0.02653469145298004,
                "std": 0.15304023027420044,
                "max": 0.34024813771247864,
                "min": -0.26228970289230347
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.014119908213615417,
                "median": -0.008215762674808502,
                "std": 0.15600769221782684,
                "max": 0.3316366672515869,
                "min": -0.2831948697566986
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.03634962439537048,
                "median": 0.047413118183612823,
                "std": 0.15314577519893646,
                "max": 0.32822319865226746,
                "min": -0.23471415042877197
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_max_steps_200_learning_rate_0.0005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 200,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.08838653564453125,
            "mse": 555578688.0,
            "mae": 2182.518310546875,
            "r2_score": 0.879987359046936,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.0464957021176815,
                "median": 0.05688895285129547,
                "std": 0.1693258136510849,
                "max": 0.3684924840927124,
                "min": -0.2991504371166229
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.04627327248454094,
                "median": 0.03075455129146576,
                "std": 0.15389180183410645,
                "max": 0.34998035430908203,
                "min": -0.26559680700302124
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.014196460135281086,
                "median": -0.005151616409420967,
                "std": 0.15605534613132477,
                "max": 0.33192235231399536,
                "min": -0.27763786911964417
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.036277759820222855,
                "median": 0.03898140415549278,
                "std": 0.15358535945415497,
                "max": 0.3484458327293396,
                "min": -0.23562656342983246
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_max_steps_200_learning_rate_0.0001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 200,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.926908552646637,
            "mse": 4452996608.0,
            "mae": 10655.0693359375,
            "r2_score": 0.03809136152267456,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.010809608735144138,
                "median": 0.016468524932861328,
                "std": 0.1632545292377472,
                "max": 0.307551771402359,
                "min": -0.28101715445518494
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.007354521192610264,
                "median": 0.0012159427860751748,
                "std": 0.1451501101255417,
                "max": 0.26756784319877625,
                "min": -0.25238803029060364
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.007233878597617149,
                "median": -0.02366711013019085,
                "std": 0.14578992128372192,
                "max": 0.2683318555355072,
                "min": -0.2639699876308441
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": -0.00414280965924263,
                "median": -0.01967470720410347,
                "std": 0.14404720067977905,
                "max": 0.2641094923019409,
                "min": -0.23838503658771515
            }
        }
    },
    "Gluonts_m1_monthly_hidden_size_16_max_steps_200_learning_rate_0.0001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 12,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 200,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 888
        },
        "scores": {
            "smape": 0.9068379998207092,
            "mse": 4345315328.0,
            "mae": 10530.0078125,
            "r2_score": 0.06135207414627075,
            "sn_smape": 0.0828474834561348,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    12
                ],
                "input_size": 12,
                "output_size": 16,
                "mean": 0.011846105568110943,
                "median": 0.01589944399893284,
                "std": 0.16340795159339905,
                "max": 0.31142622232437134,
                "min": -0.2825334370136261
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.009118679910898209,
                "median": 0.002529553370550275,
                "std": 0.14546412229537964,
                "max": 0.27191221714019775,
                "min": -0.25584670901298523
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.0069656153209507465,
                "median": -0.022204577922821045,
                "std": 0.14625054597854614,
                "max": 0.2734462320804596,
                "min": -0.26838448643684387
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": -0.002442338038235903,
                "median": -0.01803700253367424,
                "std": 0.1443459689617157,
                "max": 0.2673790156841278,
                "min": -0.23754586279392242
            }
        }
    },
    "Gluonts_m1_quarterly_hidden_size_8_max_steps_50_learning_rate_0.001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 4,
            "horizon": 2,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 50,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 202
        },
        "scores": {
            "smape": 0.8575335741043091,
            "mse": 5566464000.0,
            "mae": 16000.0703125,
            "r2_score": 0.08511823415756226,
            "sn_smape": 0.1293550431728363,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    4
                ],
                "input_size": 4,
                "output_size": 8,
                "mean": 0.038689300417900085,
                "median": 0.04940427094697952,
                "std": 0.239233136177063,
                "max": 0.506655752658844,
                "min": -0.48992717266082764
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.014811460860073566,
                "median": 0.0312528982758522,
                "std": 0.19520863890647888,
                "max": 0.38728049397468567,
                "min": -0.3139530122280121
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.019508155062794685,
                "median": 0.04967450723052025,
                "std": 0.2116749882698059,
                "max": 0.38847339153289795,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    2,
                    8
                ],
                "input_size": 8,
                "output_size": 2,
                "mean": 0.002882426604628563,
                "median": -0.04777775704860687,
                "std": 0.22958818078041077,
                "max": 0.382954478263855,
                "min": -0.27561938762664795
            }
        }
    },
    "Gluonts_m1_quarterly_hidden_size_8_max_steps_50_learning_rate_0.001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 4,
            "horizon": 2,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 50,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 202
        },
        "scores": {
            "smape": 0.8607997298240662,
            "mse": 5584192000.0,
            "mae": 16025.61328125,
            "r2_score": 0.08220446109771729,
            "sn_smape": 0.1293550431728363,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    4
                ],
                "input_size": 4,
                "output_size": 8,
                "mean": 0.03932265192270279,
                "median": 0.049331653863191605,
                "std": 0.23918479681015015,
                "max": 0.5052902698516846,
                "min": -0.4880122244358063
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.014615284278988838,
                "median": 0.03252049908041954,
                "std": 0.19546963274478912,
                "max": 0.38865429162979126,
                "min": -0.31343135237693787
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01937035843729973,
                "median": 0.05080694705247879,
                "std": 0.2117672562599182,
                "max": 0.3883967101573944,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    2,
                    8
                ],
                "input_size": 8,
                "output_size": 2,
                "mean": 0.002573776990175247,
                "median": -0.049092162400484085,
                "std": 0.22973935306072235,
                "max": 0.3834454119205475,
                "min": -0.2773522436618805
            }
        }
    },
    "Gluonts_m1_quarterly_hidden_size_8_max_steps_50_learning_rate_0.0005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 4,
            "horizon": 2,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 50,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 202
        },
        "scores": {
            "smape": 0.9161906838417053,
            "mse": 5969594880.0,
            "mae": 16607.73828125,
            "r2_score": 0.018861234188079834,
            "sn_smape": 0.1293550431728363,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    4
                ],
                "input_size": 4,
                "output_size": 8,
                "mean": 0.03389013186097145,
                "median": 0.04022369906306267,
                "std": 0.2380329668521881,
                "max": 0.49068325757980347,
                "min": -0.48254361748695374
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.010896074585616589,
                "median": 0.025450170040130615,
                "std": 0.19418953359127045,
                "max": 0.36949214339256287,
                "min": -0.32229650020599365
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.018749050796031952,
                "median": 0.054647430777549744,
                "std": 0.21047888696193695,
                "max": 0.36952149868011475,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    2,
                    8
                ],
                "input_size": 8,
                "output_size": 2,
                "mean": -0.008665140718221664,
                "median": -0.059365592896938324,
                "std": 0.22592231631278992,
                "max": 0.36343154311180115,
                "min": -0.29032284021377563
            }
        }
    },
    "Gluonts_m1_quarterly_hidden_size_8_max_steps_50_learning_rate_0.0005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 4,
            "horizon": 2,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 50,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 202
        },
        "scores": {
            "smape": 0.9170734882354736,
            "mse": 5988497408.0,
            "mae": 16633.978515625,
            "r2_score": 0.01575446128845215,
            "sn_smape": 0.1293550431728363,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    4
                ],
                "input_size": 4,
                "output_size": 8,
                "mean": 0.03435788303613663,
                "median": 0.03955676406621933,
                "std": 0.23793399333953857,
                "max": 0.4902328848838806,
                "min": -0.4804815948009491
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01085698138922453,
                "median": 0.02489481121301651,
                "std": 0.19429385662078857,
                "max": 0.3690265715122223,
                "min": -0.3225564956665039
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01876913011074066,
                "median": 0.05463872849941254,
                "std": 0.21049822866916656,
                "max": 0.36905917525291443,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    2,
                    8
                ],
                "input_size": 8,
                "output_size": 2,
                "mean": -0.009053729474544525,
                "median": -0.060202326625585556,
                "std": 0.22596152126789093,
                "max": 0.3631207346916199,
                "min": -0.2911739945411682
            }
        }
    },
    "Gluonts_m1_quarterly_hidden_size_8_max_steps_50_learning_rate_0.0001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 4,
            "horizon": 2,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 50,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 202
        },
        "scores": {
            "smape": 0.9428515434265137,
            "mse": 6381230080.0,
            "mae": 17198.75,
            "r2_score": -0.04879343509674072,
            "sn_smape": 0.1293550431728363,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    4
                ],
                "input_size": 4,
                "output_size": 8,
                "mean": 0.03102973662316799,
                "median": 0.02742157131433487,
                "std": 0.2376893162727356,
                "max": 0.47744500637054443,
                "min": -0.48564690351486206
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.010217278264462948,
                "median": 0.02112507075071335,
                "std": 0.19319334626197815,
                "max": 0.35534000396728516,
                "min": -0.33672571182250977
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.019627194851636887,
                "median": 0.05451032519340515,
                "std": 0.2102738618850708,
                "max": 0.3555825650691986,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    2,
                    8
                ],
                "input_size": 8,
                "output_size": 2,
                "mean": -0.01889118179678917,
                "median": -0.07094977051019669,
                "std": 0.22453464567661285,
                "max": 0.3490915298461914,
                "min": -0.3025349974632263
            }
        }
    },
    "Gluonts_m1_quarterly_hidden_size_8_max_steps_50_learning_rate_0.0001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 4,
            "horizon": 2,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 50,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 202
        },
        "scores": {
            "smape": 0.9431406259536743,
            "mse": 6386915328.0,
            "mae": 17206.416015625,
            "r2_score": -0.0497279167175293,
            "sn_smape": 0.1293550431728363,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    4
                ],
                "input_size": 4,
                "output_size": 8,
                "mean": 0.031089860945940018,
                "median": 0.02726629748940468,
                "std": 0.23767243325710297,
                "max": 0.47730040550231934,
                "min": -0.4857759177684784
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.010212959721684456,
                "median": 0.021027276292443275,
                "std": 0.1931932270526886,
                "max": 0.3551974594593048,
                "min": -0.3368507921695709
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.019613686949014664,
                "median": 0.054505009204149246,
                "std": 0.21026000380516052,
                "max": 0.35542407631874084,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    2,
                    8
                ],
                "input_size": 8,
                "output_size": 2,
                "mean": -0.018994733691215515,
                "median": -0.07111139595508575,
                "std": 0.22451329231262207,
                "max": 0.34893298149108887,
                "min": -0.3026987612247467
            }
        }
    },
    "Gluonts_m1_quarterly_hidden_size_8_max_steps_100_learning_rate_0.001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 4,
            "horizon": 2,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 100,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 202
        },
        "scores": {
            "smape": 0.5912752151489258,
            "mse": 3973623552.0,
            "mae": 13223.0693359375,
            "r2_score": 0.34691107273101807,
            "sn_smape": 0.1293550431728363,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    4
                ],
                "input_size": 4,
                "output_size": 8,
                "mean": 0.06070953607559204,
                "median": 0.0738772600889206,
                "std": 0.24489954113960266,
                "max": 0.5499328374862671,
                "min": -0.4956185817718506
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03760095685720444,
                "median": 0.052485398948192596,
                "std": 0.1986510157585144,
                "max": 0.43176692724227905,
                "min": -0.27617427706718445
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.030991168692708015,
                "median": 0.048301003873348236,
                "std": 0.21906022727489471,
                "max": 0.440023273229599,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    2,
                    8
                ],
                "input_size": 8,
                "output_size": 2,
                "mean": 0.027407504618167877,
                "median": -0.02609000727534294,
                "std": 0.24522988498210907,
                "max": 0.43674856424331665,
                "min": -0.259625643491745
            }
        }
    },
    "Gluonts_m1_quarterly_hidden_size_8_max_steps_100_learning_rate_0.001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 4,
            "horizon": 2,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 100,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 202
        },
        "scores": {
            "smape": 0.5849260687828064,
            "mse": 3932544512.0,
            "mae": 13141.458984375,
            "r2_score": 0.3536626696586609,
            "sn_smape": 0.1293550431728363,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    4
                ],
                "input_size": 4,
                "output_size": 8,
                "mean": 0.06193617731332779,
                "median": 0.07266928255558014,
                "std": 0.24505232274532318,
                "max": 0.5494105219841003,
                "min": -0.4925495386123657
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03720837086439133,
                "median": 0.05149954557418823,
                "std": 0.19920644164085388,
                "max": 0.43869540095329285,
                "min": -0.27606409788131714
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.031040489673614502,
                "median": 0.04942864179611206,
                "std": 0.2192509025335312,
                "max": 0.4426201283931732,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    2,
                    8
                ],
                "input_size": 8,
                "output_size": 2,
                "mean": 0.028476018458604813,
                "median": -0.026964180171489716,
                "std": 0.24602369964122772,
                "max": 0.440412312746048,
                "min": -0.2598859667778015
            }
        }
    },
    "Gluonts_m1_quarterly_hidden_size_8_max_steps_100_learning_rate_0.0005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 4,
            "horizon": 2,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 100,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 202
        },
        "scores": {
            "smape": 0.8517177700996399,
            "mse": 5530113536.0,
            "mae": 15938.7587890625,
            "r2_score": 0.09109258651733398,
            "sn_smape": 0.1293550431728363,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    4
                ],
                "input_size": 4,
                "output_size": 8,
                "mean": 0.04094453155994415,
                "median": 0.04989141970872879,
                "std": 0.2393789291381836,
                "max": 0.5072890520095825,
                "min": -0.48645803332328796
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.016693349927663803,
                "median": 0.03613102063536644,
                "std": 0.1953173130750656,
                "max": 0.3911013901233673,
                "min": -0.3083035349845886
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02076043374836445,
                "median": 0.052319541573524475,
                "std": 0.2123938798904419,
                "max": 0.39171192049980164,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    2,
                    8
                ],
                "input_size": 8,
                "output_size": 2,
                "mean": 0.0026064999401569366,
                "median": -0.04949376732110977,
                "std": 0.23193319141864777,
                "max": 0.38713693618774414,
                "min": -0.27620866894721985
            }
        }
    },
    "Gluonts_m1_quarterly_hidden_size_8_max_steps_100_learning_rate_0.0005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 4,
            "horizon": 2,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 100,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 202
        },
        "scores": {
            "smape": 0.8511119484901428,
            "mse": 5526691328.0,
            "mae": 15932.6572265625,
            "r2_score": 0.09165501594543457,
            "sn_smape": 0.1293550431728363,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    4
                ],
                "input_size": 4,
                "output_size": 8,
                "mean": 0.04165980964899063,
                "median": 0.049932993948459625,
                "std": 0.23932144045829773,
                "max": 0.5077282786369324,
                "min": -0.483596533536911
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01661854423582554,
                "median": 0.03565390408039093,
                "std": 0.19563591480255127,
                "max": 0.3912830650806427,
                "min": -0.309399276971817
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.020719485357403755,
                "median": 0.052147265523672104,
                "std": 0.21247944235801697,
                "max": 0.39225155115127563,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    2,
                    8
                ],
                "input_size": 8,
                "output_size": 2,
                "mean": 0.002944227308034897,
                "median": -0.04999241977930069,
                "std": 0.23206056654453278,
                "max": 0.387922078371048,
                "min": -0.2767751216888428
            }
        }
    },
    "Gluonts_m1_quarterly_hidden_size_8_max_steps_100_learning_rate_0.0001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 4,
            "horizon": 2,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 100,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 202
        },
        "scores": {
            "smape": 0.9365302920341492,
            "mse": 6275008000.0,
            "mae": 17049.951171875,
            "r2_score": -0.03133523464202881,
            "sn_smape": 0.1293550431728363,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    4
                ],
                "input_size": 4,
                "output_size": 8,
                "mean": 0.03175783157348633,
                "median": 0.030583839863538742,
                "std": 0.23771120607852936,
                "max": 0.48077860474586487,
                "min": -0.48235809803009033
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0102646853774786,
                "median": 0.021860677748918533,
                "std": 0.1934327334165573,
                "max": 0.3587535321712494,
                "min": -0.3332425057888031
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.019432557746767998,
                "median": 0.05454128980636597,
                "std": 0.21024353802204132,
                "max": 0.35904911160469055,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    2,
                    8
                ],
                "input_size": 8,
                "output_size": 2,
                "mean": -0.016349878162145615,
                "median": -0.06801807135343552,
                "std": 0.224897563457489,
                "max": 0.3526970148086548,
                "min": -0.29950690269470215
            }
        }
    },
    "Gluonts_m1_quarterly_hidden_size_8_max_steps_100_learning_rate_0.0001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 4,
            "horizon": 2,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 100,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 202
        },
        "scores": {
            "smape": 0.9365877509117126,
            "mse": 6277696512.0,
            "mae": 17053.498046875,
            "r2_score": -0.031777143478393555,
            "sn_smape": 0.1293550431728363,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    4
                ],
                "input_size": 4,
                "output_size": 8,
                "mean": 0.03180073946714401,
                "median": 0.030503148213028908,
                "std": 0.23770774900913239,
                "max": 0.48071160912513733,
                "min": -0.482382208108902
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.010384640656411648,
                "median": 0.021605215966701508,
                "std": 0.19340775907039642,
                "max": 0.35870829224586487,
                "min": -0.33324843645095825
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01941658928990364,
                "median": 0.05453479290008545,
                "std": 0.21027325093746185,
                "max": 0.35896825790405273,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    2,
                    8
                ],
                "input_size": 8,
                "output_size": 2,
                "mean": -0.016334880143404007,
                "median": -0.06811673939228058,
                "std": 0.22484472393989563,
                "max": 0.352647066116333,
                "min": -0.299608439207077
            }
        }
    },
    "Gluonts_m1_quarterly_hidden_size_8_max_steps_200_learning_rate_0.001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 4,
            "horizon": 2,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 200,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 202
        },
        "scores": {
            "smape": 0.06414565443992615,
            "mse": 192346928.0,
            "mae": 2551.757568359375,
            "r2_score": 0.9683866500854492,
            "sn_smape": 0.1293550431728363,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    4
                ],
                "input_size": 4,
                "output_size": 8,
                "mean": 0.11025753617286682,
                "median": 0.1659349948167801,
                "std": 0.25841647386550903,
                "max": 0.6160513758659363,
                "min": -0.4994559586048126
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0677865594625473,
                "median": 0.08031415939331055,
                "std": 0.2106281965970993,
                "max": 0.4817033112049103,
                "min": -0.2761751711368561
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04808643087744713,
                "median": 0.06605448573827744,
                "std": 0.2322215586900711,
                "max": 0.5443410277366638,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    2,
                    8
                ],
                "input_size": 8,
                "output_size": 2,
                "mean": 0.06262018531560898,
                "median": 0.010361146181821823,
                "std": 0.26524975895881653,
                "max": 0.5331623554229736,
                "min": -0.2596241235733032
            }
        }
    },
    "Gluonts_m1_quarterly_hidden_size_8_max_steps_200_learning_rate_0.001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 4,
            "horizon": 2,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 200,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 202
        },
        "scores": {
            "smape": 0.06338785588741302,
            "mse": 195411456.0,
            "mae": 2563.341552734375,
            "r2_score": 0.9678829312324524,
            "sn_smape": 0.1293550431728363,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    4
                ],
                "input_size": 4,
                "output_size": 8,
                "mean": 0.1090388149023056,
                "median": 0.16204872727394104,
                "std": 0.2579303979873657,
                "max": 0.6156187057495117,
                "min": -0.49640387296676636
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06819315999746323,
                "median": 0.08073806762695312,
                "std": 0.21069209277629852,
                "max": 0.4939667284488678,
                "min": -0.27606481313705444
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04645240306854248,
                "median": 0.06669711321592331,
                "std": 0.2312648445367813,
                "max": 0.5421552062034607,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    2,
                    8
                ],
                "input_size": 8,
                "output_size": 2,
                "mean": 0.0640251561999321,
                "median": 0.013919677585363388,
                "std": 0.26731595396995544,
                "max": 0.5369846820831299,
                "min": -0.25988444685935974
            }
        }
    },
    "Gluonts_m1_quarterly_hidden_size_8_max_steps_200_learning_rate_0.0005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 4,
            "horizon": 2,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 200,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 202
        },
        "scores": {
            "smape": 0.5108548402786255,
            "mse": 3447094528.0,
            "mae": 12114.423828125,
            "r2_score": 0.43344932794570923,
            "sn_smape": 0.1293550431728363,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    4
                ],
                "input_size": 4,
                "output_size": 8,
                "mean": 0.06905515491962433,
                "median": 0.0811970978975296,
                "std": 0.24641519784927368,
                "max": 0.5584293603897095,
                "min": -0.49186578392982483
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04405392333865166,
                "median": 0.05645940452814102,
                "std": 0.20020294189453125,
                "max": 0.44600310921669006,
                "min": -0.27381381392478943
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0354953408241272,
                "median": 0.05208907276391983,
                "std": 0.22171302139759064,
                "max": 0.45079341530799866,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    2,
                    8
                ],
                "input_size": 8,
                "output_size": 2,
                "mean": 0.03145618364214897,
                "median": -0.023669235408306122,
                "std": 0.25042206048965454,
                "max": 0.44905713200569153,
                "min": -0.26347529888153076
            }
        }
    },
    "Gluonts_m1_quarterly_hidden_size_8_max_steps_200_learning_rate_0.0005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 4,
            "horizon": 2,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 200,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 202
        },
        "scores": {
            "smape": 0.5033844709396362,
            "mse": 3397680640.0,
            "mae": 12010.0439453125,
            "r2_score": 0.4415707588195801,
            "sn_smape": 0.1293550431728363,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    4
                ],
                "input_size": 4,
                "output_size": 8,
                "mean": 0.07009363174438477,
                "median": 0.08248324692249298,
                "std": 0.2463354617357254,
                "max": 0.560009241104126,
                "min": -0.4888398349285126
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04412079602479935,
                "median": 0.055550482124090195,
                "std": 0.20078516006469727,
                "max": 0.4462277889251709,
                "min": -0.27629849314689636
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03583041951060295,
                "median": 0.05187254399061203,
                "std": 0.22192151844501495,
                "max": 0.4525343179702759,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    2,
                    8
                ],
                "input_size": 8,
                "output_size": 2,
                "mean": 0.031929224729537964,
                "median": -0.02383757382631302,
                "std": 0.2511166036128998,
                "max": 0.4508804678916931,
                "min": -0.2642602026462555
            }
        }
    },
    "Gluonts_m1_quarterly_hidden_size_8_max_steps_200_learning_rate_0.0001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 4,
            "horizon": 2,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 200,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 202
        },
        "scores": {
            "smape": 0.9199339151382446,
            "mse": 6035566080.0,
            "mae": 16702.423828125,
            "r2_score": 0.00801849365234375,
            "sn_smape": 0.1293550431728363,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    4
                ],
                "input_size": 4,
                "output_size": 8,
                "mean": 0.033822111785411835,
                "median": 0.037932850420475006,
                "std": 0.2379002422094345,
                "max": 0.48871782422065735,
                "min": -0.478925496339798
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.011376278474926949,
                "median": 0.025574002414941788,
                "std": 0.19390058517456055,
                "max": 0.36729052662849426,
                "min": -0.32433855533599854
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.019212158396840096,
                "median": 0.05466277897357941,
                "std": 0.21058544516563416,
                "max": 0.36757922172546387,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    2,
                    8
                ],
                "input_size": 8,
                "output_size": 2,
                "mean": -0.010811952874064445,
                "median": -0.061989136040210724,
                "std": 0.22637735307216644,
                "max": 0.3617401123046875,
                "min": -0.29288190603256226
            }
        }
    },
    "Gluonts_m1_quarterly_hidden_size_8_max_steps_200_learning_rate_0.0001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 4,
            "horizon": 2,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 200,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 202
        },
        "scores": {
            "smape": 0.9201170206069946,
            "mse": 6039741440.0,
            "mae": 16708.220703125,
            "r2_score": 0.007332205772399902,
            "sn_smape": 0.1293550431728363,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    4
                ],
                "input_size": 4,
                "output_size": 8,
                "mean": 0.0339123010635376,
                "median": 0.03780326247215271,
                "std": 0.2378922551870346,
                "max": 0.488630473613739,
                "min": -0.4788818657398224
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.011478173546493053,
                "median": 0.024958021938800812,
                "std": 0.1938677579164505,
                "max": 0.36716488003730774,
                "min": -0.3243752717971802
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01918983645737171,
                "median": 0.05463908985257149,
                "std": 0.21066226065158844,
                "max": 0.36746421456336975,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    2,
                    8
                ],
                "input_size": 8,
                "output_size": 2,
                "mean": -0.010830879211425781,
                "median": -0.062150441110134125,
                "std": 0.2263217717409134,
                "max": 0.3616328537464142,
                "min": -0.29306450486183167
            }
        }
    },
    "Gluonts_m1_quarterly_hidden_size_16_max_steps_50_learning_rate_0.001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 4,
            "horizon": 2,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 50,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 658
        },
        "scores": {
            "smape": 0.633678138256073,
            "mse": 4267510016.0,
            "mae": 13742.6650390625,
            "r2_score": 0.29860907793045044,
            "sn_smape": 0.1293550431728363,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    4
                ],
                "input_size": 4,
                "output_size": 16,
                "mean": 0.040559038519859314,
                "median": 0.019572140648961067,
                "std": 0.2775401175022125,
                "max": 0.5333438515663147,
                "min": -0.5083228349685669
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.006134083028882742,
                "median": -0.0008595376857556403,
                "std": 0.1480749100446701,
                "max": 0.2837740480899811,
                "min": -0.26312652230262756
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0074850693345069885,
                "median": 0.011710913851857185,
                "std": 0.14667361974716187,
                "max": 0.28208497166633606,
                "min": -0.27166464924812317
            },
            "out.weight": {
                "shape": [
                    2,
                    16
                ],
                "input_size": 16,
                "output_size": 2,
                "mean": 0.015191416256129742,
                "median": -0.018185583874583244,
                "std": 0.15847207605838776,
                "max": 0.2778591811656952,
                "min": -0.2219579815864563
            }
        }
    },
    "Gluonts_m1_quarterly_hidden_size_16_max_steps_50_learning_rate_0.001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 4,
            "horizon": 2,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 50,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 658
        },
        "scores": {
            "smape": 0.6313351988792419,
            "mse": 4257121024.0,
            "mae": 13722.6025390625,
            "r2_score": 0.30031657218933105,
            "sn_smape": 0.1293550431728363,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    4
                ],
                "input_size": 4,
                "output_size": 16,
                "mean": 0.0406830757856369,
                "median": 0.022907249629497528,
                "std": 0.2778789699077606,
                "max": 0.533833384513855,
                "min": -0.5096223950386047
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.005911019165068865,
                "median": -0.0029572076164186,
                "std": 0.1476949006319046,
                "max": 0.28273531794548035,
                "min": -0.26356959342956543
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.006941067986190319,
                "median": 0.011914647184312344,
                "std": 0.14672324061393738,
                "max": 0.28664642572402954,
                "min": -0.2687978744506836
            },
            "out.weight": {
                "shape": [
                    2,
                    16
                ],
                "input_size": 16,
                "output_size": 2,
                "mean": 0.014467514120042324,
                "median": -0.018795162439346313,
                "std": 0.15937106311321259,
                "max": 0.27864551544189453,
                "min": -0.22433403134346008
            }
        }
    },
    "Gluonts_m1_quarterly_hidden_size_16_max_steps_50_learning_rate_0.0005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 4,
            "horizon": 2,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 50,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 658
        },
        "scores": {
            "smape": 0.8451566696166992,
            "mse": 5542069760.0,
            "mae": 15924.8818359375,
            "r2_score": 0.0891275405883789,
            "sn_smape": 0.1293550431728363,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    4
                ],
                "input_size": 4,
                "output_size": 16,
                "mean": 0.03421344980597496,
                "median": 0.011858356185257435,
                "std": 0.27576276659965515,
                "max": 0.5137205123901367,
                "min": -0.5038483142852783
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0033138024155050516,
                "median": -0.001737187965773046,
                "std": 0.14594395458698273,
                "max": 0.2631153464317322,
                "min": -0.25010815262794495
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0030371341854333878,
                "median": 0.013103486970067024,
                "std": 0.14497092366218567,
                "max": 0.26427170634269714,
                "min": -0.259887158870697
            },
            "out.weight": {
                "shape": [
                    2,
                    16
                ],
                "input_size": 16,
                "output_size": 2,
                "mean": 0.002239309251308441,
                "median": -0.036730874329805374,
                "std": 0.15460018813610077,
                "max": 0.25866934657096863,
                "min": -0.2278970330953598
            }
        }
    },
    "Gluonts_m1_quarterly_hidden_size_16_max_steps_50_learning_rate_0.0005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 4,
            "horizon": 2,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 50,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 658
        },
        "scores": {
            "smape": 0.8438773155212402,
            "mse": 5534008320.0,
            "mae": 15911.357421875,
            "r2_score": 0.09045249223709106,
            "sn_smape": 0.1293550431728363,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    4
                ],
                "input_size": 4,
                "output_size": 16,
                "mean": 0.034050244837999344,
                "median": 0.012991741299629211,
                "std": 0.2760050296783447,
                "max": 0.5138400197029114,
                "min": -0.5044600367546082
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0034297823440283537,
                "median": -0.0004535728367045522,
                "std": 0.14579351246356964,
                "max": 0.26528993248939514,
                "min": -0.2510359287261963
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0029308749362826347,
                "median": 0.013018898665904999,
                "std": 0.14496374130249023,
                "max": 0.2645324468612671,
                "min": -0.25896480679512024
            },
            "out.weight": {
                "shape": [
                    2,
                    16
                ],
                "input_size": 16,
                "output_size": 2,
                "mean": 0.0018028002232313156,
                "median": -0.03730354458093643,
                "std": 0.15492531657218933,
                "max": 0.2585602402687073,
                "min": -0.2283782809972763
            }
        }
    },
    "Gluonts_m1_quarterly_hidden_size_16_max_steps_50_learning_rate_0.0001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 4,
            "horizon": 2,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 50,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 658
        },
        "scores": {
            "smape": 0.9572615027427673,
            "mse": 6323169792.0,
            "mae": 17119.78125,
            "r2_score": -0.039250969886779785,
            "sn_smape": 0.1293550431728363,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    4
                ],
                "input_size": 4,
                "output_size": 16,
                "mean": 0.03131289780139923,
                "median": 0.014756975695490837,
                "std": 0.27556607127189636,
                "max": 0.5019850730895996,
                "min": -0.49255141615867615
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0030842511914670467,
                "median": -0.0031577199697494507,
                "std": 0.14479869604110718,
                "max": 0.24815122783184052,
                "min": -0.24118678271770477
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0005979724228382111,
                "median": 0.00690038874745369,
                "std": 0.14415046572685242,
                "max": 0.25175291299819946,
                "min": -0.2501181662082672
            },
            "out.weight": {
                "shape": [
                    2,
                    16
                ],
                "input_size": 16,
                "output_size": 2,
                "mean": -0.008391217328608036,
                "median": -0.05017564073204994,
                "std": 0.1524878889322281,
                "max": 0.24459822475910187,
                "min": -0.23312562704086304
            }
        }
    },
    "Gluonts_m1_quarterly_hidden_size_16_max_steps_50_learning_rate_0.0001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 4,
            "horizon": 2,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 50,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 658
        },
        "scores": {
            "smape": 0.9574649333953857,
            "mse": 6324318720.0,
            "mae": 17120.984375,
            "r2_score": -0.03943979740142822,
            "sn_smape": 0.1293550431728363,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    4
                ],
                "input_size": 4,
                "output_size": 16,
                "mean": 0.03121982142329216,
                "median": 0.014632686972618103,
                "std": 0.2756277024745941,
                "max": 0.502615213394165,
                "min": -0.4931045174598694
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0031439196318387985,
                "median": -0.0031577199697494507,
                "std": 0.1447788029909134,
                "max": 0.2477252334356308,
                "min": -0.2416779100894928
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0005583176389336586,
                "median": 0.006675648503005505,
                "std": 0.1441674679517746,
                "max": 0.25187426805496216,
                "min": -0.2499588280916214
            },
            "out.weight": {
                "shape": [
                    2,
                    16
                ],
                "input_size": 16,
                "output_size": 2,
                "mean": -0.008491757325828075,
                "median": -0.05032440274953842,
                "std": 0.15251271426677704,
                "max": 0.24447138607501984,
                "min": -0.23332668840885162
            }
        }
    },
    "Gluonts_m1_quarterly_hidden_size_16_max_steps_100_learning_rate_0.001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 4,
            "horizon": 2,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 100,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 658
        },
        "scores": {
            "smape": 0.08878389000892639,
            "mse": 318487488.0,
            "mae": 3287.2607421875,
            "r2_score": 0.947654664516449,
            "sn_smape": 0.1293550431728363,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    4
                ],
                "input_size": 4,
                "output_size": 16,
                "mean": 0.0655604749917984,
                "median": 0.06519488990306854,
                "std": 0.2873840630054474,
                "max": 0.5812807083129883,
                "min": -0.480694055557251
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.022653860971331596,
                "median": 0.010230183601379395,
                "std": 0.15416063368320465,
                "max": 0.3290642499923706,
                "min": -0.29401662945747375
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.018766075372695923,
                "median": 0.01846848428249359,
                "std": 0.15345996618270874,
                "max": 0.33925294876098633,
                "min": -0.28350454568862915
            },
            "out.weight": {
                "shape": [
                    2,
                    16
                ],
                "input_size": 16,
                "output_size": 2,
                "mean": 0.04138673096895218,
                "median": 0.015308805741369724,
                "std": 0.17394736409187317,
                "max": 0.3350473642349243,
                "min": -0.2179211974143982
            }
        }
    },
    "Gluonts_m1_quarterly_hidden_size_16_max_steps_100_learning_rate_0.001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 4,
            "horizon": 2,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 100,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 658
        },
        "scores": {
            "smape": 0.09418188780546188,
            "mse": 380970816.0,
            "mae": 3498.71923828125,
            "r2_score": 0.9373851418495178,
            "sn_smape": 0.1293550431728363,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    4
                ],
                "input_size": 4,
                "output_size": 16,
                "mean": 0.06433534622192383,
                "median": 0.06539402157068253,
                "std": 0.28780418634414673,
                "max": 0.5812170505523682,
                "min": -0.4807862341403961
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.020425841212272644,
                "median": 0.009594487026333809,
                "std": 0.15380285680294037,
                "max": 0.3288043439388275,
                "min": -0.28708982467651367
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.016382448375225067,
                "median": 0.017287347465753555,
                "std": 0.15299193561077118,
                "max": 0.34527334570884705,
                "min": -0.2713036835193634
            },
            "out.weight": {
                "shape": [
                    2,
                    16
                ],
                "input_size": 16,
                "output_size": 2,
                "mean": 0.03839326649904251,
                "median": 0.01573066972196102,
                "std": 0.17411531507968903,
                "max": 0.3394696116447449,
                "min": -0.2224094122648239
            }
        }
    },
    "Gluonts_m1_quarterly_hidden_size_16_max_steps_100_learning_rate_0.0005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 4,
            "horizon": 2,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 100,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 658
        },
        "scores": {
            "smape": 0.5795583724975586,
            "mse": 3917367552.0,
            "mae": 13069.2119140625,
            "r2_score": 0.356157124042511,
            "sn_smape": 0.1293550431728363,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    4
                ],
                "input_size": 4,
                "output_size": 16,
                "mean": 0.04407625272870064,
                "median": 0.02815997786819935,
                "std": 0.27853813767433167,
                "max": 0.5365792512893677,
                "min": -0.5040791034698486
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.008369716815650463,
                "median": 0.00035446861875243485,
                "std": 0.14847467839717865,
                "max": 0.2863086462020874,
                "min": -0.2653029263019562
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.00803825631737709,
                "median": 0.01365426741540432,
                "std": 0.14721901714801788,
                "max": 0.2915119528770447,
                "min": -0.2697561979293823
            },
            "out.weight": {
                "shape": [
                    2,
                    16
                ],
                "input_size": 16,
                "output_size": 2,
                "mean": 0.015430805273354053,
                "median": -0.015228179283440113,
                "std": 0.1609807312488556,
                "max": 0.2822115123271942,
                "min": -0.2265079766511917
            }
        }
    },
    "Gluonts_m1_quarterly_hidden_size_16_max_steps_100_learning_rate_0.0005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 4,
            "horizon": 2,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 100,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 658
        },
        "scores": {
            "smape": 0.5640137195587158,
            "mse": 3818554112.0,
            "mae": 12887.7978515625,
            "r2_score": 0.37239766120910645,
            "sn_smape": 0.1293550431728363,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    4
                ],
                "input_size": 4,
                "output_size": 16,
                "mean": 0.043900392949581146,
                "median": 0.030932579189538956,
                "std": 0.2788764536380768,
                "max": 0.5411025881767273,
                "min": -0.5075726509094238
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.008196908980607986,
                "median": -0.0020305453799664974,
                "std": 0.14804279804229736,
                "max": 0.2912560701370239,
                "min": -0.26603466272354126
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.007629138417541981,
                "median": 0.013952689245343208,
                "std": 0.14725586771965027,
                "max": 0.2953474521636963,
                "min": -0.2665911018848419
            },
            "out.weight": {
                "shape": [
                    2,
                    16
                ],
                "input_size": 16,
                "output_size": 2,
                "mean": 0.015536694787442684,
                "median": -0.015334488824009895,
                "std": 0.1618393361568451,
                "max": 0.28376513719558716,
                "min": -0.22692064940929413
            }
        }
    },
    "Gluonts_m1_quarterly_hidden_size_16_max_steps_100_learning_rate_0.0001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 4,
            "horizon": 2,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 100,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 658
        },
        "scores": {
            "smape": 0.9346704483032227,
            "mse": 6110542336.0,
            "mae": 16808.13671875,
            "r2_score": -0.004304409027099609,
            "sn_smape": 0.1293550431728363,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    4
                ],
                "input_size": 4,
                "output_size": 16,
                "mean": 0.03183659166097641,
                "median": 0.014602655544877052,
                "std": 0.27556177973747253,
                "max": 0.5067565441131592,
                "min": -0.4970402717590332
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.003072879044339061,
                "median": -0.0026255925185978413,
                "std": 0.14497266709804535,
                "max": 0.25197914242744446,
                "min": -0.24173222482204437
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0011020144447684288,
                "median": 0.008285955525934696,
                "std": 0.14436858892440796,
                "max": 0.2549859583377838,
                "min": -0.2518637180328369
            },
            "out.weight": {
                "shape": [
                    2,
                    16
                ],
                "input_size": 16,
                "output_size": 2,
                "mean": -0.005673328414559364,
                "median": -0.0468909852206707,
                "std": 0.15300436317920685,
                "max": 0.24816621840000153,
                "min": -0.231904998421669
            }
        }
    },
    "Gluonts_m1_quarterly_hidden_size_16_max_steps_100_learning_rate_0.0001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 4,
            "horizon": 2,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 100,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 658
        },
        "scores": {
            "smape": 0.933972954750061,
            "mse": 6103311360.0,
            "mae": 16797.498046875,
            "r2_score": -0.0031158924102783203,
            "sn_smape": 0.1293550431728363,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    4
                ],
                "input_size": 4,
                "output_size": 16,
                "mean": 0.03168700262904167,
                "median": 0.01439034566283226,
                "std": 0.27561256289482117,
                "max": 0.5075618028640747,
                "min": -0.49780744314193726
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.003171751042827964,
                "median": -0.0023943702690303326,
                "std": 0.1449456661939621,
                "max": 0.2523577809333801,
                "min": -0.24184644222259521
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0010619745589792728,
                "median": 0.00830254890024662,
                "std": 0.14439401030540466,
                "max": 0.25518500804901123,
                "min": -0.2518414855003357
            },
            "out.weight": {
                "shape": [
                    2,
                    16
                ],
                "input_size": 16,
                "output_size": 2,
                "mean": -0.005704921670258045,
                "median": -0.047113724052906036,
                "std": 0.15307970345020294,
                "max": 0.24819163978099823,
                "min": -0.23217234015464783
            }
        }
    },
    "Gluonts_m1_quarterly_hidden_size_16_max_steps_200_learning_rate_0.001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 4,
            "horizon": 2,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 200,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 658
        },
        "scores": {
            "smape": 0.0609772689640522,
            "mse": 180512672.0,
            "mae": 2465.7431640625,
            "r2_score": 0.9703316688537598,
            "sn_smape": 0.1293550431728363,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    4
                ],
                "input_size": 4,
                "output_size": 16,
                "mean": 0.06181696057319641,
                "median": 0.06519052386283875,
                "std": 0.289945513010025,
                "max": 0.5714417099952698,
                "min": -0.48897820711135864
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.02460513263940811,
                "median": 0.011636083945631981,
                "std": 0.1567196398973465,
                "max": 0.3862851858139038,
                "min": -0.3084365725517273
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.019400840625166893,
                "median": 0.01844390295445919,
                "std": 0.15485073626041412,
                "max": 0.3431757092475891,
                "min": -0.2835918962955475
            },
            "out.weight": {
                "shape": [
                    2,
                    16
                ],
                "input_size": 16,
                "output_size": 2,
                "mean": 0.04235464334487915,
                "median": 0.013558420352637768,
                "std": 0.1741494983434677,
                "max": 0.3459465801715851,
                "min": -0.21627117693424225
            }
        }
    },
    "Gluonts_m1_quarterly_hidden_size_16_max_steps_200_learning_rate_0.001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 4,
            "horizon": 2,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 200,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 658
        },
        "scores": {
            "smape": 0.061767350882291794,
            "mse": 169288000.0,
            "mae": 2409.01904296875,
            "r2_score": 0.9721764922142029,
            "sn_smape": 0.1293550431728363,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    4
                ],
                "input_size": 4,
                "output_size": 16,
                "mean": 0.06307663023471832,
                "median": 0.07092154026031494,
                "std": 0.29042986035346985,
                "max": 0.5717372298240662,
                "min": -0.4957244396209717
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.021724212914705276,
                "median": 0.011901289224624634,
                "std": 0.15673604607582092,
                "max": 0.3663855195045471,
                "min": -0.3170587122440338
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.01606350764632225,
                "median": 0.0223979651927948,
                "std": 0.15431222319602966,
                "max": 0.35476237535476685,
                "min": -0.2713220715522766
            },
            "out.weight": {
                "shape": [
                    2,
                    16
                ],
                "input_size": 16,
                "output_size": 2,
                "mean": 0.03945006802678108,
                "median": 0.026021244004368782,
                "std": 0.17521549761295319,
                "max": 0.35709014534950256,
                "min": -0.22245191037654877
            }
        }
    },
    "Gluonts_m1_quarterly_hidden_size_16_max_steps_200_learning_rate_0.0005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 4,
            "horizon": 2,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 200,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 658
        },
        "scores": {
            "smape": 0.06677921861410141,
            "mse": 265727376.0,
            "mae": 2902.85498046875,
            "r2_score": 0.9563261270523071,
            "sn_smape": 0.1293550431728363,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    4
                ],
                "input_size": 4,
                "output_size": 16,
                "mean": 0.06692709028720856,
                "median": 0.06501509249210358,
                "std": 0.28768670558929443,
                "max": 0.5761911869049072,
                "min": -0.480694055557251
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.022141603752970695,
                "median": 0.011901289224624634,
                "std": 0.15412461757659912,
                "max": 0.3285459578037262,
                "min": -0.2901848256587982
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.016849137842655182,
                "median": 0.018678653985261917,
                "std": 0.1530049443244934,
                "max": 0.34738534688949585,
                "min": -0.2726821005344391
            },
            "out.weight": {
                "shape": [
                    2,
                    16
                ],
                "input_size": 16,
                "output_size": 2,
                "mean": 0.03708133473992348,
                "median": 0.019301796332001686,
                "std": 0.17516644299030304,
                "max": 0.3469863831996918,
                "min": -0.23575446009635925
            }
        }
    },
    "Gluonts_m1_quarterly_hidden_size_16_max_steps_200_learning_rate_0.0005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 4,
            "horizon": 2,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 200,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 658
        },
        "scores": {
            "smape": 0.0659685730934143,
            "mse": 261560272.0,
            "mae": 2889.196533203125,
            "r2_score": 0.9570109844207764,
            "sn_smape": 0.1293550431728363,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    4
                ],
                "input_size": 4,
                "output_size": 16,
                "mean": 0.06561225652694702,
                "median": 0.06606893241405487,
                "std": 0.28794461488723755,
                "max": 0.580600380897522,
                "min": -0.480694055557251
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.022566644474864006,
                "median": 0.011901289224624634,
                "std": 0.15327630937099457,
                "max": 0.33435797691345215,
                "min": -0.2876277267932892
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.015821192413568497,
                "median": 0.018600784242153168,
                "std": 0.1524580717086792,
                "max": 0.35058677196502686,
                "min": -0.26720625162124634
            },
            "out.weight": {
                "shape": [
                    2,
                    16
                ],
                "input_size": 16,
                "output_size": 2,
                "mean": 0.036209654062986374,
                "median": 0.017680462449789047,
                "std": 0.17431683838367462,
                "max": 0.3489707112312317,
                "min": -0.22393742203712463
            }
        }
    },
    "Gluonts_m1_quarterly_hidden_size_16_max_steps_200_learning_rate_0.0001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 4,
            "horizon": 2,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 200,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 658
        },
        "scores": {
            "smape": 0.8581308722496033,
            "mse": 5612157440.0,
            "mae": 16035.515625,
            "r2_score": 0.07760816812515259,
            "sn_smape": 0.1293550431728363,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    4
                ],
                "input_size": 4,
                "output_size": 16,
                "mean": 0.033896662294864655,
                "median": 0.013483075425028801,
                "std": 0.2759209871292114,
                "max": 0.514602541923523,
                "min": -0.5040736198425293
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.004246291238814592,
                "median": 0.001154575147666037,
                "std": 0.14567437767982483,
                "max": 0.262825071811676,
                "min": -0.24868793785572052
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.002617231570184231,
                "median": 0.011654822155833244,
                "std": 0.1449672132730484,
                "max": 0.2639012634754181,
                "min": -0.25704288482666016
            },
            "out.weight": {
                "shape": [
                    2,
                    16
                ],
                "input_size": 16,
                "output_size": 2,
                "mean": 1.604575663805008e-05,
                "median": -0.038824662566185,
                "std": 0.15496313571929932,
                "max": 0.2571195662021637,
                "min": -0.23094777762889862
            }
        }
    },
    "Gluonts_m1_quarterly_hidden_size_16_max_steps_200_learning_rate_0.0001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Gluonts",
            "group": "m1_quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 4,
            "horizon": 2,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 200,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 658
        },
        "scores": {
            "smape": 0.8572587370872498,
            "mse": 5606967808.0,
            "mae": 16026.0712890625,
            "r2_score": 0.0784611701965332,
            "sn_smape": 0.1293550431728363,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    4
                ],
                "input_size": 4,
                "output_size": 16,
                "mean": 0.03378477320075035,
                "median": 0.013515534810721874,
                "std": 0.27594879269599915,
                "max": 0.515464186668396,
                "min": -0.5043771266937256
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.004424158483743668,
                "median": 0.0012491492088884115,
                "std": 0.14564335346221924,
                "max": 0.2633633315563202,
                "min": -0.24922214448451996
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0025204960256814957,
                "median": 0.011425253003835678,
                "std": 0.1449868232011795,
                "max": 0.2643718719482422,
                "min": -0.25689834356307983
            },
            "out.weight": {
                "shape": [
                    2,
                    16
                ],
                "input_size": 16,
                "output_size": 2,
                "mean": -8.062086999416351e-05,
                "median": -0.03947632387280464,
                "std": 0.15501874685287476,
                "max": 0.2571900188922882,
                "min": -0.23126327991485596
            }
        }
    },
    "M3_Monthly_hidden_size_8_max_steps_50_learning_rate_0.001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 50,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 452
        },
        "scores": {
            "smape": 0.5275072768514892,
            "mse": 21616592.506322738,
            "mae": 3756.533538442473,
            "r2_score": -1.9369959974093742,
            "sn_smape": 0.07984804639626009,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    24
                ],
                "input_size": 24,
                "output_size": 8,
                "mean": 0.024754861369729042,
                "median": 0.0344657264649868,
                "std": 0.12148690223693848,
                "max": 0.26375317573547363,
                "min": -0.22443222999572754
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04125693440437317,
                "median": 0.013116978108882904,
                "std": 0.22571876645088196,
                "max": 0.40394940972328186,
                "min": -0.33231621980667114
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.0025653745979070663,
                "median": -0.024437543004751205,
                "std": 0.1852104514837265,
                "max": 0.3696346879005432,
                "min": -0.35731878876686096
            },
            "out.weight": {
                "shape": [
                    12,
                    8
                ],
                "input_size": 8,
                "output_size": 12,
                "mean": 0.043673548847436905,
                "median": 0.03457295522093773,
                "std": 0.19951888918876648,
                "max": 0.4001365303993225,
                "min": -0.33149322867393494
            }
        }
    },
    "M3_Monthly_hidden_size_8_max_steps_50_learning_rate_0.001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 50,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 452
        },
        "scores": {
            "smape": 0.5279924476538234,
            "mse": 21601402.001881335,
            "mae": 3757.694543507304,
            "r2_score": -1.9349320990067942,
            "sn_smape": 0.07984804639626009,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    24
                ],
                "input_size": 24,
                "output_size": 8,
                "mean": 0.024594366550445557,
                "median": 0.034396201372146606,
                "std": 0.12155867367982864,
                "max": 0.2639797627925873,
                "min": -0.22473125159740448
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03981092944741249,
                "median": 0.01089172437787056,
                "std": 0.2263968288898468,
                "max": 0.4043535590171814,
                "min": -0.33231621980667114
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.0025201207026839256,
                "median": -0.023130126297473907,
                "std": 0.18541020154953003,
                "max": 0.3697090148925781,
                "min": -0.3582712709903717
            },
            "out.weight": {
                "shape": [
                    12,
                    8
                ],
                "input_size": 8,
                "output_size": 12,
                "mean": 0.044323164969682693,
                "median": 0.03437788039445877,
                "std": 0.19924555718898773,
                "max": 0.40015366673469543,
                "min": -0.3279228210449219
            }
        }
    },
    "M3_Monthly_hidden_size_8_max_steps_50_learning_rate_0.0005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 50,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 452
        },
        "scores": {
            "smape": 0.8321076407798306,
            "mse": 31764962.34988266,
            "mae": 4975.898756058155,
            "r2_score": -3.315831334294569,
            "sn_smape": 0.07984804639626009,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    24
                ],
                "input_size": 24,
                "output_size": 8,
                "mean": 0.01449254434555769,
                "median": 0.022049836814403534,
                "std": 0.11734224110841751,
                "max": 0.23320414125919342,
                "min": -0.21885709464550018
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03418191894888878,
                "median": 0.0013750427169725299,
                "std": 0.22091390192508698,
                "max": 0.37417787313461304,
                "min": -0.33231621980667114
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.01410495862364769,
                "median": -0.04309316352009773,
                "std": 0.18122822046279907,
                "max": 0.33823615312576294,
                "min": -0.3543208837509155
            },
            "out.weight": {
                "shape": [
                    12,
                    8
                ],
                "input_size": 8,
                "output_size": 12,
                "mean": 0.026643818244338036,
                "median": 0.02979901432991028,
                "std": 0.19549594819545746,
                "max": 0.37011000514030457,
                "min": -0.334648072719574
            }
        }
    },
    "M3_Monthly_hidden_size_8_max_steps_50_learning_rate_0.0005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 50,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 452
        },
        "scores": {
            "smape": 0.8316792410760803,
            "mse": 31741024.95722986,
            "mae": 4974.132130815051,
            "r2_score": -3.312579016595138,
            "sn_smape": 0.07984804639626009,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    24
                ],
                "input_size": 24,
                "output_size": 8,
                "mean": 0.014213722199201584,
                "median": 0.021992236375808716,
                "std": 0.1173446774482727,
                "max": 0.2332458198070526,
                "min": -0.21926404535770416
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.033466219902038574,
                "median": 0.0014843902317807078,
                "std": 0.22103004157543182,
                "max": 0.37356388568878174,
                "min": -0.33231621980667114
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.014240721240639687,
                "median": -0.0437619686126709,
                "std": 0.18144506216049194,
                "max": 0.3382870852947235,
                "min": -0.35444316267967224
            },
            "out.weight": {
                "shape": [
                    12,
                    8
                ],
                "input_size": 8,
                "output_size": 12,
                "mean": 0.026947833597660065,
                "median": 0.030000146478414536,
                "std": 0.19537463784217834,
                "max": 0.3701564371585846,
                "min": -0.3327508270740509
            }
        }
    },
    "M3_Monthly_hidden_size_8_max_steps_50_learning_rate_0.0001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 50,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 452
        },
        "scores": {
            "smape": 0.963625597569274,
            "mse": 35402640.154987976,
            "mae": 5303.867532285666,
            "r2_score": -3.810074131827726,
            "sn_smape": 0.07984804639626009,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    24
                ],
                "input_size": 24,
                "output_size": 8,
                "mean": 0.007311011198908091,
                "median": 0.013117795810103416,
                "std": 0.11569421738386154,
                "max": 0.2090565711259842,
                "min": -0.2044326215982437
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.029170989990234375,
                "median": 0.008885658346116543,
                "std": 0.2185417115688324,
                "max": 0.35097673535346985,
                "min": -0.3325040340423584
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.022138334810733795,
                "median": -0.05873310565948486,
                "std": 0.1787179857492447,
                "max": 0.3198755085468292,
                "min": -0.34981051087379456
            },
            "out.weight": {
                "shape": [
                    12,
                    8
                ],
                "input_size": 8,
                "output_size": 12,
                "mean": 0.012439906597137451,
                "median": 0.02017180435359478,
                "std": 0.1933366060256958,
                "max": 0.35427793860435486,
                "min": -0.3410688042640686
            }
        }
    },
    "M3_Monthly_hidden_size_8_max_steps_50_learning_rate_0.0001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 50,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 452
        },
        "scores": {
            "smape": 0.9636144875671203,
            "mse": 35402060.642145224,
            "mae": 5303.821470258712,
            "r2_score": -3.809995394769648,
            "sn_smape": 0.07984804639626009,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    24
                ],
                "input_size": 24,
                "output_size": 8,
                "mean": 0.0073122805915772915,
                "median": 0.013421254232525826,
                "std": 0.11569535732269287,
                "max": 0.2089417278766632,
                "min": -0.2044217884540558
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02913742884993553,
                "median": 0.008633360266685486,
                "std": 0.21850822865962982,
                "max": 0.3507711589336395,
                "min": -0.33231621980667114
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.02203524298965931,
                "median": -0.058681197464466095,
                "std": 0.17876148223876953,
                "max": 0.31988534331321716,
                "min": -0.34964263439178467
            },
            "out.weight": {
                "shape": [
                    12,
                    8
                ],
                "input_size": 8,
                "output_size": 12,
                "mean": 0.01240634173154831,
                "median": 0.020130477845668793,
                "std": 0.19334149360656738,
                "max": 0.3545835614204407,
                "min": -0.34106189012527466
            }
        }
    },
    "M3_Monthly_hidden_size_8_max_steps_100_learning_rate_0.001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 100,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 452
        },
        "scores": {
            "smape": 0.2040243249417195,
            "mse": 7320230.07906418,
            "mae": 1625.5995571589895,
            "r2_score": 0.005417415532132597,
            "sn_smape": 0.07984804639626009,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    24
                ],
                "input_size": 24,
                "output_size": 8,
                "mean": 0.04076264798641205,
                "median": 0.05483356863260269,
                "std": 0.12820729613304138,
                "max": 0.29295405745506287,
                "min": -0.22368812561035156
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.042174890637397766,
                "median": 0.01235424168407917,
                "std": 0.23248592019081116,
                "max": 0.44102537631988525,
                "min": -0.33257001638412476
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.00879992451518774,
                "median": -0.011535034514963627,
                "std": 0.18854160606861115,
                "max": 0.4298999607563019,
                "min": -0.3574204742908478
            },
            "out.weight": {
                "shape": [
                    12,
                    8
                ],
                "input_size": 8,
                "output_size": 12,
                "mean": 0.06504326313734055,
                "median": 0.06508716940879822,
                "std": 0.20236492156982422,
                "max": 0.4698637127876282,
                "min": -0.3314068019390106
            }
        }
    },
    "M3_Monthly_hidden_size_8_max_steps_100_learning_rate_0.001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 100,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 452
        },
        "scores": {
            "smape": 0.20597725742591633,
            "mse": 7340701.525202415,
            "mae": 1636.7554912240166,
            "r2_score": 0.0026360079003983072,
            "sn_smape": 0.07984804639626009,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    24
                ],
                "input_size": 24,
                "output_size": 8,
                "mean": 0.040992219001054764,
                "median": 0.0545753613114357,
                "std": 0.1280389279127121,
                "max": 0.2928589880466461,
                "min": -0.22425362467765808
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04027704894542694,
                "median": 0.011138620786368847,
                "std": 0.23346315324306488,
                "max": 0.4404509365558624,
                "min": -0.33416059613227844
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.008709322661161423,
                "median": -0.011138979345560074,
                "std": 0.18874503672122955,
                "max": 0.43019968271255493,
                "min": -0.3583837151527405
            },
            "out.weight": {
                "shape": [
                    12,
                    8
                ],
                "input_size": 8,
                "output_size": 12,
                "mean": 0.0657099112868309,
                "median": 0.06403036415576935,
                "std": 0.20204578340053558,
                "max": 0.47059714794158936,
                "min": -0.3277696967124939
            }
        }
    },
    "M3_Monthly_hidden_size_8_max_steps_100_learning_rate_0.0005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 100,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 452
        },
        "scores": {
            "smape": 0.41115295593987355,
            "mse": 18060080.57449557,
            "mae": 3142.4392328582358,
            "r2_score": -1.453781017737632,
            "sn_smape": 0.07984804639626009,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    24
                ],
                "input_size": 24,
                "output_size": 8,
                "mean": 0.03031025268137455,
                "median": 0.03987082839012146,
                "std": 0.12204089015722275,
                "max": 0.2724464535713196,
                "min": -0.22099778056144714
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04558788239955902,
                "median": 0.015621564351022243,
                "std": 0.22844451665878296,
                "max": 0.41825607419013977,
                "min": -0.33231621980667114
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0022284570150077343,
                "median": -0.01865363121032715,
                "std": 0.1875290870666504,
                "max": 0.3793092668056488,
                "min": -0.35447779297828674
            },
            "out.weight": {
                "shape": [
                    12,
                    8
                ],
                "input_size": 8,
                "output_size": 12,
                "mean": 0.04781407117843628,
                "median": 0.03917048126459122,
                "std": 0.20231084525585175,
                "max": 0.40802276134490967,
                "min": -0.3344290852546692
            }
        }
    },
    "M3_Monthly_hidden_size_8_max_steps_100_learning_rate_0.0005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 100,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 452
        },
        "scores": {
            "smape": 0.4154385875537135,
            "mse": 18112686.36152707,
            "mae": 3165.252042846769,
            "r2_score": -1.460928443304677,
            "sn_smape": 0.07984804639626009,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    24
                ],
                "input_size": 24,
                "output_size": 8,
                "mean": 0.029432497918605804,
                "median": 0.0394805446267128,
                "std": 0.12200881540775299,
                "max": 0.27188414335250854,
                "min": -0.22164948284626007
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.044068776071071625,
                "median": 0.015800975263118744,
                "std": 0.2287326157093048,
                "max": 0.41732338070869446,
                "min": -0.33231621980667114
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0018704915419220924,
                "median": -0.01991099864244461,
                "std": 0.18768978118896484,
                "max": 0.379108726978302,
                "min": -0.35461151599884033
            },
            "out.weight": {
                "shape": [
                    12,
                    8
                ],
                "input_size": 8,
                "output_size": 12,
                "mean": 0.047992412000894547,
                "median": 0.039432816207408905,
                "std": 0.2020859569311142,
                "max": 0.4077583849430084,
                "min": -0.3325252830982208
            }
        }
    },
    "M3_Monthly_hidden_size_8_max_steps_100_learning_rate_0.0001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 100,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 452
        },
        "scores": {
            "smape": 0.9408189822369925,
            "mse": 34883392.899951294,
            "mae": 5259.765305659707,
            "r2_score": -3.739525218567578,
            "sn_smape": 0.07984804639626009,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    24
                ],
                "input_size": 24,
                "output_size": 8,
                "mean": 0.010340304113924503,
                "median": 0.019872121512889862,
                "std": 0.11582931876182556,
                "max": 0.21679487824440002,
                "min": -0.20946289598941803
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.030238738283514977,
                "median": 0.005568249151110649,
                "std": 0.21933013200759888,
                "max": 0.35829630494117737,
                "min": -0.33261728286743164
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.020177582278847694,
                "median": -0.05697350576519966,
                "std": 0.1792360544204712,
                "max": 0.32161855697631836,
                "min": -0.3508187532424927
            },
            "out.weight": {
                "shape": [
                    12,
                    8
                ],
                "input_size": 8,
                "output_size": 12,
                "mean": 0.016216913238167763,
                "median": 0.024394303560256958,
                "std": 0.1937965750694275,
                "max": 0.3563472330570221,
                "min": -0.33628013730049133
            }
        }
    },
    "M3_Monthly_hidden_size_8_max_steps_100_learning_rate_0.0001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 100,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 452
        },
        "scores": {
            "smape": 0.9409822895717522,
            "mse": 34884277.38047376,
            "mae": 5259.872456280728,
            "r2_score": -3.73964539087288,
            "sn_smape": 0.07984804639626009,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    24
                ],
                "input_size": 24,
                "output_size": 8,
                "mean": 0.010317864827811718,
                "median": 0.020075101405382156,
                "std": 0.11582774668931961,
                "max": 0.21656101942062378,
                "min": -0.20936211943626404
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03014982119202614,
                "median": 0.005822857841849327,
                "std": 0.21923981606960297,
                "max": 0.3585827946662903,
                "min": -0.33231621980667114
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.01985522173345089,
                "median": -0.056600965559482574,
                "std": 0.17928354442119598,
                "max": 0.32134875655174255,
                "min": -0.35050731897354126
            },
            "out.weight": {
                "shape": [
                    12,
                    8
                ],
                "input_size": 8,
                "output_size": 12,
                "mean": 0.016393298283219337,
                "median": 0.02420293539762497,
                "std": 0.1938662976026535,
                "max": 0.3563581109046936,
                "min": -0.33626917004585266
            }
        }
    },
    "M3_Monthly_hidden_size_8_max_steps_200_learning_rate_0.001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 200,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 452
        },
        "scores": {
            "smape": 0.08574409450707988,
            "mse": 1967395.7371127459,
            "mae": 804.0182192671176,
            "r2_score": 0.7326945306698871,
            "sn_smape": 0.07984804639626009,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    24
                ],
                "input_size": 24,
                "output_size": 8,
                "mean": 0.05383194610476494,
                "median": 0.05824030190706253,
                "std": 0.12979309260845184,
                "max": 0.3253873884677887,
                "min": -0.2083464115858078
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.027834417298436165,
                "median": 0.0005996158579364419,
                "std": 0.2428373247385025,
                "max": 0.46378639340400696,
                "min": -0.4279215931892395
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.011936672031879425,
                "median": -0.011087734252214432,
                "std": 0.1900816410779953,
                "max": 0.4511258602142334,
                "min": -0.3574211001396179
            },
            "out.weight": {
                "shape": [
                    12,
                    8
                ],
                "input_size": 8,
                "output_size": 12,
                "mean": 0.07007084786891937,
                "median": 0.0764632523059845,
                "std": 0.19851426780223846,
                "max": 0.4619426429271698,
                "min": -0.33140629529953003
            }
        }
    },
    "M3_Monthly_hidden_size_8_max_steps_200_learning_rate_0.001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 200,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 452
        },
        "scores": {
            "smape": 0.08495782496743187,
            "mse": 1931309.0770058534,
            "mae": 796.8304437670454,
            "r2_score": 0.7375975409969225,
            "sn_smape": 0.07984804639626009,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    24
                ],
                "input_size": 24,
                "output_size": 8,
                "mean": 0.05664704367518425,
                "median": 0.06356798112392426,
                "std": 0.13115409016609192,
                "max": 0.32845547795295715,
                "min": -0.21370069682598114
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02521607093513012,
                "median": -0.00038403552025556564,
                "std": 0.24482417106628418,
                "max": 0.4652247130870819,
                "min": -0.43685925006866455
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.012454049661755562,
                "median": -0.0104634128510952,
                "std": 0.1908814013004303,
                "max": 0.4512532651424408,
                "min": -0.3583844304084778
            },
            "out.weight": {
                "shape": [
                    12,
                    8
                ],
                "input_size": 8,
                "output_size": 12,
                "mean": 0.0711553618311882,
                "median": 0.07679753005504608,
                "std": 0.19814462959766388,
                "max": 0.46189767122268677,
                "min": -0.3277687132358551
            }
        }
    },
    "M3_Monthly_hidden_size_8_max_steps_200_learning_rate_0.0005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 200,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 452
        },
        "scores": {
            "smape": 0.1877330100352123,
            "mse": 6410552.668202353,
            "mae": 1470.189781257957,
            "r2_score": 0.12901316328254453,
            "sn_smape": 0.07984804639626009,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    24
                ],
                "input_size": 24,
                "output_size": 8,
                "mean": 0.04650068283081055,
                "median": 0.05635809525847435,
                "std": 0.12523745000362396,
                "max": 0.2849702835083008,
                "min": -0.21682533621788025
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04610181972384453,
                "median": 0.014397265389561653,
                "std": 0.23409684002399445,
                "max": 0.4380664527416229,
                "min": -0.33231621980667114
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.008962427265942097,
                "median": -0.01840648055076599,
                "std": 0.18975423276424408,
                "max": 0.4246823191642761,
                "min": -0.354479044675827
            },
            "out.weight": {
                "shape": [
                    12,
                    8
                ],
                "input_size": 8,
                "output_size": 12,
                "mean": 0.06354402750730515,
                "median": 0.06457777321338654,
                "std": 0.20213337242603302,
                "max": 0.4612088203430176,
                "min": -0.33442720770835876
            }
        }
    },
    "M3_Monthly_hidden_size_8_max_steps_200_learning_rate_0.0005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 200,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 452
        },
        "scores": {
            "smape": 0.187336562374172,
            "mse": 6377655.588561273,
            "mae": 1466.8630492445466,
            "r2_score": 0.13348281275223073,
            "sn_smape": 0.07984804639626009,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    24
                ],
                "input_size": 24,
                "output_size": 8,
                "mean": 0.04564148560166359,
                "median": 0.05707162618637085,
                "std": 0.12549012899398804,
                "max": 0.28432735800743103,
                "min": -0.21823827922344208
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.044631462544202805,
                "median": 0.010736487805843353,
                "std": 0.23463506996631622,
                "max": 0.43895867466926575,
                "min": -0.33231621980667114
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.009006436914205551,
                "median": -0.01959933340549469,
                "std": 0.19007012248039246,
                "max": 0.4252447187900543,
                "min": -0.35461339354515076
            },
            "out.weight": {
                "shape": [
                    12,
                    8
                ],
                "input_size": 8,
                "output_size": 12,
                "mean": 0.06395302712917328,
                "median": 0.06521658599376678,
                "std": 0.20197579264640808,
                "max": 0.4615683853626251,
                "min": -0.33252274990081787
            }
        }
    },
    "M3_Monthly_hidden_size_8_max_steps_200_learning_rate_0.0001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 200,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 452
        },
        "scores": {
            "smape": 0.8289932903100263,
            "mse": 31614633.420794833,
            "mae": 4960.582252581606,
            "r2_score": -3.2954064933814298,
            "sn_smape": 0.07984804639626009,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    24
                ],
                "input_size": 24,
                "output_size": 8,
                "mean": 0.014754828065633774,
                "median": 0.021549254655838013,
                "std": 0.11671339720487595,
                "max": 0.23191501200199127,
                "min": -0.21575073897838593
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03434041887521744,
                "median": 0.0024667512625455856,
                "std": 0.22131465375423431,
                "max": 0.3790293037891388,
                "min": -0.33261799812316895
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.01291719637811184,
                "median": -0.04231179133057594,
                "std": 0.1812683343887329,
                "max": 0.34083300828933716,
                "min": -0.35122784972190857
            },
            "out.weight": {
                "shape": [
                    12,
                    8
                ],
                "input_size": 8,
                "output_size": 12,
                "mean": 0.025997072458267212,
                "median": 0.02673763409256935,
                "std": 0.19619502127170563,
                "max": 0.36806151270866394,
                "min": -0.3355907201766968
            }
        }
    },
    "M3_Monthly_hidden_size_8_max_steps_200_learning_rate_0.0001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 200,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 452
        },
        "scores": {
            "smape": 0.8259613808192394,
            "mse": 31502146.367427494,
            "mae": 4950.19449373134,
            "r2_score": -3.280123139846241,
            "sn_smape": 0.07984804639626009,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    24
                ],
                "input_size": 24,
                "output_size": 8,
                "mean": 0.014694531448185444,
                "median": 0.020949823781847954,
                "std": 0.1166936382651329,
                "max": 0.23205536603927612,
                "min": -0.21569176018238068
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03415202349424362,
                "median": 0.0031464833300560713,
                "std": 0.221242293715477,
                "max": 0.3795398473739624,
                "min": -0.33231621980667114
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.01241457648575306,
                "median": -0.04191280156373978,
                "std": 0.18136316537857056,
                "max": 0.3415352702140808,
                "min": -0.35093986988067627
            },
            "out.weight": {
                "shape": [
                    12,
                    8
                ],
                "input_size": 8,
                "output_size": 12,
                "mean": 0.026412243023514748,
                "median": 0.02704150788486004,
                "std": 0.19633319973945618,
                "max": 0.36811521649360657,
                "min": -0.3348657190799713
            }
        }
    },
    "M3_Monthly_hidden_size_16_max_steps_50_learning_rate_0.001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 50,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 1148
        },
        "scores": {
            "smape": 0.2587022398434779,
            "mse": 8355720.544744995,
            "mae": 2066.553261742044,
            "r2_score": -0.1352722584842776,
            "sn_smape": 0.07984804639626009,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    24
                ],
                "input_size": 24,
                "output_size": 16,
                "mean": 0.019582336768507957,
                "median": 0.015556823462247849,
                "std": 0.12309107929468155,
                "max": 0.2589710056781769,
                "min": -0.22150801122188568
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.006856799125671387,
                "median": 0.0015080762095749378,
                "std": 0.15054470300674438,
                "max": 0.30663833022117615,
                "min": -0.2551395297050476
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.006963103543967009,
                "median": -0.0014062219997867942,
                "std": 0.150345578789711,
                "max": 0.30108317732810974,
                "min": -0.25556573271751404
            },
            "out.weight": {
                "shape": [
                    12,
                    16
                ],
                "input_size": 16,
                "output_size": 12,
                "mean": 0.03433572128415108,
                "median": 0.047690387815237045,
                "std": 0.15681493282318115,
                "max": 0.3098410964012146,
                "min": -0.2498229742050171
            }
        }
    },
    "M3_Monthly_hidden_size_16_max_steps_50_learning_rate_0.001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 50,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 1148
        },
        "scores": {
            "smape": 0.2565002345796418,
            "mse": 8280439.750255647,
            "mae": 2058.624745752208,
            "r2_score": -0.12504403254939245,
            "sn_smape": 0.07984804639626009,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    24
                ],
                "input_size": 24,
                "output_size": 16,
                "mean": 0.020413197576999664,
                "median": 0.016290023922920227,
                "std": 0.12331964820623398,
                "max": 0.25908568501472473,
                "min": -0.21763765811920166
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.007049701176583767,
                "median": 0.004273201338946819,
                "std": 0.15074357390403748,
                "max": 0.3066718280315399,
                "min": -0.25991374254226685
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.007494816556572914,
                "median": 0.0005230704555287957,
                "std": 0.15029320120811462,
                "max": 0.3013322353363037,
                "min": -0.2553519904613495
            },
            "out.weight": {
                "shape": [
                    12,
                    16
                ],
                "input_size": 16,
                "output_size": 12,
                "mean": 0.03366446495056152,
                "median": 0.04760671779513359,
                "std": 0.15684527158737183,
                "max": 0.3100307583808899,
                "min": -0.2498229742050171
            }
        }
    },
    "M3_Monthly_hidden_size_16_max_steps_50_learning_rate_0.0005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 50,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 1148
        },
        "scores": {
            "smape": 0.7306248815574988,
            "mse": 26768439.37141345,
            "mae": 4533.183386105168,
            "r2_score": -2.6369654129225606,
            "sn_smape": 0.07984804639626009,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    24
                ],
                "input_size": 24,
                "output_size": 16,
                "mean": 0.007111710961908102,
                "median": 0.0004985538544133306,
                "std": 0.11850933730602264,
                "max": 0.2286028414964676,
                "min": -0.21584583818912506
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0006159031763672829,
                "median": -0.003683755174279213,
                "std": 0.1464867889881134,
                "max": 0.27612897753715515,
                "min": -0.2569270431995392
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0005772640579380095,
                "median": -0.00863049365580082,
                "std": 0.14683297276496887,
                "max": 0.26917901635169983,
                "min": -0.2600652277469635
            },
            "out.weight": {
                "shape": [
                    12,
                    16
                ],
                "input_size": 16,
                "output_size": 12,
                "mean": 0.017195768654346466,
                "median": 0.022679530084133148,
                "std": 0.1536734700202942,
                "max": 0.2783789038658142,
                "min": -0.2498229742050171
            }
        }
    },
    "M3_Monthly_hidden_size_16_max_steps_50_learning_rate_0.0005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 50,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 1148
        },
        "scores": {
            "smape": 0.7276496832268325,
            "mse": 26655106.073346414,
            "mae": 4521.662830931808,
            "r2_score": -2.6215670820941135,
            "sn_smape": 0.07984804639626009,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    24
                ],
                "input_size": 24,
                "output_size": 16,
                "mean": 0.007596620824187994,
                "median": 7.027661195024848e-05,
                "std": 0.11856450140476227,
                "max": 0.2286691814661026,
                "min": -0.21117722988128662
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0006328658200800419,
                "median": -0.0037542993668466806,
                "std": 0.14643560349941254,
                "max": 0.27615463733673096,
                "min": -0.2571885287761688
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0005682413466274738,
                "median": -0.009373145177960396,
                "std": 0.1469101756811142,
                "max": 0.2693532407283783,
                "min": -0.2600078880786896
            },
            "out.weight": {
                "shape": [
                    12,
                    16
                ],
                "input_size": 16,
                "output_size": 12,
                "mean": 0.016919467598199844,
                "median": 0.022572115063667297,
                "std": 0.15366224944591522,
                "max": 0.2784465253353119,
                "min": -0.2498229742050171
            }
        }
    },
    "M3_Monthly_hidden_size_16_max_steps_50_learning_rate_0.0001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 50,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 1148
        },
        "scores": {
            "smape": 0.9355190802264682,
            "mse": 34414382.124239594,
            "mae": 5223.135135495527,
            "r2_score": -3.6758018185634276,
            "sn_smape": 0.07984804639626009,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    24
                ],
                "input_size": 24,
                "output_size": 16,
                "mean": 0.0020290259271860123,
                "median": -0.00028294502408243716,
                "std": 0.11623835563659668,
                "max": 0.20606288313865662,
                "min": -0.20335029065608978
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.0025865372736006975,
                "median": -0.0003014479298144579,
                "std": 0.14470963180065155,
                "max": 0.250640869140625,
                "min": -0.25031834840774536
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.0036207891535013914,
                "median": -0.01116134412586689,
                "std": 0.1454787254333496,
                "max": 0.24646124243736267,
                "min": -0.243757963180542
            },
            "out.weight": {
                "shape": [
                    12,
                    16
                ],
                "input_size": 16,
                "output_size": 12,
                "mean": 0.0032228592317551374,
                "median": 0.0034858528524637222,
                "std": 0.15220920741558075,
                "max": 0.2547324299812317,
                "min": -0.2498229742050171
            }
        }
    },
    "M3_Monthly_hidden_size_16_max_steps_50_learning_rate_0.0001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 50,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 1148
        },
        "scores": {
            "smape": 0.9354237919407754,
            "mse": 34410986.907726124,
            "mae": 5222.855049611909,
            "r2_score": -3.6753405184159833,
            "sn_smape": 0.07984804639626009,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    24
                ],
                "input_size": 24,
                "output_size": 16,
                "mean": 0.002038785954937339,
                "median": -0.000724489102140069,
                "std": 0.11626240611076355,
                "max": 0.20609132945537567,
                "min": -0.20208807289600372
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.002619190141558647,
                "median": -7.822999032214284e-05,
                "std": 0.14468896389007568,
                "max": 0.2506104111671448,
                "min": -0.25034719705581665
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.0035961498506367207,
                "median": -0.011027766391634941,
                "std": 0.1454702466726303,
                "max": 0.2464732974767685,
                "min": -0.243757963180542
            },
            "out.weight": {
                "shape": [
                    12,
                    16
                ],
                "input_size": 16,
                "output_size": 12,
                "mean": 0.0032670442014932632,
                "median": 0.003292354755103588,
                "std": 0.15220095217227936,
                "max": 0.2547435164451599,
                "min": -0.2498229742050171
            }
        }
    },
    "M3_Monthly_hidden_size_16_max_steps_100_learning_rate_0.001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 100,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 1148
        },
        "scores": {
            "smape": 0.07938118795833764,
            "mse": 1811015.9536805786,
            "mae": 744.0328803658507,
            "r2_score": 0.7539414870475716,
            "sn_smape": 0.07984804639626009,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    24
                ],
                "input_size": 24,
                "output_size": 16,
                "mean": 0.020824557170271873,
                "median": 0.01468957494944334,
                "std": 0.12478222697973251,
                "max": 0.2737811505794525,
                "min": -0.21682460606098175
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.009586685337126255,
                "median": 0.0015174738364294171,
                "std": 0.151914581656456,
                "max": 0.32168033719062805,
                "min": -0.2547256648540497
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.009846467524766922,
                "median": 0.009528962895274162,
                "std": 0.15174303948879242,
                "max": 0.3228439390659332,
                "min": -0.27343687415122986
            },
            "out.weight": {
                "shape": [
                    12,
                    16
                ],
                "input_size": 16,
                "output_size": 12,
                "mean": 0.040817465633153915,
                "median": 0.04876706749200821,
                "std": 0.1567315310239792,
                "max": 0.34670165181159973,
                "min": -0.2498229742050171
            }
        }
    },
    "M3_Monthly_hidden_size_16_max_steps_100_learning_rate_0.001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 100,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 1148
        },
        "scores": {
            "smape": 0.07955386508869566,
            "mse": 1809907.206699806,
            "mae": 744.3446743717426,
            "r2_score": 0.7540921299134034,
            "sn_smape": 0.07984804639626009,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    24
                ],
                "input_size": 24,
                "output_size": 16,
                "mean": 0.02176322042942047,
                "median": 0.015151364728808403,
                "std": 0.12493680417537689,
                "max": 0.27388978004455566,
                "min": -0.21688874065876007
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.008566287346184254,
                "median": 0.0025903168134391308,
                "std": 0.1520928293466568,
                "max": 0.3217644691467285,
                "min": -0.2600366473197937
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.010065244510769844,
                "median": 0.009781191125512123,
                "std": 0.15155288577079773,
                "max": 0.3225959241390228,
                "min": -0.2727285623550415
            },
            "out.weight": {
                "shape": [
                    12,
                    16
                ],
                "input_size": 16,
                "output_size": 12,
                "mean": 0.040034566074609756,
                "median": 0.0492214635014534,
                "std": 0.1567898541688919,
                "max": 0.3474917709827423,
                "min": -0.2498229742050171
            }
        }
    },
    "M3_Monthly_hidden_size_16_max_steps_100_learning_rate_0.0005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 100,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 1148
        },
        "scores": {
            "smape": 0.18947278375146018,
            "mse": 5721315.679230437,
            "mae": 1712.8101825269953,
            "r2_score": 0.22265818514641667,
            "sn_smape": 0.07984804639626009,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    24
                ],
                "input_size": 24,
                "output_size": 16,
                "mean": 0.024068839848041534,
                "median": 0.01854090392589569,
                "std": 0.12319033592939377,
                "max": 0.26095134019851685,
                "min": -0.22189673781394958
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.009590573608875275,
                "median": 0.004931310191750526,
                "std": 0.1517914980649948,
                "max": 0.3142196834087372,
                "min": -0.25656986236572266
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.009348606690764427,
                "median": 0.0035116071812808514,
                "std": 0.15096895396709442,
                "max": 0.30062806606292725,
                "min": -0.2650018334388733
            },
            "out.weight": {
                "shape": [
                    12,
                    16
                ],
                "input_size": 16,
                "output_size": 12,
                "mean": 0.0350959450006485,
                "median": 0.04313773289322853,
                "std": 0.1574125736951828,
                "max": 0.313604474067688,
                "min": -0.2498229742050171
            }
        }
    },
    "M3_Monthly_hidden_size_16_max_steps_100_learning_rate_0.0005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 100,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 1148
        },
        "scores": {
            "smape": 0.18921855196999807,
            "mse": 5702095.667328863,
            "mae": 1703.373833982715,
            "r2_score": 0.22526956332771741,
            "sn_smape": 0.07984804639626009,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    24
                ],
                "input_size": 24,
                "output_size": 16,
                "mean": 0.02469468116760254,
                "median": 0.019523782655596733,
                "std": 0.12306281179189682,
                "max": 0.26065492630004883,
                "min": -0.21322594583034515
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.009113734588027,
                "median": 0.005362387280911207,
                "std": 0.15174567699432373,
                "max": 0.3137839138507843,
                "min": -0.25564226508140564
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.009229513816535473,
                "median": 0.0047220708802342415,
                "std": 0.15097489953041077,
                "max": 0.3002128005027771,
                "min": -0.2654314637184143
            },
            "out.weight": {
                "shape": [
                    12,
                    16
                ],
                "input_size": 16,
                "output_size": 12,
                "mean": 0.034628238528966904,
                "median": 0.04275086894631386,
                "std": 0.1573682576417923,
                "max": 0.3134565055370331,
                "min": -0.2498229742050171
            }
        }
    },
    "M3_Monthly_hidden_size_16_max_steps_100_learning_rate_0.0001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 100,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 1148
        },
        "scores": {
            "smape": 0.897428422155423,
            "mse": 33072270.584741764,
            "mae": 5110.1394066087705,
            "r2_score": -3.493452254522327,
            "sn_smape": 0.07984804639626009,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    24
                ],
                "input_size": 24,
                "output_size": 16,
                "mean": 0.0031150858849287033,
                "median": 0.000611680094152689,
                "std": 0.11666689068078995,
                "max": 0.21129761636257172,
                "min": -0.2062913328409195
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.0019220216199755669,
                "median": -0.0018986554350703955,
                "std": 0.14503060281276703,
                "max": 0.257704496383667,
                "min": -0.2540590167045593
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.002647308399900794,
                "median": -0.01300480030477047,
                "std": 0.14564844965934753,
                "max": 0.2518976330757141,
                "min": -0.24627692997455597
            },
            "out.weight": {
                "shape": [
                    12,
                    16
                ],
                "input_size": 16,
                "output_size": 12,
                "mean": 0.00670081190764904,
                "median": 0.007461714558303356,
                "std": 0.15254278481006622,
                "max": 0.2608329951763153,
                "min": -0.2498229742050171
            }
        }
    },
    "M3_Monthly_hidden_size_16_max_steps_100_learning_rate_0.0001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 100,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 1148
        },
        "scores": {
            "smape": 0.8973704837802945,
            "mse": 33071148.96190298,
            "mae": 5110.027690954492,
            "r2_score": -3.4932998622437035,
            "sn_smape": 0.07984804639626009,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    24
                ],
                "input_size": 24,
                "output_size": 16,
                "mean": 0.0031382988672703505,
                "median": 0.0009057920542545617,
                "std": 0.1166844591498375,
                "max": 0.21125143766403198,
                "min": -0.20539362728595734
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.0019120345823466778,
                "median": -0.0010493360459804535,
                "std": 0.14500847458839417,
                "max": 0.25770214200019836,
                "min": -0.2543330192565918
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.002654388314113021,
                "median": -0.012827737256884575,
                "std": 0.14564456045627594,
                "max": 0.2518858015537262,
                "min": -0.2462598830461502
            },
            "out.weight": {
                "shape": [
                    12,
                    16
                ],
                "input_size": 16,
                "output_size": 12,
                "mean": 0.006806857883930206,
                "median": 0.007435023784637451,
                "std": 0.15251128375530243,
                "max": 0.26081031560897827,
                "min": -0.2498229742050171
            }
        }
    },
    "M3_Monthly_hidden_size_16_max_steps_200_learning_rate_0.001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 200,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 1148
        },
        "scores": {
            "smape": 0.07205489855030006,
            "mse": 1672485.472890753,
            "mae": 664.6860246189948,
            "r2_score": 0.7727633003134649,
            "sn_smape": 0.07984804639626009,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    24
                ],
                "input_size": 24,
                "output_size": 16,
                "mean": 0.03015315532684326,
                "median": 0.026463348418474197,
                "std": 0.12562499940395355,
                "max": 0.3076712191104889,
                "min": -0.2120399922132492
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.00807253085076809,
                "median": 0.00451450701802969,
                "std": 0.16122733056545258,
                "max": 0.3757900595664978,
                "min": -0.29864394664764404
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.01363572757691145,
                "median": 0.010034263134002686,
                "std": 0.15465927124023438,
                "max": 0.3662947416305542,
                "min": -0.2748989462852478
            },
            "out.weight": {
                "shape": [
                    12,
                    16
                ],
                "input_size": 16,
                "output_size": 12,
                "mean": 0.04267331585288048,
                "median": 0.05020026117563248,
                "std": 0.15726876258850098,
                "max": 0.3487863540649414,
                "min": -0.2498229742050171
            }
        }
    },
    "M3_Monthly_hidden_size_16_max_steps_200_learning_rate_0.001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 200,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 1148
        },
        "scores": {
            "smape": 0.07250430471146772,
            "mse": 1669756.0032135968,
            "mae": 667.986665268443,
            "r2_score": 0.7731341469912895,
            "sn_smape": 0.07984804639626009,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    24
                ],
                "input_size": 24,
                "output_size": 16,
                "mean": 0.029238291084766388,
                "median": 0.026053210720419884,
                "std": 0.12689943611621857,
                "max": 0.3074503540992737,
                "min": -0.2115909606218338
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.007898136973381042,
                "median": 0.0032752107363194227,
                "std": 0.16274002194404602,
                "max": 0.3890727162361145,
                "min": -0.3053043782711029
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.014064505696296692,
                "median": 0.011374457739293575,
                "std": 0.15481586754322052,
                "max": 0.3755507469177246,
                "min": -0.2737337052822113
            },
            "out.weight": {
                "shape": [
                    12,
                    16
                ],
                "input_size": 16,
                "output_size": 12,
                "mean": 0.04184506833553314,
                "median": 0.049829792231321335,
                "std": 0.15732230246067047,
                "max": 0.34824249148368835,
                "min": -0.2498229742050171
            }
        }
    },
    "M3_Monthly_hidden_size_16_max_steps_200_learning_rate_0.0005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 200,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 1148
        },
        "scores": {
            "smape": 0.07730204793177753,
            "mse": 1766977.1542440313,
            "mae": 719.628807302808,
            "r2_score": 0.759924935994857,
            "sn_smape": 0.07984804639626009,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    24
                ],
                "input_size": 24,
                "output_size": 16,
                "mean": 0.025804350152611732,
                "median": 0.02280496060848236,
                "std": 0.12364726513624191,
                "max": 0.27328619360923767,
                "min": -0.21198920905590057
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.010304875671863556,
                "median": 0.003150366712361574,
                "std": 0.15327170491218567,
                "max": 0.3291226327419281,
                "min": -0.25657206773757935
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.012141858227550983,
                "median": 0.012095263227820396,
                "std": 0.1520681232213974,
                "max": 0.3214152753353119,
                "min": -0.27153047919273376
            },
            "out.weight": {
                "shape": [
                    12,
                    16
                ],
                "input_size": 16,
                "output_size": 12,
                "mean": 0.03757603093981743,
                "median": 0.04130712151527405,
                "std": 0.15697519481182098,
                "max": 0.3449958860874176,
                "min": -0.2498229742050171
            }
        }
    },
    "M3_Monthly_hidden_size_16_max_steps_200_learning_rate_0.0005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 200,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 1148
        },
        "scores": {
            "smape": 0.07788516249292483,
            "mse": 1770335.4805029577,
            "mae": 724.286293002003,
            "r2_score": 0.7594686480402417,
            "sn_smape": 0.07984804639626009,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    24
                ],
                "input_size": 24,
                "output_size": 16,
                "mean": 0.028380626812577248,
                "median": 0.022705618292093277,
                "std": 0.12329317629337311,
                "max": 0.27372390031814575,
                "min": -0.2099580019712448
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.009193621575832367,
                "median": 0.003550171386450529,
                "std": 0.15376858413219452,
                "max": 0.3299655616283417,
                "min": -0.26067590713500977
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.012219073250889778,
                "median": 0.012239541858434677,
                "std": 0.15226344764232635,
                "max": 0.32163259387016296,
                "min": -0.27163100242614746
            },
            "out.weight": {
                "shape": [
                    12,
                    16
                ],
                "input_size": 16,
                "output_size": 12,
                "mean": 0.03736410662531853,
                "median": 0.041415125131607056,
                "std": 0.1570330411195755,
                "max": 0.3453499674797058,
                "min": -0.2498229742050171
            }
        }
    },
    "M3_Monthly_hidden_size_16_max_steps_200_learning_rate_0.0001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 200,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 1148
        },
        "scores": {
            "smape": 0.7428930536251235,
            "mse": 27210044.668764014,
            "mae": 4574.544218596928,
            "r2_score": -2.6969652945123173,
            "sn_smape": 0.07984804639626009,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    24
                ],
                "input_size": 24,
                "output_size": 16,
                "mean": 0.00987896416336298,
                "median": 0.002758846152573824,
                "std": 0.1179511770606041,
                "max": 0.2284124195575714,
                "min": -0.2112867832183838
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.000837729312479496,
                "median": -0.0022510639391839504,
                "std": 0.14662645757198334,
                "max": 0.27765876054763794,
                "min": -0.25339555740356445
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.001271988032385707,
                "median": -0.008425894193351269,
                "std": 0.14677926898002625,
                "max": 0.26645180583000183,
                "min": -0.25513172149658203
            },
            "out.weight": {
                "shape": [
                    12,
                    16
                ],
                "input_size": 16,
                "output_size": 12,
                "mean": 0.014894922263920307,
                "median": 0.01975538767874241,
                "std": 0.15389835834503174,
                "max": 0.2755168676376343,
                "min": -0.2498229742050171
            }
        }
    },
    "M3_Monthly_hidden_size_16_max_steps_200_learning_rate_0.0001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 200,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 1148
        },
        "scores": {
            "smape": 0.7410093816952329,
            "mse": 27140033.27776132,
            "mae": 4567.418285309806,
            "r2_score": -2.6874530101368856,
            "sn_smape": 0.07984804639626009,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    24
                ],
                "input_size": 24,
                "output_size": 16,
                "mean": 0.009968250058591366,
                "median": 0.002963694278150797,
                "std": 0.11799480020999908,
                "max": 0.22860439121723175,
                "min": -0.21051166951656342
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0009836412500590086,
                "median": -0.001111018587835133,
                "std": 0.14662128686904907,
                "max": 0.2776443064212799,
                "min": -0.25256848335266113
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0012833686778321862,
                "median": -0.008577952161431313,
                "std": 0.14677873253822327,
                "max": 0.2665870785713196,
                "min": -0.25511911511421204
            },
            "out.weight": {
                "shape": [
                    12,
                    16
                ],
                "input_size": 16,
                "output_size": 12,
                "mean": 0.015087262727320194,
                "median": 0.019688963890075684,
                "std": 0.15385490655899048,
                "max": 0.2755982577800751,
                "min": -0.2498229742050171
            }
        }
    },
    "M3_Quarterly_hidden_size_8_max_steps_50_learning_rate_0.001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 50,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 288
        },
        "scores": {
            "smape": 0.6863541529328748,
            "mse": 28535910.260584705,
            "mae": 4826.345907865946,
            "r2_score": -7.1333500564324375,
            "sn_smape": 0.08631027685390233,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06827734410762787,
                "median": 0.05230260640382767,
                "std": 0.19870710372924805,
                "max": 0.40710389614105225,
                "min": -0.2867780327796936
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06006646156311035,
                "median": 0.09012790024280548,
                "std": 0.2156846672296524,
                "max": 0.3956092894077301,
                "min": -0.33241644501686096
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.013527458533644676,
                "median": -0.016938909888267517,
                "std": 0.20740367472171783,
                "max": 0.4048902690410614,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0374794565141201,
                "median": 0.02284272573888302,
                "std": 0.22153759002685547,
                "max": 0.4051688611507416,
                "min": -0.32680240273475647
            }
        }
    },
    "M3_Quarterly_hidden_size_8_max_steps_50_learning_rate_0.001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 50,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 288
        },
        "scores": {
            "smape": 0.6856984171580427,
            "mse": 28582831.174560547,
            "mae": 4827.442406322212,
            "r2_score": -7.146723529184783,
            "sn_smape": 0.08631027685390233,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06830742210149765,
                "median": 0.05222602188587189,
                "std": 0.19865766167640686,
                "max": 0.4069688618183136,
                "min": -0.28687188029289246
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06045377999544144,
                "median": 0.09062299132347107,
                "std": 0.2156704068183899,
                "max": 0.3955152928829193,
                "min": -0.33241644501686096
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.012611407786607742,
                "median": -0.01688554510474205,
                "std": 0.20714707672595978,
                "max": 0.4048479497432709,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03674348443746567,
                "median": 0.019151553511619568,
                "std": 0.22133034467697144,
                "max": 0.40510961413383484,
                "min": -0.32564952969551086
            }
        }
    },
    "M3_Quarterly_hidden_size_8_max_steps_50_learning_rate_0.0005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 50,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 288
        },
        "scores": {
            "smape": 0.8507070086625512,
            "mse": 33790090.850087896,
            "mae": 5469.675405309554,
            "r2_score": -8.630904877845252,
            "sn_smape": 0.08631027685390233,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04351240396499634,
                "median": 0.033037543296813965,
                "std": 0.1965581327676773,
                "max": 0.3785952031612396,
                "min": -0.31753432750701904
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04320994392037392,
                "median": 0.08374343812465668,
                "std": 0.21043677628040314,
                "max": 0.3642621636390686,
                "min": -0.3462516963481903
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.00421280600130558,
                "median": -0.021233372390270233,
                "std": 0.20260483026504517,
                "max": 0.3733363449573517,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.020477838814258575,
                "median": 0.0013427019584923983,
                "std": 0.21948444843292236,
                "max": 0.37510788440704346,
                "min": -0.329267680644989
            }
        }
    },
    "M3_Quarterly_hidden_size_8_max_steps_50_learning_rate_0.0005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 50,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 288
        },
        "scores": {
            "smape": 0.8508207087358112,
            "mse": 33794599.64965771,
            "mae": 5470.112998634826,
            "r2_score": -8.632189982995243,
            "sn_smape": 0.08631027685390233,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.043623290956020355,
                "median": 0.03292521461844444,
                "std": 0.1964683085680008,
                "max": 0.37858396768569946,
                "min": -0.3176032304763794
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04369507357478142,
                "median": 0.08472375571727753,
                "std": 0.2104024440050125,
                "max": 0.36420950293540955,
                "min": -0.34652069211006165
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.004170997068285942,
                "median": -0.02123047411441803,
                "std": 0.2026219367980957,
                "max": 0.3733118772506714,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.020663168281316757,
                "median": 0.0020946208387613297,
                "std": 0.21948693692684174,
                "max": 0.3750647008419037,
                "min": -0.3280707597732544
            }
        }
    },
    "M3_Quarterly_hidden_size_8_max_steps_50_learning_rate_0.0001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 50,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 288
        },
        "scores": {
            "smape": 0.9281741551887888,
            "mse": 35924213.00295096,
            "mae": 5686.067855323283,
            "r2_score": -9.239175732845721,
            "sn_smape": 0.08631027685390233,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.025852270424365997,
                "median": 0.015709739178419113,
                "std": 0.1952357292175293,
                "max": 0.3572291433811188,
                "min": -0.34045079350471497
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03330480307340622,
                "median": 0.0713387131690979,
                "std": 0.20811712741851807,
                "max": 0.35237422585487366,
                "min": -0.33241644501686096
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.001512671820819378,
                "median": -0.014248584397137165,
                "std": 0.2000017613172531,
                "max": 0.3528834879398346,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.009091803804039955,
                "median": -0.009796210564672947,
                "std": 0.219175785779953,
                "max": 0.3531988561153412,
                "min": -0.3311662971973419
            }
        }
    },
    "M3_Quarterly_hidden_size_8_max_steps_50_learning_rate_0.0001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 50,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 288
        },
        "scores": {
            "smape": 0.9282169389721275,
            "mse": 35925231.42528261,
            "mae": 5686.164291722766,
            "r2_score": -9.239466005181628,
            "sn_smape": 0.08631027685390233,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.025854535400867462,
                "median": 0.01569238118827343,
                "std": 0.19522981345653534,
                "max": 0.3572269380092621,
                "min": -0.3404668867588043
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03331843018531799,
                "median": 0.0713697150349617,
                "std": 0.2081461399793625,
                "max": 0.35237422585487366,
                "min": -0.33241644501686096
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0015531275421380997,
                "median": -0.01424431148916483,
                "std": 0.1999996453523636,
                "max": 0.3528834879398346,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.009103911928832531,
                "median": -0.009799234569072723,
                "std": 0.21920092403888702,
                "max": 0.3531903326511383,
                "min": -0.33128198981285095
            }
        }
    },
    "M3_Quarterly_hidden_size_8_max_steps_100_learning_rate_0.001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 100,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 288
        },
        "scores": {
            "smape": 0.30788997120756606,
            "mse": 10640991.110814424,
            "mae": 2302.026403337282,
            "r2_score": -2.0329120347418073,
            "sn_smape": 0.08631027685390233,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.1011374443769455,
                "median": 0.07416871190071106,
                "std": 0.20224739611148834,
                "max": 0.4510539472103119,
                "min": -0.24957118928432465
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08013874292373657,
                "median": 0.09601122885942459,
                "std": 0.22456054389476776,
                "max": 0.454220712184906,
                "min": -0.33241644501686096
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.030177295207977295,
                "median": 0.003222380531951785,
                "std": 0.21539783477783203,
                "max": 0.44280487298965454,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0682215765118599,
                "median": 0.04321061819791794,
                "std": 0.22722110152244568,
                "max": 0.47202932834625244,
                "min": -0.3267576992511749
            }
        }
    },
    "M3_Quarterly_hidden_size_8_max_steps_100_learning_rate_0.001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 100,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 288
        },
        "scores": {
            "smape": 0.32003856647191387,
            "mse": 11115160.152430646,
            "mae": 2350.1262698437326,
            "r2_score": -2.1680604412993763,
            "sn_smape": 0.08631027685390233,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.10098960250616074,
                "median": 0.07532602548599243,
                "std": 0.20203571021556854,
                "max": 0.4500170648097992,
                "min": -0.24981385469436646
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08151718974113464,
                "median": 0.10120151937007904,
                "std": 0.22461353242397308,
                "max": 0.4538911283016205,
                "min": -0.33241644501686096
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.029299667105078697,
                "median": 0.0030178080778568983,
                "std": 0.2150181233882904,
                "max": 0.44324228167533875,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06761252880096436,
                "median": 0.04379759356379509,
                "std": 0.22690875828266144,
                "max": 0.47246697545051575,
                "min": -0.3255998492240906
            }
        }
    },
    "M3_Quarterly_hidden_size_8_max_steps_100_learning_rate_0.0005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 100,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 288
        },
        "scores": {
            "smape": 0.6345604259193566,
            "mse": 26753200.733099323,
            "mae": 4565.109914666232,
            "r2_score": -6.62523938102135,
            "sn_smape": 0.08631027685390233,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07373550534248352,
                "median": 0.057755716145038605,
                "std": 0.19854532182216644,
                "max": 0.4109255075454712,
                "min": -0.28105610609054565
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06518027186393738,
                "median": 0.09863607585430145,
                "std": 0.21787621080875397,
                "max": 0.40329352021217346,
                "min": -0.33241644501686096
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01700376719236374,
                "median": -0.015315706841647625,
                "std": 0.2086450755596161,
                "max": 0.41246911883354187,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04046178609132767,
                "median": 0.02709723263978958,
                "std": 0.22252701222896576,
                "max": 0.4099615812301636,
                "min": -0.32923808693885803
            }
        }
    },
    "M3_Quarterly_hidden_size_8_max_steps_100_learning_rate_0.0005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 100,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 288
        },
        "scores": {
            "smape": 0.6327261286123601,
            "mse": 26749132.725500308,
            "mae": 4558.438121415206,
            "r2_score": -6.624079911092658,
            "sn_smape": 0.08631027685390233,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07398094236850739,
                "median": 0.05784876272082329,
                "std": 0.19846206903457642,
                "max": 0.4108871519565582,
                "min": -0.2810567617416382
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06571789085865021,
                "median": 0.09922687709331512,
                "std": 0.21789218485355377,
                "max": 0.4033164381980896,
                "min": -0.33241644501686096
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01699082739651203,
                "median": -0.015306806191802025,
                "std": 0.20864033699035645,
                "max": 0.4125540256500244,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04071018099784851,
                "median": 0.027140790596604347,
                "std": 0.22252948582172394,
                "max": 0.41005393862724304,
                "min": -0.3280336558818817
            }
        }
    },
    "M3_Quarterly_hidden_size_8_max_steps_100_learning_rate_0.0001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 100,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 288
        },
        "scores": {
            "smape": 0.9113865673860311,
            "mse": 35494028.71973511,
            "mae": 5644.550007869743,
            "r2_score": -9.116563931357026,
            "sn_smape": 0.08631027685390233,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.030205613002181053,
                "median": 0.021309781819581985,
                "std": 0.19553665816783905,
                "max": 0.3625870645046234,
                "min": -0.3347876965999603
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.035893894731998444,
                "median": 0.07537248730659485,
                "std": 0.20851163566112518,
                "max": 0.35237422585487366,
                "min": -0.3373301327228546
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0019031092524528503,
                "median": -0.016889624297618866,
                "std": 0.2005157470703125,
                "max": 0.35612952709198,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.011891528964042664,
                "median": -0.006957393605262041,
                "std": 0.21918657422065735,
                "max": 0.35857993364334106,
                "min": -0.3310909867286682
            }
        }
    },
    "M3_Quarterly_hidden_size_8_max_steps_100_learning_rate_0.0001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 100,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 288
        },
        "scores": {
            "smape": 0.911360806612888,
            "mse": 35493842.47637817,
            "mae": 5644.520515656018,
            "r2_score": -9.116510847982296,
            "sn_smape": 0.08631027685390233,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.030221756547689438,
                "median": 0.021302934736013412,
                "std": 0.1955074816942215,
                "max": 0.3625933825969696,
                "min": -0.33479440212249756
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03594997525215149,
                "median": 0.07544116675853729,
                "std": 0.20853383839130402,
                "max": 0.35237422585487366,
                "min": -0.33735188841819763
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.001899472437798977,
                "median": -0.01689113862812519,
                "std": 0.20050212740898132,
                "max": 0.3561268150806427,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.011982986703515053,
                "median": -0.0069119371473789215,
                "std": 0.21920208632946014,
                "max": 0.35858386754989624,
                "min": -0.33120667934417725
            }
        }
    },
    "M3_Quarterly_hidden_size_8_max_steps_200_learning_rate_0.001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 200,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 288
        },
        "scores": {
            "smape": 0.057317272501233224,
            "mse": 1132131.5688891408,
            "mae": 613.7530510150566,
            "r2_score": 0.6773180783221049,
            "sn_smape": 0.08631027685390233,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.11176305264234543,
                "median": 0.0890783816576004,
                "std": 0.21026268601417542,
                "max": 0.5095899701118469,
                "min": -0.24511241912841797
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0806165263056755,
                "median": 0.0864858478307724,
                "std": 0.2358221560716629,
                "max": 0.5279189348220825,
                "min": -0.40353816747665405
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.034059587866067886,
                "median": 0.0008928847964853048,
                "std": 0.21797962486743927,
                "max": 0.46027684211730957,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07897473871707916,
                "median": 0.07220393419265747,
                "std": 0.22976456582546234,
                "max": 0.5313414335250854,
                "min": -0.3267574608325958
            }
        }
    },
    "M3_Quarterly_hidden_size_8_max_steps_200_learning_rate_0.001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 200,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 288
        },
        "scores": {
            "smape": 0.05958225356691836,
            "mse": 1172219.3292356252,
            "mae": 643.8093706556855,
            "r2_score": 0.6658922017722096,
            "sn_smape": 0.08631027685390233,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.11263930052518845,
                "median": 0.08953075110912323,
                "std": 0.21021975576877594,
                "max": 0.5121108293533325,
                "min": -0.2457520067691803
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08182920515537262,
                "median": 0.08888101577758789,
                "std": 0.23617610335350037,
                "max": 0.5306996703147888,
                "min": -0.4009473919868469
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03402549400925636,
                "median": 0.002772255800664425,
                "std": 0.2178673893213272,
                "max": 0.4512523114681244,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07884210348129272,
                "median": 0.07456155121326447,
                "std": 0.22998592257499695,
                "max": 0.529382050037384,
                "min": -0.3255995810031891
            }
        }
    },
    "M3_Quarterly_hidden_size_8_max_steps_200_learning_rate_0.0005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 200,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 288
        },
        "scores": {
            "smape": 0.24237962666161894,
            "mse": 8007927.892327957,
            "mae": 1972.7211890913948,
            "r2_score": -1.282432211911432,
            "sn_smape": 0.08631027685390233,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.10302917659282684,
                "median": 0.07636494934558868,
                "std": 0.20211027562618256,
                "max": 0.4550568461418152,
                "min": -0.24721315503120422
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08089831471443176,
                "median": 0.09788528829813004,
                "std": 0.22687920928001404,
                "max": 0.47365060448646545,
                "min": -0.33241644501686096
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0323917418718338,
                "median": 0.008682227693498135,
                "std": 0.21588847041130066,
                "max": 0.44013333320617676,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07099319994449615,
                "median": 0.03952499479055405,
                "std": 0.2280067652463913,
                "max": 0.48771214485168457,
                "min": -0.3292379677295685
            }
        }
    },
    "M3_Quarterly_hidden_size_8_max_steps_200_learning_rate_0.0005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 200,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 288
        },
        "scores": {
            "smape": 0.24213092239964543,
            "mse": 7992175.429739692,
            "mae": 1973.3710005325238,
            "r2_score": -1.2779424202310112,
            "sn_smape": 0.08631027685390233,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.1031021773815155,
                "median": 0.07643997669219971,
                "std": 0.20205479860305786,
                "max": 0.4552094638347626,
                "min": -0.24738001823425293
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08105349540710449,
                "median": 0.09789635241031647,
                "std": 0.22682450711727142,
                "max": 0.47377723455429077,
                "min": -0.33241644501686096
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.032392438501119614,
                "median": 0.008608152158558369,
                "std": 0.21582040190696716,
                "max": 0.44010818004608154,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07121783494949341,
                "median": 0.04010501503944397,
                "std": 0.22806113958358765,
                "max": 0.48796534538269043,
                "min": -0.3280334770679474
            }
        }
    },
    "M3_Quarterly_hidden_size_8_max_steps_200_learning_rate_0.0001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 200,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 288
        },
        "scores": {
            "smape": 0.8657819847096351,
            "mse": 34254990.610838085,
            "mae": 5518.4082159331765,
            "r2_score": -8.763411339381044,
            "sn_smape": 0.08631027685390233,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04039304330945015,
                "median": 0.03296106308698654,
                "std": 0.19614821672439575,
                "max": 0.3742760419845581,
                "min": -0.32173338532447815
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04247065633535385,
                "median": 0.0857996940612793,
                "std": 0.2102554589509964,
                "max": 0.36095136404037476,
                "min": -0.3454827666282654
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.003926766104996204,
                "median": -0.019841179251670837,
                "std": 0.2022179216146469,
                "max": 0.3698331117630005,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.017751449719071388,
                "median": -0.00042892899364233017,
                "std": 0.21950721740722656,
                "max": 0.37059932947158813,
                "min": -0.3310905396938324
            }
        }
    },
    "M3_Quarterly_hidden_size_8_max_steps_200_learning_rate_0.0001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 200,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 288
        },
        "scores": {
            "smape": 0.8657128921611126,
            "mse": 34253684.484202534,
            "mae": 5518.243969138582,
            "r2_score": -8.763039065111608,
            "sn_smape": 0.08631027685390233,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.040456973016262054,
                "median": 0.032791174948215485,
                "std": 0.1960824579000473,
                "max": 0.3742855191230774,
                "min": -0.3217218220233917
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04246057569980621,
                "median": 0.08514377474784851,
                "std": 0.21034207940101624,
                "max": 0.3609839379787445,
                "min": -0.3455210328102112
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.003913620486855507,
                "median": -0.019841179251670837,
                "std": 0.20219257473945618,
                "max": 0.3698534071445465,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.017823750153183937,
                "median": -8.884351700544357e-05,
                "std": 0.21951566636562347,
                "max": 0.37061750888824463,
                "min": -0.3312058746814728
            }
        }
    },
    "M3_Quarterly_hidden_size_16_max_steps_50_learning_rate_0.001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 50,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 824
        },
        "scores": {
            "smape": 0.37113986196748394,
            "mse": 17902708.253608532,
            "mae": 3215.1710420604486,
            "r2_score": -4.102658084326232,
            "sn_smape": 0.08631027685390233,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    8
                ],
                "input_size": 8,
                "output_size": 16,
                "mean": 0.0486881323158741,
                "median": 0.048412591218948364,
                "std": 0.2041374295949936,
                "max": 0.4111637771129608,
                "min": -0.3814343214035034
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.031990788877010345,
                "median": 0.020855098962783813,
                "std": 0.15036436915397644,
                "max": 0.3090853691101074,
                "min": -0.2687055766582489
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.016182752326130867,
                "median": 0.008667724207043648,
                "std": 0.1534550040960312,
                "max": 0.30931356549263,
                "min": -0.28746283054351807
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.03705720603466034,
                "median": 0.029941152781248093,
                "std": 0.15105092525482178,
                "max": 0.3094300925731659,
                "min": -0.2430494725704193
            }
        }
    },
    "M3_Quarterly_hidden_size_16_max_steps_50_learning_rate_0.001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 50,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 824
        },
        "scores": {
            "smape": 0.37003793276635477,
            "mse": 17829240.332718298,
            "mae": 3213.751677320773,
            "r2_score": -4.0817181418796125,
            "sn_smape": 0.08631027685390233,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    8
                ],
                "input_size": 8,
                "output_size": 16,
                "mean": 0.04866684973239899,
                "median": 0.04701976478099823,
                "std": 0.20411281287670135,
                "max": 0.4110659956932068,
                "min": -0.3814038932323456
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.03218111768364906,
                "median": 0.020394805818796158,
                "std": 0.15021578967571259,
                "max": 0.3088536560535431,
                "min": -0.2689523994922638
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.016498055309057236,
                "median": 0.006468616891652346,
                "std": 0.15354099869728088,
                "max": 0.30925843119621277,
                "min": -0.2871461808681488
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.03752276673913002,
                "median": 0.030039876699447632,
                "std": 0.1511899083852768,
                "max": 0.3091371953487396,
                "min": -0.2430494725704193
            }
        }
    },
    "M3_Quarterly_hidden_size_16_max_steps_50_learning_rate_0.0005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 50,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 824
        },
        "scores": {
            "smape": 0.7594892399670817,
            "mse": 30601673.30585086,
            "mae": 5135.236629704671,
            "r2_score": -7.722137090992144,
            "sn_smape": 0.08631027685390233,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    8
                ],
                "input_size": 8,
                "output_size": 16,
                "mean": 0.028182080015540123,
                "median": 0.045872949063777924,
                "std": 0.20081587135791779,
                "max": 0.37922191619873047,
                "min": -0.3541123867034912
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.01576385460793972,
                "median": 0.0017653161194175482,
                "std": 0.1452002227306366,
                "max": 0.2763243317604065,
                "min": -0.24367749691009521
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.005023758392781019,
                "median": -0.0010743660386651754,
                "std": 0.14894026517868042,
                "max": 0.27773427963256836,
                "min": -0.2711861729621887
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.01858312264084816,
                "median": 0.014877328649163246,
                "std": 0.14768771827220917,
                "max": 0.2786288559436798,
                "min": -0.2430494725704193
            }
        }
    },
    "M3_Quarterly_hidden_size_16_max_steps_50_learning_rate_0.0005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 50,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 824
        },
        "scores": {
            "smape": 0.7597687829677857,
            "mse": 30619797.830443088,
            "mae": 5136.752045397831,
            "r2_score": -7.72730297151843,
            "sn_smape": 0.08631027685390233,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    8
                ],
                "input_size": 8,
                "output_size": 16,
                "mean": 0.027979619801044464,
                "median": 0.04555231332778931,
                "std": 0.20087073743343353,
                "max": 0.37936267256736755,
                "min": -0.35417482256889343
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.015675777569413185,
                "median": 0.0013770149089396,
                "std": 0.14522521197795868,
                "max": 0.2760257124900818,
                "min": -0.24485933780670166
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.005178544204682112,
                "median": -0.0009592975256964564,
                "std": 0.1489754468202591,
                "max": 0.27770712971687317,
                "min": -0.2710958421230316
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.01868455484509468,
                "median": 0.015331549569964409,
                "std": 0.1476958841085434,
                "max": 0.27818384766578674,
                "min": -0.2430494725704193
            }
        }
    },
    "M3_Quarterly_hidden_size_16_max_steps_50_learning_rate_0.0001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 50,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 824
        },
        "scores": {
            "smape": 0.9261432378318488,
            "mse": 35661976.88580201,
            "mae": 5663.822884556966,
            "r2_score": -9.164432781990634,
            "sn_smape": 0.08631027685390233,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    8
                ],
                "input_size": 8,
                "output_size": 16,
                "mean": 0.014197618700563908,
                "median": 0.023523394018411636,
                "std": 0.19880448281764984,
                "max": 0.3566690683364868,
                "min": -0.3404674828052521
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0044089509174227715,
                "median": -0.004995419178158045,
                "std": 0.1421409249305725,
                "max": 0.253378301858902,
                "min": -0.2416815608739853
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.0018409446347504854,
                "median": -0.003404830116778612,
                "std": 0.14701952040195465,
                "max": 0.2531634271144867,
                "min": -0.25091928243637085
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.004124297760426998,
                "median": -0.0033237342722713947,
                "std": 0.14612598717212677,
                "max": 0.253911554813385,
                "min": -0.2430494725704193
            }
        }
    },
    "M3_Quarterly_hidden_size_16_max_steps_50_learning_rate_0.0001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 50,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 824
        },
        "scores": {
            "smape": 0.9261821546144052,
            "mse": 35663628.07574339,
            "mae": 5663.963247496718,
            "r2_score": -9.164903406746609,
            "sn_smape": 0.08631027685390233,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    8
                ],
                "input_size": 8,
                "output_size": 16,
                "mean": 0.014119060710072517,
                "median": 0.023518800735473633,
                "std": 0.19883160293102264,
                "max": 0.35667672753334045,
                "min": -0.3404887318611145
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.004419917706400156,
                "median": -0.005295994691550732,
                "std": 0.14213617146015167,
                "max": 0.2533465027809143,
                "min": -0.24099308252334595
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.0018374980427324772,
                "median": -0.003297575283795595,
                "std": 0.14701880514621735,
                "max": 0.25316163897514343,
                "min": -0.2509014308452606
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.004158127587288618,
                "median": -0.0032259677536785603,
                "std": 0.14612488448619843,
                "max": 0.2538633644580841,
                "min": -0.2430494725704193
            }
        }
    },
    "M3_Quarterly_hidden_size_16_max_steps_100_learning_rate_0.001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 100,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 824
        },
        "scores": {
            "smape": 0.14216055249153056,
            "mse": 4383844.0204296345,
            "mae": 1192.3722826333021,
            "r2_score": -0.24949012263335413,
            "sn_smape": 0.08631027685390233,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    8
                ],
                "input_size": 8,
                "output_size": 16,
                "mean": 0.05552798509597778,
                "median": 0.05769618600606918,
                "std": 0.20655572414398193,
                "max": 0.4307750463485718,
                "min": -0.3908880650997162
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.04745802283287048,
                "median": 0.03292883560061455,
                "std": 0.15410621464252472,
                "max": 0.3923587203025818,
                "min": -0.2578122019767761
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.021273184567689896,
                "median": 0.009000839665532112,
                "std": 0.15505994856357574,
                "max": 0.32875412702560425,
                "min": -0.2895857095718384
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.052096571773290634,
                "median": 0.04792116582393646,
                "std": 0.1520998775959015,
                "max": 0.3516746163368225,
                "min": -0.2430494725704193
            }
        }
    },
    "M3_Quarterly_hidden_size_16_max_steps_100_learning_rate_0.001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 100,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 824
        },
        "scores": {
            "smape": 0.14076682753073527,
            "mse": 4322932.813891342,
            "mae": 1189.1096797603022,
            "r2_score": -0.23212911467490538,
            "sn_smape": 0.08631027685390233,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    8
                ],
                "input_size": 8,
                "output_size": 16,
                "mean": 0.05507911741733551,
                "median": 0.05667218565940857,
                "std": 0.20669585466384888,
                "max": 0.43015286326408386,
                "min": -0.38984915614128113
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.04805753380060196,
                "median": 0.03304578363895416,
                "std": 0.15384642779827118,
                "max": 0.3917931318283081,
                "min": -0.2611803710460663
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.021956373006105423,
                "median": 0.009848508983850479,
                "std": 0.1550029218196869,
                "max": 0.3302752375602722,
                "min": -0.2891922891139984
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.05272611230611801,
                "median": 0.05518998205661774,
                "std": 0.15217864513397217,
                "max": 0.35048386454582214,
                "min": -0.2430494725704193
            }
        }
    },
    "M3_Quarterly_hidden_size_16_max_steps_100_learning_rate_0.0005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 100,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 824
        },
        "scores": {
            "smape": 0.29592843539973124,
            "mse": 15562908.827987444,
            "mae": 2760.2669926155936,
            "r2_score": -3.435764769319503,
            "sn_smape": 0.08631027685390233,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    8
                ],
                "input_size": 8,
                "output_size": 16,
                "mean": 0.05463483929634094,
                "median": 0.05265124514698982,
                "std": 0.20423607528209686,
                "max": 0.4197743237018585,
                "min": -0.38419511914253235
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.037142932415008545,
                "median": 0.02009880170226097,
                "std": 0.15145643055438995,
                "max": 0.3184243440628052,
                "min": -0.2438051998615265
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.017839593812823296,
                "median": 0.007245062384754419,
                "std": 0.15497203171253204,
                "max": 0.3176911771297455,
                "min": -0.2834646701812744
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.036607660353183746,
                "median": 0.02147073671221733,
                "std": 0.15163689851760864,
                "max": 0.3263622224330902,
                "min": -0.2430494725704193
            }
        }
    },
    "M3_Quarterly_hidden_size_16_max_steps_100_learning_rate_0.0005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 100,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 824
        },
        "scores": {
            "smape": 0.29702244902258584,
            "mse": 15651496.687618377,
            "mae": 2769.0625227973574,
            "r2_score": -3.4610142205039534,
            "sn_smape": 0.08631027685390233,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    8
                ],
                "input_size": 8,
                "output_size": 16,
                "mean": 0.05360112339258194,
                "median": 0.05168981850147247,
                "std": 0.20469129085540771,
                "max": 0.4197464883327484,
                "min": -0.38435235619544983
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.036544498056173325,
                "median": 0.019110698252916336,
                "std": 0.15159611403942108,
                "max": 0.31775224208831787,
                "min": -0.24395838379859924
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.01857208088040352,
                "median": 0.007999077439308167,
                "std": 0.1548698991537094,
                "max": 0.31768620014190674,
                "min": -0.2830273509025574
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.03741103410720825,
                "median": 0.02664177678525448,
                "std": 0.15160143375396729,
                "max": 0.32577332854270935,
                "min": -0.2430494725704193
            }
        }
    },
    "M3_Quarterly_hidden_size_16_max_steps_100_learning_rate_0.0001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 100,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 824
        },
        "scores": {
            "smape": 0.8943120681421605,
            "mse": 34773109.164134555,
            "mae": 5579.20265016193,
            "r2_score": -8.911086304931843,
            "sn_smape": 0.08631027685390233,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    8
                ],
                "input_size": 8,
                "output_size": 16,
                "mean": 0.017639681696891785,
                "median": 0.02859601378440857,
                "std": 0.19917981326580048,
                "max": 0.3610525131225586,
                "min": -0.3376592993736267
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.007383223623037338,
                "median": -0.003231999697163701,
                "std": 0.14280866086483002,
                "max": 0.25894105434417725,
                "min": -0.239848330616951
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.0002921614795923233,
                "median": -0.004431046079844236,
                "std": 0.14730578660964966,
                "max": 0.25964730978012085,
                "min": -0.25604164600372314
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.007757955696433783,
                "median": 0.003024980193004012,
                "std": 0.14647532999515533,
                "max": 0.25999581813812256,
                "min": -0.2430494725704193
            }
        }
    },
    "M3_Quarterly_hidden_size_16_max_steps_100_learning_rate_0.0001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 100,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 824
        },
        "scores": {
            "smape": 0.8942596472583978,
            "mse": 34770734.567961186,
            "mae": 5578.987127465987,
            "r2_score": -8.910409493793024,
            "sn_smape": 0.08631027685390233,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    8
                ],
                "input_size": 8,
                "output_size": 16,
                "mean": 0.017554137855768204,
                "median": 0.02874130569398403,
                "std": 0.1991763561964035,
                "max": 0.3611244261264801,
                "min": -0.337687224149704
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.007411228492856026,
                "median": -0.004141706973314285,
                "std": 0.14281192421913147,
                "max": 0.25878310203552246,
                "min": -0.2398306280374527
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.000230494886636734,
                "median": -0.004617811646312475,
                "std": 0.14728973805904388,
                "max": 0.2596454620361328,
                "min": -0.25603869557380676
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.007828747853636742,
                "median": 0.0034670960158109665,
                "std": 0.14647753536701202,
                "max": 0.25981125235557556,
                "min": -0.2430494725704193
            }
        }
    },
    "M3_Quarterly_hidden_size_16_max_steps_200_learning_rate_0.001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 200,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 824
        },
        "scores": {
            "smape": 0.054150208927897445,
            "mse": 1043774.7429532413,
            "mae": 576.8306976249736,
            "r2_score": 0.7025016799191619,
            "sn_smape": 0.08631027685390233,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    8
                ],
                "input_size": 8,
                "output_size": 16,
                "mean": 0.05205945670604706,
                "median": 0.05441155284643173,
                "std": 0.21214915812015533,
                "max": 0.46128273010253906,
                "min": -0.39236825704574585
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.07110941410064697,
                "median": 0.054887108504772186,
                "std": 0.1636824905872345,
                "max": 0.5273568034172058,
                "min": -0.24779531359672546
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.022927427664399147,
                "median": 0.01289546862244606,
                "std": 0.1580762416124344,
                "max": 0.35837480425834656,
                "min": -0.28960075974464417
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.05485343188047409,
                "median": 0.06302530318498611,
                "std": 0.15152721107006073,
                "max": 0.3387352228164673,
                "min": -0.2430494725704193
            }
        }
    },
    "M3_Quarterly_hidden_size_16_max_steps_200_learning_rate_0.001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 200,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 824
        },
        "scores": {
            "smape": 0.05286897919085322,
            "mse": 1023193.4090034208,
            "mae": 560.5852612110925,
            "r2_score": 0.7083678041154328,
            "sn_smape": 0.08631027685390233,
            "is_better": true
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    8
                ],
                "input_size": 8,
                "output_size": 16,
                "mean": 0.05033485218882561,
                "median": 0.049882106482982635,
                "std": 0.2124323695898056,
                "max": 0.46156781911849976,
                "min": -0.39357292652130127
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.07190913707017899,
                "median": 0.0571863129734993,
                "std": 0.1630222350358963,
                "max": 0.5328376889228821,
                "min": -0.24867106974124908
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.025744976475834846,
                "median": 0.022043932229280472,
                "std": 0.15758290886878967,
                "max": 0.3572399914264679,
                "min": -0.28920671343803406
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.05515072122216225,
                "median": 0.06457680463790894,
                "std": 0.1513179987668991,
                "max": 0.3415154218673706,
                "min": -0.2430494725704193
            }
        }
    },
    "M3_Quarterly_hidden_size_16_max_steps_200_learning_rate_0.0005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 200,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 824
        },
        "scores": {
            "smape": 0.11935479410165982,
            "mse": 3494182.962888164,
            "mae": 1057.9217072863303,
            "r2_score": 0.00408247226491687,
            "sn_smape": 0.08631027685390233,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    8
                ],
                "input_size": 8,
                "output_size": 16,
                "mean": 0.05809493735432625,
                "median": 0.06257776916027069,
                "std": 0.206854909658432,
                "max": 0.4400908648967743,
                "min": -0.3915521800518036
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.05171133205294609,
                "median": 0.03777911514043808,
                "std": 0.1550607979297638,
                "max": 0.4221954345703125,
                "min": -0.2438061684370041
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.020421013236045837,
                "median": 0.011718053370714188,
                "std": 0.15605933964252472,
                "max": 0.33955520391464233,
                "min": -0.2836315333843231
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.045340318232774734,
                "median": 0.03636367619037628,
                "std": 0.1516043245792389,
                "max": 0.3554452061653137,
                "min": -0.2430494725704193
            }
        }
    },
    "M3_Quarterly_hidden_size_16_max_steps_200_learning_rate_0.0005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 200,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 824
        },
        "scores": {
            "smape": 0.11818682293667875,
            "mse": 3390316.8522642087,
            "mae": 1069.4470139092743,
            "r2_score": 0.03368655459452874,
            "sn_smape": 0.08631027685390233,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    8
                ],
                "input_size": 8,
                "output_size": 16,
                "mean": 0.05845857784152031,
                "median": 0.0611325204372406,
                "std": 0.20677196979522705,
                "max": 0.44073960185050964,
                "min": -0.39132213592529297
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.05058004707098007,
                "median": 0.040385618805885315,
                "std": 0.15561650693416595,
                "max": 0.4227061867713928,
                "min": -0.2439592331647873
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.021130798384547234,
                "median": 0.01037161611020565,
                "std": 0.15618321299552917,
                "max": 0.33915776014328003,
                "min": -0.28317901492118835
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.04689648002386093,
                "median": 0.035873182117938995,
                "std": 0.15191154181957245,
                "max": 0.35306546092033386,
                "min": -0.2430494725704193
            }
        }
    },
    "M3_Quarterly_hidden_size_16_max_steps_200_learning_rate_0.0001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 200,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 824
        },
        "scores": {
            "smape": 0.7838422589996307,
            "mse": 31393916.44602156,
            "mae": 5222.272325748533,
            "r2_score": -7.947943477750927,
            "sn_smape": 0.08631027685390233,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    8
                ],
                "input_size": 8,
                "output_size": 16,
                "mean": 0.02671925164759159,
                "median": 0.03963539004325867,
                "std": 0.20020362734794617,
                "max": 0.37594881653785706,
                "min": -0.35010963678359985
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.015186471864581108,
                "median": 0.004443975631147623,
                "std": 0.14466492831707,
                "max": 0.2756861448287964,
                "min": -0.24010740220546722
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.005049135535955429,
                "median": 0.00050860590999946,
                "std": 0.14899778366088867,
                "max": 0.27558356523513794,
                "min": -0.2660648226737976
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.015241403132677078,
                "median": 0.010715178214013577,
                "std": 0.1474222093820572,
                "max": 0.2779402732849121,
                "min": -0.2430494725704193
            }
        }
    },
    "M3_Quarterly_hidden_size_16_max_steps_200_learning_rate_0.0001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "M3",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 200,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 824
        },
        "scores": {
            "smape": 0.7832612763054556,
            "mse": 31371519.385739353,
            "mae": 5219.604294861805,
            "r2_score": -7.941559832377546,
            "sn_smape": 0.08631027685390233,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    8
                ],
                "input_size": 8,
                "output_size": 16,
                "mean": 0.026337428018450737,
                "median": 0.039366669952869415,
                "std": 0.2001255452632904,
                "max": 0.375622034072876,
                "min": -0.35015934705734253
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.015336735174059868,
                "median": 0.004103951621800661,
                "std": 0.1446741819381714,
                "max": 0.2755933701992035,
                "min": -0.24007196724414825
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.005158959422260523,
                "median": 0.00046560558257624507,
                "std": 0.14900149405002594,
                "max": 0.2755310833454132,
                "min": -0.2660267651081085
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.015318497084081173,
                "median": 0.010740550234913826,
                "std": 0.14741769433021545,
                "max": 0.2773934304714203,
                "min": -0.2430494725704193
            }
        }
    },
    "Tourism_Monthly_hidden_size_8_max_steps_50_learning_rate_0.001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 50,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 452
        },
        "scores": {
            "smape": 0.5823894874109239,
            "mse": 4123590782.1057167,
            "mae": 15101.431416848865,
            "r2_score": 0.27966573454574417,
            "sn_smape": 0.09147245045800445,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    24
                ],
                "input_size": 24,
                "output_size": 8,
                "mean": 0.022377878427505493,
                "median": 0.0328596830368042,
                "std": 0.12052653729915619,
                "max": 0.2576063573360443,
                "min": -0.22223040461540222
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03637353330850601,
                "median": 0.0053586894646286964,
                "std": 0.22589215636253357,
                "max": 0.40240558981895447,
                "min": -0.3401097059249878
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.0057233599945902824,
                "median": -0.02432306297123432,
                "std": 0.18424925208091736,
                "max": 0.36299949884414673,
                "min": -0.35723739862442017
            },
            "out.weight": {
                "shape": [
                    12,
                    8
                ],
                "input_size": 8,
                "output_size": 12,
                "mean": 0.041353490203619,
                "median": 0.03473062813282013,
                "std": 0.19835485517978668,
                "max": 0.3937876522541046,
                "min": -0.3306635320186615
            }
        }
    },
    "Tourism_Monthly_hidden_size_8_max_steps_50_learning_rate_0.001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 50,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 452
        },
        "scores": {
            "smape": 0.5547207497969517,
            "mse": 3947177868.7913938,
            "mae": 14629.52514770928,
            "r2_score": 0.31048263007290566,
            "sn_smape": 0.09147245045800445,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    24
                ],
                "input_size": 24,
                "output_size": 8,
                "mean": 0.023310871794819832,
                "median": 0.03385641425848007,
                "std": 0.12120059877634048,
                "max": 0.26027682423591614,
                "min": -0.22393353283405304
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.036424294114112854,
                "median": 0.00785072147846222,
                "std": 0.22686362266540527,
                "max": 0.40319859981536865,
                "min": -0.34834375977516174
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.004478978458791971,
                "median": -0.02715083211660385,
                "std": 0.18558606505393982,
                "max": 0.36641350388526917,
                "min": -0.3566353917121887
            },
            "out.weight": {
                "shape": [
                    12,
                    8
                ],
                "input_size": 8,
                "output_size": 12,
                "mean": 0.042375121265649796,
                "median": 0.03358663618564606,
                "std": 0.1990620195865631,
                "max": 0.3975180983543396,
                "min": -0.3317117393016815
            }
        }
    },
    "Tourism_Monthly_hidden_size_8_max_steps_50_learning_rate_0.0005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 50,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 452
        },
        "scores": {
            "smape": 0.849035374845533,
            "mse": 5581500011.856266,
            "mae": 18479.57267081002,
            "r2_score": 0.024989160267666843,
            "sn_smape": 0.09147245045800445,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    24
                ],
                "input_size": 24,
                "output_size": 8,
                "mean": 0.013979244977235794,
                "median": 0.0208735428750515,
                "std": 0.11703946441411972,
                "max": 0.22894072532653809,
                "min": -0.2157215029001236
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.031114041805267334,
                "median": 0.0024238149635493755,
                "std": 0.22058503329753876,
                "max": 0.37315669655799866,
                "min": -0.33231621980667114
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.01581164263188839,
                "median": -0.04484378546476364,
                "std": 0.18074138462543488,
                "max": 0.3347315788269043,
                "min": -0.35383057594299316
            },
            "out.weight": {
                "shape": [
                    12,
                    8
                ],
                "input_size": 8,
                "output_size": 12,
                "mean": 0.025066571310162544,
                "median": 0.03066430613398552,
                "std": 0.19483135640621185,
                "max": 0.36696937680244446,
                "min": -0.33522459864616394
            }
        }
    },
    "Tourism_Monthly_hidden_size_8_max_steps_50_learning_rate_0.0005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 50,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 452
        },
        "scores": {
            "smape": 0.8288990703837451,
            "mse": 5494873457.177676,
            "mae": 18296.69150572306,
            "r2_score": 0.040121621011351416,
            "sn_smape": 0.09147245045800445,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    24
                ],
                "input_size": 24,
                "output_size": 8,
                "mean": 0.013491731137037277,
                "median": 0.02089705690741539,
                "std": 0.11733607202768326,
                "max": 0.2315041720867157,
                "min": -0.21842627227306366
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03197701275348663,
                "median": -0.00041787000373005867,
                "std": 0.22091448307037354,
                "max": 0.3743435740470886,
                "min": -0.33277755975723267
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.01465913001447916,
                "median": -0.04374700039625168,
                "std": 0.1813156008720398,
                "max": 0.3366008400917053,
                "min": -0.3537611663341522
            },
            "out.weight": {
                "shape": [
                    12,
                    8
                ],
                "input_size": 8,
                "output_size": 12,
                "mean": 0.0259980708360672,
                "median": 0.029596924781799316,
                "std": 0.19532804191112518,
                "max": 0.36874088644981384,
                "min": -0.3352785110473633
            }
        }
    },
    "Tourism_Monthly_hidden_size_8_max_steps_50_learning_rate_0.0001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 50,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 452
        },
        "scores": {
            "smape": 0.9589753210394797,
            "mse": 6009609200.41023,
            "mae": 19338.02784364393,
            "r2_score": -0.049795592673739675,
            "sn_smape": 0.09147245045800445,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    24
                ],
                "input_size": 24,
                "output_size": 8,
                "mean": 0.006899900734424591,
                "median": 0.01233713235706091,
                "std": 0.11567312479019165,
                "max": 0.20784372091293335,
                "min": -0.20368890464305878
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.028760502114892006,
                "median": 0.009946583770215511,
                "std": 0.2183838188648224,
                "max": 0.35117727518081665,
                "min": -0.33231621980667114
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.022389236837625504,
                "median": -0.05963846296072006,
                "std": 0.17861193418502808,
                "max": 0.3183196187019348,
                "min": -0.3493988513946533
            },
            "out.weight": {
                "shape": [
                    12,
                    8
                ],
                "input_size": 8,
                "output_size": 12,
                "mean": 0.012034564279019833,
                "median": 0.01957932859659195,
                "std": 0.19329625368118286,
                "max": 0.35368916392326355,
                "min": -0.3417554795742035
            }
        }
    },
    "Tourism_Monthly_hidden_size_8_max_steps_50_learning_rate_0.0001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 50,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 452
        },
        "scores": {
            "smape": 0.9576489851930973,
            "mse": 6004579030.726396,
            "mae": 19328.772377678502,
            "r2_score": -0.04891689161541968,
            "sn_smape": 0.09147245045800445,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    24
                ],
                "input_size": 24,
                "output_size": 8,
                "mean": 0.006861494388431311,
                "median": 0.012895021587610245,
                "std": 0.11572158336639404,
                "max": 0.20830850303173065,
                "min": -0.20404955744743347
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02886183187365532,
                "median": 0.009081389755010605,
                "std": 0.21837837994098663,
                "max": 0.35138991475105286,
                "min": -0.33231621980667114
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.022124316543340683,
                "median": -0.05914100259542465,
                "std": 0.17869971692562103,
                "max": 0.3187515437602997,
                "min": -0.349489688873291
            },
            "out.weight": {
                "shape": [
                    12,
                    8
                ],
                "input_size": 8,
                "output_size": 12,
                "mean": 0.01230562012642622,
                "median": 0.019799552857875824,
                "std": 0.193344846367836,
                "max": 0.35357972979545593,
                "min": -0.3413420021533966
            }
        }
    },
    "Tourism_Monthly_hidden_size_8_max_steps_100_learning_rate_0.001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 100,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 452
        },
        "scores": {
            "smape": 0.2687701426399148,
            "mse": 1504751617.8806832,
            "mae": 7828.803014843756,
            "r2_score": 0.7371407085152912,
            "sn_smape": 0.09147245045800445,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    24
                ],
                "input_size": 24,
                "output_size": 8,
                "mean": 0.0442533977329731,
                "median": 0.051542457193136215,
                "std": 0.12629178166389465,
                "max": 0.28438761830329895,
                "min": -0.2226937860250473
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.040236249566078186,
                "median": 0.0001592292683199048,
                "std": 0.23462097346782684,
                "max": 0.4428859353065491,
                "min": -0.36528119444847107
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.005895966663956642,
                "median": -0.015069238841533661,
                "std": 0.1894165426492691,
                "max": 0.4233758747577667,
                "min": -0.35733291506767273
            },
            "out.weight": {
                "shape": [
                    12,
                    8
                ],
                "input_size": 8,
                "output_size": 12,
                "mean": 0.06456007808446884,
                "median": 0.055120207369327545,
                "std": 0.2029581218957901,
                "max": 0.4603278636932373,
                "min": -0.330340176820755
            }
        }
    },
    "Tourism_Monthly_hidden_size_8_max_steps_100_learning_rate_0.001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 100,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 452
        },
        "scores": {
            "smape": 0.26571979059825107,
            "mse": 1401941907.25067,
            "mae": 7613.514292729262,
            "r2_score": 0.7551001427320924,
            "sn_smape": 0.09147245045800445,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    24
                ],
                "input_size": 24,
                "output_size": 8,
                "mean": 0.04509100317955017,
                "median": 0.052526745945215225,
                "std": 0.1269661784172058,
                "max": 0.28619036078453064,
                "min": -0.22158703207969666
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0396999791264534,
                "median": -3.869610372930765e-05,
                "std": 0.2354786992073059,
                "max": 0.44145524501800537,
                "min": -0.3694784641265869
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.005711567588150501,
                "median": -0.011630051769316196,
                "std": 0.19024667143821716,
                "max": 0.4252059757709503,
                "min": -0.3567237854003906
            },
            "out.weight": {
                "shape": [
                    12,
                    8
                ],
                "input_size": 8,
                "output_size": 12,
                "mean": 0.06465910375118256,
                "median": 0.057372406125068665,
                "std": 0.2029392272233963,
                "max": 0.4607234597206116,
                "min": -0.3314565122127533
            }
        }
    },
    "Tourism_Monthly_hidden_size_8_max_steps_100_learning_rate_0.0005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 100,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 452
        },
        "scores": {
            "smape": 0.4979373607047728,
            "mse": 3606924075.965786,
            "mae": 13620.00142636146,
            "r2_score": 0.3699202607385509,
            "sn_smape": 0.09147245045800445,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    24
                ],
                "input_size": 24,
                "output_size": 8,
                "mean": 0.02645130455493927,
                "median": 0.037286896258592606,
                "std": 0.12099500745534897,
                "max": 0.2643252909183502,
                "min": -0.22131389379501343
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03890411928296089,
                "median": 0.012537561357021332,
                "std": 0.2278687208890915,
                "max": 0.412952184677124,
                "min": -0.3442138135433197
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.002275485545396805,
                "median": -0.024234747514128685,
                "std": 0.18590258061885834,
                "max": 0.37110137939453125,
                "min": -0.3539632260799408
            },
            "out.weight": {
                "shape": [
                    12,
                    8
                ],
                "input_size": 8,
                "output_size": 12,
                "mean": 0.04409143701195717,
                "median": 0.03502077981829643,
                "std": 0.20076587796211243,
                "max": 0.40072375535964966,
                "min": -0.33480364084243774
            }
        }
    },
    "Tourism_Monthly_hidden_size_8_max_steps_100_learning_rate_0.0005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 100,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 452
        },
        "scores": {
            "smape": 0.46404108703052505,
            "mse": 3387271214.8589964,
            "mae": 12933.208249052564,
            "r2_score": 0.4082905769801368,
            "sn_smape": 0.09147245045800445,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    24
                ],
                "input_size": 24,
                "output_size": 8,
                "mean": 0.027220776304602623,
                "median": 0.03649057447910309,
                "std": 0.12162436544895172,
                "max": 0.2674902081489563,
                "min": -0.22242623567581177
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.040085043758153915,
                "median": 0.008294276893138885,
                "std": 0.22832751274108887,
                "max": 0.41561415791511536,
                "min": -0.3502708971500397
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.0012107128277420998,
                "median": -0.027207694947719574,
                "std": 0.1872006505727768,
                "max": 0.37425604462623596,
                "min": -0.35386210680007935
            },
            "out.weight": {
                "shape": [
                    12,
                    8
                ],
                "input_size": 8,
                "output_size": 12,
                "mean": 0.04570816829800606,
                "median": 0.03688078746199608,
                "std": 0.20162594318389893,
                "max": 0.4035877287387848,
                "min": -0.3346032500267029
            }
        }
    },
    "Tourism_Monthly_hidden_size_8_max_steps_100_learning_rate_0.0001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 100,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 452
        },
        "scores": {
            "smape": 0.9387959178095622,
            "mse": 5940063249.896022,
            "mae": 19202.905825262973,
            "r2_score": -0.037646877191019446,
            "sn_smape": 0.09147245045800445,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    24
                ],
                "input_size": 24,
                "output_size": 8,
                "mean": 0.009128441102802753,
                "median": 0.017890170216560364,
                "std": 0.11578834056854248,
                "max": 0.212967187166214,
                "min": -0.20772132277488708
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02890852279961109,
                "median": 0.007559043355286121,
                "std": 0.21887698769569397,
                "max": 0.35509777069091797,
                "min": -0.33231621980667114
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.020974857732653618,
                "median": -0.057613760232925415,
                "std": 0.1789853572845459,
                "max": 0.3199484050273895,
                "min": -0.3502199351787567
            },
            "out.weight": {
                "shape": [
                    12,
                    8
                ],
                "input_size": 8,
                "output_size": 12,
                "mean": 0.01524321734905243,
                "median": 0.023363223299384117,
                "std": 0.1936168074607849,
                "max": 0.35468077659606934,
                "min": -0.33795273303985596
            }
        }
    },
    "Tourism_Monthly_hidden_size_8_max_steps_100_learning_rate_0.0001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 100,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 452
        },
        "scores": {
            "smape": 0.93598749865926,
            "mse": 5930813428.610273,
            "mae": 19183.49143304337,
            "r2_score": -0.0360310613708934,
            "sn_smape": 0.09147245045800445,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    24
                ],
                "input_size": 24,
                "output_size": 8,
                "mean": 0.009235309436917305,
                "median": 0.018728595227003098,
                "std": 0.11585789173841476,
                "max": 0.21363645792007446,
                "min": -0.208222433924675
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.029179275035858154,
                "median": 0.006609736010432243,
                "std": 0.21894779801368713,
                "max": 0.357212096452713,
                "min": -0.33231621980667114
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.02040703594684601,
                "median": -0.056513309478759766,
                "std": 0.17917297780513763,
                "max": 0.32065549492836,
                "min": -0.35035815834999084
            },
            "out.weight": {
                "shape": [
                    12,
                    8
                ],
                "input_size": 8,
                "output_size": 12,
                "mean": 0.015842901542782784,
                "median": 0.02352321892976761,
                "std": 0.19373641908168793,
                "max": 0.3544483184814453,
                "min": -0.3381922245025635
            }
        }
    },
    "Tourism_Monthly_hidden_size_8_max_steps_200_learning_rate_0.001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 200,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 452
        },
        "scores": {
            "smape": 0.16791527985923177,
            "mse": 431970694.1369986,
            "mae": 5118.986516704142,
            "r2_score": 0.9245406954518305,
            "sn_smape": 0.09147245045800445,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    24
                ],
                "input_size": 24,
                "output_size": 8,
                "mean": 0.05427752807736397,
                "median": 0.059964489191770554,
                "std": 0.12782864272594452,
                "max": 0.30022910237312317,
                "min": -0.20996414124965668
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03127396106719971,
                "median": -0.00901746191084385,
                "std": 0.2416335493326187,
                "max": 0.45238202810287476,
                "min": -0.3901838958263397
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.007478514686226845,
                "median": -0.014763857237994671,
                "std": 0.19035954773426056,
                "max": 0.4487884044647217,
                "min": -0.3573334813117981
            },
            "out.weight": {
                "shape": [
                    12,
                    8
                ],
                "input_size": 8,
                "output_size": 12,
                "mean": 0.06985515356063843,
                "median": 0.06758372485637665,
                "std": 0.19843408465385437,
                "max": 0.44842302799224854,
                "min": -0.3303334712982178
            }
        }
    },
    "Tourism_Monthly_hidden_size_8_max_steps_200_learning_rate_0.001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 200,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 452
        },
        "scores": {
            "smape": 0.163243547684961,
            "mse": 391253230.81167555,
            "mae": 4988.896442716664,
            "r2_score": 0.9316534730249314,
            "sn_smape": 0.09147245045800445,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    24
                ],
                "input_size": 24,
                "output_size": 8,
                "mean": 0.05634450539946556,
                "median": 0.06341487914323807,
                "std": 0.1287933886051178,
                "max": 0.3106137812137604,
                "min": -0.2123733013868332
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03040541149675846,
                "median": -0.008536659181118011,
                "std": 0.24363559484481812,
                "max": 0.4565967321395874,
                "min": -0.40692901611328125
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.007673231419175863,
                "median": -0.011305036023259163,
                "std": 0.19163084030151367,
                "max": 0.4520891308784485,
                "min": -0.3567242920398712
            },
            "out.weight": {
                "shape": [
                    12,
                    8
                ],
                "input_size": 8,
                "output_size": 12,
                "mean": 0.06933462619781494,
                "median": 0.07037954032421112,
                "std": 0.19832901656627655,
                "max": 0.4527944326400757,
                "min": -0.33149588108062744
            }
        }
    },
    "Tourism_Monthly_hidden_size_8_max_steps_200_learning_rate_0.0005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 200,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 452
        },
        "scores": {
            "smape": 0.2556295516848806,
            "mse": 1293839387.7512984,
            "mae": 7267.661183120159,
            "r2_score": 0.7739841574396744,
            "sn_smape": 0.09147245045800445,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    24
                ],
                "input_size": 24,
                "output_size": 8,
                "mean": 0.04671436920762062,
                "median": 0.05561252683401108,
                "std": 0.1254100501537323,
                "max": 0.2814233899116516,
                "min": -0.21935206651687622
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0424698106944561,
                "median": 0.008306077681481838,
                "std": 0.23560455441474915,
                "max": 0.44466134905815125,
                "min": -0.370954304933548
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0059646558947861195,
                "median": -0.01889514923095703,
                "std": 0.19023366272449493,
                "max": 0.4226113557815552,
                "min": -0.3539641201496124
            },
            "out.weight": {
                "shape": [
                    12,
                    8
                ],
                "input_size": 8,
                "output_size": 12,
                "mean": 0.0633673444390297,
                "median": 0.05914512276649475,
                "std": 0.20291535556316376,
                "max": 0.4579886496067047,
                "min": -0.33479607105255127
            }
        }
    },
    "Tourism_Monthly_hidden_size_8_max_steps_200_learning_rate_0.0005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 200,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 452
        },
        "scores": {
            "smape": 0.2517715266130856,
            "mse": 1214681858.6592536,
            "mae": 7093.109824480407,
            "r2_score": 0.7878118827370364,
            "sn_smape": 0.09147245045800445,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    24
                ],
                "input_size": 24,
                "output_size": 8,
                "mean": 0.04693271592259407,
                "median": 0.056066226214170456,
                "std": 0.1255844682455063,
                "max": 0.28099626302719116,
                "min": -0.2155735045671463
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04243522137403488,
                "median": 0.00794453639537096,
                "std": 0.23584717512130737,
                "max": 0.4434593617916107,
                "min": -0.3758540451526642
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.005738149397075176,
                "median": -0.01927138864994049,
                "std": 0.19105400145053864,
                "max": 0.42353230714797974,
                "min": -0.3538627326488495
            },
            "out.weight": {
                "shape": [
                    12,
                    8
                ],
                "input_size": 8,
                "output_size": 12,
                "mean": 0.0637938380241394,
                "median": 0.05950289964675903,
                "std": 0.20299199223518372,
                "max": 0.45680543780326843,
                "min": -0.3346036672592163
            }
        }
    },
    "Tourism_Monthly_hidden_size_8_max_steps_200_learning_rate_0.0001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 200,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 452
        },
        "scores": {
            "smape": 0.8535481963598069,
            "mse": 5595421431.067492,
            "mae": 18505.83636925214,
            "r2_score": 0.02255728091506093,
            "sn_smape": 0.09147245045800445,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    24
                ],
                "input_size": 24,
                "output_size": 8,
                "mean": 0.013510044664144516,
                "median": 0.020099520683288574,
                "std": 0.11655929684638977,
                "max": 0.2275504320859909,
                "min": -0.21342326700687408
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03169133514165878,
                "median": 0.003485908266156912,
                "std": 0.22071892023086548,
                "max": 0.3765888214111328,
                "min": -0.33231621980667114
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.015519127249717712,
                "median": -0.04404469579458237,
                "std": 0.18067128956317902,
                "max": 0.33281219005584717,
                "min": -0.351022869348526
            },
            "out.weight": {
                "shape": [
                    12,
                    8
                ],
                "input_size": 8,
                "output_size": 12,
                "mean": 0.023047901690006256,
                "median": 0.026956424117088318,
                "std": 0.195315420627594,
                "max": 0.36530426144599915,
                "min": -0.3375486433506012
            }
        }
    },
    "Tourism_Monthly_hidden_size_8_max_steps_200_learning_rate_0.0001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 200,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 452
        },
        "scores": {
            "smape": 0.833083930159384,
            "mse": 5501918933.210514,
            "mae": 18309.998349840287,
            "r2_score": 0.03889087381283862,
            "sn_smape": 0.09147245045800445,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    24
                ],
                "input_size": 24,
                "output_size": 8,
                "mean": 0.01360919326543808,
                "median": 0.020882602781057358,
                "std": 0.11673325300216675,
                "max": 0.22960597276687622,
                "min": -0.2140588015317917
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03239109367132187,
                "median": 0.002813141094520688,
                "std": 0.2210259586572647,
                "max": 0.38054633140563965,
                "min": -0.33373144268989563
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": -0.013968853279948235,
                "median": -0.04233969375491142,
                "std": 0.18106532096862793,
                "max": 0.3346862494945526,
                "min": -0.35082945227622986
            },
            "out.weight": {
                "shape": [
                    12,
                    8
                ],
                "input_size": 8,
                "output_size": 12,
                "mean": 0.024580368772149086,
                "median": 0.026460561901330948,
                "std": 0.195816308259964,
                "max": 0.3666830062866211,
                "min": -0.33743545413017273
            }
        }
    },
    "Tourism_Monthly_hidden_size_16_max_steps_50_learning_rate_0.001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 50,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 1148
        },
        "scores": {
            "smape": 0.35940860358341337,
            "mse": 1841994637.0536592,
            "mae": 10030.521981882383,
            "r2_score": 0.6782290183568682,
            "sn_smape": 0.09147245045800445,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    24
                ],
                "input_size": 24,
                "output_size": 16,
                "mean": 0.01858726143836975,
                "median": 0.013521822169423103,
                "std": 0.12247850745916367,
                "max": 0.253367155790329,
                "min": -0.2225184291601181
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.006469414569437504,
                "median": 0.002239271067082882,
                "std": 0.14990082383155823,
                "max": 0.30061134696006775,
                "min": -0.25604456663131714
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.005677212029695511,
                "median": -0.004762750118970871,
                "std": 0.14924447238445282,
                "max": 0.2946765124797821,
                "min": -0.26152539253234863
            },
            "out.weight": {
                "shape": [
                    12,
                    16
                ],
                "input_size": 16,
                "output_size": 12,
                "mean": 0.031546514481306076,
                "median": 0.04313867539167404,
                "std": 0.15594768524169922,
                "max": 0.302717000246048,
                "min": -0.24165087938308716
            }
        }
    },
    "Tourism_Monthly_hidden_size_16_max_steps_50_learning_rate_0.001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 50,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 1148
        },
        "scores": {
            "smape": 0.3236800070554227,
            "mse": 1524949042.0941978,
            "mae": 9126.038056966132,
            "r2_score": 0.7336124979086411,
            "sn_smape": 0.09147245045800445,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    24
                ],
                "input_size": 24,
                "output_size": 16,
                "mean": 0.020431624725461006,
                "median": 0.015155790373682976,
                "std": 0.12314055860042572,
                "max": 0.2561567425727844,
                "min": -0.22207264602184296
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.00789681263267994,
                "median": 0.005094601307064295,
                "std": 0.15048891305923462,
                "max": 0.3032422661781311,
                "min": -0.252450555562973
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.006136029958724976,
                "median": -0.003907762002199888,
                "std": 0.14993175864219666,
                "max": 0.29827597737312317,
                "min": -0.2603111267089844
            },
            "out.weight": {
                "shape": [
                    12,
                    16
                ],
                "input_size": 16,
                "output_size": 12,
                "mean": 0.03310847282409668,
                "median": 0.04616958275437355,
                "std": 0.15656688809394836,
                "max": 0.30660882592201233,
                "min": -0.2498229742050171
            }
        }
    },
    "Tourism_Monthly_hidden_size_16_max_steps_50_learning_rate_0.0005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 50,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 1148
        },
        "scores": {
            "smape": 0.7550129352477266,
            "mse": 4810078424.193562,
            "mae": 17165.59095765648,
            "r2_score": 0.15974584008079096,
            "sn_smape": 0.09147245045800445,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    24
                ],
                "input_size": 24,
                "output_size": 16,
                "mean": 0.0075122942216694355,
                "median": 0.0009737031068652868,
                "std": 0.11822822690010071,
                "max": 0.22496271133422852,
                "min": -0.2104952186346054
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.00011744722723960876,
                "median": -0.0020193762611597776,
                "std": 0.14636392891407013,
                "max": 0.27255502343177795,
                "min": -0.25672629475593567
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.0002013577031902969,
                "median": -0.010057805106043816,
                "std": 0.14639127254486084,
                "max": 0.2660661041736603,
                "min": -0.25761878490448
            },
            "out.weight": {
                "shape": [
                    12,
                    16
                ],
                "input_size": 16,
                "output_size": 12,
                "mean": 0.015610367059707642,
                "median": 0.019333213567733765,
                "std": 0.15326352417469025,
                "max": 0.2747552692890167,
                "min": -0.24452415108680725
            }
        }
    },
    "Tourism_Monthly_hidden_size_16_max_steps_50_learning_rate_0.0005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 50,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 1148
        },
        "scores": {
            "smape": 0.7293642339505882,
            "mse": 4642324425.662046,
            "mae": 16836.231440009647,
            "r2_score": 0.18905014297951517,
            "sn_smape": 0.09147245045800445,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    24
                ],
                "input_size": 24,
                "output_size": 16,
                "mean": 0.007971924729645252,
                "median": 2.6485358830541372e-06,
                "std": 0.11862574517726898,
                "max": 0.22718848288059235,
                "min": -0.2111077904701233
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0007120827212929726,
                "median": -0.0022273699287325144,
                "std": 0.1464659571647644,
                "max": 0.2740037143230438,
                "min": -0.2546558678150177
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 2.5945657398551702e-05,
                "median": -0.010145314037799835,
                "std": 0.14658483862876892,
                "max": 0.26809459924697876,
                "min": -0.2593251168727875
            },
            "out.weight": {
                "shape": [
                    12,
                    16
                ],
                "input_size": 16,
                "output_size": 12,
                "mean": 0.01665538363158703,
                "median": 0.021180136129260063,
                "std": 0.15355917811393738,
                "max": 0.27684032917022705,
                "min": -0.2498229742050171
            }
        }
    },
    "Tourism_Monthly_hidden_size_16_max_steps_50_learning_rate_0.0001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 50,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 1148
        },
        "scores": {
            "smape": 0.9340632399770027,
            "mse": 5859061501.318943,
            "mae": 19116.865758185286,
            "r2_score": -0.02349699226184976,
            "sn_smape": 0.09147245045800445,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    24
                ],
                "input_size": 24,
                "output_size": 16,
                "mean": 0.002620851621031761,
                "median": -0.00042850591125898063,
                "std": 0.1162186712026596,
                "max": 0.20681701600551605,
                "min": -0.20021741092205048
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.002671779366210103,
                "median": -0.0009931281674653292,
                "std": 0.14475515484809875,
                "max": 0.24988813698291779,
                "min": -0.24994833767414093
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.0037422121968120337,
                "median": -0.010569596663117409,
                "std": 0.14548343420028687,
                "max": 0.24585860967636108,
                "min": -0.243757963180542
            },
            "out.weight": {
                "shape": [
                    12,
                    16
                ],
                "input_size": 16,
                "output_size": 12,
                "mean": 0.0029608283657580614,
                "median": 0.0034576065372675657,
                "std": 0.15214644372463226,
                "max": 0.25403159856796265,
                "min": -0.24840421974658966
            }
        }
    },
    "Tourism_Monthly_hidden_size_16_max_steps_50_learning_rate_0.0001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 50,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 1148
        },
        "scores": {
            "smape": 0.9316090036096575,
            "mse": 5843936835.437586,
            "mae": 19091.392378392477,
            "r2_score": -0.020854922361226658,
            "sn_smape": 0.09147245045800445,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    24
                ],
                "input_size": 24,
                "output_size": 16,
                "mean": 0.002603036817163229,
                "median": -0.0008879174711182714,
                "std": 0.11627128720283508,
                "max": 0.20686845481395721,
                "min": -0.2006342113018036
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.002600286854431033,
                "median": -0.0008097622776404023,
                "std": 0.14473819732666016,
                "max": 0.2500300407409668,
                "min": -0.2503736913204193
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.003829552326351404,
                "median": -0.010727789252996445,
                "std": 0.145506352186203,
                "max": 0.2462492734193802,
                "min": -0.243757963180542
            },
            "out.weight": {
                "shape": [
                    12,
                    16
                ],
                "input_size": 16,
                "output_size": 12,
                "mean": 0.0032644718885421753,
                "median": 0.003981348592787981,
                "std": 0.15215972065925598,
                "max": 0.25446486473083496,
                "min": -0.24925880134105682
            }
        }
    },
    "Tourism_Monthly_hidden_size_16_max_steps_100_learning_rate_0.001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 100,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 1148
        },
        "scores": {
            "smape": 0.16352942941296375,
            "mse": 372241407.85913867,
            "mae": 4972.375954926913,
            "r2_score": 0.9349745754924437,
            "sn_smape": 0.09147245045800445,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    24
                ],
                "input_size": 24,
                "output_size": 16,
                "mean": 0.025252236053347588,
                "median": 0.02150643989443779,
                "std": 0.12497133016586304,
                "max": 0.27104613184928894,
                "min": -0.22123445570468903
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.01025150902569294,
                "median": 0.0034974010195583105,
                "std": 0.15233325958251953,
                "max": 0.3198067843914032,
                "min": -0.25470495223999023
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.009466471150517464,
                "median": 0.006449321284890175,
                "std": 0.15154503285884857,
                "max": 0.32185712456703186,
                "min": -0.28276118636131287
            },
            "out.weight": {
                "shape": [
                    12,
                    16
                ],
                "input_size": 16,
                "output_size": 12,
                "mean": 0.04081515967845917,
                "median": 0.042128950357437134,
                "std": 0.1566849797964096,
                "max": 0.34505829215049744,
                "min": -0.24154813587665558
            }
        }
    },
    "Tourism_Monthly_hidden_size_16_max_steps_100_learning_rate_0.001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 100,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 1148
        },
        "scores": {
            "smape": 0.16011302737068628,
            "mse": 361670163.16107357,
            "mae": 4827.891752695872,
            "r2_score": 0.9368212257026348,
            "sn_smape": 0.09147245045800445,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    24
                ],
                "input_size": 24,
                "output_size": 16,
                "mean": 0.024930603802204132,
                "median": 0.020200788974761963,
                "std": 0.12492691725492477,
                "max": 0.2680502235889435,
                "min": -0.22119870781898499
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.01043149083852768,
                "median": 0.004680653568357229,
                "std": 0.1522779017686844,
                "max": 0.31852468848228455,
                "min": -0.25250792503356934
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.009119163267314434,
                "median": 0.00440578069537878,
                "std": 0.15155182778835297,
                "max": 0.322288453578949,
                "min": -0.28161299228668213
            },
            "out.weight": {
                "shape": [
                    12,
                    16
                ],
                "input_size": 16,
                "output_size": 12,
                "mean": 0.04078662768006325,
                "median": 0.043234094977378845,
                "std": 0.15696027874946594,
                "max": 0.3477935791015625,
                "min": -0.2498229742050171
            }
        }
    },
    "Tourism_Monthly_hidden_size_16_max_steps_100_learning_rate_0.0005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 100,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 1148
        },
        "scores": {
            "smape": 0.2791797878062822,
            "mse": 1169691587.53419,
            "mae": 8252.592549304027,
            "r2_score": 0.7956710607243611,
            "sn_smape": 0.09147245045800445,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    24
                ],
                "input_size": 24,
                "output_size": 16,
                "mean": 0.02464861236512661,
                "median": 0.022476203739643097,
                "std": 0.12291339039802551,
                "max": 0.2590448558330536,
                "min": -0.22054634988307953
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.009365417063236237,
                "median": 0.0077338386327028275,
                "std": 0.1514633148908615,
                "max": 0.30956441164016724,
                "min": -0.2548425793647766
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.008057869970798492,
                "median": 0.0004793669213540852,
                "std": 0.15033447742462158,
                "max": 0.3001934289932251,
                "min": -0.26494544744491577
            },
            "out.weight": {
                "shape": [
                    12,
                    16
                ],
                "input_size": 16,
                "output_size": 12,
                "mean": 0.033039286732673645,
                "median": 0.04742803797125816,
                "std": 0.15712670981884003,
                "max": 0.3085676431655884,
                "min": -0.24443453550338745
            }
        }
    },
    "Tourism_Monthly_hidden_size_16_max_steps_100_learning_rate_0.0005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 100,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 1148
        },
        "scores": {
            "smape": 0.2601629351120509,
            "mse": 1036072698.462998,
            "mae": 7928.566383025636,
            "r2_score": 0.8190124322124311,
            "sn_smape": 0.09147245045800445,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    24
                ],
                "input_size": 24,
                "output_size": 16,
                "mean": 0.024872446432709694,
                "median": 0.020774634554982185,
                "std": 0.12341233342885971,
                "max": 0.26221024990081787,
                "min": -0.21626615524291992
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.010246801190078259,
                "median": 0.007596245035529137,
                "std": 0.151494100689888,
                "max": 0.3108876943588257,
                "min": -0.24987803399562836
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.008340801112353802,
                "median": 0.003884748788550496,
                "std": 0.15061375498771667,
                "max": 0.30070239305496216,
                "min": -0.2675513029098511
            },
            "out.weight": {
                "shape": [
                    12,
                    16
                ],
                "input_size": 16,
                "output_size": 12,
                "mean": 0.03414161875844002,
                "median": 0.046700239181518555,
                "std": 0.1573886275291443,
                "max": 0.30966323614120483,
                "min": -0.2498229742050171
            }
        }
    },
    "Tourism_Monthly_hidden_size_16_max_steps_100_learning_rate_0.0001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 100,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 1148
        },
        "scores": {
            "smape": 0.9010847734339145,
            "mse": 5672845091.039077,
            "mae": 18792.778095472386,
            "r2_score": 0.009032438567360135,
            "sn_smape": 0.09147245045800445,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    24
                ],
                "input_size": 24,
                "output_size": 16,
                "mean": 0.0038362580817192793,
                "median": 0.0016685228329151869,
                "std": 0.11654725670814514,
                "max": 0.2102695107460022,
                "min": -0.2033717781305313
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.0020803557708859444,
                "median": -0.0018752694595605135,
                "std": 0.14503827691078186,
                "max": 0.25536563992500305,
                "min": -0.2532886862754822
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.0028985501267015934,
                "median": -0.012610431760549545,
                "std": 0.14557504653930664,
                "max": 0.250838965177536,
                "min": -0.24488671123981476
            },
            "out.weight": {
                "shape": [
                    12,
                    16
                ],
                "input_size": 16,
                "output_size": 12,
                "mean": 0.006175985559821129,
                "median": 0.00646706810221076,
                "std": 0.15238800644874573,
                "max": 0.2594011425971985,
                "min": -0.24779793620109558
            }
        }
    },
    "Tourism_Monthly_hidden_size_16_max_steps_100_learning_rate_0.0001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 100,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 1148
        },
        "scores": {
            "smape": 0.8959872517077181,
            "mse": 5644112011.616522,
            "mae": 18740.712740129282,
            "r2_score": 0.014051710060036027,
            "sn_smape": 0.09147245045800445,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    24
                ],
                "input_size": 24,
                "output_size": 16,
                "mean": 0.003934734035283327,
                "median": 0.0013339400757104158,
                "std": 0.11663610488176346,
                "max": 0.2105465531349182,
                "min": -0.20380456745624542
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.001889827661216259,
                "median": -0.002300278050825,
                "std": 0.1450348049402237,
                "max": 0.2557700276374817,
                "min": -0.2540890872478485
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.0029220017604529858,
                "median": -0.012880856171250343,
                "std": 0.14561432600021362,
                "max": 0.25138047337532043,
                "min": -0.2455691695213318
            },
            "out.weight": {
                "shape": [
                    12,
                    16
                ],
                "input_size": 16,
                "output_size": 12,
                "mean": 0.00667509576305747,
                "median": 0.0073979804292321205,
                "std": 0.1524272859096527,
                "max": 0.260047048330307,
                "min": -0.248556986451149
            }
        }
    },
    "Tourism_Monthly_hidden_size_16_max_steps_200_learning_rate_0.001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 200,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 1148
        },
        "scores": {
            "smape": 0.15584979097246984,
            "mse": 345652061.67504036,
            "mae": 4648.500719044655,
            "r2_score": 0.939619366443948,
            "sn_smape": 0.09147245045800445,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    24
                ],
                "input_size": 24,
                "output_size": 16,
                "mean": 0.03478173539042473,
                "median": 0.02891586907207966,
                "std": 0.1232612207531929,
                "max": 0.28169071674346924,
                "min": -0.21593132615089417
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.005342571996152401,
                "median": -3.6948476918041706e-05,
                "std": 0.1569504290819168,
                "max": 0.32288074493408203,
                "min": -0.2923765480518341
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.009589572437107563,
                "median": 0.0028210363816469908,
                "std": 0.15242445468902588,
                "max": 0.3240569233894348,
                "min": -0.2857036590576172
            },
            "out.weight": {
                "shape": [
                    12,
                    16
                ],
                "input_size": 16,
                "output_size": 12,
                "mean": 0.041113149374723434,
                "median": 0.04668886214494705,
                "std": 0.15695486962795258,
                "max": 0.34399908781051636,
                "min": -0.24154745042324066
            }
        }
    },
    "Tourism_Monthly_hidden_size_16_max_steps_200_learning_rate_0.001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 200,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 1148
        },
        "scores": {
            "smape": 0.15544158384692866,
            "mse": 343366408.66187984,
            "mae": 4635.666460428255,
            "r2_score": 0.9400186384064965,
            "sn_smape": 0.09147245045800445,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    24
                ],
                "input_size": 24,
                "output_size": 16,
                "mean": 0.03346159681677818,
                "median": 0.027125656604766846,
                "std": 0.12441990524530411,
                "max": 0.2852814793586731,
                "min": -0.21157342195510864
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.006773052737116814,
                "median": 0.002406800864264369,
                "std": 0.15877610445022583,
                "max": 0.32249781489372253,
                "min": -0.3134613633155823
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.008726909756660461,
                "median": 0.0005216723075136542,
                "std": 0.15318259596824646,
                "max": 0.32606130838394165,
                "min": -0.2881452441215515
            },
            "out.weight": {
                "shape": [
                    12,
                    16
                ],
                "input_size": 16,
                "output_size": 12,
                "mean": 0.04208559915423393,
                "median": 0.04871407151222229,
                "std": 0.15733276307582855,
                "max": 0.3462471663951874,
                "min": -0.2498229742050171
            }
        }
    },
    "Tourism_Monthly_hidden_size_16_max_steps_200_learning_rate_0.0005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 200,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 1148
        },
        "scores": {
            "smape": 0.1574791869933584,
            "mse": 346013454.88733035,
            "mae": 4705.915307146534,
            "r2_score": 0.9395562360491365,
            "sn_smape": 0.09147245045800445,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    24
                ],
                "input_size": 24,
                "output_size": 16,
                "mean": 0.031222909688949585,
                "median": 0.025026146322488785,
                "std": 0.1228925883769989,
                "max": 0.26827722787857056,
                "min": -0.21461687982082367
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.010277939029037952,
                "median": 0.006797978654503822,
                "std": 0.1535814255475998,
                "max": 0.32163843512535095,
                "min": -0.2546617090702057
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.010025253519415855,
                "median": 0.005853652022778988,
                "std": 0.1517234444618225,
                "max": 0.3175998628139496,
                "min": -0.27988430857658386
            },
            "out.weight": {
                "shape": [
                    12,
                    16
                ],
                "input_size": 16,
                "output_size": 12,
                "mean": 0.03630382940173149,
                "median": 0.03886962682008743,
                "std": 0.15692909061908722,
                "max": 0.34090471267700195,
                "min": -0.2444339543581009
            }
        }
    },
    "Tourism_Monthly_hidden_size_16_max_steps_200_learning_rate_0.0005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 200,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 1148
        },
        "scores": {
            "smape": 0.1582859832945774,
            "mse": 347126966.0419481,
            "mae": 4747.360591048047,
            "r2_score": 0.9393617210543128,
            "sn_smape": 0.09147245045800445,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    24
                ],
                "input_size": 24,
                "output_size": 16,
                "mean": 0.031176602467894554,
                "median": 0.025044023990631104,
                "std": 0.12323684245347977,
                "max": 0.27097654342651367,
                "min": -0.21160568296909332
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.00999896414577961,
                "median": 0.006747680250555277,
                "std": 0.15365038812160492,
                "max": 0.3225030303001404,
                "min": -0.27395567297935486
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.00933320913463831,
                "median": 0.005374734755605459,
                "std": 0.15186426043510437,
                "max": 0.31845855712890625,
                "min": -0.2800729274749756
            },
            "out.weight": {
                "shape": [
                    12,
                    16
                ],
                "input_size": 16,
                "output_size": 12,
                "mean": 0.036859434098005295,
                "median": 0.04101395606994629,
                "std": 0.15686790645122528,
                "max": 0.3435284197330475,
                "min": -0.2498229742050171
            }
        }
    },
    "Tourism_Monthly_hidden_size_16_max_steps_200_learning_rate_0.0001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 200,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 1148
        },
        "scores": {
            "smape": 0.7717298761442904,
            "mse": 4899480775.052239,
            "mae": 17353.28994044709,
            "r2_score": 0.14412848614374862,
            "sn_smape": 0.09147245045800445,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    24
                ],
                "input_size": 24,
                "output_size": 16,
                "mean": 0.00894060917198658,
                "median": 0.002224454889073968,
                "std": 0.11776947975158691,
                "max": 0.22467423975467682,
                "min": -0.20765364170074463
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.00037227431312203407,
                "median": 0.0002914877259172499,
                "std": 0.14622637629508972,
                "max": 0.2717903256416321,
                "min": -0.2509114742279053
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0003253264003433287,
                "median": -0.00938437506556511,
                "std": 0.14636993408203125,
                "max": 0.26357293128967285,
                "min": -0.25376760959625244
            },
            "out.weight": {
                "shape": [
                    12,
                    16
                ],
                "input_size": 16,
                "output_size": 12,
                "mean": 0.013245202600955963,
                "median": 0.017178140580654144,
                "std": 0.15344049036502838,
                "max": 0.27220430970191956,
                "min": -0.24777713418006897
            }
        }
    },
    "Tourism_Monthly_hidden_size_16_max_steps_200_learning_rate_0.0001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Monthly"
        },
        "model": {
            "name": "MLP",
            "input_size": 24,
            "horizon": 12,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 200,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 1148
        },
        "scores": {
            "smape": 0.748782359314695,
            "mse": 4746091906.931774,
            "mae": 17055.896095898992,
            "r2_score": 0.17092339948138902,
            "sn_smape": 0.09147245045800445,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    24
                ],
                "input_size": 24,
                "output_size": 16,
                "mean": 0.009645453654229641,
                "median": 0.0015772052574902773,
                "std": 0.11800862848758698,
                "max": 0.22703121602535248,
                "min": -0.2090039998292923
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.000982989789918065,
                "median": -0.00042181750177405775,
                "std": 0.14636613428592682,
                "max": 0.2737705409526825,
                "min": -0.24912716448307037
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0006856903783045709,
                "median": -0.009439606219530106,
                "std": 0.1465354710817337,
                "max": 0.2651994526386261,
                "min": -0.254883348941803
            },
            "out.weight": {
                "shape": [
                    12,
                    16
                ],
                "input_size": 16,
                "output_size": 12,
                "mean": 0.014348581433296204,
                "median": 0.018122753128409386,
                "std": 0.15361803770065308,
                "max": 0.27378344535827637,
                "min": -0.24854505062103271
            }
        }
    },
    "Tourism_Quarterly_hidden_size_8_max_steps_50_learning_rate_0.001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 50,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 288
        },
        "scores": {
            "smape": 0.8110331771446261,
            "mse": 532088109172.49,
            "mae": 88322.84935548935,
            "r2_score": 0.10124221521245758,
            "sn_smape": 0.1340001106045662,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05219585821032524,
                "median": 0.03458794951438904,
                "std": 0.19667373597621918,
                "max": 0.3861791491508484,
                "min": -0.3085542619228363
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04799980670213699,
                "median": 0.08279344439506531,
                "std": 0.21222680807113647,
                "max": 0.37294065952301025,
                "min": -0.3384629189968109
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.009777876548469067,
                "median": -0.024199113249778748,
                "std": 0.20329426229000092,
                "max": 0.3822959065437317,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03152234107255936,
                "median": 0.019892027601599693,
                "std": 0.2207299917936325,
                "max": 0.3851282298564911,
                "min": -0.3224848508834839
            }
        }
    },
    "Tourism_Quarterly_hidden_size_8_max_steps_50_learning_rate_0.001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 50,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 288
        },
        "scores": {
            "smape": 0.7736414346725349,
            "mse": 512778586248.25006,
            "mae": 86134.55308759464,
            "r2_score": 0.13385821197976777,
            "sn_smape": 0.1340001106045662,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05833420902490616,
                "median": 0.03856226056814194,
                "std": 0.197246715426445,
                "max": 0.393871933221817,
                "min": -0.3009363114833832
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.052320972084999084,
                "median": 0.0861278772354126,
                "std": 0.2131863385438919,
                "max": 0.3808884918689728,
                "min": -0.3389517068862915
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.011421202681958675,
                "median": -0.020188141614198685,
                "std": 0.20490171015262604,
                "max": 0.3903256058692932,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03366122767329216,
                "median": 0.021000783890485764,
                "std": 0.22140449285507202,
                "max": 0.39306119084358215,
                "min": -0.32429587841033936
            }
        }
    },
    "Tourism_Quarterly_hidden_size_8_max_steps_50_learning_rate_0.0005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 50,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 288
        },
        "scores": {
            "smape": 0.8933596312202224,
            "mse": 568753923064.9286,
            "mae": 92354.56057619616,
            "r2_score": 0.03930945425929433,
            "sn_smape": 0.1340001106045662,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.036204222589731216,
                "median": 0.027925586327910423,
                "std": 0.19562602043151855,
                "max": 0.3691246807575226,
                "min": -0.3277449905872345
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.037736259400844574,
                "median": 0.0764104351401329,
                "std": 0.20924626290798187,
                "max": 0.3534505069255829,
                "min": -0.3438648581504822
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.003936765715479851,
                "median": -0.022427137941122055,
                "std": 0.20062865316867828,
                "max": 0.3632766008377075,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01902470551431179,
                "median": 0.0015689115971326828,
                "std": 0.21952404081821442,
                "max": 0.36602431535720825,
                "min": -0.32523593306541443
            }
        }
    },
    "Tourism_Quarterly_hidden_size_8_max_steps_50_learning_rate_0.0005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 50,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 288
        },
        "scores": {
            "smape": 0.8803237287055585,
            "mse": 562629424680.8708,
            "mae": 91741.1641941229,
            "r2_score": 0.04965443379501666,
            "sn_smape": 0.1340001106045662,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03922131657600403,
                "median": 0.029844705015420914,
                "std": 0.1959286630153656,
                "max": 0.37279683351516724,
                "min": -0.3239936828613281
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03961106762290001,
                "median": 0.07823343575000763,
                "std": 0.20979535579681396,
                "max": 0.35760775208473206,
                "min": -0.34408673644065857
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.004728640429675579,
                "median": -0.023195188492536545,
                "std": 0.20125772058963776,
                "max": 0.36720818281173706,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.020704561844468117,
                "median": 0.005280670244246721,
                "std": 0.2196085900068283,
                "max": 0.36984726786613464,
                "min": -0.3253425657749176
            }
        }
    },
    "Tourism_Quarterly_hidden_size_8_max_steps_50_learning_rate_0.0001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 50,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 288
        },
        "scores": {
            "smape": 0.9374664407904713,
            "mse": 586732074911.8213,
            "mae": 94140.69025490532,
            "r2_score": 0.008942295794474475,
            "sn_smape": 0.1340001106045662,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.024556102231144905,
                "median": 0.013999988324940205,
                "std": 0.19509033858776093,
                "max": 0.35546988248825073,
                "min": -0.34220314025878906
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03264424949884415,
                "median": 0.07216888666152954,
                "std": 0.20813603699207306,
                "max": 0.35036057233810425,
                "min": -0.33360612392425537
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0016487976536154747,
                "median": -0.013898585923016071,
                "std": 0.19973276555538177,
                "max": 0.35450026392936707,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.008791259489953518,
                "median": -0.009681656956672668,
                "std": 0.21924352645874023,
                "max": 0.3516031503677368,
                "min": -0.3299625515937805
            }
        }
    },
    "Tourism_Quarterly_hidden_size_8_max_steps_50_learning_rate_0.0001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 50,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 288
        },
        "scores": {
            "smape": 0.9357273641968603,
            "mse": 585967065022.4078,
            "mae": 94069.18951423759,
            "r2_score": 0.010234485155028117,
            "sn_smape": 0.1340001106045662,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.025069544091820717,
                "median": 0.014686430804431438,
                "std": 0.19513875246047974,
                "max": 0.3561415672302246,
                "min": -0.3415133059024811
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.032866090536117554,
                "median": 0.07179835438728333,
                "std": 0.2082120180130005,
                "max": 0.35102689266204834,
                "min": -0.3342439830303192
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0017476566135883331,
                "median": -0.01400706171989441,
                "std": 0.19983205199241638,
                "max": 0.35522329807281494,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.00917410384863615,
                "median": -0.009430953301489353,
                "std": 0.21925340592861176,
                "max": 0.35231849551200867,
                "min": -0.3301979601383209
            }
        }
    },
    "Tourism_Quarterly_hidden_size_8_max_steps_100_learning_rate_0.001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 100,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 288
        },
        "scores": {
            "smape": 0.536835903085784,
            "mse": 350853172060.7945,
            "mae": 64422.896340221414,
            "r2_score": 0.4073687904857517,
            "sn_smape": 0.1340001106045662,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0864185243844986,
                "median": 0.06959901750087738,
                "std": 0.19934973120689392,
                "max": 0.42492491006851196,
                "min": -0.2684650123119354
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07415057718753815,
                "median": 0.09966320544481277,
                "std": 0.21899235248565674,
                "max": 0.4251602292060852,
                "min": -0.3382820785045624
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02626926451921463,
                "median": -0.004517321474850178,
                "std": 0.21096421778202057,
                "max": 0.4233400225639343,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05730999633669853,
                "median": 0.03670413792133331,
                "std": 0.22494632005691528,
                "max": 0.4256778359413147,
                "min": -0.3223864734172821
            }
        }
    },
    "Tourism_Quarterly_hidden_size_8_max_steps_100_learning_rate_0.001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 100,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 288
        },
        "scores": {
            "smape": 0.42702705532086604,
            "mse": 250879090759.53058,
            "mae": 48697.18569013181,
            "r2_score": 0.5762364691606864,
            "sn_smape": 0.1340001106045662,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.10254956036806107,
                "median": 0.08447584509849548,
                "std": 0.20077843964099884,
                "max": 0.4445632994174957,
                "min": -0.24980954825878143
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08510477840900421,
                "median": 0.10849320888519287,
                "std": 0.22265556454658508,
                "max": 0.44359683990478516,
                "min": -0.33874985575675964
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.031218599528074265,
                "median": 0.000919173879083246,
                "std": 0.21558170020580292,
                "max": 0.44206202030181885,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06722749769687653,
                "median": 0.044292062520980835,
                "std": 0.2273709774017334,
                "max": 0.44838786125183105,
                "min": -0.3242281377315521
            }
        }
    },
    "Tourism_Quarterly_hidden_size_8_max_steps_100_learning_rate_0.0005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 100,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 288
        },
        "scores": {
            "smape": 0.809790642276826,
            "mse": 531856391409.5354,
            "mae": 88284.79892311717,
            "r2_score": 0.10163361306506669,
            "sn_smape": 0.1340001106045662,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05271518975496292,
                "median": 0.03483477234840393,
                "std": 0.19625267386436462,
                "max": 0.3857240378856659,
                "min": -0.30896657705307007
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.04869657754898071,
                "median": 0.08517742902040482,
                "std": 0.2122993767261505,
                "max": 0.37301936745643616,
                "min": -0.3367989659309387
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.010790349915623665,
                "median": -0.020093683153390884,
                "std": 0.20307089388370514,
                "max": 0.3817632794380188,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.029790349304676056,
                "median": 0.019263923168182373,
                "std": 0.22087708115577698,
                "max": 0.384244829416275,
                "min": -0.32477840781211853
            }
        }
    },
    "Tourism_Quarterly_hidden_size_8_max_steps_100_learning_rate_0.0005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 100,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 288
        },
        "scores": {
            "smape": 0.7484114650213717,
            "mse": 500216973080.8914,
            "mae": 84618.06934297987,
            "r2_score": 0.15507621597014332,
            "sn_smape": 0.1340001106045662,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.06094857305288315,
                "median": 0.04137714207172394,
                "std": 0.19708888232707977,
                "max": 0.39424341917037964,
                "min": -0.29812490940093994
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.055878181010484695,
                "median": 0.09096464514732361,
                "std": 0.21430440247058868,
                "max": 0.3848181664943695,
                "min": -0.335956871509552
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.014722808264195919,
                "median": -0.017811987549066544,
                "std": 0.20534291863441467,
                "max": 0.3927629590034485,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03627120330929756,
                "median": 0.026782047003507614,
                "std": 0.2219288945198059,
                "max": 0.3949701488018036,
                "min": -0.32509085536003113
            }
        }
    },
    "Tourism_Quarterly_hidden_size_8_max_steps_100_learning_rate_0.0001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 100,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 288
        },
        "scores": {
            "smape": 0.9290370765515489,
            "mse": 583279556744.8446,
            "mae": 93808.6067546189,
            "r2_score": 0.014773994579317606,
            "sn_smape": 0.1340001106045662,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.02713814191520214,
                "median": 0.01723403111100197,
                "std": 0.19517192244529724,
                "max": 0.3585442006587982,
                "min": -0.33900076150894165
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.033684320747852325,
                "median": 0.0711505115032196,
                "std": 0.20833317935466766,
                "max": 0.34994789958000183,
                "min": -0.3341815769672394
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0020717885345220566,
                "median": -0.015697944909334183,
                "std": 0.1998794823884964,
                "max": 0.35541123151779175,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.011062368750572205,
                "median": -0.007364694960415363,
                "std": 0.21921761333942413,
                "max": 0.35480454564094543,
                "min": -0.32823342084884644
            }
        }
    },
    "Tourism_Quarterly_hidden_size_8_max_steps_100_learning_rate_0.0001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 100,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 288
        },
        "scores": {
            "smape": 0.9247522497650867,
            "mse": 581471466435.22,
            "mae": 93634.78104698825,
            "r2_score": 0.017828066289172995,
            "sn_smape": 0.1340001106045662,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.028298411518335342,
                "median": 0.01875361241400242,
                "std": 0.19529283046722412,
                "max": 0.3599174916744232,
                "min": -0.3373805284500122
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03425885736942291,
                "median": 0.07213126122951508,
                "std": 0.2085137665271759,
                "max": 0.35016685724258423,
                "min": -0.3354877531528473
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0022437945008277893,
                "median": -0.016347941011190414,
                "std": 0.20010346174240112,
                "max": 0.35693755745887756,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.011949736624956131,
                "median": -0.006552595645189285,
                "std": 0.21927207708358765,
                "max": 0.35636597871780396,
                "min": -0.328866183757782
            }
        }
    },
    "Tourism_Quarterly_hidden_size_8_max_steps_200_learning_rate_0.001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 200,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 288
        },
        "scores": {
            "smape": 0.2137882593350834,
            "mse": 77546640902.95096,
            "mae": 27131.41437810839,
            "r2_score": 0.8690148379672631,
            "sn_smape": 0.1340001106045662,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.10854855924844742,
                "median": 0.08934937417507172,
                "std": 0.20100688934326172,
                "max": 0.4464099109172821,
                "min": -0.24871793389320374
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.10148349404335022,
                "median": 0.11080072820186615,
                "std": 0.2169717252254486,
                "max": 0.4719083607196808,
                "min": -0.3382369577884674
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.041010793298482895,
                "median": 0.005516655743122101,
                "std": 0.21841010451316833,
                "max": 0.4410926103591919,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08393995463848114,
                "median": 0.05511513352394104,
                "std": 0.22873766720294952,
                "max": 0.5190983414649963,
                "min": -0.322374552488327
            }
        }
    },
    "Tourism_Quarterly_hidden_size_8_max_steps_200_learning_rate_0.001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 200,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 288
        },
        "scores": {
            "smape": 0.13693782027074033,
            "mse": 11628929701.199139,
            "mae": 15580.674035832124,
            "r2_score": 0.9803574052538888,
            "sn_smape": 0.1340001106045662,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.1253875494003296,
                "median": 0.09713607281446457,
                "std": 0.19947275519371033,
                "max": 0.48469892144203186,
                "min": -0.23404298722743988
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.09286274760961533,
                "median": 0.10465333610773087,
                "std": 0.22722996771335602,
                "max": 0.5092234015464783,
                "min": -0.3796430230140686
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.039255935698747635,
                "median": 0.00896844919770956,
                "std": 0.21712620556354523,
                "max": 0.44834068417549133,
                "min": -0.3402314782142639
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08924210071563721,
                "median": 0.060533441603183746,
                "std": 0.22959895431995392,
                "max": 0.549498975276947,
                "min": -0.324198454618454
            }
        }
    },
    "Tourism_Quarterly_hidden_size_8_max_steps_200_learning_rate_0.0005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 200,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 288
        },
        "scores": {
            "smape": 0.5522465036531985,
            "mse": 349298668889.9604,
            "mae": 65528.42752824182,
            "r2_score": 0.4099945244613462,
            "sn_smape": 0.1340001106045662,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08323825895786285,
                "median": 0.06365364789962769,
                "std": 0.19865061342716217,
                "max": 0.42174240946769714,
                "min": -0.2733924388885498
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.07647430896759033,
                "median": 0.09801362454891205,
                "std": 0.21723248064517975,
                "max": 0.4337864816188812,
                "min": -0.33670151233673096
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.028323665261268616,
                "median": -0.0031444202177226543,
                "std": 0.21132323145866394,
                "max": 0.4191970229148865,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.05728362500667572,
                "median": 0.032509494572877884,
                "std": 0.2255844920873642,
                "max": 0.4291478991508484,
                "min": -0.3247700333595276
            }
        }
    },
    "Tourism_Quarterly_hidden_size_8_max_steps_200_learning_rate_0.0005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 200,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 288
        },
        "scores": {
            "smape": 0.3959009095447623,
            "mse": 220923873473.00912,
            "mae": 45139.09580554686,
            "r2_score": 0.6268342635243562,
            "sn_smape": 0.1340001106045662,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.1017933040857315,
                "median": 0.08301395922899246,
                "std": 0.20074237883090973,
                "max": 0.44186079502105713,
                "min": -0.2510039210319519
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.08734595775604248,
                "median": 0.1080288290977478,
                "std": 0.221943661570549,
                "max": 0.4513377845287323,
                "min": -0.3344935476779938
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03509654477238655,
                "median": 0.005699924658983946,
                "std": 0.215016707777977,
                "max": 0.44076764583587646,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0707821398973465,
                "median": 0.041885603219270706,
                "std": 0.2278919368982315,
                "max": 0.45354506373405457,
                "min": -0.3250819742679596
            }
        }
    },
    "Tourism_Quarterly_hidden_size_8_max_steps_200_learning_rate_0.0001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 200,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 288
        },
        "scores": {
            "smape": 0.9124914652149346,
            "mse": 576929619165.9851,
            "mae": 93177.80539083332,
            "r2_score": 0.025499766746620134,
            "sn_smape": 0.1340001106045662,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.031715720891952515,
                "median": 0.022176381200551987,
                "std": 0.19516201317310333,
                "max": 0.3631651699542999,
                "min": -0.333757221698761
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03640398383140564,
                "median": 0.07666194438934326,
                "std": 0.20868955552577972,
                "max": 0.34956562519073486,
                "min": -0.3379532992839813
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.0032455790787935257,
                "median": -0.018727779388427734,
                "std": 0.20028343796730042,
                "max": 0.3574346899986267,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.015037836506962776,
                "median": -0.00325904693454504,
                "std": 0.21933674812316895,
                "max": 0.36007893085479736,
                "min": -0.32624703645706177
            }
        }
    },
    "Tourism_Quarterly_hidden_size_8_max_steps_200_learning_rate_0.0001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 8,
            "max_steps": 200,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 288
        },
        "scores": {
            "smape": 0.895179343007756,
            "mse": 569599665200.3126,
            "mae": 92443.0210461047,
            "r2_score": 0.03788089888473167,
            "sn_smape": 0.1340001106045662,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03595784306526184,
                "median": 0.02728927507996559,
                "std": 0.1955101191997528,
                "max": 0.36813589930534363,
                "min": -0.32821470499038696
            },
            "mlp.1.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.03857900947332382,
                "median": 0.079966701567173,
                "std": 0.20949584245681763,
                "max": 0.353736013174057,
                "min": -0.3406890630722046
            },
            "mlp.2.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.004008742049336433,
                "median": -0.02140587568283081,
                "std": 0.2010250836610794,
                "max": 0.36278268694877625,
                "min": -0.33371198177337646
            },
            "out.weight": {
                "shape": [
                    8,
                    8
                ],
                "input_size": 8,
                "output_size": 8,
                "mean": 0.01777573674917221,
                "median": 0.0008288512472063303,
                "std": 0.2195492535829544,
                "max": 0.3651694655418396,
                "min": -0.32703861594200134
            }
        }
    },
    "Tourism_Quarterly_hidden_size_16_max_steps_50_learning_rate_0.001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 50,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 824
        },
        "scores": {
            "smape": 0.6202401303964667,
            "mse": 427348569429.01984,
            "mae": 77000.3270733085,
            "r2_score": 0.27815929923808747,
            "sn_smape": 0.1340001106045662,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    8
                ],
                "input_size": 8,
                "output_size": 16,
                "mean": 0.036182548850774765,
                "median": 0.04280400276184082,
                "std": 0.20062296092510223,
                "max": 0.3908732831478119,
                "min": -0.3625825345516205
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.022636624053120613,
                "median": 0.009449305012822151,
                "std": 0.14614786207675934,
                "max": 0.291748046875,
                "min": -0.251647412776947
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.010255319997668266,
                "median": 0.008739843964576721,
                "std": 0.15060225129127502,
                "max": 0.28851035237312317,
                "min": -0.2777310013771057
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.02846815250813961,
                "median": 0.027643052861094475,
                "std": 0.14902189373970032,
                "max": 0.2829728126525879,
                "min": -0.2430494725704193
            }
        }
    },
    "Tourism_Quarterly_hidden_size_16_max_steps_50_learning_rate_0.001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 50,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 824
        },
        "scores": {
            "smape": 0.5402313600577082,
            "mse": 375967899637.6962,
            "mae": 70194.71471946895,
            "r2_score": 0.3649471378807665,
            "sn_smape": 0.1340001106045662,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    8
                ],
                "input_size": 8,
                "output_size": 16,
                "mean": 0.041528813540935516,
                "median": 0.04343303292989731,
                "std": 0.2009403109550476,
                "max": 0.39655178785324097,
                "min": -0.3699895739555359
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.025332104414701462,
                "median": 0.012059040367603302,
                "std": 0.1473599672317505,
                "max": 0.2946760058403015,
                "min": -0.2544536292552948
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.011873734183609486,
                "median": 0.009949585422873497,
                "std": 0.1514502912759781,
                "max": 0.29489725828170776,
                "min": -0.28248292207717896
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.032673001289367676,
                "median": 0.023474832996726036,
                "std": 0.14964477717876434,
                "max": 0.2954249680042267,
                "min": -0.2430494725704193
            }
        }
    },
    "Tourism_Quarterly_hidden_size_16_max_steps_50_learning_rate_0.0005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 50,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 824
        },
        "scores": {
            "smape": 0.8359345190937381,
            "mse": 543206048718.5106,
            "mae": 90070.94433119672,
            "r2_score": 0.08246274138936549,
            "sn_smape": 0.1340001106045662,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    8
                ],
                "input_size": 8,
                "output_size": 16,
                "mean": 0.0216359980404377,
                "median": 0.035409603267908096,
                "std": 0.1991337239742279,
                "max": 0.36802685260772705,
                "min": -0.34409379959106445
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.011376241222023964,
                "median": -0.001855369540862739,
                "std": 0.14342588186264038,
                "max": 0.2698380947113037,
                "min": -0.24560986459255219
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0019700005650520325,
                "median": -0.0025512794964015484,
                "std": 0.1476992964744568,
                "max": 0.2677413821220398,
                "min": -0.26314687728881836
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.014420391991734505,
                "median": 0.012890901416540146,
                "std": 0.14698505401611328,
                "max": 0.26130878925323486,
                "min": -0.2430494725704193
            }
        }
    },
    "Tourism_Quarterly_hidden_size_16_max_steps_50_learning_rate_0.0005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 50,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 824
        },
        "scores": {
            "smape": 0.8076111461941029,
            "mse": 529000309767.29517,
            "mae": 88618.90774441087,
            "r2_score": 0.10645786221798292,
            "sn_smape": 0.1340001106045662,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    8
                ],
                "input_size": 8,
                "output_size": 16,
                "mean": 0.023753490298986435,
                "median": 0.03826507180929184,
                "std": 0.19945184886455536,
                "max": 0.37176787853240967,
                "min": -0.3480990529060364
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.012779688462615013,
                "median": -0.001025114906951785,
                "std": 0.14398923516273499,
                "max": 0.2705966830253601,
                "min": -0.2454880028963089
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.002867253962904215,
                "median": -0.002266248455271125,
                "std": 0.14795859158039093,
                "max": 0.2710745930671692,
                "min": -0.2666751444339752
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.01639258861541748,
                "median": 0.014170276001095772,
                "std": 0.14721864461898804,
                "max": 0.2683688998222351,
                "min": -0.2430494725704193
            }
        }
    },
    "Tourism_Quarterly_hidden_size_16_max_steps_50_learning_rate_0.0001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 50,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 824
        },
        "scores": {
            "smape": 0.929229952509511,
            "mse": 583380653144.8127,
            "mae": 93901.83286405419,
            "r2_score": 0.014603231175815523,
            "sn_smape": 0.1340001106045662,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    8
                ],
                "input_size": 8,
                "output_size": 16,
                "mean": 0.013057841919362545,
                "median": 0.020561061799526215,
                "std": 0.19846570491790771,
                "max": 0.3552011251449585,
                "min": -0.3420874774456024
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0035363072529435158,
                "median": -0.006500672549009323,
                "std": 0.1419433057308197,
                "max": 0.251073956489563,
                "min": -0.2421407550573349
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.0022402345202863216,
                "median": -0.0033095679245889187,
                "std": 0.14689506590366364,
                "max": 0.25161048769950867,
                "min": -0.2493070513010025
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.0031999507918953896,
                "median": -0.0042140912264585495,
                "std": 0.14602461457252502,
                "max": 0.25097349286079407,
                "min": -0.2430494725704193
            }
        }
    },
    "Tourism_Quarterly_hidden_size_16_max_steps_50_learning_rate_0.0001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 50,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 824
        },
        "scores": {
            "smape": 0.9259749171468334,
            "mse": 582025999952.0522,
            "mae": 93779.66879873484,
            "r2_score": 0.01689139563897979,
            "sn_smape": 0.1340001106045662,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    8
                ],
                "input_size": 8,
                "output_size": 16,
                "mean": 0.013415593653917313,
                "median": 0.021332943812012672,
                "std": 0.19853344559669495,
                "max": 0.3558899164199829,
                "min": -0.34140872955322266
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.003837901633232832,
                "median": -0.004965273663401604,
                "std": 0.14201746881008148,
                "max": 0.25176969170570374,
                "min": -0.2418818324804306
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.0021356185898184776,
                "median": -0.003944238647818565,
                "std": 0.146894171833992,
                "max": 0.2522062063217163,
                "min": -0.2500365674495697
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.0036232825368642807,
                "median": -0.003957097418606281,
                "std": 0.14605171978473663,
                "max": 0.2524755299091339,
                "min": -0.2430494725704193
            }
        }
    },
    "Tourism_Quarterly_hidden_size_16_max_steps_100_learning_rate_0.001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 100,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 824
        },
        "scores": {
            "smape": 0.26744406500055656,
            "mse": 134326196195.977,
            "mae": 33534.342742145665,
            "r2_score": 0.7731076630902562,
            "sn_smape": 0.1340001106045662,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    8
                ],
                "input_size": 8,
                "output_size": 16,
                "mean": 0.0641406700015068,
                "median": 0.06573692709207535,
                "std": 0.20144343376159668,
                "max": 0.4302268326282501,
                "min": -0.37452802062034607
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.04106677696108818,
                "median": 0.020641189068555832,
                "std": 0.15119297802448273,
                "max": 0.32756897807121277,
                "min": -0.25950074195861816
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.02310688979923725,
                "median": 0.014859285205602646,
                "std": 0.15655802190303802,
                "max": 0.32620254158973694,
                "min": -0.2793038487434387
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.04883789271116257,
                "median": 0.05208861827850342,
                "std": 0.15259838104248047,
                "max": 0.34014782309532166,
                "min": -0.2430494725704193
            }
        }
    },
    "Tourism_Quarterly_hidden_size_16_max_steps_100_learning_rate_0.001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 100,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 824
        },
        "scores": {
            "smape": 0.2461868143425467,
            "mse": 86575557852.49385,
            "mae": 25260.375852813442,
            "r2_score": 0.8537639626766611,
            "sn_smape": 0.1340001106045662,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    8
                ],
                "input_size": 8,
                "output_size": 16,
                "mean": 0.06247717887163162,
                "median": 0.061565741896629333,
                "std": 0.20126144587993622,
                "max": 0.4302290081977844,
                "min": -0.38916876912117004
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.038355231285095215,
                "median": 0.025236081331968307,
                "std": 0.15170079469680786,
                "max": 0.3192600607872009,
                "min": -0.2884398102760315
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.02129715122282505,
                "median": 0.014508076012134552,
                "std": 0.15645097196102142,
                "max": 0.32945457100868225,
                "min": -0.2820948660373688
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.05325491726398468,
                "median": 0.05429597944021225,
                "std": 0.1525340974330902,
                "max": 0.35642871260643005,
                "min": -0.2430494725704193
            }
        }
    },
    "Tourism_Quarterly_hidden_size_16_max_steps_100_learning_rate_0.0005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 100,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 824
        },
        "scores": {
            "smape": 0.6050240725650196,
            "mse": 416073549182.8103,
            "mae": 75790.25801879147,
            "r2_score": 0.2972041003626188,
            "sn_smape": 0.1340001106045662,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    8
                ],
                "input_size": 8,
                "output_size": 16,
                "mean": 0.037004295736551285,
                "median": 0.043544963002204895,
                "std": 0.20021261274814606,
                "max": 0.3892528712749481,
                "min": -0.36138102412223816
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.023082274943590164,
                "median": 0.006852383725345135,
                "std": 0.14618264138698578,
                "max": 0.2932470142841339,
                "min": -0.2524402439594269
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.011483174748718739,
                "median": 0.008739843964576721,
                "std": 0.1507347822189331,
                "max": 0.29048818349838257,
                "min": -0.27697521448135376
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.028703324496746063,
                "median": 0.02641807310283184,
                "std": 0.1495024859905243,
                "max": 0.2912023067474365,
                "min": -0.2430494725704193
            }
        }
    },
    "Tourism_Quarterly_hidden_size_16_max_steps_100_learning_rate_0.0005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 100,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 824
        },
        "scores": {
            "smape": 0.46322941832527414,
            "mse": 319485316589.9415,
            "mae": 62262.42939172165,
            "r2_score": 0.46035269260745915,
            "sn_smape": 0.1340001106045662,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    8
                ],
                "input_size": 8,
                "output_size": 16,
                "mean": 0.04566090926527977,
                "median": 0.046342942863702774,
                "std": 0.2011258453130722,
                "max": 0.40217873454093933,
                "min": -0.3708396255970001
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.028804752975702286,
                "median": 0.015092958696186543,
                "std": 0.1480528563261032,
                "max": 0.3032020032405853,
                "min": -0.2584887742996216
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.01565890572965145,
                "median": 0.009814023971557617,
                "std": 0.15252065658569336,
                "max": 0.30249953269958496,
                "min": -0.27774253487586975
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.03511509299278259,
                "median": 0.028365008533000946,
                "std": 0.15084271132946014,
                "max": 0.3040333390235901,
                "min": -0.2430494725704193
            }
        }
    },
    "Tourism_Quarterly_hidden_size_16_max_steps_100_learning_rate_0.0001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 100,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 824
        },
        "scores": {
            "smape": 0.9126926458046852,
            "mse": 576746425246.5582,
            "mae": 93290.37920903294,
            "r2_score": 0.025809202267490394,
            "sn_smape": 0.1340001106045662,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    8
                ],
                "input_size": 8,
                "output_size": 16,
                "mean": 0.015057236887514591,
                "median": 0.023933039978146553,
                "std": 0.19853104650974274,
                "max": 0.3574400246143341,
                "min": -0.33857110142707825
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.005189014598727226,
                "median": -0.004446716979146004,
                "std": 0.14224624633789062,
                "max": 0.25501760840415955,
                "min": -0.24058061838150024
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.0014886329881846905,
                "median": -0.003438409883528948,
                "std": 0.1469372659921646,
                "max": 0.25523895025253296,
                "min": -0.25244978070259094
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.005815161857753992,
                "median": 5.561340367421508e-05,
                "std": 0.14625351130962372,
                "max": 0.2541627883911133,
                "min": -0.2430494725704193
            }
        }
    },
    "Tourism_Quarterly_hidden_size_16_max_steps_100_learning_rate_0.0001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 100,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 824
        },
        "scores": {
            "smape": 0.9038388125557502,
            "mse": 572806918833.0824,
            "mae": 92935.43801042999,
            "r2_score": 0.03246348000137622,
            "sn_smape": 0.1340001106045662,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    8
                ],
                "input_size": 8,
                "output_size": 16,
                "mean": 0.015814159065485,
                "median": 0.025801705196499825,
                "std": 0.19865475594997406,
                "max": 0.3588915765285492,
                "min": -0.33710840344429016
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0059130010195076466,
                "median": -0.0030043749138712883,
                "std": 0.1423736959695816,
                "max": 0.25564485788345337,
                "min": -0.24083152413368225
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": -0.0011552730575203896,
                "median": -0.004186287056654692,
                "std": 0.146961510181427,
                "max": 0.2568914592266083,
                "min": -0.25390201807022095
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.006799626164138317,
                "median": 0.0015789635945111513,
                "std": 0.14631476998329163,
                "max": 0.25579261779785156,
                "min": -0.2430494725704193
            }
        }
    },
    "Tourism_Quarterly_hidden_size_16_max_steps_200_learning_rate_0.001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 200,
            "learning_rate": 0.001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 824
        },
        "scores": {
            "smape": 0.17415714330649756,
            "mse": 28689999289.098186,
            "mae": 20653.14866989433,
            "r2_score": 0.9515393038067929,
            "sn_smape": 0.1340001106045662,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    8
                ],
                "input_size": 8,
                "output_size": 16,
                "mean": 0.07481066882610321,
                "median": 0.07095789909362793,
                "std": 0.19885875284671783,
                "max": 0.4380650818347931,
                "min": -0.3649956285953522
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.04391505941748619,
                "median": 0.03097308799624443,
                "std": 0.15657198429107666,
                "max": 0.3576850891113281,
                "min": -0.299260675907135
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.022894367575645447,
                "median": 0.013085126876831055,
                "std": 0.15851961076259613,
                "max": 0.3505198657512665,
                "min": -0.3066910207271576
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.05385218560695648,
                "median": 0.047057561576366425,
                "std": 0.15250685811042786,
                "max": 0.3361532986164093,
                "min": -0.2430494725704193
            }
        }
    },
    "Tourism_Quarterly_hidden_size_16_max_steps_200_learning_rate_0.001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 200,
            "learning_rate": 0.001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 824
        },
        "scores": {
            "smape": 0.13676595102940176,
            "mse": 7267578957.441606,
            "mae": 15409.24206501792,
            "r2_score": 0.9877242263979229,
            "sn_smape": 0.1340001106045662,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    8
                ],
                "input_size": 8,
                "output_size": 16,
                "mean": 0.07114608585834503,
                "median": 0.062037065625190735,
                "std": 0.20012834668159485,
                "max": 0.4352070391178131,
                "min": -0.3915923535823822
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.043216854333877563,
                "median": 0.03533844277262688,
                "std": 0.1611594557762146,
                "max": 0.37419191002845764,
                "min": -0.33262407779693604
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.025235669687390327,
                "median": 0.009026291780173779,
                "std": 0.16143852472305298,
                "max": 0.38528406620025635,
                "min": -0.3511851131916046
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.05536797642707825,
                "median": 0.06503669917583466,
                "std": 0.15267649292945862,
                "max": 0.34007397294044495,
                "min": -0.2430494725704193
            }
        }
    },
    "Tourism_Quarterly_hidden_size_16_max_steps_200_learning_rate_0.0005_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 200,
            "learning_rate": 0.0005,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 824
        },
        "scores": {
            "smape": 0.264566994238883,
            "mse": 120657710383.76651,
            "mae": 31941.352015840905,
            "r2_score": 0.7961953018068731,
            "sn_smape": 0.1340001106045662,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    8
                ],
                "input_size": 8,
                "output_size": 16,
                "mean": 0.0649586170911789,
                "median": 0.06861536204814911,
                "std": 0.1987846940755844,
                "max": 0.4466802477836609,
                "min": -0.3731551468372345
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.04810028895735741,
                "median": 0.026403609663248062,
                "std": 0.1503249853849411,
                "max": 0.3485676646232605,
                "min": -0.26609840989112854
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.022889913991093636,
                "median": 0.010905017144978046,
                "std": 0.1571103036403656,
                "max": 0.34023788571357727,
                "min": -0.27666378021240234
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.04799444228410721,
                "median": 0.05065545067191124,
                "std": 0.15323543548583984,
                "max": 0.360455721616745,
                "min": -0.2430494725704193
            }
        }
    },
    "Tourism_Quarterly_hidden_size_16_max_steps_200_learning_rate_0.0005_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 200,
            "learning_rate": 0.0005,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 824
        },
        "scores": {
            "smape": 0.2312802603857424,
            "mse": 72489036599.9429,
            "mae": 24240.59757964992,
            "r2_score": 0.8775577111518805,
            "sn_smape": 0.1340001106045662,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    8
                ],
                "input_size": 8,
                "output_size": 16,
                "mean": 0.06880021095275879,
                "median": 0.06563770025968552,
                "std": 0.1986781358718872,
                "max": 0.43796026706695557,
                "min": -0.3848893344402313
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.0415237694978714,
                "median": 0.028259441256523132,
                "std": 0.1518174260854721,
                "max": 0.3325616419315338,
                "min": -0.28061091899871826
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.022732635959982872,
                "median": 0.01137424074113369,
                "std": 0.15681831538677216,
                "max": 0.33316880464553833,
                "min": -0.27444103360176086
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.051034171134233475,
                "median": 0.0510442852973938,
                "std": 0.15252600610256195,
                "max": 0.3540146052837372,
                "min": -0.2430494725704193
            }
        }
    },
    "Tourism_Quarterly_hidden_size_16_max_steps_200_learning_rate_0.0001_batch_size_32_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 200,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "scaler_type": "identity",
            "total_params": 824
        },
        "scores": {
            "smape": 0.8758658155298592,
            "mse": 561173795439.791,
            "mae": 91835.86732155636,
            "r2_score": 0.052113158373958024,
            "sn_smape": 0.1340001106045662,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    8
                ],
                "input_size": 8,
                "output_size": 16,
                "mean": 0.01899368315935135,
                "median": 0.032594021409749985,
                "std": 0.19868509471416473,
                "max": 0.3627915680408478,
                "min": -0.33797818422317505
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.008794194087386131,
                "median": -0.002400611061602831,
                "std": 0.14287404716014862,
                "max": 0.26367396116256714,
                "min": -0.24344098567962646
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.001101488247513771,
                "median": -0.0033726186957210302,
                "std": 0.14719901978969574,
                "max": 0.2625220715999603,
                "min": -0.25755733251571655
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.010862874798476696,
                "median": 0.010401403531432152,
                "std": 0.14686569571495056,
                "max": 0.25983044505119324,
                "min": -0.2430494725704193
            }
        }
    },
    "Tourism_Quarterly_hidden_size_16_max_steps_200_learning_rate_0.0001_batch_size_64_scaler_type_identity": {
        "dataset": {
            "name": "Tourism",
            "group": "Quarterly"
        },
        "model": {
            "name": "MLP",
            "input_size": 8,
            "horizon": 8,
            "num_layers": 3,
            "hidden_size": 16,
            "max_steps": 200,
            "learning_rate": 0.0001,
            "batch_size": 64,
            "scaler_type": "identity",
            "total_params": 824
        },
        "scores": {
            "smape": 0.8359144468370466,
            "mse": 543268100181.6278,
            "mae": 90065.1079846767,
            "r2_score": 0.08235792935810105,
            "sn_smape": 0.1340001106045662,
            "is_better": false
        },
        "weights": {
            "mlp.0.weight": {
                "shape": [
                    16,
                    8
                ],
                "input_size": 8,
                "output_size": 16,
                "mean": 0.022234752774238586,
                "median": 0.03615730255842209,
                "std": 0.19910843670368195,
                "max": 0.3670893907546997,
                "min": -0.3437352776527405
            },
            "mlp.1.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.01128263957798481,
                "median": 0.000808690907433629,
                "std": 0.14336144924163818,
                "max": 0.2690114676952362,
                "min": -0.24146397411823273
            },
            "mlp.2.weight": {
                "shape": [
                    16,
                    16
                ],
                "input_size": 16,
                "output_size": 16,
                "mean": 0.002562165493145585,
                "median": -0.002039788058027625,
                "std": 0.14763011038303375,
                "max": 0.2679290771484375,
                "min": -0.2617930471897125
            },
            "out.weight": {
                "shape": [
                    8,
                    16
                ],
                "input_size": 16,
                "output_size": 8,
                "mean": 0.013395539484918118,
                "median": 0.014579830691218376,
                "std": 0.14703868329524994,
                "max": 0.26176878809928894,
                "min": -0.2430494725704193
            }
        }
    }
}